{"https://arxiv.org/abs/2405.05275": {"title": "SoMeR: Multi-View User Representation Learning for Social Media", "link": "https://arxiv.org/abs/2405.05275", "description": "arXiv:2405.05275v1 Announce Type: new \nAbstract: User representation learning aims to capture user preferences, interests, and behaviors in low-dimensional vector representations. These representations have widespread applications in recommendation systems and advertising; however, existing methods typically rely on specific features like text content, activity patterns, or platform metadata, failing to holistically model user behavior across different modalities. To address this limitation, we propose SoMeR, a Social Media user Representation learning framework that incorporates temporal activities, text content, profile information, and network interactions to learn comprehensive user portraits. SoMeR encodes user post streams as sequences of timestamped textual features, uses transformers to embed this along with profile data, and jointly trains with link prediction and contrastive learning objectives to capture user similarity. We demonstrate SoMeR's versatility through two applications: 1) Identifying inauthentic accounts involved in coordinated influence operations by detecting users posting similar content simultaneously, and 2) Measuring increased polarization in online discussions after major events by quantifying how users with different beliefs moved farther apart in the embedding space. SoMeR's ability to holistically model users enables new solutions to important problems around disinformation, societal tensions, and online behavior understanding."}, "https://arxiv.org/abs/2405.05288": {"title": "Learning Social Graph for Inactive User Recommendation", "link": "https://arxiv.org/abs/2405.05288", "description": "arXiv:2405.05288v1 Announce Type: new \nAbstract: Social relations have been widely incorporated into recommender systems to alleviate data sparsity problem. However, raw social relations don't always benefit recommendation due to their inferior quality and insufficient quantity, especially for inactive users, whose interacted items are limited. In this paper, we propose a novel social recommendation method called LSIR (\\textbf{L}earning \\textbf{S}ocial Graph for \\textbf{I}nactive User \\textbf{R}ecommendation) that learns an optimal social graph structure for social recommendation, especially for inactive users. LSIR recursively aggregates user and item embeddings to collaboratively encode item and user features. Then, graph structure learning (GSL) is employed to refine the raw user-user social graph, by removing noisy edges and adding new edges based on the enhanced embeddings. Meanwhile, mimic learning is implemented to guide active users in mimicking inactive users during model training, which improves the construction of new edges for inactive users. Extensive experiments on real-world datasets demonstrate that LSIR achieves significant improvements of up to 129.58\\% on NDCG in inactive user recommendation. Our code is available at~\\url{https://github.com/liun-online/LSIR}."}, "https://arxiv.org/abs/2405.05393": {"title": "Mutual information and the encoding of contingency tables", "link": "https://arxiv.org/abs/2405.05393", "description": "arXiv:2405.05393v1 Announce Type: new \nAbstract: Mutual information is commonly used as a measure of similarity between competing labelings of a given set of objects, for example to quantify performance in classification and community detection tasks. As argued recently, however, the mutual information as conventionally defined can return biased results because it neglects the information cost of the so-called contingency table, a crucial component of the similarity calculation. In principle the bias can be rectified by subtracting the appropriate information cost, leading to the modified measure known as the reduced mutual information, but in practice one can only ever compute an upper bound on this information cost, and the value of the reduced mutual information depends crucially on how good a bound is established. In this paper we describe an improved method for encoding contingency tables that gives a substantially better bound in typical use cases, and approaches the ideal value in the common case where the labelings are closely similar, as we demonstrate with extensive numerical results."}, "https://arxiv.org/abs/2405.05400": {"title": "Comparative analysis of graph randomization: Tools,methods, pitfalls, and best practices", "link": "https://arxiv.org/abs/2405.05400", "description": "arXiv:2405.05400v1 Announce Type: new \nAbstract: Graph randomization techniques play a crucial role in network analysis, allowing researchers to assess the statistical significance of observed network properties and distinguish meaningful patterns from random fluctuations. In this survey we provide an overview of the graph randomization methods available in the most popular software tools for network analysis. We propose a comparative analysis of popular software tools to highlight their functionalities and limitations. Through case studies involving diverse graph types, we demonstrate how different randomization methods can lead to divergent conclusions, emphasizing the importance of careful method selection based on the characteristics of the observed network and the research question at hand. This survey proposes some guidelines for researchers and practitioners seeking to understand and utilize graph randomization techniques effectively in their network analysis projects."}, "https://arxiv.org/abs/2405.05576": {"title": "LayerPlexRank: Exploring Node Centrality and Layer Influence through Algebraic Connectivity in Multiplex Networks", "link": "https://arxiv.org/abs/2405.05576", "description": "arXiv:2405.05576v1 Announce Type: new \nAbstract: As the calculation of centrality in complex networks becomes increasingly vital across technological, biological, and social systems, precise and scalable ranking methods are essential for understanding these networks. This paper introduces LayerPlexRank, an algorithm that simultaneously assesses node centrality and layer influence in multiplex networks using algebraic connectivity metrics. This method enhances the robustness of the ranking algorithm by effectively assessing structural changes across layers using random walk, considering the overall connectivity of the graph. We substantiate the utility of LayerPlexRank with theoretical analyses and empirical validations on varied real-world datasets, contrasting it with established centrality measures."}, "https://arxiv.org/abs/2405.05724": {"title": "Private Online Community Detection for Censored Block Models", "link": "https://arxiv.org/abs/2405.05724", "description": "arXiv:2405.05724v1 Announce Type: new \nAbstract: We study the private online change detection problem for dynamic communities, using a censored block model (CBM). Focusing on the notion of edge differential privacy (DP), we seek to understand the fundamental tradeoffs between the privacy budget, detection delay, and exact community recovery of community labels. We establish the theoretical lower bound on the delay in detecting changes privately and propose an algorithm capable of identifying changes in the community structure, while maintaining user privacy. Further, we provide theoretical guarantees for the effectiveness of our proposed method by showing necessary and sufficient conditions on change detection and exact recovery under edge DP. Simulation and real data examples are provided to validate the proposed method."}, "https://arxiv.org/abs/2405.05903": {"title": "The Other Side of the Coin: Recipient Norms and Their Impact on Indirect Reciprocity and Cooperation", "link": "https://arxiv.org/abs/2405.05903", "description": "arXiv:2405.05903v1 Announce Type: new \nAbstract: Human cooperation depends on indirect reciprocity. In this work, we explore the concept of indirect reciprocity using a donation game in an infinitely large population. In particular, we examine how updating the reputations of recipients influences cooperation. Our work adds a time-scale parameter for updating donor and recipient reputations. We find a trade-off between the level of cooperation and evolutionary stability influenced by social norms. `Forgiving' recipient norms enhance cooperation but increase susceptibility to defectors, whereas `unforgiving' norms reduce cooperation but defend against invasion by defectors. Expanding to include gossip groups allows us to analyze the evolutionary dynamics of the time-scale parameter, identifying `generous' norms that support cooperation, and `strict' norms that discourage such generosity, ultimately showing vulnerability to defector invasions and potential cooperation collapse."}, "https://arxiv.org/abs/2405.05433": {"title": "Robust Reward Placement under Uncertainty", "link": "https://arxiv.org/abs/2405.05433", "description": "arXiv:2405.05433v1 Announce Type: cross \nAbstract: Reward placement is a common optimization problem in network diffusion processes, where a number of rewards are to be placed in a network so as to maximize the total reward obtained as agents move randomly in it. In many settings, the precise mobility network might be one of several possible, based on parameters outside our control, such as the weather conditions affecting peoples' transportation means. Solutions to the reward placement problem must thus be robust to this uncertainty, by achieving a high utility in all possible networks. To study such scenarios, we introduce the Robust Reward Placement problem (RRP). Agents move randomly on a Markovian Mobility Model that has a predetermined set of locations but its precise connectivity is unknown and chosen adversarialy from a known set $\\Pi$ of candidates. Network optimization is achieved by selecting a set of reward states, and the goal is to maximize the minimum, among all candidates, ratio of rewards obtained over the optimal solution for each candidate. We first prove that RRP is NP-hard and inapproximable in general. We then develop $\\Psi$-Saturate, a pseudo-polynomial time algorithm that achieves an $\\epsilon$-additive approximation by exceeding the budget constraint by a factor that scales as $O(ln|\\Pi|/\\epsilon)$. In addition, we present several heuristics, most prominently one inspired from a dynamic programming algorithm for the max-min 0-1 Knapsack problem. We corroborate our theoretical findings with an experimental evaluation of the methods in both synthetic and real-world datasets."}, "https://arxiv.org/abs/2405.05487": {"title": "Design of Targeted Community-Based Resource Allocation in the Presence of Vaccine Hesitancy via a Data-Driven Compartmental Stochastic Optimization Model", "link": "https://arxiv.org/abs/2405.05487", "description": "arXiv:2405.05487v1 Announce Type: cross \nAbstract: Vaccines have proven effective in mitigating the threat of severe infections and deaths during outbreaks of infectious diseases. However, vaccine hesitancy (VH) complicates disease spread prediction and healthcare resource assessment across regions and populations. We propose a modeling framework that integrates an epidemiological compartmental model that captures the spread of an infectious disease within a multi-stage stochastic program (MSP) that determines the allocation of critical resources under uncertainty. The proposed compartmental MSP model adaptively manages the allocation of resources to account for changes in population behavior toward vaccines (i.e., variability in VH), the unique patterns of disease spread, and the availability of healthcare resources over time and space. The compartmental MSP model allowed us to analyze the price of fairness in resource allocation. Using real COVID-19 vaccination and healthcare resource data from Arkansas, U.S. (January-May 2021), our findings include: (i) delaying the initial deployment of additional ventilators by one month could lead to an average increase in the expected number of deaths by 285.41/month, highlighting the importance of prompt action; (ii) each additional ventilator in the initial stockpile and in supply leads to a decrease in the expected number of deaths by 1.09/month and 0.962/month, respectively, emphasizing the importance of maintaining a large stockpile and scalable production response; (iii) the cost of ensuring equitable resource allocation varies over time and location, peaking during the peak of a disease outbreak and in densely populated areas. This study emphasizes the importance of flexible, informed public health decision-making and preparedness, providing a model for effective resource allocation in public health emergencies."}, "https://arxiv.org/abs/2211.06352": {"title": "Spectral Triadic Decompositions of Real-World Networks", "link": "https://arxiv.org/abs/2211.06352", "description": "arXiv:2211.06352v3 Announce Type: replace \nAbstract: A fundamental problem in mathematics and network analysis is to find conditions under which a graph can be partitioned into smaller pieces. The most important tool for this partitioning is the Fiedler vector or discrete Cheeger inequality. These results relate the graph spectrum (eigenvalues of the normalized adjacency matrix) to the ability to break a graph into two pieces, with few edge deletions. An entire subfield of mathematics, called spectral graph theory, has emerged from these results. Yet these results do not say anything about the rich community structure exhibited by real-world networks, which typically have a significant fraction of edges contained in numerous densely clustered blocks. Inspired by the properties of real-world networks, we discover a new spectral condition that relates eigenvalue powers to a network decomposition into densely clustered blocks. We call this the \\emph{spectral triadic decomposition}. Our relationship exactly predicts the existence of community structure, as commonly seen in real networked data. Our proof provides an efficient algorithm to produce the spectral triadic decomposition. We observe on numerous social, coauthorship, and citation network datasets that these decompositions have significant correlation with semantically meaningful communities."}, "https://arxiv.org/abs/2301.06774": {"title": "Temporal Dynamics of Coordinated Online Behavior: Stability, Archetypes, and Influence", "link": "https://arxiv.org/abs/2301.06774", "description": "arXiv:2301.06774v2 Announce Type: replace \nAbstract: Large-scale online campaigns, malicious or otherwise, require a significant degree of coordination among participants, which sparked interest in the study of coordinated online behavior. State-of-the-art methods for detecting coordinated behavior perform static analyses, disregarding the temporal dynamics of coordination. Here, we carry out the first dynamic analysis of coordinated behavior. To reach our goal we build a multiplex temporal network and we perform dynamic community detection to identify groups of users that exhibited coordinated behaviors in time. Thanks to our novel approach we find that: (i) coordinated communities feature variable degrees of temporal instability; (ii) dynamic analyses are needed to account for such instability, and results of static analyses can be unreliable and scarcely representative of unstable communities; (iii) some users exhibit distinct archetypal behaviors that have important practical implications; (iv) content and network characteristics contribute to explaining why users leave and join coordinated communities. Our results demonstrate the advantages of dynamic analyses and open up new directions of research on the unfolding of online debates, on the strategies of coordinated communities, and on the patterns of online influence."}, "https://arxiv.org/abs/2303.03774": {"title": "Network science meets history", "link": "https://arxiv.org/abs/2303.03774", "description": "arXiv:2303.03774v3 Announce Type: replace \nAbstract: Alliances and conflicts represent important features of complex systems like international relations. Such relations create a time-evolving signed network, where each node contributes in a unique manner to the global balance of the system. Therefore, a local index mathematically quantifying such a property becomes valuable. In this work, we introduce a local balance index for signed networks. We analyze its mathematical foundations and unique structural properties, differentiating it from existing local vertex invariants. We also establish a novel methodology linking changes in a nation's local balance to historical events. By scrutinizing the time series of local balance for countries between 1816 and 2014, we detect and categorize major historic events based on balance fluctuations. This approach harmonizes quantitative and qualitative analyses, and combined with the theory of \"balance of power\" is able to build up a new mixed approach to history based on network theory."}, "https://arxiv.org/abs/2312.07077": {"title": "On the Potential of an Independent Avatar to Augment Metaverse Social Networks", "link": "https://arxiv.org/abs/2312.07077", "description": "arXiv:2312.07077v2 Announce Type: replace \nAbstract: We present a computational modelling approach which targets capturing the specifics on how to virtually augment a Metaverse user's available social time capacity via using an independent and autonomous version of her digital representation in the Metaverse. We motivate why this is a fundamental building block to model large-scale social networks in the Metaverse, and emerging properties herein. We envision a Metaverse-focused extension of the traditional avatar concept: An avatar can be as well programmed to operate independently when its user is not controlling it directly, thus turning it into an agent-based digital human representation. This way, we highlight how such an independent avatar could help its user to better navigate their social relationships and optimize their socializing time in the Metaverse by (partly) offloading some interactions to the avatar. We model the setting and identify the characteristic variables by using selected concepts from social sciences: ego networks, social presence, and social cues. Then, we formulate the problem of maximizing the user's non-avatar-mediated spare time as a linear optimization. Finally, we analyze the feasible region of the problem and we present some initial insights on the spare time that can be achieved for different parameter values of the avatar-mediated interactions."}, "https://arxiv.org/abs/2402.05739": {"title": "Critical mobility in policy making for epidemic containment", "link": "https://arxiv.org/abs/2402.05739", "description": "arXiv:2402.05739v2 Announce Type: replace \nAbstract: When considering airborne epidemic spreading in social systems, a natural connection arises between mobility and epidemic contacts. As individuals travel, possibilities to encounter new people either at the final destination or during the transportation process appear. Such contacts can lead to new contagion events. In fact, mobility has been a crucial target for early non-pharmaceutical containment measures against the recent COVID-19 pandemic, with a degree of intensity ranging from public transportation line closures to regional, city or even home confinements. Nonetheless, quantitative knowledge on the relationship between mobility-contagions and, consequently, on the efficiency of containment measures remains elusive. Here we introduce an agent-based model with a simple interaction between mobility and contacts. Despite its simplicity our model shows the emergence of a critical mobility level, inducing major outbreaks when surpassed. We explore the interplay between mobility restrictions and the infection in recent intervention policies seen across many countries, and how interventions in the form of closures triggered by incidence rates can guide the epidemic into an oscillatory regime with recurrent waves. We consider how the different interventions impact societal well-being, the economy and the population. Finally, we propose a mitigation framework based on the critical nature of mobility in an epidemic, able to suppress incidence and oscillations at will, preventing extreme incidence peaks with potential to saturate health care resources."}, "https://arxiv.org/abs/2404.12178": {"title": "Designing a sector-coupled European energy system robust to 60 years of historical weather data", "link": "https://arxiv.org/abs/2404.12178", "description": "arXiv:2404.12178v2 Announce Type: replace \nAbstract: As energy systems transform to rely on renewable energy and electrification, they encounter stronger year-to-year variability in energy supply and demand. However, most infrastructure planning is based on a single weather year, resulting in a lack of robustness. In this paper, we optimize energy infrastructure for a European energy system designed for net-zero CO$_2$ emissions in 62 different weather years. Subsequently, we fix the capacity layouts and simulate their operation in every weather year, to evaluate resource adequacy and CO$_2$ emissions abatement. We show that interannual weather variability causes variation of $\\pm$10\\% in total system cost. The most expensive capacity layout obtains the lowest net CO$_2$ emissions but not the highest resource adequacy. Instead, capacity layouts designed with years including compound weather events result in a more robust and cost-effective design. Deploying CO$_2$-emitting backup generation is a cost-effective robustness measure, which only increase CO$_2$ emissions marginally as the average CO$_2$ emissions remain less than 1\\% of 1990 levels. Our findings highlight how extreme weather years drive investments in robustness measures, making them compatible with all weather conditions within six decades of historical weather data."}, "https://arxiv.org/abs/2011.08069": {"title": "Reconciling Security and Utility in Next-Generation Epidemic Risk Mitigation Systems", "link": "https://arxiv.org/abs/2011.08069", "description": "arXiv:2011.08069v3 Announce Type: replace-cross \nAbstract: Epidemics like the recent COVID-19 require proactive contact tracing and epidemiological analysis to predict and subsequently contain infection transmissions. The proactive measures require large scale data collection, which simultaneously raise concerns regarding users' privacy. Digital contact tracing systems developed in response to COVID-19 either collected extensive data for effective analytics at the cost of users' privacy or collected minimal data for the sake of user privacy but were ineffective in predicting and mitigating the epidemic risks. We present Silmarillion--in preparation for future epidemics--a system that reconciles user's privacy with rich data collection for higher utility. In Silmarillion, user devices record Bluetooth encounters with beacons installed in strategic locations. The beacons further enrich the encounters with geo-location, location type, and environment conditions at the beacon installation site. This enriched information enables detailed scientific analysis of disease parameters as well as more accurate personalized exposure risk notification. At the same time, Silmarillion provides privacy to all participants and non-participants at the same level as that guaranteed in digital and manual contact tracing. We describe the design of Silmarillion and its communication protocols that ensure user privacy and data security. We also evaluate a prototype of Silmarillion built using low-end IoT boards, showing that the power consumption and user latencies are adequately low for a practical deployment. Finally, we briefly report on a small-scale deployment within a university building as a proof-of-concept."}, "https://arxiv.org/abs/2203.07678": {"title": "Incorporating Heterophily into Graph Neural Networks for Graph Classification", "link": "https://arxiv.org/abs/2203.07678", "description": "arXiv:2203.07678v2 Announce Type: replace-cross \nAbstract: Graph Neural Networks (GNNs) often assume strong homophily for graph classification, seldom considering heterophily, which means connected nodes tend to have different class labels and dissimilar features. In real-world scenarios, graphs may have nodes that exhibit both homophily and heterophily. Failing to generalize to this setting makes many GNNs underperform in graph classification. In this paper, we address this limitation by identifying three effective designs and develop a novel GNN architecture called IHGNN (short for Incorporating Heterophily into Graph Neural Networks). These designs include the combination of integration and separation of the ego- and neighbor-embeddings of nodes, adaptive aggregation of node embeddings from different layers, and differentiation between different node embeddings for constructing the graph-level readout function. We empirically validate IHGNN on various graph datasets and demonstrate that it outperforms the state-of-the-art GNNs for graph classification."}, "https://arxiv.org/abs/2308.13604": {"title": "Network science Ising states of matter", "link": "https://arxiv.org/abs/2308.13604", "description": "arXiv:2308.13604v3 Announce Type: replace-cross \nAbstract: Network science provides very powerful tools for extracting information from interacting data. Although recently the unsupervised detection of phases of matter using machine learning has raised significant interest, the full prediction power of network science has not yet been systematically explored in this context. Here we fill this gap by providing an in-depth statistical, combinatorial, geometrical and topological characterization of 2D Ising snapshot networks (IsingNets) extracted from Monte Carlo simulations of the $2$D Ising model at different temperatures, going across the phase transition. Our analysis reveals the complex organization properties of IsingNets in both the ferromagnetic and paramagnetic phases and demonstrates the significant deviations of the IsingNets with respect to randomized null models. In particular percolation properties of the IsingNets reflect the existence of the symmetry between configurations with opposite magnetization below the critical temperature and the very compact nature of the two emerging giant clusters revealed by our persistent homology analysis of the IsingNets. Moreover, the IsingNets display a very broad degree distribution and significant degree-degree correlations and weight-degree correlations demonstrating that they encode relevant information present in the configuration space of the $2$D Ising model. The geometrical organization of the critical IsingNets is reflected in their spectral properties deviating from the one of the null model. This work reveals the important insights that network science can bring to the characterization of phases of matter. The set of tools described hereby can be applied as well to numerical and experimental data."}, "https://arxiv.org/abs/2312.11834": {"title": "Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics", "link": "https://arxiv.org/abs/2312.11834", "description": "arXiv:2312.11834v3 Announce Type: replace-cross \nAbstract: In recent years, simulations of pedestrians using the multi-agent reinforcement learning (MARL) have been studied. This study considered the roads on a grid-world environment, and implemented pedestrians as MARL agents using an echo-state network and the least squares policy iteration method. Under this environment, the ability of these agents to learn to move forward by avoiding other agents was investigated. Specifically, we considered two types of tasks: the choice between a narrow direct route and a broad detour, and the bidirectional pedestrian flow in a corridor. The simulations results indicated that the learning was successful when the density of the agents was not that high."}, "https://arxiv.org/abs/2401.09438": {"title": "Recurrence analysis of meteorological data from climate zones in India", "link": "https://arxiv.org/abs/2401.09438", "description": "arXiv:2401.09438v4 Announce Type: replace-cross \nAbstract: We present a study on the spatio-temporal pattern underlying the climate dynamics in various locations spread over India, including the Himalayan region, coastal region, central and northeastern parts of India. We try to capture the variations in the complexity of their dynamics derived from temperature and relative humidity data from 1948-2022. By estimating the recurrence-based measures from the reconstructed phase space dynamics using a sliding window analysis on the data sets, we study the climate variability in different spatial locations. The study brings out the variations in the complexity of the underlying dynamics as well as their heterogeneity across the locations in India. We find almost all locations indicate shifts to more irregular and stochastic dynamics for temperature data around 1972-79 and shifts back to more regular dynamics beyond 2000. These patterns correlate with reported shifts in the climate and Indian Summer Monsoon related to strong and moderate ENSO events and confirm their associated regional variability."}, "https://arxiv.org/abs/2405.06075": {"title": "The Building Blocks of Consciousness", "link": "https://arxiv.org/abs/2405.06075", "description": "arXiv:2405.06075v1 Announce Type: new \nAbstract: Consciousness is presented not as a unified and uniquely human characteristic, but rather as an emergent property of several building blocks, most of which are demonstrably present in other species. Each block has its own rationale under natural selection and could have arisen independently, and the jumps between blocks -- which culminate in consciousness -- are small enough to be evolutionarily plausible. One underappreciated block involves unconscious engram playback and discrimination, and plays a major role in brain storage optimization. This function is present in birds and nearly all mammals and is recognized by its side-effect: dreams."}, "https://arxiv.org/abs/2405.06282": {"title": "A cellular automata approach for modelling pedestrian-vehicle mixed traffic flow in urban city", "link": "https://arxiv.org/abs/2405.06282", "description": "arXiv:2405.06282v1 Announce Type: new \nAbstract: In urban streets, the intrusion of pedestrians presents significant safety challenges. Modelling mixed pedestrian-vehicle traffic is complex due to the distinct motion characteristics and spatial dimensions of pedestrians and vehicles, making unified modelling difficult, with few studies addressing these issues. This paper employs a multi-grid cellular automata model to bridge the gap between vehicle and pedestrian models. An Improved Kerner-Klenov-Wolf (IKKW) model and a pedestrian motion model that incorporates Time-To-Collision (TTC) are introduced. Both models update the spatial motions of vehicles and pedestrians uniformly. Empirical analysis indicates that the model achieves high simulation accuracy. This model effectively illustrates the impact of pedestrian intrusion within mixed traffic scenario. The fundamental diagram of heterogeneous traffic reveals substantial differences, highlighting the effects of pedestrian intrusion on traffic flow states and identifying six phase regions in mixed traffic. Additionally, this paper examines conflicts between pedestrians and vehicles under varying speed limits and sidewalk widths, demonstrating that lower speeds and broader sidewalks significantly reduce the frequency of pedestrian-vehicle conflicts. Notably, the frequency of peak conflicts at a vehicle speed limit of 60.48 km/h is more than three times higher than at 30.24 km/h. This model offers a potential approach to studying mixed traffic flows and exhibits substantial scalability."}, "https://arxiv.org/abs/2405.06285": {"title": "Pedestrian Crossing Discrepancy Within Static and Dynamic Crowds: An Experimental Study", "link": "https://arxiv.org/abs/2405.06285", "description": "arXiv:2405.06285v1 Announce Type: new \nAbstract: This paper aims to investigate the disparities in pedestrian crossing behaviors within static and dynamic crowds through experimental analysis. First, the crossing trajectories of pedestrians in various crowd environments were qualitatively observed. These trajectories have shown significant discrepancies and the phenomenon of cross-channel formation within static crowds was observed, a phenomenon similar to the evolution of human trails. To quantitatively assess these discrepancies, metrics of behavior patterns and swarm factor were introduced. Different behavioral patterns, including anticipation and reaction behaviors in pedestrian motion, were observed. Finally, through orthogonal velocity analysis, the variation trends of crossing motions within static and dynamic contexts were revealed."}, "https://arxiv.org/abs/2405.06395": {"title": "Fitness-Based Growth of Directed Networks with Hierarchy", "link": "https://arxiv.org/abs/2405.06395", "description": "arXiv:2405.06395v1 Announce Type: new \nAbstract: Growing attention has been brought to the fact that many real directed networks exhibit hierarchy and directionality as measured through techniques like Trophic Analysis and non-normality. We propose a simple growing network model where the probability of connecting to a node is defined by a preferential attachment mechanism based on degree and the difference in fitness between nodes. In particular, we show how mechanisms such as degree-based preferential attachment and node fitness interactions can lead to the emergence of the spectrum of hierarchy and directionality observed in real networks. In this work, we study various features of this model relating to network hierarchy, as measured by Trophic Analysis. This includes (I) how preferential attachment can lead to network hierarchy, (II) how scale-free degree distributions and network hierarchy can coexist, (III) the correlation between node fitness and trophic level, (IV) how the fitness parameters can predict trophic incoherence and how the trophic level difference distribution compares to the fitness difference distribution, (V) the relationship between trophic level and degree imbalance and the unique role of nodes at the ends of the fitness hierarchy and (VI) how fitness interactions and degree-based preferential attachment can interplay to generate networks of varying coherence and degree distribution. We also provide an example of the intuition this work enables in the analysis of a real historical network. This work provides insight into simple mechanisms which can give rise to hierarchy in directed networks and quantifies the usefulness and limitations of using Trophic Analysis as an analysis tool for real networks."}, "https://arxiv.org/abs/2405.06508": {"title": "Simple crowd dynamics to generate complex temporal contact networks", "link": "https://arxiv.org/abs/2405.06508", "description": "arXiv:2405.06508v1 Announce Type: new \nAbstract: Empirical contact networks or interaction networks demonstrate peculiar characteristics stemming from the fundamental social, psychological, physical mechanisms governing human interactions. Although these mechanisms are complex, we test whether we are able to reproduce some dynamical properties of these empirical networks from relatively simple models. In this study, we perform simulations for a range of 2D models of particle dynamics, namely the Random Walk, Active Brownian Particles, and Vicsek models, to generate artificial contact networks. We investigate temporal properties of these contact networks: the distributions of contact durations, inter-contact durations and number of contact per pair of particle. We demonstrate that the distribution of inter-contact durations can be recovered by the dynamics of these simple crowd particle models, and show that it is simply related to the well-know first-return process, which explains the -3/2 exponent that is found in both the numerical models and empirical contact networks."}, "https://arxiv.org/abs/2405.06476": {"title": "Is the panel fair? Evaluating panel compositions through network analysis", "link": "https://arxiv.org/abs/2405.06476", "description": "arXiv:2405.06476v1 Announce Type: cross \nAbstract: In research evaluation, the fair representation of panels is usually defined in terms of observable characteristics of scholars such as gender or affiliations. An an empirical strategy is proposed for exploring hidden connections between panellists such that, despite the respect of formal requirements, the panel could be considered alike as unfair with respect to the representation of diversity of research approaches and methodologies. The case study regards the three panels selected to evaluate research in economics, statistics and business during the Italian research assessment exercises. The first two panels were appointed directly by the governmental agency responsible for the evaluation, while the third was randomly selected. Hence the third panel can be considered as a control for evaluating about the fairness of the others. The fair representation is explored by comparing the networks of panellists based on their co-authorship relations, the networks based on journals in which they published and the networks based on their affiliated institutions (universities, research centres and newspapers). The results show that the members of the first two panels had connections much higher than the members of the control group. Hence the composition of the first two panels should be considered as unfair, as the results of the research assessments."}, "https://arxiv.org/abs/2405.06478": {"title": "Attention is all they need: Cognitive science and the (techno)political economy of attention in humans and machines", "link": "https://arxiv.org/abs/2405.06478", "description": "arXiv:2405.06478v1 Announce Type: cross \nAbstract: This paper critically analyses the \"attention economy\" within the framework of cognitive science and techno-political economics, as applied to both human and machine interactions. We explore how current business models, particularly in digital platform capitalism, harness user engagement by strategically shaping attentional patterns. These platforms utilize advanced AI and massive data analytics to enhance user engagement, creating a cycle of attention capture and data extraction. We review contemporary (neuro)cognitive theories of attention and platform engagement design techniques and criticize classical cognitivist and behaviourist theories for their inadequacies in addressing the potential harms of such engagement on user autonomy and wellbeing. 4E approaches to cognitive science, instead, emphasizing the embodied, extended, enactive, and ecological aspects of cognition, offer us an intrinsic normative standpoint and a more integrated understanding of how attentional patterns are actively constituted by adaptive digital environments. By examining the precarious nature of habit formation in digital contexts, we reveal the techno-economic underpinnings that threaten personal autonomy by disaggregating habits away from the individual, into an AI managed collection of behavioural patterns. Our current predicament suggests the necessity of a paradigm shift towards an ecology of attention. This shift aims to foster environments that respect and preserve human cognitive and social capacities, countering the exploitative tendencies of cognitive capitalism."}, "https://arxiv.org/abs/2405.06541": {"title": "ATSumm: Auxiliary information enhanced approach for abstractive disaster Tweet Summarization with sparse training data", "link": "https://arxiv.org/abs/2405.06541", "description": "arXiv:2405.06541v1 Announce Type: cross \nAbstract: The abundance of situational information on Twitter poses a challenge for users to manually discern vital and relevant information during disasters. A concise and human-interpretable overview of this information helps decision-makers in implementing efficient and quick disaster response. Existing abstractive summarization approaches can be categorized as sentence-based or key-phrase-based approaches. This paper focuses on sentence-based approach, which is typically implemented as a dual-phase procedure in literature. The initial phase, known as the extractive phase, involves identifying the most relevant tweets. The subsequent phase, referred to as the abstractive phase, entails generating a more human-interpretable summary. In this study, we adopt the methodology from prior research for the extractive phase. For the abstractive phase of summarization, most existing approaches employ deep learning-based frameworks, which can either be pre-trained or require training from scratch. However, to achieve the appropriate level of performance, it is imperative to have substantial training data for both methods, which is not readily available. This work presents an Abstractive Tweet Summarizer (ATSumm) that effectively addresses the issue of data sparsity by using auxiliary information. We introduced the Auxiliary Pointer Generator Network (AuxPGN) model, which utilizes a unique attention mechanism called Key-phrase attention. This attention mechanism incorporates auxiliary information in the form of key-phrases and their corresponding importance scores from the input tweets. We evaluate the proposed approach by comparing it with 10 state-of-the-art approaches across 13 disaster datasets. The evaluation results indicate that ATSumm achieves superior performance compared to state-of-the-art approaches, with improvement of 4-80% in ROUGE-N F1-score."}, "https://arxiv.org/abs/2405.06551": {"title": "ADSumm: Annotated Ground-truth Summary Datasets for Disaster Tweet Summarization", "link": "https://arxiv.org/abs/2405.06551", "description": "arXiv:2405.06551v1 Announce Type: cross \nAbstract: Online social media platforms, such as Twitter, provide valuable information during disaster events. Existing tweet disaster summarization approaches provide a summary of these events to aid government agencies, humanitarian organizations, etc., to ensure effective disaster response. In the literature, there are two types of approaches for disaster summarization, namely, supervised and unsupervised approaches. Although supervised approaches are typically more effective, they necessitate a sizable number of disaster event summaries for testing and training. However, there is a lack of good number of disaster summary datasets for training and evaluation. This motivates us to add more datasets to make supervised learning approaches more efficient. In this paper, we present ADSumm, which adds annotated ground-truth summaries for eight disaster events which consist of both natural and man-made disaster events belonging to seven different countries. Our experimental analysis shows that the newly added datasets improve the performance of the supervised summarization approaches by 8-28% in terms of ROUGE-N F1-score. Moreover, in newly annotated dataset, we have added a category label for each input tweet which helps to ensure good coverage from different categories in summary. Additionally, we have added two other features relevance label and key-phrase, which provide information about the quality of a tweet and explanation about the inclusion of the tweet into summary, respectively. For ground-truth summary creation, we provide the annotation procedure adapted in detail, which has not been described in existing literature. Experimental analysis shows the quality of ground-truth summary is very good with Coverage, Relevance and Diversity."}, "https://arxiv.org/abs/2306.16568": {"title": "Early warning signals for predicting cryptomarket vendor success using dark net forum networks", "link": "https://arxiv.org/abs/2306.16568", "description": "arXiv:2306.16568v3 Announce Type: replace \nAbstract: In this work we focus on identifying key players in dark net cryptomarkets that facilitate online trade of illegal goods. Law enforcement aims to disrupt criminal activity conducted through these markets by targeting key players vital to the market's existence and success. We particularly focus on detecting successful vendors responsible for the majority of illegal trade. Our methodology aims to uncover whether the task of key player identification should center around plainly measuring user and forum activity, or that it requires leveraging specific patterns of user communication. We focus on a large-scale dataset from the Evolution cryptomarket, which we model as an evolving communication network. Results indicate that user and forum activity, measured through topic engagement, is best able to identify successful vendors. Interestingly, considering users with higher betweenness centrality in the communication network further improves performance, also identifying successful vendors with moderate activity on the forum. But more importantly, analyzing the forum data over time, we find evidence that attaining a high betweenness score comes before vendor success. This suggests that the proposed network-driven approach of modelling user communication might prove useful as an early warning signal for key player identification."}, "https://arxiv.org/abs/2312.14040": {"title": "Balancing Specialization and Adaptation in a Transforming Scientific Landscape", "link": "https://arxiv.org/abs/2312.14040", "description": "arXiv:2312.14040v5 Announce Type: replace \nAbstract: How do scientists navigate between the need to capitalize on their prior knowledge through specialization, and the urge to adapt to evolving research opportunities? Drawing from diverse perspectives on adaptation, including cultural evolution, this paper proposes an unsupervised Bayesian approach motivated by Optimal Transport of the evolution of scientists' research portfolios in response to transformations in their field. The model relies on $186,162$ scientific abstracts and authorship data to evaluate the influence of intellectual, social, and institutional resources on scientists' trajectories within a cohort of $2\\,195$ high-energy physicists between 2000 and 2019. Using Inverse Optimal Transport, the reallocation of research efforts is shown to be shaped by learning costs, thus enhancing the utility of the scientific capital disseminated among scientists. Two dimensions of social capital, namely \"diversity\" and \"power\", have opposite associations with the magnitude of change in scientists' research interests: while \"diversity\" disrupts and expands research interests, \"power\" is associated with more stable research agendas. Social capital plays a more crucial role in shifts between cognitively distant research areas. More generally, this work suggests new approaches for understanding, measuring and modeling collective adaptation using Optimal Transport."}, "https://arxiv.org/abs/2401.03656": {"title": "CosIn: A Statistical-Based Algorithm for Computation of Speed-Space Time Delay in Pedestrian Motion", "link": "https://arxiv.org/abs/2401.03656", "description": "arXiv:2401.03656v3 Announce Type: replace \nAbstract: The precise assessment of speed-space time delay (TD) facilitates the differentiation between pedestrian anticipation behavior and reaction behavior. Importantly, the TD scale is instrumental in the evaluation of potential collision risks inherent in the crowd, thereby offering crucial quantitative metrics for crowd risk. This article introduces the CosIn algorithm for evaluate TD during pedestrian motion, comprising the CosIn-1 and CosIn-2 algorithms. The CosIn-1 algorithm specifically addresses the precise computation issue associated with the TD of individual pedestrians, while the CosIn-2 algorithm is employed for assessing TD at a crowd scale, concurrently addressing the imperative of real-time computation. Efficacy analyses of the CosIn-1 and CosIn-2 algorithms are conducted using the data from single-file pedestrian experiments and crowd cross experiments, respectively. The results obtained demonstrate commendable precision in the algorithmic solutions. This algorithm contributes to the precise assessment of behavior patterns and collision risk within crowd dynamics."}, "https://arxiv.org/abs/2403.01269": {"title": "Network analysis using Krylov subspace trajectories", "link": "https://arxiv.org/abs/2403.01269", "description": "arXiv:2403.01269v2 Announce Type: replace \nAbstract: We describe a set of network analysis methods based on the rows of the Krylov subspace matrix computed from a network adjacency matrix via power iteration using a non-random initial vector. We refer to these node-specific row vectors as Krylov subspace trajectories. While power iteration using a random initial starting vector is commonly applied to the network adjacency matrix to compute eigenvector centrality values, this application only uses the final vector generated after numerical convergence. Importantly, use of a random initial vector means that the intermediate results of power iteration are also random and lack a clear interpretation. To the best of our knowledge, use of intermediate power iteration results for network analysis has been limited to techniques that leverage just a single pre-convergence solution, e.g., Power Iteration Clustering. In this paper, we explore methods that apply power iteration with a non-random inital vector to the network adjacency matrix to generate Krylov subspace trajectories for each node. These non-random trajectories provide important information regarding network structure, node importance, and response to perturbations. We have created this short preprint in part to generate feedback from others in the network analysis community who might be aware of similar existing work."}, "https://arxiv.org/abs/2404.05334": {"title": "Modeling the Dynamic Process of Inventions for Reducing Knowledge Search Costs", "link": "https://arxiv.org/abs/2404.05334", "description": "arXiv:2404.05334v2 Announce Type: replace \nAbstract: A knowledge search is a key process for inventions. However, there is inadequate quantitative modeling of dynamic knowledge search processes and associated search costs. In this study, agent-based and complex network methodologies were proposed to quantitatively describe the dynamic process of knowledge search for actual inventions. Prior knowledge networks (PKNs), the search space of historical patents, were constructed, representative search rules were formulated for R&amp;D agents, and measures for knowledge search cost were designed to serve as search objectives. Simulation results in the field of photolithographic technology show that search costs differ significantly with different search rules. Familiarity and Degree rules significantly outperform BFS, DFS and Recency rules in terms of knowledge search costs, and are less affected by the size and density of PKNs. Interestingly, there is no significant correlation between the mean and variance of search costs and patent value, indicating that high-value patents are not particularly difficult to obtain. The implications for innovation theories and R&amp;D practices are drawn from the models and results."}, "https://arxiv.org/abs/2301.09289": {"title": "Fundamental Limits of Spectral Clustering in Stochastic Block Models", "link": "https://arxiv.org/abs/2301.09289", "description": "arXiv:2301.09289v3 Announce Type: replace-cross \nAbstract: Spectral clustering has been widely used for community detection in network sciences. While its empirical successes are well-documented, a clear theoretical understanding, particularly for sparse networks where degrees are much smaller than $\\log n$, remains unclear. In this paper, we address this significant gap by demonstrating that spectral clustering offers exponentially small error rates when applied to sparse networks under Stochastic Block Models. Our analysis provides sharp characterizations of its performance, backed by matching upper and lower bounds possessing an identical exponent with the same leading constant. The key to our results is a novel truncated $\\ell_2$ perturbation analysis for eigenvectors, coupled with a new analysis idea of eigenvectors truncation."}, "https://arxiv.org/abs/2312.15099": {"title": "Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models", "link": "https://arxiv.org/abs/2312.15099", "description": "arXiv:2312.15099v2 Announce Type: replace-cross \nAbstract: Online hate is an escalating problem that negatively impacts the lives of Internet users, and is also subject to rapid changes due to evolving events, resulting in new waves of online hate that pose a critical threat. Detecting and mitigating these new waves present two key challenges: it demands reasoning-based complex decision-making to determine the presence of hateful content, and the limited availability of training samples hinders updating the detection model. To address this critical issue, we present a novel framework called HATEGUARD for effectively moderating new waves of online hate. HATEGUARD employs a reasoning-based approach that leverages the recently introduced chain-of-thought (CoT) prompting technique, harnessing the capabilities of large language models (LLMs). HATEGUARD further achieves prompt-based zero-shot detection by automatically generating and updating detection prompts with new derogatory terms and targets in new wave samples to effectively address new waves of online hate. To demonstrate the effectiveness of our approach, we compile a new dataset consisting of tweets related to three recently witnessed new waves: the 2022 Russian invasion of Ukraine, the 2021 insurrection of the US Capitol, and the COVID-19 pandemic. Our studies reveal crucial longitudinal patterns in these new waves concerning the evolution of events and the pressing need for techniques to rapidly update existing moderation tools to counteract them. Comparative evaluations against state-of-the-art tools illustrate the superiority of our framework, showcasing a substantial 22.22% to 83.33% improvement in detecting the three new waves of online hate. Our work highlights the severe threat posed by the emergence of new waves of online hate and represents a paradigm shift in addressing this threat practically."}, "https://arxiv.org/abs/2405.06698": {"title": "Optimizing Viscous Democracy", "link": "https://arxiv.org/abs/2405.06698", "description": "arXiv:2405.06698v1 Announce Type: new \nAbstract: Viscous democracy is a generalization of liquid democracy, a social choice framework in which voters may transitively delegate their votes. In viscous democracy, a \"viscosity\" factor decreases the weight of a delegation the further it travels, reducing the chance of excessive weight flowing between ideologically misaligned voters. We demonstrate that viscous democracy often significantly improves the quality of group decision-making over liquid democracy. We first show that finding optimal delegations within a viscous setting is NP-hard. However, simulations allow us to explore the practical effects of viscosity. Across social network structures, competence distributions, and delegation mechanisms we find high viscosity reduces the chance of \"super-voters\" attaining large amounts of weight and increases the number of voters that are able to affect the outcome of elections. This, in turn, improves group accuracy as a whole. As a result, we argue that viscosity should be considered a core component of liquid democracy."}, "https://arxiv.org/abs/2405.06700": {"title": "LLM-Augmented Agent-Based Modelling for Social Simulations: Challenges and Opportunities", "link": "https://arxiv.org/abs/2405.06700", "description": "arXiv:2405.06700v1 Announce Type: new \nAbstract: As large language models (LLMs) continue to make significant strides, their better integration into agent-based simulations offers a transformational potential for understanding complex social systems. However, such integration is not trivial and poses numerous challenges. Based on this observation, in this paper, we explore architectures and methods to systematically develop LLM-augmented social simulations and discuss potential research directions in this field. We conclude that integrating LLMs with agent-based simulations offers a powerful toolset for researchers and scientists, allowing for more nuanced, realistic, and comprehensive models of complex systems and human behaviours."}, "https://arxiv.org/abs/2405.06947": {"title": "A Galton Board Approximation Method for Estimating Pedestrian Walking Preferences within Crowds", "link": "https://arxiv.org/abs/2405.06947", "description": "arXiv:2405.06947v1 Announce Type: new \nAbstract: This paper proposes a Galton board approximation method to analyze the potential walking preferences of pedestrians. We employ the binomial distribution to estimate the walking preferences of pedestrians in dynamic crowds. Estimating the probability of the right-side preference $(p)$ based on observational data poses the challenge, as statistical measures such as means and variances often lead to divergent results. This paper aims to explore this issue."}, "https://arxiv.org/abs/2405.07071": {"title": "Colocation of skill related suppliers -- Revisiting coagglomeration using firm-to-firm network data", "link": "https://arxiv.org/abs/2405.07071", "description": "arXiv:2405.07071v1 Announce Type: new \nAbstract: Strong local clusters help firms compete on global markets. One explanation for this is that firms benefit from locating close to their suppliers and customers. However, the emergence of global supply chains shows that physical proximity is not necessarily a prerequisite to successfully manage customer-supplier relations anymore. This raises the question when firms need to colocate in value chains and when they can coordinate over longer distances. We hypothesize that one important aspect is the extent to which supply chain partners exchange not just goods but also know-how. To test this, we build on an expanding literature that studies the drivers of industrial coagglomeration to analyze when supply chain connections lead firms to colocation. We exploit detailed micro-data for the Hungarian economy between 2015 and 2017, linking firm registries, employer-employee matched data and firm-to-firm transaction data from value-added tax records. This allows us to observe colocation, labor flows and value chain connections at the level of firms, as well as construct aggregated coagglomeration patterns, skill relatedness and input-output connections between pairs of industries. We show that supply chains are more likely to support coagglomeration when the industries involved are also skill related. That is, input-output and labor market channels reinforce each other, but supplier connections only matter for colocation when industries have similar labor requirements, suggesting that they employ similar types of know-how. We corroborate this finding by analyzing the interactions between firms, showing that supplier relations are more geographically constrained between companies that operate in skill related industries."}, "https://arxiv.org/abs/2405.07072": {"title": "Selecting focused digital cohorts from social media using the metric backbone of biomedical knowledge graphs", "link": "https://arxiv.org/abs/2405.07072", "description": "arXiv:2405.07072v1 Announce Type: new \nAbstract: The abundance of social media data allows researchers to construct large digital cohorts to study the interplay between human behavior and medical treatment. Identifying the users most relevant to a specific health problem is, however, a challenge in that social media sites vary in the generality of their discourse. While X (formerly Twitter), Instagram, and Facebook cater to wide ranging topics, Reddit subgroups and dedicated patient advocacy forums trade in much more specific, biomedically-relevant discourse. To hone in on relevant users anywhere, we have developed a general framework and applied it to epilepsy discourse in social media as a test case. We analyzed the text from posts by users who mention epilepsy drugs in the general-purpose social media sites X and Instagram, the epilepsy-focused Reddit subgroup (r/Epilepsy), and the Epilepsy Foundation of America (EFA) forums. We curated a medical terms dictionary and used it to generate a knowledge graph (KG) for each online community. For each KG, we computed the metric backbone--the smallest subgraph that preserves all shortest paths in the network. By comparing the subset of users who contribute to the backbone to the subset who do not, we found that epilepsy-focused social media users contribute to the KG backbone in much higher proportion than do general-purpose social media users. Furthermore, using human annotation of Instagram posts, we demonstrated that users who do not contribute to the backbone are more than twice as likely to use dictionary terms in a manner inconsistent with their biomedical meaning. For biomedical research applications, our backbone-based approach thus has several benefits over simple engagement-based approaches: It can retain low-engagement users who nonetheless contribute meaningful biomedical insights. It can filter out very vocal users who contribute no relevant content."}, "https://arxiv.org/abs/2405.07096": {"title": "Multi-Relational Structural Entropy", "link": "https://arxiv.org/abs/2405.07096", "description": "arXiv:2405.07096v1 Announce Type: new \nAbstract: Structural Entropy (SE) measures the structural information contained in a graph. Minimizing or maximizing SE helps to reveal or obscure the intrinsic structural patterns underlying graphs in an interpretable manner, finding applications in various tasks driven by networked data. However, SE ignores the heterogeneity inherent in the graph relations, which is ubiquitous in modern networks. In this work, we extend SE to consider heterogeneous relations and propose the first metric for multi-relational graph structural information, namely, Multi-relational Structural Entropy (MrSE). To this end, we first cast SE through the novel lens of the stationary distribution from random surfing, which readily extends to multi-relational networks by considering the choices of both nodes and relation types simultaneously at each step. The resulting MrSE is then optimized by a new greedy algorithm to reveal the essential structures within a multi-relational network. Experimental results highlight that the proposed MrSE offers a more insightful interpretation of the structure of multi-relational graphs compared to SE. Additionally, it enhances the performance of two tasks that involve real-world multi-relational graphs, including node clustering and social event detection."}, "https://arxiv.org/abs/2405.07277": {"title": "Mining Influential Spreaders in Complex Networks by an Effective Combination of the Degree and K-Shell", "link": "https://arxiv.org/abs/2405.07277", "description": "arXiv:2405.07277v1 Announce Type: new \nAbstract: Graph mining is an important technique that used in many applications such as predicting and understanding behaviors and information dissemination within networks. One crucial aspect of graph mining is the identification and ranking of influential nodes, which has applications in various fields including marketing, social communications, and disease control. However, existing models and methods come with high computational complexity and may not accurately distinguish and identify influential nodes. This paper develops a method based on the k-shell index and degree centrality of nodes and their neighbors. Comparisons to previous works, such as Degree and Neighborhood information Centrality (DNC) and Neighborhood and Path Information Centrality (NPIC), are conducted. The evaluations, which include the correctness with Kendall's Tau, resolution with monotonicity index, correlation plots, and time complexity, demonstrate its superior results."}, "https://arxiv.org/abs/2405.07417": {"title": "Identifying Hate Speech Peddlers in Online Platforms", "link": "https://arxiv.org/abs/2405.07417", "description": "arXiv:2405.07417v1 Announce Type: new \nAbstract: This paper studies the problem of autonomous agents performing Bayesian social learning for sequential detection when the observations of the state belong to a high-dimensional space and are expensive to analyze. Specifically, when the observations are textual, the Bayesian agent can use a large language model (LLM) as a map to get a low-dimensional private observation. The agent performs Bayesian learning and takes an action that minimizes the expected cost and is visible to subsequent agents. We prove that a sequence of such Bayesian agents herd in finite time to the public belief and take the same action disregarding the private observations. We propose a stopping time formulation for quickest time herding in social learning and optimally balance privacy and herding. Structural results are shown on the threshold nature of the optimal policy to the stopping time problem. We illustrate the application of our framework when autonomous Bayesian detectors aim to sequentially identify if a user is a hate speech peddler on an online platform by parsing text observations using an LLM. We numerically validate our results on real-world hate speech datasets. We show that autonomous Bayesian agents designed to flag hate speech peddlers in online platforms herd and misclassify the users when the public prior is strong. We also numerically show the effect of a threshold policy in delaying herding."}, "https://arxiv.org/abs/2405.07574": {"title": "Is it getting harder to make a hit? Evidence from 65 years of US music chart history", "link": "https://arxiv.org/abs/2405.07574", "description": "arXiv:2405.07574v1 Announce Type: new \nAbstract: Since the creation of the Billboard Hot 100 music chart in 1958, the chart has been a window into the music consumption of Americans. Which songs succeed on the chart is decided by consumption volumes, which can be affected by consumer music taste, and other factors such as advertisement budgets, airplay time, the specifics of ranking algorithms, and more. Since its introduction, the chart has documented music consumerism through eras of globalization, economic growth, and the emergence of new technologies for music listening. In recent years, musicians and other hitmakers have voiced their worry that the music world is changing: Many claim that it is getting harder to make a hit but until now, the claims have not been backed using chart data. Here we show that the dynamics of the Billboard Hot 100 chart have changed significantly since the chart's founding in 1958, and in particular in the past 15 years. Whereas most songs spend less time on the chart now than songs did in the past, we show that top-1 songs have tripled their chart lifetime since the 1960s, the highest-ranked songs maintain their positions for far longer than previously, and the lowest-ranked songs are replaced more frequently than ever. At the same time, who occupies the chart has also changed over the years: In recent years, fewer new artists make it into the chart and more positions are occupied by established hit makers. Finally, investigating how song chart trajectories have changed over time, we show that historical song trajectories cluster into clear trajectory archetypes characteristic of the time period they were part of. The results are interesting in the context of collective attention: Whereas recent studies have documented that other cultural products such as books, news, and movies fade in popularity quicker in recent years, music hits seem to last longer now than in the past."}, "https://arxiv.org/abs/2405.07828": {"title": "Can LLMs Help Predict Elections? (Counter)Evidence from the World's Largest Democracy", "link": "https://arxiv.org/abs/2405.07828", "description": "arXiv:2405.07828v1 Announce Type: new \nAbstract: The study of how social media affects the formation of public opinion and its influence on political results has been a popular field of inquiry. However, current approaches frequently offer a limited comprehension of the complex political phenomena, yielding inconsistent outcomes. In this work, we introduce a new method: harnessing the capabilities of Large Language Models (LLMs) to examine social media data and forecast election outcomes. Our research diverges from traditional methodologies in two crucial respects. First, we utilize the sophisticated capabilities of foundational LLMs, which can comprehend the complex linguistic subtleties and contextual details present in social media data. Second, we focus on data from X (Twitter) in India to predict state assembly election outcomes. Our method entails sentiment analysis of election-related tweets through LLMs to forecast the actual election results, and we demonstrate the superiority of our LLM-based method against more traditional exit and opinion polls. Overall, our research offers valuable insights into the unique dynamics of Indian politics and the remarkable impact of social media in molding public attitudes within this context."}, "https://arxiv.org/abs/2405.07950": {"title": "Quantum-like states on complex synchronized networks", "link": "https://arxiv.org/abs/2405.07950", "description": "arXiv:2405.07950v1 Announce Type: new \nAbstract: Recent work has exposed the idea that interesting quantum-like probability laws, including interference effects, can be manifest in classical systems. Here we propose a model for quantum-like (QL) states and QL bits. We suggest a way that huge, complex systems can host robust states that can process information in a QL fashion. Axioms that such states should satisfy are proposed. Specifically, it is shown that building blocks suited for QL states are networks, possibly very complex, that we defined based on $k$-regular random graphs. These networks can dynamically encode a lot of information that is distilled into the emergent states we can use for QL like processing. Although the emergent states are classical, they have properties analogous to quantum states. Concrete examples of how QL functions are possible are given. The possibility of a `QL advantage' for computing-type operations and the potential relevance for new kinds of function in the brain are discussed and left as open questions."}, "https://arxiv.org/abs/2405.06656": {"title": "Exploring Social Media Posts for Depression Identification: A Study on Reddit Dataset", "link": "https://arxiv.org/abs/2405.06656", "description": "arXiv:2405.06656v1 Announce Type: cross \nAbstract: Depression is one of the most common mental disorders affecting an individual's personal and professional life. In this work, we investigated the possibility of utilizing social media posts to identify depression in individuals. To achieve this goal, we conducted a preliminary study where we extracted and analyzed the top Reddit posts made in 2022 from depression-related forums. The collected data were labeled as depressive and non-depressive using UMLS Metathesaurus. Further, the pre-processed data were fed to classical machine learning models, where we achieved an accuracy of 92.28\\% in predicting the depressive and non-depressive posts."}, "https://arxiv.org/abs/2405.06668": {"title": "Exposing and Explaining Fake News On-the-Fly", "link": "https://arxiv.org/abs/2405.06668", "description": "arXiv:2405.06668v1 Announce Type: cross \nAbstract: Social media platforms enable the rapid dissemination and consumption of information. However, users instantly consume such content regardless of the reliability of the shared data. Consequently, the latter crowdsourcing model is exposed to manipulation. This work contributes with an explainable and online classification method to recognize fake news in real-time. The proposed method combines both unsupervised and supervised Machine Learning approaches with online created lexica. The profiling is built using creator-, content- and context-based features using Natural Language Processing techniques. The explainable classification mechanism displays in a dashboard the features selected for classification and the prediction confidence. The performance of the proposed solution has been validated with real data sets from Twitter and the results attain 80 % accuracy and macro F-measure. This proposal is the first to jointly provide data stream processing, profiling, classification and explainability. Ultimately, the proposed early detection, isolation and explanation of fake news contribute to increase the quality and trustworthiness of social media contents."}, "https://arxiv.org/abs/2405.06684": {"title": "QuakeBERT: Accurate Classification of Social Media Texts for Rapid Earthquake Impact Assessment", "link": "https://arxiv.org/abs/2405.06684", "description": "arXiv:2405.06684v1 Announce Type: cross \nAbstract: Social media aids disaster response but suffers from noise, hindering accurate impact assessment and decision making for resilient cities, which few studies considered. To address the problem, this study proposes the first domain-specific LLM model and an integrated method for rapid earthquake impact assessment. First, a few categories are introduced to classify and filter microblogs considering their relationship to the physical and social impacts of earthquakes, and a dataset comprising 7282 earthquake-related microblogs from twenty earthquakes in different locations is developed as well. Then, with a systematic analysis of various influential factors, QuakeBERT, a domain-specific large language model (LLM), is developed and fine-tuned for accurate classification and filtering of microblogs. Meanwhile, an integrated method integrating public opinion trend analysis, sentiment analysis, and keyword-based physical impact quantification is introduced to assess both the physical and social impacts of earthquakes based on social media texts. Experiments show that data diversity and data volume dominate the performance of QuakeBERT and increase the macro average F1 score by 27%, while the best classification model QuakeBERT outperforms the CNN- or RNN-based models by improving the macro average F1 score from 60.87% to 84.33%. Finally, the proposed approach is applied to assess two earthquakes with the same magnitude and focal depth. Results show that the proposed approach can effectively enhance the impact assessment process by accurate detection of noisy microblogs, which enables effective post-disaster emergency responses to create more resilient cities."}, "https://arxiv.org/abs/2405.07217": {"title": "Improved bounds for polylogarithmic graph distances in scale-free percolation and related models", "link": "https://arxiv.org/abs/2405.07217", "description": "arXiv:2405.07217v1 Announce Type: cross \nAbstract: In this paper, we study graph distances in the geometric random graph models scale-free percolation SFP, geometric inhomogeneous random graphs GIRG, and hyperbolic random graphs HRG. Despite the wide success of the models, the parameter regime in which graph distances are polylogarithmic is poorly understood. We provide new and improved lower bounds. In a certain portion of the parameter regime, those match the known upper bounds.\n  Compared to the best previous lower bounds by Hao and Heydenreich, our result has several advantages: it gives matching bounds for a larger range of parameters, thus settling the question for a larger portion of the parameter space. It strictly improves the lower bounds by Hao and Heydenreich for all parameters settings in which those bounds were not tight. It gives tail bounds on the probability of having short paths, which imply shape theorems for the $k$-neighbourhood of a vertex whenever our lower bounds are tight, and tight bounds for the size of this $k$-neighbourhood. And last but not least, our proof is much simpler and not much longer than two pages, and we demonstrate that it generalizes well by showing that the same technique also works for first passage percolation."}, "https://arxiv.org/abs/2405.07764": {"title": "LGDE: Local Graph-based Dictionary Expansion", "link": "https://arxiv.org/abs/2405.07764", "description": "arXiv:2405.07764v1 Announce Type: cross \nAbstract: Expanding a dictionary of pre-selected keywords is crucial for tasks in information retrieval, such as database query and online data collection. Here we propose Local Graph-based Dictionary Expansion (LGDE), a method that uses tools from manifold learning and network science for the data-driven discovery of keywords starting from a seed dictionary. At the heart of LGDE lies the creation of a word similarity graph derived from word embeddings and the application of local community detection based on graph diffusion to discover semantic neighbourhoods of pre-defined seed keywords. The diffusion in the local graph manifold allows the exploration of the complex nonlinear geometry of word embeddings and can capture word similarities based on paths of semantic association. We validate our method on a corpus of hate speech-related posts from Reddit and Gab and show that LGDE enriches the list of keywords and achieves significantly better performance than threshold methods based on direct word similarities. We further demonstrate the potential of our method through a real-world use case from communication science, where LGDE is evaluated quantitatively on data collected and analysed by domain experts by expanding a conspiracy-related dictionary."}, "https://arxiv.org/abs/2405.07877": {"title": "Optimal accuracy for linear sets of equations with the graph Laplacian", "link": "https://arxiv.org/abs/2405.07877", "description": "arXiv:2405.07877v1 Announce Type: cross \nAbstract: We show that certain Graph Laplacian linear sets of equations exhibit optimal accuracy, guaranteeing that the relative error is no larger than the norm of the relative residual and that optimality occurs for carefully chosen right-hand sides. Such sets of equations arise in PageRank and Markov chain theory. We establish new relationships among the PageRank teleportation parameter, the Markov chain discount, and approximations to linear sets of equations. The set of optimally accurate systems can be separated into two groups for an undirected graph -- those that achieve optimality asymptotically with the graph size and those that do not -- determined by the angle between the right-hand side of the linear system and the vector of all ones. We provide supporting numerical experiments."}, "https://arxiv.org/abs/2306.08426": {"title": "Patterns of Patterns II", "link": "https://arxiv.org/abs/2306.08426", "description": "arXiv:2306.08426v3 Announce Type: replace \nAbstract: Our earlier paper \"Patterns of Patterns\" combined three techniques from training, futures studies, and design in a design pattern called PLACARD that helps groups of people work together effectively. We used that pattern in five hands-on workshop case studies which took place at various locations in the US and the UK. This experience report documents what we learned, including the way our thinking about PLACARD evolved, together with additional patterns our work generated. We evaluate the reproducibility of our methods and results, and consider the broader economic implications of this way of working. We discuss implications of our prototyping work for the design of future platforms, drawing connections with recent developments in cognitive science and artificial intelligence. This positions our patterns of patterns as a toolkit for the design and governance of systems that combine social dynamics with technical components."}, "https://arxiv.org/abs/2306.12136": {"title": "Node-layer duality in networked systems", "link": "https://arxiv.org/abs/2306.12136", "description": "arXiv:2306.12136v2 Announce Type: replace \nAbstract: Real-world networks typically exhibit several aspects, or layers, of interactions among their nodes. By permuting the role of the nodes and the layers, we establish a new criterion to construct the dual of a network. This approach allows to examine information from either a node-centric or layer-centric viewpoint. Through rigorous analytical methods and extensive simulations, we demonstrate that nodewise and layerwise connectivity measure different but related aspects of the same system. Leveraging node-layer duality provides complementary insights, enabling a deeper comprehension of diverse networks across social science, technology and biology. Taken together, these findings reveal previously unappreciated features of complex systems and provide a fresh tool for delving into their structure and dynamics."}, "https://arxiv.org/abs/2310.12181": {"title": "Precise influence evaluation in complex networks", "link": "https://arxiv.org/abs/2310.12181", "description": "arXiv:2310.12181v2 Announce Type: replace \nAbstract: Evaluating node influence is fundamental for identifying key nodes in complex networks. Existing methods typically rely on generic indicators to rank node influence across diverse networks, thereby ignoring the individualized features of each network itself. Actually, node influence stems not only from general features but the multi-scale individualized information encompassing specific network structure and task. Here we design an active learning architecture to predict node influence quantitively and precisely, which samples representative nodes based on graph entropy correlation matrix integrating multi-scale individualized information. This brings two intuitive advantages: (1) discovering potential high-influence but weak-connected nodes that are usually ignored in existing methods, (2) improving the influence maximization strategy by deducing influence interference. Significantly, our architecture demonstrates exceptional transfer learning capabilities across multiple types of networks, which can identify those key nodes with large disputation across different existing methods. Additionally, our approach, combined with a simple greedy algorithm, exhibits dominant performance in solving the influence maximization problem. This architecture holds great potential for applications in graph mining and prediction tasks."}, "https://arxiv.org/abs/2312.12186": {"title": "Social Learning in Community Structured Graphs", "link": "https://arxiv.org/abs/2312.12186", "description": "arXiv:2312.12186v3 Announce Type: replace \nAbstract: Traditional social learning frameworks consider environments with a homogeneous state, where each agent receives observations conditioned on that true state of nature. In this work, we relax this assumption and study the distributed hypothesis testing problem in a heterogeneous environment, where each agent can receive observations conditioned on their own personalized state of nature (or truth). We particularly focus on community structured networks, where each community admits their own true hypothesis. This scenario is common in various contexts, such as when sensors are spatially distributed, or when individuals in a social network have differing views or opinions. We show that the adaptive social learning strategy is a preferred choice for nonstationary environments, and allows each cluster to discover its own truth."}, "https://arxiv.org/abs/2401.00651": {"title": "IRWE: Inductive Random Walk for Joint Inference of Identity and Position Network Embedding", "link": "https://arxiv.org/abs/2401.00651", "description": "arXiv:2401.00651v2 Announce Type: replace \nAbstract: Network embedding, which maps graphs to distributed representations, is a unified framework for various graph inference tasks. According to the topology properties (e.g., structural roles and community memberships of nodes) to be preserved, it can be categorized into the identity and position embedding. However, existing methods can only capture one type of property. Some approaches can support the inductive inference that generalizes the embedding model to new nodes or graphs but relies on the availability of attributes. Due to the complicated correlations between topology and attributes, it is unclear for some inductive methods which type of property they can capture. In this study, we explore a unified framework for the joint inductive inference of identity and position embeddings without attributes. An inductive random walk embedding (IRWE) method is proposed, which combines multiple attention units to handle the random walk on graph topology and simultaneously derives identity and position embeddings that are jointly optimized. In particular, we demonstrate that some random walk statistics can be informative features to characterize node identities and positions while supporting the inductive embedding inference. Experiments validate the superior performance of IRWE beyond various baselines for the transductive and inductive inference of identity and position embeddings."}, "https://arxiv.org/abs/2402.03837": {"title": "Expressivity of Geometric Inhomogeneous Random Graphs -- Metric and Non-Metric", "link": "https://arxiv.org/abs/2402.03837", "description": "arXiv:2402.03837v2 Announce Type: replace \nAbstract: Recently there has been increased interest in fitting generative graph models to real-world networks. In particular, Bl\\\"asius et al. have proposed a framework for systematic evaluation of the expressivity of random graph models. We extend this framework to Geometric Inhomogeneous Random Graphs (GIRGs). This includes a family of graphs induced by non-metric distance functions which allow capturing more complex models of partial similarity between nodes as a basis of connection - as well as homogeneous and non-homogeneous feature spaces. As part of the extension, we develop schemes for estimating the multiplicative constant and the long-range parameter in the connection probability. Moreover, we devise an algorithm for sampling Minimum-Component-Distance GIRGs whose runtime is linear both in the number of vertices and in the dimension of the underlying geometric space. Our results provide evidence that GIRGs are more realistic candidates with respect to various graph features such as closeness centrality, betweenness centrality, local clustering coefficient, and graph effective diameter, while they face difficulties to replicate higher variance and more extreme values of graph statistics observed in real-world networks."}, "https://arxiv.org/abs/2402.18850": {"title": "A simple model of global cascades on random hypergraphs", "link": "https://arxiv.org/abs/2402.18850", "description": "arXiv:2402.18850v2 Announce Type: replace \nAbstract: This study introduces a comprehensive framework that situates information cascade research within the domain of higher-order interactions, utilizing a double-threshold hypergraph model. We propose that individuals (nodes) gain awareness of information through each communication channel (hyperedge) once the number of information adopters surpasses the threshold $\\phi_m$. However, actual adoption of the information only occurs when the cumulative influence across all communication channels exceeds a second threshold, $\\phi_k$. We analytically derive the cascade condition for both the case of a single seed node using percolation methods and the case of any seed size employing mean-field approximation. Our findings underscore that when considering the fractional seed size, $r_0 \\in (0,1]$, the connectivity pattern of the random hypergraph, characterized by the hyperdegree ($k$) and cardinality ($m$) distribution, exerts an asymmetric impact on the global cascade boundary. This asymmetry manifests in the observed differences in the boundaries of the global cascade within the $(\\phi_m, \\langle m \\rangle)$ and $(\\phi_k, \\langle k \\rangle)$ planes. However, as $r_0 \\to 0$, this asymmetric effect gradually diminishes. Overall, by elucidating the mechanisms driving information cascades within a broader context of higher-order interactions, our research contributes to theoretical advancements in complex systems theory."}, "https://arxiv.org/abs/2403.13945": {"title": "$N$-player game formulation of the majority-vote model of opinion dynamics", "link": "https://arxiv.org/abs/2403.13945", "description": "arXiv:2403.13945v2 Announce Type: replace \nAbstract: From a self-centered perspective, it can be assumed that people only hold opinions that can benefit them. If opinions have no intrinsic value, and acquire their value when held by the majority of individuals in a discussion group, then we have a situation that can be modeled as an $N$-player game. Here we explore the dynamics of (binary) opinion formation using a game-theoretic framework to study an $N$-player game version of Galam's local majority-vote model. The opinion dynamics is modeled by a stochastic imitation dynamics in which the individuals copy the opinion of more successful peers. In the infinite population limit, this dynamics is described by the classical replicator equation of evolutionary game theory. The equilibrium solution shows a threshold separating the initial frequencies that lead to the fixation of one opinion or the other. A comparison with Galam's deterministic model reveals contrasting results, especially in the presence of inflexible individuals, who never change their opinions. In particular, the $N$-player game predicts a polarized equilibrium consisting only of extremists. Using finite-size scaling analysis, we evaluate the critical exponents that determine the population size dependence of the opinion's fixation probability and mean fixation times near the threshold. The results underscore the usefulness of combining evolutionary game theory with opinion dynamics and the importance of statistical physics tools to summarize the results of Monte Carlo simulations."}, "https://arxiv.org/abs/2310.16181": {"title": "Hidden Citations Obscure True Impact in Science", "link": "https://arxiv.org/abs/2310.16181", "description": "arXiv:2310.16181v2 Announce Type: replace-cross \nAbstract: References, the mechanism scientists rely on to signal previous knowledge, lately have turned into widely used and misused measures of scientific impact. Yet, when a discovery becomes common knowledge, citations suffer from obliteration by incorporation. This leads to the concept of hidden citation, representing a clear textual credit to a discovery without a reference to the publication embodying it. Here, we rely on unsupervised interpretable machine learning applied to the full text of each paper to systematically identify hidden citations. We find that for influential discoveries hidden citations outnumber citation counts, emerging regardless of publishing venue and discipline. We show that the prevalence of hidden citations is not driven by citation counts, but rather by the degree of the discourse on the topic within the text of the manuscripts, indicating that the more discussed is a discovery, the less visible it is to standard bibliometric analysis. Hidden citations indicate that bibliometric measures offer a limited perspective on quantifying the true impact of a discovery, raising the need to extract knowledge from the full text of the scientific corpus."}, "https://arxiv.org/abs/2311.08605": {"title": "Exploring the Jungle of Bias: Political Bias Attribution in Language Models via Dependency Analysis", "link": "https://arxiv.org/abs/2311.08605", "description": "arXiv:2311.08605v2 Announce Type: replace-cross \nAbstract: The rapid advancement of Large Language Models (LLMs) has sparked intense debate regarding the prevalence of bias in these models and its mitigation. Yet, as exemplified by both results on debiasing methods in the literature and reports of alignment-related defects from the wider community, bias remains a poorly understood topic despite its practical relevance. To enhance the understanding of the internal causes of bias, we analyse LLM bias through the lens of causal fairness analysis, which enables us to both comprehend the origins of bias and reason about its downstream consequences and mitigation. To operationalize this framework, we propose a prompt-based method for the extraction of confounding and mediating attributes which contribute to the LLM decision process. By applying Activity Dependency Networks (ADNs), we then analyse how these attributes influence an LLM's decision process. We apply our method to LLM ratings of argument quality in political debates. We find that the observed disparate treatment can at least in part be attributed to confounding and mitigating attributes and model misalignment, and discuss the consequences of our findings for human-AI alignment and bias mitigation. Our code and data are at https://github.com/david-jenny/LLM-Political-Study."}, "https://arxiv.org/abs/2401.13248": {"title": "\"Here's Your Evidence\": False Consensus in Public Twitter Discussions of COVID-19 Science", "link": "https://arxiv.org/abs/2401.13248", "description": "arXiv:2401.13248v2 Announce Type: replace-cross \nAbstract: The COVID-19 pandemic brought about an extraordinary rate of scientific papers on the topic that were discussed among the general public, although often in biased or misinformed ways. In this paper, we present a mixed-methods analysis aimed at examining whether public discussions were commensurate with the scientific consensus on several COVID-19 issues. We estimate scientific consensus based on samples of abstracts from preprint servers and compare against the volume of public discussions on Twitter mentioning these papers. We find that anti-consensus posts and users, though overall less numerous than pro-consensus ones, are vastly over-represented on Twitter, thus producing a false consensus effect. This transpires with favorable papers being disproportionately amplified, along with an influx of new anti-consensus user sign-ups. Finally, our content analysis highlights that anti-consensus users misrepresent scientific findings or question scientists' integrity in their efforts to substantiate their claims."}, "https://arxiv.org/abs/2402.00447": {"title": "A Survey of Data-Efficient Graph Learning", "link": "https://arxiv.org/abs/2402.00447", "description": "arXiv:2402.00447v2 Announce Type: replace-cross \nAbstract: Graph-structured data, prevalent in domains ranging from social networks to biochemical analysis, serve as the foundation for diverse real-world systems. While graph neural networks demonstrate proficiency in modeling this type of data, their success is often reliant on significant amounts of labeled data, posing a challenge in practical scenarios with limited annotation resources. To tackle this problem, tremendous efforts have been devoted to enhancing graph machine learning performance under low-resource settings by exploring various approaches to minimal supervision. In this paper, we introduce a novel concept of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the first survey that summarizes the current progress of DEGL. We initiate by highlighting the challenges inherent in training models with large labeled data, paving the way for our exploration into DEGL. Next, we systematically review recent advances on this topic from several key aspects, including self-supervised graph learning, semi-supervised graph learning, and few-shot graph learning. Also, we state promising directions for future research, contributing to the evolution of graph machine learning."}, "https://arxiv.org/abs/2402.15119": {"title": "A multidisciplinary framework for deconstructing bots' pluripotency in dualistic antagonism", "link": "https://arxiv.org/abs/2402.15119", "description": "arXiv:2402.15119v4 Announce Type: replace-cross \nAbstract: Anthropomorphic social bots are engineered to emulate human verbal communication and generate toxic or inflammatory content across social networking services (SNSs). Bot-disseminated misinformation could subtly yet profoundly reshape societal processes by complexly interweaving factors like repeated disinformation exposure, amplified political polarization, compromised indicators of democratic health, shifted perceptions of national identity, propagation of false social norms, and manipulation of collective memory over time. However, extrapolating bots' pluripotency across hybridized, multilingual, and heterogeneous media ecologies from isolated SNS analyses remains largely unknown, underscoring the need for a comprehensive framework to characterise bots' emergent risks to civic discourse. Here we propose an interdisciplinary framework to characterise bots' pluripotency, incorporating quantification of influence, network dynamics monitoring, and interlingual feature analysis. When applied to the geopolitical discourse around the Russo-Ukrainian conflict, results from interlanguage toxicity profiling and network analysis elucidated spatiotemporal trajectories of pro-Russian and pro-Ukrainian human and bots across hybrid SNSs. Weaponized bots predominantly inhabited X, while human primarily populated Reddit in the social media warfare. This rigorous framework promises to elucidate interlingual homogeneity and heterogeneity in bots' pluripotent behaviours, revealing synergistic human-bot mechanisms underlying regimes of information manipulation, echo chamber formation, and collective memory manifestation in algorithmically structured societies."}, "https://arxiv.org/abs/2404.15986": {"title": "Seed Selection in the Heterogeneous Moran Process", "link": "https://arxiv.org/abs/2404.15986", "description": "arXiv:2404.15986v2 Announce Type: replace-cross \nAbstract: The Moran process is a classic stochastic process that models the rise and takeover of novel traits in network-structured populations. In biological terms, a set of mutants, each with fitness $m\\in(0,\\infty)$ invade a population of residents with fitness $1$. Each agent reproduces at a rate proportional to its fitness and each offspring replaces a random network neighbor. The process ends when the mutants either fixate (take over the whole population) or go extinct. The fixation probability measures the success of the invasion. To account for environmental heterogeneity, we study a generalization of the Standard process, called the Heterogeneous Moran process. Here, the fitness of each agent is determined both by its type (resident/mutant) and the node it occupies. We study the natural optimization problem of seed selection: given a budget $k$, which $k$ agents should initiate the mutant invasion to maximize the fixation probability? We show that the problem is strongly inapproximable: it is $\\mathbf{NP}$-hard to distinguish between maximum fixation probability 0 and 1. We then focus on mutant-biased networks, where each node exhibits at least as large mutant fitness as resident fitness. We show that the problem remains $\\mathbf{NP}$-hard, but the fixation probability becomes submodular, and thus the optimization problem admits a greedy $(1-1/e)$-approximation. An experimental evaluation of the greedy algorithm along with various heuristics on real-world data sets corroborates our results."}, "https://arxiv.org/abs/2404.19634": {"title": "DF Louvain: Fast Incrementally Expanding Approach for Community Detection on Dynamic Graphs", "link": "https://arxiv.org/abs/2404.19634", "description": "arXiv:2404.19634v2 Announce Type: replace-cross \nAbstract: Community detection is the problem of recognizing natural divisions in networks. A relevant challenge in this problem is to find communities on rapidly evolving graphs. In this report we present our Parallel Dynamic Frontier (DF) Louvain algorithm, which given a batch update of edge deletions and insertions, incrementally identifies and processes an approximate set of affected vertices in the graph with minimal overhead, while using a novel approach of incrementally updating weighted-degrees of vertices and total edge weights of communities. We also present our parallel implementations of Naive-dynamic (ND) and Delta-screening (DS) Louvain. On a server with a 64-core AMD EPYC-7742 processor, our experiments show that DF Louvain obtains speedups of 179x, 7.2x, and 5.3x on real-world dynamic graphs, compared to Static, ND, and DS Louvain, respectively, and is 183x, 13.8x, and 8.7x faster, respectively, on large graphs with random batch updates. Moreover, DF Louvain improves its performance by 1.6x for every doubling of threads."}, "https://arxiv.org/abs/2405.08040": {"title": "No evidence of systematic proximity ascertainment bias in early COVID-19 cases in Wuhan Reply to Weissman (2024)", "link": "https://arxiv.org/abs/2405.08040", "description": "arXiv:2405.08040v1 Announce Type: new \nAbstract: In a short text published as Letter to the Editor of the Journal of the Royal Statistical Society Series A, Weissman (2024) argues that the finding that early COVID-19 cases without an ascertained link to Wuhan's Huanan Seafood Wholesale market resided on average closer to the market than cases epidemiologically linked to it, reveals \"major proximity ascertainment bias\". Here we show that Weissman's conclusion is based on a flawed premise, and that there is no such \"internal evidence\" of major bias. The pattern can indeed be explained by places of infection not being limited to residential neighbourhoods, and by stochasticity -- i.e., without requiring any ascertainment bias."}, "https://arxiv.org/abs/2405.08203": {"title": "Community detection in bipartite signed networks is highly dependent on parameter choice", "link": "https://arxiv.org/abs/2405.08203", "description": "arXiv:2405.08203v1 Announce Type: new \nAbstract: Decision-making processes often involve voting. Human interactions with exogenous entities such as legislations or products can be effectively modeled as two-mode (bipartite) signed networks-where people can either vote positively, negatively, or abstain from voting on the entities. Detecting communities in such networks could help us understand underlying properties: for example ideological camps or consumer preferences. While community detection is an established practice separately for bipartite and signed networks, it remains largely unexplored in the case of bipartite signed networks. In this paper, we systematically evaluate the efficacy of community detection methods on bipartite signed networks using a synthetic benchmark and real-world datasets. Our findings reveal that when no communities are present in the data, these methods often recover spurious communities. When communities are present, the algorithms exhibit promising performance, although their performance is highly susceptible to parameter choice. This indicates that researchers using community detection methods in the context of bipartite signed networks should not take the communities found at face value: it is essential to assess the robustness of parameter choices or perform domain-specific external validation."}, "https://arxiv.org/abs/2405.08331": {"title": "Are Generics and Negativity about Social Groups Common on Social Media? A Comparative Analysis of Twitter (X) Data", "link": "https://arxiv.org/abs/2405.08331", "description": "arXiv:2405.08331v1 Announce Type: new \nAbstract: Generics (unquantified generalizations) are thought to be pervasive in communication and when they are about social groups, this may offend and polarize people because generics gloss over variations between individuals. Generics about social groups might be particularly common on Twitter (X). This remains unexplored, however. Using machine learning (ML) techniques, we therefore developed an automatic classifier for social generics, applied it to more than a million tweets about people, and analyzed the tweets. We found that most tweets (78%) about people contained no generics. However, tweets with social generics received more 'likes' and retweets. Furthermore, while recent psychological research may lead to the prediction that tweets with generics about political groups are more common than tweets with generics about ethnic groups, we found the opposite. However, consistent with recent claims that political animosity is less constrained by social norms than animosity against gender and ethnic groups, negative tweets with generics about political groups were significantly more prevalent and retweeted than negative tweets about ethnic groups. Our study provides the first ML-based insights into the use and impact of social generics on Twitter."}, "https://arxiv.org/abs/2405.08398": {"title": "Exploring the spatial segmentation of housing markets from online listings", "link": "https://arxiv.org/abs/2405.08398", "description": "arXiv:2405.08398v1 Announce Type: new \nAbstract: The real estate market shows an inherent connection to space. Real estate agencies unevenly operate and specialize across space, price and type of properties, thereby segmenting the market into submarkets. We introduce here a methodology based on multipartite networks to detect the spatial segmentation emerging from data on housing online listings. Considering the spatial information of the listings, we build a bipartite network that connects agencies and spatial units. This bipartite network is projected into a network of spatial units, whose connections account for similarities in the agency ecosystem. We then apply clustering methods to this network to segment markets into spatially-coherent regions, which are found to be robust across different clustering detection algorithms, discretization of space and spatial scales, and across countries with case studies in France and Spain. This methodology addresses the long-standing issue of housing market segmentation, relevant in disciplines such as urban studies and spatial economics, and with implications for policymaking."}, "https://arxiv.org/abs/2405.08746": {"title": "Decomposing geographical and universal aspects of human mobility", "link": "https://arxiv.org/abs/2405.08746", "description": "arXiv:2405.08746v1 Announce Type: new \nAbstract: Driven by access to large volumes of detailed movement data, the study of human mobility has grown rapidly over the past decade. This body of work has argued that human mobility is scale-free, has proposed models to generate scale-free moving distance distribution, and explained how the scale-free distribution arises from aggregating displacements across scales. However, the field of human mobility has not explicitly addressed how mobility is structured by geographical constraints - such as the outlines of landmasses, lakes, rivers, the placement of buildings, roadways, and cities.\n  Using unique datasets capturing millions of movements between precise locations, this paper shows how separating the effect of geography from mobility choices reveals a universal power law spanning five orders of magnitude (from 10 m to 1,000,000 m). We incorporate geography through the pair distribution function, a fundamental quantity from condensed matter physics that encapsulates the structure of locations on which mobility occurs. This distribution captures the constraints that geography places on human mobility across different length scales.\n  Our description conclusively addresses debates between distance-based and opportunity-based perspectives on human mobility. By demonstrating how the spatial distribution of human settlements shapes human mobility, we provide a novel perspective that bridges the gap between these previously opposing ideas."}, "https://arxiv.org/abs/2405.08013": {"title": "CTRL: Continuous-Time Representation Learning on Temporal Heterogeneous Information Network", "link": "https://arxiv.org/abs/2405.08013", "description": "arXiv:2405.08013v1 Announce Type: cross \nAbstract: Inductive representation learning on temporal heterogeneous graphs is crucial for scalable deep learning on heterogeneous information networks (HINs) which are time-varying, such as citation networks. However, most existing approaches are not inductive and thus cannot handle new nodes or edges. Moreover, previous temporal graph embedding methods are often trained with the temporal link prediction task to simulate the link formation process of temporal graphs, while ignoring the evolution of high-order topological structures on temporal graphs. To fill these gaps, we propose a Continuous-Time Representation Learning (CTRL) model on temporal HINs. To preserve heterogeneous node features and temporal structures, CTRL integrates three parts in a single layer, they are 1) a \\emph{heterogeneous attention} unit that measures the semantic correlation between nodes, 2) a \\emph{edge-based Hawkes process} to capture temporal influence between heterogeneous nodes, and 3) \\emph{dynamic centrality} that indicates the dynamic importance of a node. We train the CTRL model with a future event (a subgraph) prediction task to capture the evolution of the high-order network structure. Extensive experiments have been conducted on three benchmark datasets. The results demonstrate that our model significantly boosts performance and outperforms various state-of-the-art approaches. Ablation studies are conducted to demonstrate the effectiveness of the model design."}, "https://arxiv.org/abs/2405.08278": {"title": "Facilitating Feature and Topology Lightweighting: An Ethereum Transaction Graph Compression Method for Malicious Account Detection", "link": "https://arxiv.org/abs/2405.08278", "description": "arXiv:2405.08278v1 Announce Type: cross \nAbstract: Ethereum has become one of the primary global platforms for cryptocurrency, playing an important role in promoting the diversification of the financial ecosystem. However, the relative lag in regulation has led to a proliferation of malicious activities in Ethereum, posing a serious threat to fund security. Existing regulatory methods usually detect malicious accounts through feature engineering or large-scale transaction graph mining. However, due to the immense scale of transaction data and malicious attacks, these methods suffer from inefficiency and low robustness during data processing and anomaly detection. In this regard, we propose an Ethereum Transaction Graph Compression method named TGC4Eth, which assists malicious account detection by lightweighting both features and topology of the transaction graph. At the feature level, we select transaction features based on their low importance to improve the robustness of the subsequent detection models against feature evasion attacks; at the topology level, we employ focusing and coarsening processes to compress the structure of the transaction graph, thereby improving both data processing and inference efficiency of detection models. Extensive experiments demonstrate that TGC4Eth significantly improves the computational efficiency of existing detection models while preserving the connectivity of the transaction graph. Furthermore, TGC4Eth enables existing detection models to maintain stable performance and exhibit high robustness against feature evasion attacks."}, "https://arxiv.org/abs/2405.08465": {"title": "How to Surprisingly Consider Recommendations? A Knowledge-Graph-based Approach Relying on Complex Network Metrics", "link": "https://arxiv.org/abs/2405.08465", "description": "arXiv:2405.08465v1 Announce Type: cross \nAbstract: Traditional recommendation proposals, including content-based and collaborative filtering, usually focus on similarity between items or users. Existing approaches lack ways of introducing unexpectedness into recommendations, prioritizing globally popular items over exposing users to unforeseen items. This investigation aims to design and evaluate a novel layer on top of recommender systems suited to incorporate relational information and suggest items with a user-defined degree of surprise. We propose a Knowledge Graph (KG) based recommender system by encoding user interactions on item catalogs. Our study explores whether network-level metrics on KGs can influence the degree of surprise in recommendations. We hypothesize that surprisingness correlates with certain network metrics, treating user profiles as subgraphs within a larger catalog KG. The achieved solution reranks recommendations based on their impact on structural graph metrics. Our research contributes to optimizing recommendations to reflect the metrics. We experimentally evaluate our approach on two datasets of LastFM listening histories and synthetic Netflix viewing profiles. We find that reranking items based on complex network metrics leads to a more unexpected and surprising composition of recommendation lists."}, "https://arxiv.org/abs/2405.08515": {"title": "Precarious Experiences: Citizens' Frustrations, Anxieties and Burdens of an Online Welfare Benefit System", "link": "https://arxiv.org/abs/2405.08515", "description": "arXiv:2405.08515v1 Announce Type: cross \nAbstract: There is a significant overlap between people who are supported by income-related social welfare benefits, often in precarious situations, and those who experience greater digital exclusion. We report on a study of claimants using the UK's Universal Credit online welfare benefit system designed as, and still, \"digital by default\". Through data collection involving remote interviews (n=11) and online surveys (n=66), we expose claimants' own lived experiences interacting with this system. The claimants explain how digital channels can contribute to an imbalance of power and agency, at a time when their own circumstances mean they have reduced abilities, resources and capacities, and where design choices can adversely affect people's utility to leverage help from their own wider socio-technical ecosystems. We contribute eight recommendations from these accounts to inform the future design and development of digital welfare benefit systems for this population, to reduce digital barriers and harms."}, "https://arxiv.org/abs/2405.08784": {"title": "Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram", "link": "https://arxiv.org/abs/2405.08784", "description": "arXiv:2405.08784v1 Announce Type: cross \nAbstract: We used a dictionary built from biomedical terminology extracted from various sources such as DrugBank, MedDRA, MedlinePlus, TCMGeneDIT, to tag more than 8 million Instagram posts by users who have mentioned an epilepsy-relevant drug at least once, between 2010 and early 2016. A random sample of 1,771 posts with 2,947 term matches was evaluated by human annotators to identify false-positives. OpenAI's GPT series models were compared against human annotation. Frequent terms with a high false-positive rate were removed from the dictionary. Analysis of the estimated false-positive rates of the annotated terms revealed 8 ambiguous terms (plus synonyms) used in Instagram posts, which were removed from the original dictionary. To study the effect of removing those terms, we constructed knowledge networks using the refined and the original dictionaries and performed an eigenvector-centrality analysis on both networks. We show that the refined dictionary thus produced leads to a significantly different rank of important terms, as measured by their eigenvector-centrality of the knowledge networks. Furthermore, the most important terms obtained after refinement are of greater medical relevance. In addition, we show that OpenAI's GPT series models fare worse than human annotators in this task."}, "https://arxiv.org/abs/2305.02902": {"title": "Biased versus unbiased numerical methods for stochastic simulations", "link": "https://arxiv.org/abs/2305.02902", "description": "arXiv:2305.02902v2 Announce Type: replace \nAbstract: Approximate numerical methods are one of the most used strategies to extract information from many-interacting-agents systems. In particular, numerical approximations are of extended use to deal with epidemic, ecological and biological models, since unbiased methods like the Gillespie algorithm can become unpractical due to high CPU time usage required. However, the use of approximations has been debated and there is no clear consensus about whether unbiased methods or biased approach is the best option. In this work, we derive scaling relations for the errors in approximations based on binomial extractions. This finding allows us to build rules to compute the optimal values of both the discretization time and number of realizations needed to compute averages with the biased method with a target precision and minimum CPU-time usage. Furthermore, we also present another rule to discern whether the unbiased method or biased approach is more efficient. Ultimately, we will show that the choice of the method should depend on the desired precision for the estimation of averages."}, "https://arxiv.org/abs/2312.11529": {"title": "Efficient and Scalable Graph Generation through Iterative Local Expansion", "link": "https://arxiv.org/abs/2312.11529", "description": "arXiv:2312.11529v4 Announce Type: replace \nAbstract: In the realm of generative models for graphs, extensive research has been conducted. However, most existing methods struggle with large graphs due to the complexity of representing the entire joint distribution across all node pairs and capturing both global and local graph structures simultaneously. To overcome these issues, we introduce a method that generates a graph by progressively expanding a single node to a target graph. In each step, nodes and edges are added in a localized manner through denoising diffusion, building first the global structure, and then refining the local details. The local generation avoids modeling the entire joint distribution over all node pairs, achieving substantial computational savings with subquadratic runtime relative to node count while maintaining high expressivity through multiscale generation. Our experiments show that our model achieves state-of-the-art performance on well-established benchmark datasets while successfully scaling to graphs with at least 5000 nodes. Our method is also the first to successfully extrapolate to graphs outside of the training distribution, showcasing a much better generalization capability over existing methods."}, "https://arxiv.org/abs/2404.00793": {"title": "Learning the mechanisms of network growth", "link": "https://arxiv.org/abs/2404.00793", "description": "arXiv:2404.00793v2 Announce Type: replace \nAbstract: We propose a novel model-selection method for dynamic networks. Our approach involves training a classifier on a large body of synthetic network data. The data is generated by simulating nine state-of-the-art random graph models for dynamic networks, with parameter range chosen to ensure exponential growth of the network size in time. We design a conceptually novel type of dynamic features that count new links received by a group of vertices in a particular time interval. The proposed features are easy to compute, analytically tractable, and interpretable. Our approach achieves a near-perfect classification of synthetic networks, exceeding the state-of-the-art by a large margin. Applying our classification method to real-world citation networks gives credibility to the claims in the literature that models with preferential attachment, fitness and aging fit real-world citation networks best, although sometimes, the predicted model does not involve vertex fitness."}, "https://arxiv.org/abs/2405.01514": {"title": "Valuing maintenance strategies for fusion plants as part of a future electricity grid", "link": "https://arxiv.org/abs/2405.01514", "description": "arXiv:2405.01514v2 Announce Type: replace \nAbstract: Scheduled maintenance is likely to be lengthy and therefore consequential for the economics of fusion power plants. The maintenance strategy that maximizes the economic value of a plant depends on internal factors such as the cost and durability of the replaceable components, the frequency and duration of the maintenance blocks, and the external factors of the electricity system in which the plant operates. This paper examines the value of fusion power plants with various maintenance properties in a decarbonized United States Eastern Interconnection circa 2050. Seasonal variations in electricity supply and demand mean that certain times of year, particularly spring to early summer, are best for scheduled maintenance. Seasonality has two important consequences. First, the value of a plant can be 15% higher than what one would naively expect if value were directly proportional to its availability. Second, in some cases, replacing fractions of a component in shorter maintenance blocks spread over multiple years is better than replacing it all at once during a longer outage, even through the overall availability of the plant is lower in the former scenario."}, "https://arxiv.org/abs/2401.10057": {"title": "A method for characterizing disease emergence curves from paired pathogen detection and serology data", "link": "https://arxiv.org/abs/2401.10057", "description": "arXiv:2401.10057v2 Announce Type: replace-cross \nAbstract: Wildlife disease surveillance programs and research studies track infection and identify risk factors for wild populations, humans, and agriculture. Often, several types of samples are collected from individuals to provide more complete information about an animal's infection history. Methods that jointly analyze multiple data streams to study disease emergence and drivers of infection via epidemiological process models remain underdeveloped. Joint-analysis methods can more thoroughly analyze all available data, more precisely quantifying epidemic processes, outbreak status, and risks. We contribute a paired data modeling approach that analyzes multiple samples from individuals. We use \"characterization maps\" to link paired data to epidemiological processes through a hierarchical statistical observation model. Our approach can provide both Bayesian and frequentist estimates of epidemiological parameters and state. We motivate our approach through the need to use paired pathogen and antibody detection tests to estimate parameters and infection trajectories for the widely applicable susceptible, infectious, recovered (SIR) model. We contribute general formulas to link characterization maps to arbitrary process models and datasets and an extended SIR model that better accommodates paired data. We find via simulation that paired data can more efficiently estimate SIR parameters than unpaired data, requiring samples from 5-10 times fewer individuals. We then study SARS-CoV-2 in wild White-tailed deer (Odocoileus virginianus) from three counties in the United States. Estimates for average infectious times corroborate captive animal studies. Our methods use general statistical theory to let applications extend beyond the SIR model we consider, and to more complicated examples of paired data."}, "https://arxiv.org/abs/2405.00808": {"title": "ReeSPOT: Reeb Graph Models Semantic Patterns of Normalcy in Human Trajectories", "link": "https://arxiv.org/abs/2405.00808", "description": "arXiv:2405.00808v2 Announce Type: replace-cross \nAbstract: This paper introduces ReeSPOT, a novel Reeb graph-based method to model patterns of life in human trajectories (akin to a fingerprint). Human behavior typically follows a pattern of normalcy in day-to-day activities. This is marked by recurring activities within specific time periods. In this paper, we model this behavior using Reeb graphs where any deviation from usual day-to-day activities is encoded as nodes in the Reeb graph. The complexity of the proposed algorithm is linear with respect to the number of time points in a given trajectory. We demonstrate the usage of ReeSPOT and how it captures the critically significant spatial and temporal deviations using the nodes of the Reeb graph. Our case study presented in this paper includes realistic human movement scenarios: visiting uncommon locations, taking odd routes at infrequent times, uncommon time visits, and uncommon stay durations. We analyze the Reeb graph to interpret the topological structure of the GPS trajectories. Potential applications of ReeSPOT include urban planning, security surveillance, and behavioral research."}, "https://arxiv.org/abs/2405.09185": {"title": "Influence Maximization in Hypergraphs Using A Genetic Algorithm with New Initialization and Evaluation Methods", "link": "https://arxiv.org/abs/2405.09185", "description": "arXiv:2405.09185v1 Announce Type: new \nAbstract: Influence maximization (IM) is a crucial optimization task related to analyzing complex networks in the real world, such as social networks, disease propagation networks, and marketing networks. Publications to date about the IM problem focus mainly on graphs, which fail to capture high-order interaction relationships from the real world. Therefore, the use of hypergraphs for addressing the IM problem has been receiving increasing attention. However, identifying the most influential nodes in hypergraphs remains challenging, mainly because nodes and hyperedges are often strongly coupled and correlated. In this paper, to effectively identify the most influential nodes, we first propose a novel hypergraph-independent cascade model that integrates the influences of both node and hyperedge failures. Afterward, we introduce genetic algorithms (GA) to identify the most influential nodes that leverage hypergraph collective influences. In the GA-based method, the hypergraph collective influence is effectively used to initialize the population, thereby enhancing the quality of initial candidate solutions. The designed fitness function considers the joint influences of both nodes and hyperedges. This ensures the optimal set of nodes with the best influence on both nodes and hyperedges to be evaluated accurately. Moreover, a new mutation operator is designed by introducing factors, i.e., the collective influence and overlapping effects of nodes in hypergraphs, to breed high-quality offspring. In the experiments, several simulations on both synthetic and real hypergraphs have been conducted, and the results demonstrate that the proposed method outperforms the compared methods."}, "https://arxiv.org/abs/2405.09357": {"title": "A universal optimization framework based on cycle ranking for influence maximization in complex networks", "link": "https://arxiv.org/abs/2405.09357", "description": "arXiv:2405.09357v1 Announce Type: new \nAbstract: Influence maximization aims to identify a set of influential individuals, referred to as influencers, as information sources to maximize the spread of information within networks, constituting a vital combinatorial optimization problem with extensive practical applications and sustained interdisciplinary interest. Diverse approaches have been devised to efficiently address this issue, one of which involves selecting the influencers from a given centrality ranking. In this paper, we propose a novel optimization framework based on ranking basic cycles in networks, capable of selecting the influencers from diverse centrality measures. The experimental results demonstrate that, compared to directly selecting the top-k nodes from centrality sequences and other state-of-the-art optimization approaches, the new framework can expand the dissemination range by 1.5 to 3 times. Counterintuitively, it exhibits minimal hub property, with the average distance between influencers being only one-third of alternative approaches, regardless of the centrality metrics or network types. Our study not only paves the way for novel strategies in influence maximization but also underscores the unique potential of underappreciated cycle structures."}, "https://arxiv.org/abs/2405.09488": {"title": "Nonequilibrium phase transitions and absorbing states in a model for the dynamics of religious affiliation", "link": "https://arxiv.org/abs/2405.09488", "description": "arXiv:2405.09488v1 Announce Type: new \nAbstract: We propose a simple model to describe the dynamics of religious affiliation. For such purpose, we built a compartmental model with three distinct subpopulations, namely religious committed individuals, religious noncommitted individuals and not religious affiliated individuals. The transitions among the compartments are governed by probabilities, modeling social interactions among the groups and also spontaneous transitions among the compartments. First of all, we consider the model on a fully-connected network. Thus, we write a set of ordinary differential equations to study the evolution of the subpopulations. Our analytical and numerical results show that there is an absorbing state in the model where only one of the subpopulations survive in the long-time limit. There are also regions of parameters where some of the subpopulations coexist (two or three). We also verified the occurrence of two distinct critical points. In addition, we also present Monte Carlo simulations of the model on two-dimensional square lattices, in order to analyze the impact of the presence of a lattice structure on the critical behavior of the model. Comparison of the models' results with data for religious affiliation in Northern Ireland shows a good qualitative agreement. Finally, we considered the presence of inflexible individuals in the population, i.e., individuals that never change their states. The impact of such special agents on the critical behavior of the model is also discussed."}, "https://arxiv.org/abs/2405.08830": {"title": "Evaluating Supply Chain Resilience During Pandemic Using Agent-based Simulation", "link": "https://arxiv.org/abs/2405.08830", "description": "arXiv:2405.08830v1 Announce Type: cross \nAbstract: Recent pandemics have highlighted vulnerabilities in our global economic systems, especially supply chains. Possible future pandemic raises a dilemma for businesses owners between short-term profitability and long-term supply chain resilience planning. In this study, we propose a novel agent-based simulation model integrating extended Susceptible-Infected-Recovered (SIR) epidemiological model and supply and demand economic model to evaluate supply chain resilience strategies during pandemics. Using this model, we explore a range of supply chain resilience strategies under pandemic scenarios using in silico experiments. We find that a balanced approach to supply chain resilience performs better in both pandemic and non-pandemic times compared to extreme strategies, highlighting the importance of preparedness in the form of a better supply chain resilience. However, our analysis shows that the exact supply chain resilience strategy is hard to obtain for each firm and is relatively sensitive to the exact profile of the pandemic and economic state at the beginning of the pandemic. As such, we used a machine learning model that uses the agent-based simulation to estimate a near-optimal supply chain resilience strategy for a firm. The proposed model offers insights for policymakers and businesses to enhance supply chain resilience in the face of future pandemics, contributing to understanding the trade-offs between short-term gains and long-term sustainability in supply chain management before and during pandemics."}, "https://arxiv.org/abs/2405.09529": {"title": "Artificial Intelligence for the Internal Democracy of Political Parties", "link": "https://arxiv.org/abs/2405.09529", "description": "arXiv:2405.09529v1 Announce Type: cross \nAbstract: The article argues that AI can enhance the measurement and implementation of democratic processes within political parties, known as Intra-Party Democracy (IPD). It identifies the limitations of traditional methods for measuring IPD, which often rely on formal parameters, self-reported data, and tools like surveys. Such limitations lead to the collection of partial data, rare updates, and significant demands on resources. To address these issues, the article suggests that specific data management and Machine Learning (ML) techniques, such as natural language processing and sentiment analysis, can improve the measurement (ML about) and practice (ML for) of IPD. The article concludes by considering some of the principal risks of ML for IPD, including concerns over data privacy, the potential for manipulation, and the dangers of overreliance on technology."}, "https://arxiv.org/abs/2310.16451": {"title": "The Small-World Effect for Interferometer Networks", "link": "https://arxiv.org/abs/2310.16451", "description": "arXiv:2310.16451v2 Announce Type: replace \nAbstract: Complex network theory has focused on properties of networks with real-valued edge weights. However, in signal transfer networks, such as those representing the transfer of light across an interferometer, complex-valued edge weights are needed to represent the manipulation of the signal in both magnitude and phase. These complex-valued edge weights introduce interference into the signal transfer, but it is unknown how such interference affects network properties such as small-worldness. To address this gap, we have introduced a small-world interferometer network model with complex-valued edge weights and generalized existing network measures to define the interferometric clustering coefficient, the apparent path length, and the interferometric small-world coefficient. Using high-performance computing resources, we generated a large set of small-world interferometers over a wide range of parameters in system size, nearest-neighbor count, and edge-weight phase and computed their interferometric network measures. We found that the interferometric small-world coefficient depends significantly on the amount of phase on complex-valued edge weights: for small edge-weight phases, constructive interference led to a higher interferometric small-world coefficient; while larger edge-weight phases induced destructive interference which led to a lower interferometric small-world coefficient. Thus, for the small-world interferometer model, interferometric measures are necessary to capture the effect of interference on signal transfer. This model is an example of the type of problem that necessitates interferometric measures, and applies to any wave-based network including quantum networks."}, "https://arxiv.org/abs/2403.08493": {"title": "Rumor Forwarding Prediction Model Based on Uncertain Time Series", "link": "https://arxiv.org/abs/2403.08493", "description": "arXiv:2403.08493v2 Announce Type: replace \nAbstract: The rapid spread of rumors in social media is mainly caused by individual retweets. This paper applies uncertainty time series analysis (UTSA) to analyze a rumor retweeting behavior on Weibo. First, the rumor forwarding is modeled using uncertain time series, including order selection, parameter estimation, residual analysis, uncertainty hypothesis testing and forecast, and the validity of using uncertain time series analysis is further supported by analyzing the characteristics of the residual plot. The experimental results show that the uncertain time series can better predict the next stage of rumor forwarding. The results of the study have important practical significance for rumor management and the management of social media information dissemination."}, "https://arxiv.org/abs/2306.05597": {"title": "On the implementation of zero-determinant strategies in repeated games", "link": "https://arxiv.org/abs/2306.05597", "description": "arXiv:2306.05597v2 Announce Type: replace-cross \nAbstract: Zero-determinant strategies are a class of strategies in repeated games which unilaterally control payoffs. Zero-determinant strategies have attracted much attention in studies of social dilemma, particularly in the context of evolution of cooperation. So far, not only general properties of zero-determinant strategies have been investigated, but zero-determinant strategies have been applied to control in the fields of information and communications technology and analysis of imitation. Here, we further deepen our understanding on general mathematical properties of zero-determinant strategies. We first prove that zero-determinant strategies, if exist, can be implemented by some one-dimensional transition probability. Next, we prove that, if a two-player game has a non-trivial potential function, a zero-determinant strategy exists in its repeated version. These results assist us to implement zero-determinant strategies in broader situations."}, "https://arxiv.org/abs/2405.09640": {"title": "Personalized Content Moderation and Emergent Outcomes", "link": "https://arxiv.org/abs/2405.09640", "description": "arXiv:2405.09640v1 Announce Type: new \nAbstract: Social media platforms have implemented automated content moderation tools to preserve community norms and mitigate online hate and harassment. Recently, these platforms have started to offer Personalized Content Moderation (PCM), granting users control over moderation settings or aligning algorithms with individual user preferences. While PCM addresses the limitations of the one-size-fits-all approach and enhances user experiences, it may also impact emergent outcomes on social media platforms. Our study reveals that PCM leads to asymmetric information loss (AIL), potentially impeding the development of a shared understanding among users, crucial for healthy community dynamics. We further demonstrate that PCM tools could foster the creation of echo chambers and filter bubbles, resulting in increased community polarization. Our research is the first to identify AIL as a consequence of PCM and to highlight its potential negative impacts on online communities."}, "https://arxiv.org/abs/2405.09643": {"title": "Energy Consumption of Plant Factory with Artificial Light: Challenges and Opportunities", "link": "https://arxiv.org/abs/2405.09643", "description": "arXiv:2405.09643v1 Announce Type: new \nAbstract: Plant factory with artificial light (PFAL) is a promising technology for relieving the food crisis, especially in urban areas or arid regions endowed with abundant resources. However, lighting and HVAC (heating, ventilation, and air conditioning) systems of PFAL have led to much greater energy consumption than open-field and greenhouse farming, limiting the application of PFAL to a wider extent. Recent researches pay much more attention to the optimization of energy consumption in order to develop and promote the PFAL technology with reduced energy usage. This work comprehensively summarizes the current energy-saving methods on lighting, HVAC systems, as well as their coupling methods for a more energy-efficient PFAL. Besides, we offer our perspectives on further energy-saving strategies and exploit the renewable energy resources for PFAL to respond to the urgent need for energy-efficient production."}, "https://arxiv.org/abs/2405.09978": {"title": "Pedestrian evacuations with imitation of cooperative behavior", "link": "https://arxiv.org/abs/2405.09978", "description": "arXiv:2405.09978v1 Announce Type: new \nAbstract: We analyze the dynamics of room evacuation for mixed populations that include both competitive and cooperative individuals through numerical simulations using the social force model. Cooperative agents represent well-trained individuals who know how to behave in order to reduce risks within high-density crowds. We consider that competitive agents can imitate cooperative behavior when they are in close proximity to cooperators. We study the effects of the imitation of cooperative behavior on the duration and safety of evacuations, analyzing evacuation time and other quantities of interest for varying parameters such as the proportions of mixing, the aspect ratio of the room, and the parameters characterizing individual behaviors. Our main findings reveal that the addition of a relatively small number of cooperative agents into a crowd can reduce evacuation time and the density near the exit door, making the evacuation faster and safer despite an increase in the total number of agents. In particular, for long spaces such as corridors, a small number of added cooperative agents can significantly facilitate the evacuation process. We compare our results with those of systems without imitation and also study the general role of cooperation, providing further analysis for homogeneous populations. Our main conclusions emphasize the potential relevance of training people how to behave in high-density crowds"}, "https://arxiv.org/abs/2405.10187": {"title": "Influence Maximization in Hypergraphs using Multi-Objective Evolutionary Algorithms", "link": "https://arxiv.org/abs/2405.10187", "description": "arXiv:2405.10187v1 Announce Type: new \nAbstract: The Influence Maximization (IM) problem is a well-known NP-hard combinatorial problem over graphs whose goal is to find the set of nodes in a network that spreads influence at most. Among the various methods for solving the IM problem, evolutionary algorithms (EAs) have been shown to be particularly effective. While the literature on the topic is particularly ample, only a few attempts have been made at solving the IM problem over higher-order networks, namely extensions of standard graphs that can capture interactions that involve more than two nodes. Hypergraphs are a valuable tool for modeling complex interaction networks in various domains; however, they require rethinking of several graph-based problems, including IM. In this work, we propose a multi-objective EA for the IM problem over hypergraphs that leverages smart initialization and hypergraph-aware mutation. While the existing methods rely on greedy or heuristic methods, to our best knowledge this is the first attempt at applying EAs to this problem. Our results over nine real-world datasets and three propagation models, compared with five baseline algorithms, reveal that our method achieves in most cases state-of-the-art results in terms of hypervolume and solution diversity."}, "https://arxiv.org/abs/2405.10213": {"title": "Words as Trigger Points in Social Media Discussions", "link": "https://arxiv.org/abs/2405.10213", "description": "arXiv:2405.10213v1 Announce Type: new \nAbstract: Trigger points are a concept introduced by Mau, Lux, and Westheuser (2023) to study qualitative focus group interviews and understand polarisation in Germany. When people communicate, trigger points represent moments when individuals feel that their understanding of what is fair, normal, or appropriate in society is questioned. In the original studies, individuals react affectively to such triggers and show strong and negative emotional responses. In this paper, we introduce the first systematic study of the large-scale effect of individual words as trigger points by analysing a large amount of social media posts. We examine online deliberations on Reddit between 2020 and 2022 and collect >100 million posts from subreddits related to a set of words identified as trigger points in UK politics. We find that such trigger words affect user engagement and have noticeable consequences on animosity in online discussions. We share empirical evidence of trigger words causing animosity, and how they provide incentives for hate speech, adversarial debates, and disagreements. Our work is the first to introduce trigger points to computational studies of online communication. Our findings are relevant to researchers interested in online harms and who examine how citizens debate politics and society in light of affective polarisation."}, "https://arxiv.org/abs/2405.10233": {"title": "iDRAMA-Scored-2024: A Dataset of the Scored Social Media Platform from 2020 to 2023", "link": "https://arxiv.org/abs/2405.10233", "description": "arXiv:2405.10233v1 Announce Type: new \nAbstract: Online web communities often face bans for violating platform policies, encouraging their migration to alternative platforms. This migration, however, can result in increased toxicity and unforeseen consequences on the new platform. In recent years, researchers have collected data from many alternative platforms, indicating coordinated efforts leading to offline events, conspiracy movements, hate speech propagation, and harassment. Thus, it becomes crucial to characterize and understand these alternative platforms. To advance research in this direction, we collect and release a large-scale dataset from Scored -- an alternative Reddit platform that sheltered banned fringe communities, for example, c/TheDonald (a prominent right-wing community) and c/GreatAwakening (a conspiratorial community). Over four years, we collected approximately 57M posts from Scored, with at least 58 communities identified as migrating from Reddit and over 950 communities created since the platform's inception. Furthermore, we provide sentence embeddings of all posts in our dataset, generated through a state-of-the-art model, to further advance the field in characterizing the discussions within these communities. We aim to provide these resources to facilitate their investigations without the need for extensive data collection and processing efforts."}, "https://arxiv.org/abs/2405.09982": {"title": "Dynamical behavior and optimal control of a stochastic SAIRS epidemic model with two saturated incidences", "link": "https://arxiv.org/abs/2405.09982", "description": "arXiv:2405.09982v1 Announce Type: cross \nAbstract: Stochastic models are widely used to investigate the spread of epidemics in a complex environment. This paper extends a deterministic SAIRS epidemic model to a stochastic case with limited patient capacity and exposure. We first study the dynamical properties of the model under certain conditions, including persistence, extinction, and ergodic. Then, we introduce vaccination and isolation into the model as control variables. The optimal control strategies are obtained based on the Pontryagin minimum principle. Finally, numerical simulations are given to illustrate our theoretical results."}, "https://arxiv.org/abs/2307.04612": {"title": "Emergence of Cooperation in Two-agent Repeated Games with Reinforcement Learning", "link": "https://arxiv.org/abs/2307.04612", "description": "arXiv:2307.04612v2 Announce Type: replace \nAbstract: Cooperation is the foundation of ecosystems and the human society, and the reinforcement learning provides crucial insight into the mechanism for its emergence. However, most previous work has mostly focused on the self-organization at the population level, the fundamental dynamics at the individual level remains unclear. Here, we investigate the evolution of cooperation in a two-agent system, where each agent pursues optimal policies according to the classical Q-learning algorithm in playing the strict prisoner's dilemma. We reveal that a strong memory and long-sighted expectation yield the emergence of Coordinated Optimal Policies (COPs), where both agents act like Win-Stay, Lose-Shift (WSLS) to maintain a high level of cooperation. Otherwise, players become tolerant toward their co-player's defection and the cooperation loses stability in the end where the policy all Defection (All-D) prevails. This suggests that tolerance could be a good precursor to a crisis in cooperation. Furthermore, our analysis shows that the Coordinated Optimal Modes (COMs) for different COPs gradually lose stability as memory weakens and expectation for the future decreases, where agents fail to predict co-player's action in games and defection dominates. As a result, we give the constraint to expectations of future and memory strength for maintaining cooperation. In contrast to the previous work, the impact of exploration on cooperation is found not be consistent, but depends on composition of COMs. By clarifying these fundamental issues in this two-player system, we hope that our work could be helpful for understanding the emergence and stability of cooperation in more complex scenarios in reality."}, "https://arxiv.org/abs/2401.12732": {"title": "CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process", "link": "https://arxiv.org/abs/2401.12732", "description": "arXiv:2401.12732v2 Announce Type: replace-cross \nAbstract: Cross-domain recommendation (CDR) has been proven as a promising way to tackle the user cold-start problem, which aims to make recommendations for users in the target domain by transferring the user preference derived from the source domain. Traditional CDR studies follow the embedding and mapping (EMCDR) paradigm, which transfers user representations from the source to target domain by learning a user-shared mapping function, neglecting the user-specific preference. Recent CDR studies attempt to learn user-specific mapping functions in meta-learning paradigm, which regards each user's CDR as an individual task, but neglects the preference correlations among users, limiting the beneficial information for user representations. Moreover, both of the paradigms neglect the explicit user-item interactions from both domains during the mapping process. To address the above issues, this paper proposes a novel CDR framework with neural process (NP), termed as CDRNP. Particularly, it develops the meta-learning paradigm to leverage user-specific preference, and further introduces a stochastic process by NP to capture the preference correlations among the overlapping and cold-start users, thus generating more powerful mapping functions by mapping the user-specific preference and common preference correlations to a predictive probability distribution. In addition, we also introduce a preference remainer to enhance the common preference from the overlapping users, and finally devises an adaptive conditional decoder with preference modulation to make prediction for cold-start users with items in the target domain. Experimental results demonstrate that CDRNP outperforms previous SOTA methods in three real-world CDR scenarios."}, "https://arxiv.org/abs/2405.10322": {"title": "Exploring the Independent Cascade Model and Its Evolution in Social Network Information Diffusion", "link": "https://arxiv.org/abs/2405.10322", "description": "arXiv:2405.10322v1 Announce Type: new \nAbstract: This paper delves into the paramount significance of information dissemination within the dynamic realm of social networks. It underscores the pivotal role of information communication models in unraveling the intricacies of data propagation in the digital age. By shedding light on the profound influence of these models, it not only lays the groundwork for exploring various hierarchies and their manifestations but also serves as a catalyst for further research in this formidable field."}, "https://arxiv.org/abs/2405.10338": {"title": "Financial Interactions and Capital Accumulation", "link": "https://arxiv.org/abs/2405.10338", "description": "arXiv:2405.10338v1 Announce Type: new \nAbstract: In a series of precedent papers, we have presented a comprehensive methodology, termed Field Economics, for translating a standard economic model into a statistical field-formalism framework. This formalism requires a large number of heterogeneous agents, possibly of different types. It reveals the emergence of collective states among these agents or type of agents while preserving the interactions and microeconomic features of the system at the individual level. In two prior papers, we applied this formalism to analyze the dynamics of capital allocation and accumulation in a simple microeconomic framework of investors and firms.Building upon our prior work, the present paper refines the initial model by expanding its scope. Instead of considering financial firms investing solely in real sectors, we now suppose that financial agents may also invest in other financial firms. We also introduce banks in the system that act as investors with a credit multiplier. Two types of interaction are now considered within the financial sector: financial agents can lend capital to, or choose to buy shares of, other financial firms. Capital now flows between financial agents and is only partly invested in real sectors, depending on their relative returns. We translate this framework into our formalism and study the diffusion of capital and possible defaults in the system, both at the macro and micro level.At the macro level, we find that several collective states may emerge, each characterized by a distinct level of average capital and investors per sector. These collective states depend on external parameters such as level of connections between investors or firms' productivity.The multiplicity of possible collective states is the consequence of the nature of the system composed of interconnected heterogeneous agents. Several equivalent patterns of returns and portfolio allocation may emerge. The multiple collective states induce the unstable nature of financial markets, and some of them include defaults may emerge. At the micro level, we study the propagation of returns and defaults within a given collective state. Our findings highlight the significant role of banks, which can either stabilize the system through lending activities or propagate instability through loans to investors."}, "https://arxiv.org/abs/2405.10355": {"title": "Assessing the Impact of Case Correction Methods on the Fairness of COVID-19 Predictive Models", "link": "https://arxiv.org/abs/2405.10355", "description": "arXiv:2405.10355v1 Announce Type: new \nAbstract: One of the central difficulties of addressing the COVID-19 pandemic has been accurately measuring and predicting the spread of infections. In particular, official COVID-19 case counts in the United States are under counts of actual caseloads due to the absence of universal testing policies. Researchers have proposed a variety of methods for recovering true caseloads, often through the estimation of statistical models on more reliable measures, such as death and hospitalization counts, positivity rates, and demographics. However, given the disproportionate impact of COVID-19 on marginalized racial, ethnic, and socioeconomic groups, it is important to consider potential unintended effects of case correction methods on these groups. Thus, we investigate two of these correction methods for their impact on a downstream COVID-19 case prediction task. For that purpose, we tailor an auditing approach and evaluation protocol to analyze the fairness of the COVID-19 prediction task by measuring the difference in model performance between majority-White counties and majority-minority counties. We find that one of the correction methods improves fairness, decreasing differences in performance between majority-White and majority-minority counties, while the other method increases differences, introducing bias. While these results are mixed, it is evident that correction methods have the potential to exacerbate existing biases in COVID-19 case data and in downstream prediction tasks. Researchers planning to develop or use case correction methods must be careful to consider negative effects on marginalized groups."}, "https://arxiv.org/abs/2405.10417": {"title": "Cosmic rays for imaging cultural heritage objects", "link": "https://arxiv.org/abs/2405.10417", "description": "arXiv:2405.10417v1 Announce Type: new \nAbstract: In cultural heritage conservation, it is increasingly common to rely on non-destructive imaging methods based on the absorption or scattering of photons ($X$ or $\\gamma$ rays) or neutrons. However, physical and practical issues limit these techniques: their penetration depth may be insufficient for large and dense objects, they require transporting the objects of interest to dedicated laboratories, artificial radiation is hazardous and may induce activation in the material under study. Muons are elementary particles abundantly and freely produced in cosmic-ray interactions in the atmosphere. Their absorption and scattering in matter are characteristically dependent on the density and elemental composition of the material that they traverse, which offers the possibility of exploiting them for sub-surface remote imaging. This novel technique, nicknamed \"muography\", has been applied in use cases ranging from geophysics to archaeology to nuclear safety, but it has been so far under-explored for a vast category of cultural heritage objects that are relatively large (from decimeters to human size) and dense (stone, metals). The development of portable muon detectors makes muography particularly competitive in cases where the items to be analysed are not transportable, or set up in a confined environment. This document reviews the relevant literature, presents some exemplary use cases, and critically assesses the strengths and weaknesses of muography in this context."}, "https://arxiv.org/abs/2405.10450": {"title": "Quantifying national space heating flexibility potential at high spatial resolution with heating consumption data", "link": "https://arxiv.org/abs/2405.10450", "description": "arXiv:2405.10450v1 Announce Type: new \nAbstract: Decarbonizing the building stock in cold countries by replacing fossil fuel boilers with heat pumps is expected to drastically increase electricity demand. While heating flexibility could reduce the impact of additional demand from heat pumps on the power system, characterizing the national spatial distribution of heating flexibility capacity to incorporate into sophisticated power system models is challenging. This paper introduces a novel method for quantifying at large scale and high spatial resolution the energy capacity and duration of heating flexibility in existing building stock based on historical heating consumption and temperature data. This method can reflect the geographic diversity of the national building stock in sophisticated power system models. The proposed heating consumption-based method was tested in Britain using national residential gas data. The results demonstrate the potential of this approach to characterize the heterogeneous distribution of heating flexibility capacity at the national scale. Assuming a 3$^\\circ$C temperature flexibility window, a total thermal energy storage capacity of 500 GWh$_{th}$ is identified in the British housing stock. For an illustrative cold weather COP value of 2.5, this thermal energy storage capacity is equivalent to 200 GWh of electricity storage. Regarding heating flexibility duration, gas-heated homes have a median of 5.9 heat-free hours for 20th percentile regional daily winter temperatures from 2010 to 2022. However, extreme cold days nearly halve flexibility duration to a median of 3.6 heat-free hours. These high spatial resolution energy capacity and self-discharge parameters can account for geographic diversity at the national scale and provide a new data-based layer of information for sophisticated power system models to support energy transition."}, "https://arxiv.org/abs/2405.10547": {"title": "GPTs Window Shopping: An analysis of the Landscape of Custom ChatGPT Models", "link": "https://arxiv.org/abs/2405.10547", "description": "arXiv:2405.10547v1 Announce Type: new \nAbstract: OpenAI's ChatGPT initiated a wave of technical iterations in the space of Large Language Models (LLMs) by demonstrating the capability and disruptive power of LLMs. OpenAI has prompted large organizations to respond with their own advancements and models to push the LLM performance envelope. OpenAI has prompted large organizations to respond with their own advancements and models to push the LLM performance envelope. OpenAI's success in spotlighting AI can be partially attributed to decreased barriers to entry, enabling any individual with an internet-enabled device to interact with LLMs. What was previously relegated to a few researchers and developers with necessary computing resources is now available to all. A desire to customize LLMs to better accommodate individual needs prompted OpenAI's creation of the GPT Store, a central platform where users can create and share custom GPT models. Customization comes in the form of prompt-tuning, analysis of reference resources, browsing, and external API interactions, alongside a promise of revenue sharing for created custom GPTs. In this work, we peer into the window of the GPT Store and measure its impact. Our analysis constitutes a large-scale overview of the store exploring community perception, GPT details, and the GPT authors, in addition to a deep-dive into a 3rd party storefront indexing user-submitted GPTs, exploring if creators seek to monetize their creations in the absence of OpenAI's revenue sharing."}, "https://arxiv.org/abs/2405.10558": {"title": "CACL: Community-Aware Heterogeneous Graph Contrastive Learning for Social Media Bot Detection", "link": "https://arxiv.org/abs/2405.10558", "description": "arXiv:2405.10558v1 Announce Type: new \nAbstract: Social media bot detection is increasingly crucial with the rise of social media platforms. Existing methods predominantly construct social networks as graph and utilize graph neural networks (GNNs) for bot detection. However, most of these methods focus on how to improve the performance of GNNs while neglecting the community structure within social networks. Moreover, GNNs based methods still face problems such as poor model generalization due to the relatively small scale of the dataset and over-smoothness caused by information propagation mechanism. To address these problems, we propose a Community-Aware Heterogeneous Graph Contrastive Learning framework (CACL), which constructs social network as heterogeneous graph with multiple node types and edge types, and then utilizes community-aware module to dynamically mine both hard positive samples and hard negative samples for supervised graph contrastive learning with adaptive graph enhancement algorithms. Extensive experiments demonstrate that our framework addresses the previously mentioned challenges and outperforms competitive baselines on three social media bot benchmarks."}, "https://arxiv.org/abs/2405.10640": {"title": "COMET: NFT Price Prediction with Wallet Profiling", "link": "https://arxiv.org/abs/2405.10640", "description": "arXiv:2405.10640v1 Announce Type: new \nAbstract: As the non-fungible token (NFT) market flourishes, price prediction emerges as a pivotal direction for investors gaining valuable insight to maximize returns. However, existing works suffer from a lack of practical definitions and standardized evaluations, limiting their practical application. Moreover, the influence of users' multi-behaviour transactions that are publicly accessible on NFT price is still not explored and exhibits challenges. In this paper, we address these gaps by presenting a practical and hierarchical problem definition. This approach unifies both collection-level and token-level task and evaluation methods, which cater to varied practical requirements of investors. To further understand the impact of user behaviours on the variation of NFT price, we propose a general wallet profiling framework and develop a COmmunity enhanced Multi-bEhavior Transaction graph model, named COMET. COMET profiles wallets with a comprehensive view and considers the impact of diverse relations and interactions within the NFT ecosystem on NFT price variations, thereby improving prediction performance. Extensive experiments conducted in our deployed system demonstrate the superiority of COMET, underscoring its potential in the insight toolkit for NFT investors."}, "https://arxiv.org/abs/2405.10665": {"title": "Leader-Follower Identification with Vehicle-Following Calibration for Non-Lane-Based Traffic", "link": "https://arxiv.org/abs/2405.10665", "description": "arXiv:2405.10665v1 Announce Type: new \nAbstract: Most car-following models were originally developed for lane-based traffic. Over the past two decades, efforts have been made to calibrate car-following models for non-lane-based traffic. However, traffic conditions with varying vehicle dimensions, intermittent following, and multiple leaders often occur and make subjective Leader-Follower (LF) pair identification challenging. In this study, we analyze Vehicle Following (VF) behavior in traffic with a lack of lane discipline using high-resolution microscopic trajectory data collected in Chennai, India. The paper's main contributions are threefold. Firstly, three criteria are used to identify LF pairs from the driver's perspective, taking into account the intermittent following, lack of lane discipline due to consideration of lateral separation, and the presence of in-between vehicles. Second, the psycho-physical concept of the regime in the Wiedemann-99 model is leveraged to determine the traffic-dependent \"influence zone\" for LF identification. Third, a joint and consistent framework is proposed for identifying LF pairs and estimating VF parameters. The proposed methodology outperforms other heuristic-based LF identification methods from the literature in terms of quantitative and qualitative performance measures. The proposed approach can enable robust and more realistic LF identification and VF parameter calibration with practical applications such as LOS analysis, capacity, and travel time estimation."}, "https://arxiv.org/abs/2405.10798": {"title": "Understanding following patterns among high-performance athletes", "link": "https://arxiv.org/abs/2405.10798", "description": "arXiv:2405.10798v1 Announce Type: new \nAbstract: Professional sports enhance interaction among athletes through training groups, sponsored events and competitions. Among these, the Olympic Games represent the largest competition with a global impact, providing the participants with a unique opportunity for interaction. We studied the following patterns among highly successful athletes to understand the structure of their interactions. We used the list of Olympic medallists in the Tokyo 2020 Games to extract their follower-followee network in Twitter, finding 7,326 connections among 964 athletes. The network displayed frequent connections to similar peers in terms of their features including sex, country and sport. We quantified the influence of these features in the followees choice through a gravity approach capturing the number of connections between homogeneous groups. Our research remarks the importance of datasets built from public exposure of professional athletes, serving as a proxy to investigate interesting aspects of many complex socio-cultural systems at different scales."}, "https://arxiv.org/abs/2405.10818": {"title": "Modeling Supply Chain Interaction and Disruption: Insights from Real-world Data and Complex Adaptive System", "link": "https://arxiv.org/abs/2405.10818", "description": "arXiv:2405.10818v1 Announce Type: new \nAbstract: In the rapidly evolving automotive industry, Systems-on-Chips (SoCs) are playing an increasingly crucial role in enhancing vehicle intelligence, connectivity, and safety features. For enterprises whose business encompasses automotive SoCs, the sustained and stable provision and receipt of SoC relevant goods or services are essential. Considering the imperative for a resilient and adaptable supply network, enterprises are concentrating their efforts on formulating strategies to address risks stemming from supply chain disruptions caused by technological obsolescence, natural disasters, and geopolitical tensions. This study presents an open supply knowledge extraction and complement approach and build a supply chain network of automotive SoC enterprises in China, which incorporates cross-domain named entity recognition under limited information, fuzzy matching of firm entities, and supply relation inferring based on knowledge graph. Subsequently, we exhibit the degree and registered capital distribution across firms, and analyze the correlations between centrality metrics in the supply chain network. Finally, based on recovery capacity and risk transfer, two interaction disruption models (IDMs) are developed to elucidate the adaptive behaviors and effect of network disruptions under various business and attack strategies. This research not only aids in exploring the complexities of Chinese automotive SoC supply chain but also enriches our understanding of the dynamics of firm behavior in this crucial industry sector."}, "https://arxiv.org/abs/2405.09843": {"title": "Organizational Selection of Innovation", "link": "https://arxiv.org/abs/2405.09843", "description": "arXiv:2405.09843v1 Announce Type: cross \nAbstract: Budgetary constraints force organizations to pursue only a subset of possible innovation projects. Identifying which subset is most promising is an error-prone exercise, and involving multiple decision makers may be prudent. This raises the question of how to most effectively aggregate their collective nous. Our model of organizational portfolio selection provides some first answers. We show that portfolio performance can vary widely. Delegating evaluation makes sense when organizations employ the relevant experts and can assign projects to them. In most other settings, aggregating the impressions of multiple agents leads to better performance than delegation. In particular, letting agents rank projects often outperforms alternative aggregation rules -- including averaging agents' project scores as well as counting their approval votes -- especially when organizations have tight budgets and can select only a few project alternatives out of many."}, "https://arxiv.org/abs/2405.10497": {"title": "SMP Challenge: An Overview and Analysis of Social Media Prediction Challenge", "link": "https://arxiv.org/abs/2405.10497", "description": "arXiv:2405.10497v1 Announce Type: cross \nAbstract: Social Media Popularity Prediction (SMPP) is a crucial task that involves automatically predicting future popularity values of online posts, leveraging vast amounts of multimodal data available on social media platforms. Studying and investigating social media popularity becomes central to various online applications and requires novel methods of comprehensive analysis, multimodal comprehension, and accurate prediction.\n  SMP Challenge is an annual research activity that has spurred academic exploration in this area. This paper summarizes the challenging task, data, and research progress. As a critical resource for evaluating and benchmarking predictive models, we have released a large-scale SMPD benchmark encompassing approximately half a million posts authored by around 70K users. The research progress analysis provides an overall analysis of the solutions and trends in recent years. The SMP Challenge website (www.smp-challenge.com) provides the latest information and news."}, "https://arxiv.org/abs/1609.00004": {"title": "On the initial value of PageRank", "link": "https://arxiv.org/abs/1609.00004", "description": "arXiv:1609.00004v5 Announce Type: replace \nAbstract: Google employs PageRank to rank web pages, determining the order in which search results are presented to users based on their queries. PageRank is primarily utilized for directed networks, although there are instances where it is also applied to undirected networks. In this paper, we have applied PageRank to undirected networks, showing that a vertex's PageRank relies on its initial value, often referred to as an intrinsic, non-network contribution. We have analytically proved that when the initial value of vertices is either proportional to their degrees or set to zero, the PageRank values of the vertices become directly proportional to their degrees. Simulated and empirical data are employed to bolster our research findings. Additionally, we have investigated the impact of initial values on PageRank localization."}, "https://arxiv.org/abs/2304.12751": {"title": "Node Feature Augmentation Vitaminizes Network Alignment", "link": "https://arxiv.org/abs/2304.12751", "description": "arXiv:2304.12751v4 Announce Type: replace \nAbstract: Network alignment (NA) is the task of discovering node correspondences across multiple networks. Although NA methods have achieved remarkable success in a myriad of scenarios, their effectiveness is not without additional information such as prior anchor links and/or node features, which may not always be available due to privacy concerns or access restrictions. To tackle this challenge, we propose Grad-Align+, a novel NA method built upon a recent state-of-the-art NA method, the so-called Grad-Align, that gradually discovers a part of node pairs until all node pairs are found. In designing Grad-Align+, we account for how to augment node features in the sense of performing the NA task and how to design our NA method by maximally exploiting the augmented node features. To achieve this goal, Grad-Align+ consists of three key components: 1) centrality-based node feature augmentation (CNFA), 2) graph neural network (GNN)-aided embedding similarity calculation alongside the augmented node features, and 3) gradual NA with similarity calculation using aligned cross-network neighbor-pairs (ACNs). Through comprehensive experiments, we demonstrate that Grad-Align+ exhibits (a) the superiority over benchmark NA methods, (b) empirical validations as well as our theoretical findings to see the effectiveness of CNFA, (c) the influence of each component, (d) the robustness to network noises, and (e) the computational efficiency."}, "https://arxiv.org/abs/2310.10155": {"title": "Analysis and implementation of nanotargeting on LinkedIn based on publicly available non-PII", "link": "https://arxiv.org/abs/2310.10155", "description": "arXiv:2310.10155v2 Announce Type: replace \nAbstract: The literature has shown that combining a few non-Personal Identifiable Information (non-PII) is enough to make a user unique in a dataset including millions of users. This work demonstrates that a combination of a few non-PII items can be activated to nanotarget users. We demonstrate that the combination of the location and {5} rare ({13} random) skills in a LinkedIn profile is enough to become unique in a user base of {$\\sim$970M} users with a probability of 75\\%. The novelty is that these attributes are publicly accessible to anyone registered on LinkedIn and can be activated through advertising campaigns. We ran an experiment configuring ad campaigns using the location and skills of three of the paper's authors, demonstrating how all the ads using $\\geq13$ skills were delivered exclusively to the targeted user. We reported this vulnerability to LinkedIn, which initially ignored the problem, but fixed it as of November 2023.%This nanotargeting may expose LinkedIn users to privacy and security risks such as malvertising or manipulation."}, "https://arxiv.org/abs/2402.03894": {"title": "Interpersonal trust: Asymptotic analysis of a stochastic coordination game with multi-agent learning", "link": "https://arxiv.org/abs/2402.03894", "description": "arXiv:2402.03894v3 Announce Type: replace \nAbstract: We study the interpersonal trust of a population of agents, asking whether chance may decide if a population ends up in a high trust or low trust state. We model this by a discrete time, random matching stochastic coordination game. Agents are endowed with an exponential smoothing learning rule about the behaviour of their neighbours. We find that, with probability one in the long run the whole population either always cooperates or always defects. By simulation we study the impact of the distributions of the payoffs in the game and of the exponential smoothing learning (memory of the agents). We find, that as the agent memory increases or as the size of the population increases, the actual dynamics start to resemble the expectation of the process. We conclude that it is indeed possible that different populations may converge upon high or low trust between its citizens simply by chance, though the game parameters (context of the society) may be quite telling."}, "https://arxiv.org/abs/2404.01319": {"title": "Information Cascade Prediction under Public Emergencies: A Survey", "link": "https://arxiv.org/abs/2404.01319", "description": "arXiv:2404.01319v2 Announce Type: replace \nAbstract: With the advent of the era of big data, massive information, expert experience, and high-accuracy models bring great opportunities to the information cascade prediction of public emergencies. However, the involvement of specialist knowledge from various disciplines has resulted in a primarily application-specific focus (e.g., earthquakes, floods, infectious diseases) for information cascade prediction of public emergencies. The lack of a unified prediction framework poses a challenge for classifying intersectional prediction methods across different application fields. This survey paper offers a systematic classification and summary of information cascade modeling, prediction, and application. We aim to help researchers identify cutting-edge research and comprehend models and methods of information cascade prediction under public emergencies. By summarizing open issues and outlining future directions in this field, this paper has the potential to be a valuable resource for researchers conducting further studies on predicting information cascades."}, "https://arxiv.org/abs/2311.03682": {"title": "Incentive Design for Eco-driving in Urban Transportation Networks", "link": "https://arxiv.org/abs/2311.03682", "description": "arXiv:2311.03682v2 Announce Type: replace-cross \nAbstract: Eco-driving emerges as a cost-effective and efficient strategy to mitigate greenhouse gas emissions in urban transportation networks. Acknowledging the persuasive influence of incentives in shaping driver behavior, this paper presents the `eco-planner,' a digital platform devised to promote eco-driving practices in urban transportation. At the outset of their trips, users provide the platform with their trip details and travel time preferences, enabling the eco-planner to formulate personalized eco-driving recommendations and corresponding incentives, while adhering to its budgetary constraints. Upon trip completion, incentives are transferred to users who comply with the recommendations and effectively reduce their emissions. By comparing our proposed incentive mechanism with a baseline scheme that offers uniform incentives to all users, we demonstrate that our approach achieves superior emission reductions and increased user compliance with a smaller budget."}, "https://arxiv.org/abs/2404.10228": {"title": "Two-Stage Stance Labeling: User-Hashtag Heuristics with Graph Neural Networks", "link": "https://arxiv.org/abs/2404.10228", "description": "arXiv:2404.10228v2 Announce Type: replace-cross \nAbstract: The high volume and rapid evolution of content on social media present major challenges for studying the stance of social media users. In this work, we develop a two stage stance labeling method that utilizes the user-hashtag bipartite graph and the user-user interaction graph. In the first stage, a simple and efficient heuristic for stance labeling uses the user-hashtag bipartite graph to iteratively update the stance association of user and hashtag nodes via a label propagation mechanism. This set of soft labels is then integrated with the user-user interaction graph to train a graph neural network (GNN) model using semi-supervised learning. We evaluate this method on two large-scale datasets containing tweets related to climate change from June 2021 to June 2022 and gun control from January 2022 to January 2023. Our experiments demonstrate that enriching text-based embeddings of users with network information from the user interaction graph using our semi-supervised GNN method outperforms both classifiers trained on user textual embeddings and zero-shot classification using LLMs such as GPT4. We discuss the need for integrating nuanced understanding from social science with the scalability of computational methods to better understand how polarization on social media occurs for divisive issues such as climate change and gun control."}, "https://arxiv.org/abs/2405.11146": {"title": "Election Polls on Social Media: Prevalence, Biases, and Voter Fraud Beliefs", "link": "https://arxiv.org/abs/2405.11146", "description": "arXiv:2405.11146v1 Announce Type: new \nAbstract: Social media platforms allow users to create polls to gather public opinion on diverse topics. However, we know little about what such polls are used for and how reliable they are, especially in significant contexts like elections. Focusing on the 2020 presidential elections in the U.S., this study shows that outcomes of election polls on Twitter deviate from election results despite their prevalence. Leveraging demographic inference and statistical analysis, we find that Twitter polls are disproportionately authored by older males and exhibit a large bias towards candidate Donald Trump relative to representative mainstream polls. We investigate potential sources of biased outcomes from the point of view of inauthentic, automated, and counter-normative behavior. Using social media experiments and interviews with poll authors, we identify inconsistencies between public vote counts and those privately visible to poll authors, with the gap potentially attributable to purchased votes. We also find that Twitter accounts participating in election polls are more likely to be bots, and election poll outcomes tend to be more biased, before the election day than after. Finally, we identify instances of polls spreading voter fraud conspiracy theories and estimate that a couple thousand of such polls were posted in 2020. The study discusses the implications of biased election polls in the context of transparency and accountability of social media platforms."}, "https://arxiv.org/abs/2405.11166": {"title": "Learning the liveability of cities from migrants: Combinatiorial-Hodge-theory approach", "link": "https://arxiv.org/abs/2405.11166", "description": "arXiv:2405.11166v1 Announce Type: new \nAbstract: Migration is a major decision to leave one place and move to another, and involves job and life changes. The migration flow of people provides relational information across places about which is better to live by ``voting with their feet'' (Tiebout, 1956; Douglas, 1997). From the people's votes, in a ``democratic'' process, we quantify a descriptive statistic of liveable cities by a potential of migration flow in Combinatorial Hodge theory. As a case study, we measure the liveability of municipalities in Japan for specific populations such as families with small children and women of reproductive age. Using these potentials as dependent variables, we perform a regression analysis to identify the factors relevant to liveability. Additionally, using the aformentioned theoretical framework, we analytically derive the expression of the utility as a function of given flow data, which was numerically estimated in previous studies (Douglas & Wall, 1993; Douglas, 1997; Douglas & Wall, 2000; Wall, 2001; Nakajima & Tabuchi, 2011). The proposed method extracts a consistent metric of interval scale from the non-transitive, pairwise comparison between locations and provides valuable statistics for urban planning by policymakers."}, "https://arxiv.org/abs/2405.11225": {"title": "SeBot: Structural Entropy Guided Multi-View Contrastive Learning for Social Bot Detection", "link": "https://arxiv.org/abs/2405.11225", "description": "arXiv:2405.11225v1 Announce Type: new \nAbstract: Recent advancements in social bot detection have been driven by the adoption of Graph Neural Networks. The social graph, constructed from social network interactions, contains benign and bot accounts that influence each other. However, previous graph-based detection methods that follow the transductive message-passing paradigm may not fully utilize hidden graph information and are vulnerable to adversarial bot behavior. The indiscriminate message passing between nodes from different categories and communities results in excessively homogeneous node representations, ultimately reducing the effectiveness of social bot detectors. In this paper, we propose SEBot, a novel multi-view graph-based contrastive learning-enabled social bot detector. In particular, we use structural entropy as an uncertainty metric to optimize the entire graph's structure and subgraph-level granularity, revealing the implicitly existing hierarchical community structure. And we design an encoder to enable message passing beyond the homophily assumption, enhancing robustness to adversarial behaviors of social bots. Finally, we employ multi-view contrastive learning to maximize mutual information between different views and enhance the detection performance through multi-task learning. Experimental results demonstrate that our approach significantly improves the performance of social bot detection compared with SOTA methods."}, "https://arxiv.org/abs/2405.11887": {"title": "Social norm dynamics in a behavioral epidemic model on multiplex networks", "link": "https://arxiv.org/abs/2405.11887", "description": "arXiv:2405.11887v1 Announce Type: new \nAbstract: Understanding the social determinants influencing preventive measures adoption during epidemics is crucial for effective disease modeling and policy making. While traditional epidemic models focused on rational decision-making and psychological biases, recent studies highlight the role of social norms. We develop a behavioral epidemic model on a multiplex network, by integrating an Experience Weighted Attractor (EWA) learning mechanism and social norm dynamics. Incorporating social norms in our decision-making mechanism significantly reduces final infected fractions, offering an alternative to altruism for boosting vaccination coverage. Furthermore, we examine the importance of the dynamics of each one of the social norms, injunctive or descriptive, in reducing the infected fraction, finding that the former has a more significant effect in agreement with some experimental evidence. We also explore the effect of external interventions on epidemic expansion, aiding in refining public communication protocols. Enhanced models of social norm dynamics, if validated and tested, can better capture the complexities of human social behavior and mitigate various societal challenges beyond pandemics."}, "https://arxiv.org/abs/2405.11922": {"title": "Effective Clustering on Large Attributed Bipartite Graphs", "link": "https://arxiv.org/abs/2405.11922", "description": "arXiv:2405.11922v1 Announce Type: new \nAbstract: Attributed bipartite graphs (ABGs) are an expressive data model for describing the interactions between two sets of heterogeneous nodes that are associated with rich attributes, such as customer-product purchase networks and author-paper authorship graphs. Partitioning the target node set in such graphs into k disjoint clusters (referred to as k-ABGC) finds widespread use in various domains, including social network analysis, recommendation systems, information retrieval, and bioinformatics. However, the majority of existing solutions towards k-ABGC either overlook attribute information or fail to capture bipartite graph structures accurately, engendering severely compromised result quality. The severity of these issues is accentuated in real ABGs, which often encompass millions of nodes and a sheer volume of attribute data, rendering effective k-ABGC over such graphs highly challenging.\n  In this paper, we propose TPO, an effective and efficient approach to k-ABGC that achieves superb clustering performance on multiple real datasets. TPO obtains high clustering quality through two major contributions: (i) a novel formulation and transformation of the k-ABGC problem based on multi-scale attribute affinity specialized for capturing attribute affinities between nodes with the consideration of their multi-hop connections in ABGs, and (ii) a highly efficient solver that includes a suite of carefully-crafted optimizations for sidestepping explicit affinity matrix construction and facilitating faster convergence. Extensive experiments, comparing TPO against 19 baselines over 5 real ABGs, showcase the superior clustering quality of TPO measured against ground-truth labels. Moreover, compared to the state of the arts, TPO is often more than 40x faster over both small and large ABGs."}, "https://arxiv.org/abs/2405.12040": {"title": "Reputation Transfer in the Twitter Diaspora", "link": "https://arxiv.org/abs/2405.12040", "description": "arXiv:2405.12040v1 Announce Type: new \nAbstract: Social media platforms have witnessed a dynamic landscape of user migration in recent years, fueled by changes in ownership, policy, and user preferences. This paper explores the phenomenon of user migration from established platforms like X/Twitter to emerging alternatives such as Threads, Mastodon, and Truth Social. Leveraging a large dataset from X/Twitter, we investigate the extent of user departure from X/Twitter and the destinations they migrate to. Additionally, we examine whether a user's reputation on one platform correlates with their reputation on another, shedding light on the transferability of digital reputation across social media ecosystems. Overall, we find that users with a large following on X/Twitter are more likely to migrate to another platform; and that their reputation on X/Twitter is highly correlated with reputations on Threads, but not Mastodon or Truth Social."}, "https://arxiv.org/abs/2405.11121": {"title": "COVID-19's Unequal Toll: An assessment of small business impact disparities with respect to ethnorace in metropolitan areas in the US using mobility data", "link": "https://arxiv.org/abs/2405.11121", "description": "arXiv:2405.11121v1 Announce Type: cross \nAbstract: Early in the pandemic, counties and states implemented a variety of non-pharmacological interventions (NPIs) focused on mobility, such as national lockdowns or work-from-home strategies, as it became clear that restricting movement was essential to containing the epidemic. Due to these restrictions, businesses were severely affected and in particular, small, urban restaurant businesses. In addition to that, COVID-19 has also amplified many of the socioeconomic disparities and systemic racial inequities that exist in our society. The overarching objective of this study was to examine the changes in small urban restaurant visitation patterns following the COVID-19 pandemic and associated mobility restrictions, as well as to uncover potential disparities across different racial/ethnic groups in order to understand inequities in the impact and recovery. Specifically, the two key objectives were: 1) to analyze the overall changes in restaurant visitation patterns in US metropolitan areas during the pandemic compared to a pre-pandemic baseline, and 2) to investigate differences in visitation pattern changes across Census Block Groups with majority Asian, Black, Hispanic, White, and American Indian populations, identifying any disproportionate effects. Using aggregated geolocated cell phone data from SafeGraph, we document the overall changes in small urban restaurant businesses' visitation patterns with respect to racial composition at a granularity of Census Block Groups. Our results show clear indications of reduced visitation patterns after the pandemic, with slow recoveries. Via visualizations and statistical analyses, we show that reductions in visitation patterns were the highest for small urban restaurant businesses in majority Asian neighborhoods."}, "https://arxiv.org/abs/2405.11192": {"title": "BrainStorm @ iREL at SMM4H 2024: Leveraging Translation and Topical Embeddings for Annotation Detection in Tweets", "link": "https://arxiv.org/abs/2405.11192", "description": "arXiv:2405.11192v1 Announce Type: cross \nAbstract: The proliferation of LLMs in various NLP tasks has sparked debates regarding their reliability, particularly in annotation tasks where biases and hallucinations may arise. In this shared task, we address the challenge of distinguishing annotations made by LLMs from those made by human domain experts in the context of COVID-19 symptom detection from tweets in Latin American Spanish. This paper presents BrainStorm @ iREL's approach to the SMM4H 2024 Shared Task, leveraging the inherent topical information in tweets, we propose a novel approach to identify and classify annotations, aiming to enhance the trustworthiness of annotated data."}, "https://arxiv.org/abs/2405.11219": {"title": "Identifying and Aligning Medical Claims Made on Social Media with Medical Evidence", "link": "https://arxiv.org/abs/2405.11219", "description": "arXiv:2405.11219v1 Announce Type: cross \nAbstract: Evidence-based medicine is the practice of making medical decisions that adhere to the latest, and best known evidence at that time. Currently, the best evidence is often found in the form of documents, such as randomized control trials, meta-analyses and systematic reviews. This research focuses on aligning medical claims made on social media platforms with this medical evidence. By doing so, individuals without medical expertise can more effectively assess the veracity of such medical claims. We study three core tasks: identifying medical claims, extracting medical vocabulary from these claims, and retrieving evidence relevant to those identified medical claims. We propose a novel system that can generate synthetic medical claims to aid each of these core tasks. We additionally introduce a novel dataset produced by our synthetic generator that, when applied to these tasks, demonstrates not only a more flexible and holistic approach, but also an improvement in all comparable metrics. We make our dataset, the Expansive Medical Claim Corpus (EMCC), available at https://zenodo.org/records/8321460"}, "https://arxiv.org/abs/2405.11414": {"title": "High-Resolution Agent-Based Modeling of Campus Population Behaviors for Pandemic Response Planning", "link": "https://arxiv.org/abs/2405.11414", "description": "arXiv:2405.11414v1 Announce Type: cross \nAbstract: This paper reports a case study of an application of high-resolution agent-based modeling and simulation to pandemic response planning on a university campus. In the summer of 2020, we were tasked with a COVID-19 pandemic response project to create a detailed behavioral simulation model of the entire campus population at Binghamton University. We conceptualized this problem as an agent migration process on a multilayer transportation network, in which each layer represented a different transportation mode. As no direct data were available about people's behaviors on campus, we collected as much indirect information as possible to inform the agents' behavioral rules. Each agent was assumed to move along the shortest path between two locations within each transportation layer and switch layers at a parking lot or a bus stop, along with several other behavioral assumptions. Using this model, we conducted simulations of the whole campus population behaviors on a typical weekday, involving more than 25,000 agents. We measured the frequency of close social contacts at each spatial location and identified several busy locations and corridors on campus that needed substantial behavioral intervention. Moreover, systematic simulations with varying population density revealed that the effect of population density reduction was nonlinear, and that reducing the population density to 40-45% would be optimal and sufficient to suppress disease spreading on campus. These results were reported to the university administration and utilized in the pandemic response planning, which led to successful outcomes."}, "https://arxiv.org/abs/2405.11658": {"title": "A Starting Point for Dynamic Community Detection with Leiden Algorithm", "link": "https://arxiv.org/abs/2405.11658", "description": "arXiv:2405.11658v1 Announce Type: cross \nAbstract: Many real-world graphs evolve with time. Identifying communities or clusters on such graphs is an important problem. In this technical report, we extend three dynamic approaches, namely, Naive-dynamic (ND), Delta-screening (DS), and Dynamic Frontier (DF), to our multicore implementation of the Leiden algorithm, an algorithm known for its high-quality community detection. Our experiments on a server with a 64-core AMD EPYC-7742 processor demonstrate that ND, DS, and DF Leiden achieve speedups of 1.25x, 1.24x, and 1.37x on large graphs with random batch updates, compared to Static, ND, and DS Leiden, respectively. However, on real-world dynamic graphs, ND Leiden performs the best, being on average 1.14x faster than Static Leiden. We hope our early results serve as a starting point for dynamic approaches to the Leiden algorithm on evolving graphs."}, "https://arxiv.org/abs/2405.11868": {"title": "Towards Graph Contrastive Learning: A Survey and Beyond", "link": "https://arxiv.org/abs/2405.11868", "description": "arXiv:2405.11868v1 Announce Type: cross \nAbstract: In recent years, deep learning on graphs has achieved remarkable success in various domains. However, the reliance on annotated graph data remains a significant bottleneck due to its prohibitive cost and time-intensive nature. To address this challenge, self-supervised learning (SSL) on graphs has gained increasing attention and has made significant progress. SSL enables machine learning models to produce informative representations from unlabeled graph data, reducing the reliance on expensive labeled data. While SSL on graphs has witnessed widespread adoption, one critical component, Graph Contrastive Learning (GCL), has not been thoroughly investigated in the existing literature. Thus, this survey aims to fill this gap by offering a dedicated survey on GCL. We provide a comprehensive overview of the fundamental principles of GCL, including data augmentation strategies, contrastive modes, and contrastive optimization objectives. Furthermore, we explore the extensions of GCL to other aspects of data-efficient graph learning, such as weakly supervised learning, transfer learning, and related scenarios. We also discuss practical applications spanning domains such as drug discovery, genomics analysis, recommender systems, and finally outline the challenges and potential future directions in this field."}, "https://arxiv.org/abs/2405.11911": {"title": "PULL: PU-Learning-based Accurate Link Prediction", "link": "https://arxiv.org/abs/2405.11911", "description": "arXiv:2405.11911v1 Announce Type: cross \nAbstract: Given an edge-incomplete graph, how can we accurately find the missing links? The link prediction in edge-incomplete graphs aims to discover the missing relations between entities when their relationships are represented as a graph. Edge-incomplete graphs are prevalent in real-world due to practical limitations, such as not checking all users when adding friends in a social network. Addressing the problem is crucial for various tasks, including recommending friends in social networks and finding references in citation networks. However, previous approaches rely heavily on the given edge-incomplete (observed) graph, making it challenging to consider the missing (unobserved) links during training. In this paper, we propose PULL (PU-Learning-based Link predictor), an accurate link prediction method based on the positive-unlabeled (PU) learning. PULL treats the observed edges in the training graph as positive examples, and the unconnected node pairs as unlabeled ones. PULL effectively prevents the link predictor from overfitting to the observed graph by proposing latent variables for every edge, and leveraging the expected graph structure with respect to the variables. Extensive experiments on five real-world datasets show that PULL consistently outperforms the baselines for predicting links in edge-incomplete graphs."}, "https://arxiv.org/abs/2405.12023": {"title": "Estimating transmission noise on networks from stationary local order", "link": "https://arxiv.org/abs/2405.12023", "description": "arXiv:2405.12023v1 Announce Type: cross \nAbstract: In this paper we study networks of nodes characterised by binary traits that change both endogenously and through nearest-neighbour interaction. Our analytical results show that those traits can be ranked according to the noisiness of their transmission using only measures of order in the stationary state. Crucially, this ranking is independent of network topology. As an example, we explain why, in line with a long-standing hypothesis, the relative stability of the structural traits of languages can be estimated from their geospatial distribution. We conjecture that similar inferences may be possible in a more general class of Markovian systems. Consequently, in many empirical domains where longitudinal information is not easily available the propensities of traits to change could be estimated from spatial data alone."}, "https://arxiv.org/abs/2405.12180": {"title": "Estimating the Impact of Social Distance Policy in Mitigating COVID-19 Spread with Factor-Based Imputation Approach", "link": "https://arxiv.org/abs/2405.12180", "description": "arXiv:2405.12180v1 Announce Type: cross \nAbstract: We identify the effectiveness of social distancing policies in reducing the transmission of the COVID-19 spread. We build a model that measures the relative frequency and geographic distribution of the virus growth rate and provides hypothetical infection distribution in the states that enacted the social distancing policies, where we control time-varying, observed and unobserved, state-level heterogeneities. Using panel data on infection and deaths in all US states from February 20 to April 20, 2020, we find that stay-at-home orders and other types of social distancing policies significantly reduced the growth rate of infection and deaths. We show that the effects are time-varying and range from the weakest at the beginning of policy intervention to the strongest by the end of our sample period. We also found that social distancing policies were more effective in states with higher income, better education, more white people, more democratic voters, and higher CNN viewership."}, "https://arxiv.org/abs/2308.05945": {"title": "Improving Ego-Cluster for Network Effect Measurement", "link": "https://arxiv.org/abs/2308.05945", "description": "arXiv:2308.05945v2 Announce Type: replace \nAbstract: The network effect, wherein one user's activity impacts another user, is common in social network platforms. Many new features in social networks are specifically designed to create a network effect, enhancing user engagement. For instance, content creators tend to produce more when their articles and posts receive positive feedback from followers. This paper discusses a new cluster-level experimentation methodology for measuring creator-side metrics in the context of A/B experiments. The methodology is designed to address cases where the experiment randomization unit and the metric measurement unit differ. It is a crucial part of LinkedIn's overall strategy to foster a robust creator community and ecosystem. The method is developed based on widely-cited research at LinkedIn but significantly improves the efficiency and flexibility of the clustering algorithm. This improvement results in a stronger capability for measuring creator-side metrics and an increased velocity for creator-related experiments."}, "https://arxiv.org/abs/2401.08680": {"title": "Proximity Ascertainment Bias in Early Covid Case Locations", "link": "https://arxiv.org/abs/2401.08680", "description": "arXiv:2401.08680v5 Announce Type: replace \nAbstract: A comparison of the distances to the Huanan Seafood Market of early Covid cases with known links to the market versus cases without known links shows results apparently incompatible with a location model lacking proximity ascertainment bias. The sign of the difference instead agrees with a model in which such ascertainment bias is large. In the presence of such bias inferences based on the clustering of case locations become unreliable."}, "https://arxiv.org/abs/2007.05637": {"title": "Multilevel Digital Contact Tracing", "link": "https://arxiv.org/abs/2007.05637", "description": "arXiv:2007.05637v4 Announce Type: replace-cross \nAbstract: Digital contact tracing plays a crucial role in alleviating an outbreak, and designing multilevel digital contact tracing for a country is an open problem due to the analysis of large volumes of temporal contact data. We develop a multilevel digital contact tracing framework that constructs dynamic contact graphs from the proximity contact data. Prominently, we introduce the edge label of the contact graph as a binary circular contact queue, which holds the temporal social interactions during the incubation period. After that, our algorithm prepares the direct and indirect (multilevel) contact list for a given set of infected persons from the contact graph. Finally, the algorithm constructs the infection pathways for the trace list. We implement the framework and validate the contact tracing process with synthetic and real-world data sets. In addition, analysis reveals that for COVID-19 close contact parameters, the framework takes reasonable space and time to create the infection pathways. Our framework can apply to any epidemic spreading by changing the algorithm's parameters."}, "https://arxiv.org/abs/2305.14375": {"title": "MGL2Rank: Learning to Rank the Importance of Nodes in Road Networks Based on Multi-Graph Fusion", "link": "https://arxiv.org/abs/2305.14375", "description": "arXiv:2305.14375v3 Announce Type: replace-cross \nAbstract: The identification of important nodes with strong propagation capabilities in road networks is a vital topic in urban planning. Existing methods for evaluating the importance of nodes in traffic networks only consider topological information and traffic volumes, the diversity of the traffic characteristics in road networks, such as the number of lanes and average speed of road segments, is ignored, thus limiting their performance. To solve this problem, we propose a graph learning-based framework (MGL2Rank) that integrates the rich characteristics of road networks to rank the importance of nodes. This framework comprises an embedding module containing a sampling algorithm (MGWalk) and an encoder network to learn the latent representations for each road segment. MGWalk utilizes multigraph fusion to capture the topology of road networks and establish associations between road segments based on their attributes. The obtained node representation is then used to learn the importance ranking of the road segments. Finally, a synthetic dataset is constructed for ranking tasks based on the regional road network of Shenyang City, and the ranking results on this dataset demonstrate the effectiveness of our method. The data and source code for MGL2Rank are available at https://github.com/iCityLab/MGL2Rank."}, "https://arxiv.org/abs/2404.14423": {"title": "A Compositional Approach to Higher-Order Structure in Complex Systems", "link": "https://arxiv.org/abs/2404.14423", "description": "arXiv:2404.14423v2 Announce Type: replace-cross \nAbstract: Relating microscopic interactions to macroscopic observables is a central challenge in the study of complex systems. Addressing this question requires understanding both pairwise and higher-order interactions, but the latter are less well understood. Here, we show that the M\\\"obius inversion theorem provides a general mathematical formalism for deriving higher-order interactions from macroscopic observables, relative to a chosen decomposition of the system into parts. Applying this framework to a diverse range of systems, we demonstrate that many existing notions of higher-order interactions, from epistasis in genetics and many-body couplings in physics, to synergy in game theory and artificial intelligence, naturally arise from an appropriate mereological decomposition. By revealing the common mathematical structure underlying seemingly disparate phenomena, our work highlights the fundamental role of decomposition choice in the definition and estimation of higher-order interactions. We discuss how this unifying perspective can facilitate the transfer of insights between domains, guide the selection of appropriate system decompositions, and motivate the search for novel interaction types through creative decomposition strategies. More broadly, our results suggest that the M\\\"obius inversion theorem provides a powerful lens for understanding the emergence of complex behaviour from the interplay of microscopic parts, with applications across a wide range of disciplines."}, "https://arxiv.org/abs/2405.12244": {"title": "Real-Time Go-Around Prediction: A case study of JFK airport", "link": "https://arxiv.org/abs/2405.12244", "description": "arXiv:2405.12244v1 Announce Type: new \nAbstract: In this paper, we employ the long-short-term memory model (LSTM) to predict the real-time go-around probability as an arrival flight is approaching JFK airport and within 10 nm of the landing runway threshold. We further develop methods to examine the causes to go-around occurrences both from a global view and an individual flight perspective. According to our results, in-trail spacing, and simultaneous runway operation appear to be the top factors that contribute to overall go-around occurrences. We then integrate these pre-trained models and analyses with real-time data streaming, and finally develop a demo web-based user interface that integrates the different components designed previously into a real-time tool that can eventually be used by flight crews and other line personnel to identify situations in which there is a high risk of a go-around."}, "https://arxiv.org/abs/2405.12253": {"title": "The statistical and dynamic modeling of the first part of the 2013-2014 Euromaidan protests in Ukraine: The Revolution of Dignity and preceding times", "link": "https://arxiv.org/abs/2405.12253", "description": "arXiv:2405.12253v1 Announce Type: new \nAbstract: Ukraine's tug-of-war between Russia and the West has had significant and lasting consequences for the country. In 2013, Viktor Yanukovych, the Ukrainian president aligned with Russia, opted against signing an association agreement with the European Union. This agreement aimed to facilitate trade and travel between the EU and Ukraine. This decision sparked widespread protests that coalesced in Kyiv's Maidan Square, eventually becoming known as the Euromaidan protests. In this study, we analyze the protest data from 2013, sourced from Ukraine's Center for Social and Labor Research. Despite the dataset's limitations and occasional inconsistencies, we demonstrate the extraction of valuable insights and the construction of a descriptive model from such data. Our investigation reveals a pre-existing state of self-excitation within the system even before the onset of the Euromaidan protests. This self-excitation intensified during the Euromaidan protests. A statistical analysis indicates that the government's utilization of force correlates with increased future protests, exacerbating rather than quelling the protest movement. Furthermore, we introduce the implementation of Hawkes process models to comprehend the spatiotemporal dynamics of the protest activity. Our findings highlight that, while protest activities spread across the entire country, the driving force behind the dynamics of these protests was the level of activity in Kyiv. Furthermore, in contrast to prior research that emphasized geographical proximity as a key predictor of event propagation, our study illustrates that the political alignment among oblasts, which are the distinct municipalities comprising Ukraine, had a more profound impact than mere geographic distance. This underscores the significance of social and cultural factors in molding the trajectory of political movements."}, "https://arxiv.org/abs/2405.12566": {"title": "Unveiling Online Conspiracy Theorists: a Text-Based Approach and Characterization", "link": "https://arxiv.org/abs/2405.12566", "description": "arXiv:2405.12566v1 Announce Type: new \nAbstract: In today's digital landscape, the proliferation of conspiracy theories within the disinformation ecosystem of online platforms represents a growing concern. This paper delves into the complexities of this phenomenon. We conducted a comprehensive analysis of two distinct X (formerly known as Twitter) datasets: one comprising users with conspiracy theorizing patterns and another made of users lacking such tendencies and thus serving as a control group. The distinguishing factors between these two groups are explored across three dimensions: emotions, idioms, and linguistic features. Our findings reveal marked differences in the lexicon and language adopted by conspiracy theorists with respect to other users. We developed a machine learning classifier capable of identifying users who propagate conspiracy theories based on a rich set of 871 features. The results demonstrate high accuracy, with an average F1 score of 0.88. Moreover, this paper unveils the most discriminating characteristics that define conspiracy theory propagators."}, "https://arxiv.org/abs/2405.12642": {"title": "Combining Twitter and Mobile Phone Data to Observe Border-Rush: The Turkish-European Border Opening", "link": "https://arxiv.org/abs/2405.12642", "description": "arXiv:2405.12642v1 Announce Type: new \nAbstract: Following Turkey's 2020 decision to revoke border controls, many individuals journeyed towards the Greek, Bulgarian, and Turkish borders. However, the lack of verifiable statistics on irregular migration and discrepancies between media reports and actual migration patterns require further exploration. The objective of this study is to bridge this knowledge gap by harnessing novel data sources, specifically mobile phone and Twitter data, to construct estimators of cross-border mobility and to cultivate a qualitative comprehension of the unfolding events. By employing a migration diplomacy framework, we analyse emergent mobility patterns at the border. Our findings demonstrate the potential of mobile phone data for quantitative metrics and Twitter data for qualitative understanding. We underscore the ethical implications of leveraging Big Data, particularly considering the vulnerability of the population under study. This underscores the imperative for exhaustive research into the socio-political facets of human mobility, with the aim of discerning the potentialities, limitations, and risks inherent in these data sources and their integration. This scholarly endeavour contributes to a more nuanced understanding of migration dynamics and paves the way for the formulation of regulations that preclude misuse and oppressive surveillance, thereby ensuring a more accurate representation of migration realities."}, "https://arxiv.org/abs/2405.12764": {"title": "Detecting and Mitigating Bias in Algorithms Used to Disseminate Information in Social Networks", "link": "https://arxiv.org/abs/2405.12764", "description": "arXiv:2405.12764v1 Announce Type: new \nAbstract: Social connections are a conduit through which individuals communicate, information propagates, and diseases spread. Identifying individuals that are more likely to adopt ideas or technologies and spread them to others is essential in order to develop effective information campaigns, fight epidemics, and to maximize the reach of limited resources. Consequently a lot of work has focused on identifying sets of influencers. Here we show that seeding information using these influence maximization methods, only benefits connected and central individuals, consistently leaving the most vulnerable behind. Our results highlights troublesome outcomes of influence maximization algorithms: they do not disseminate information in an equitable manner threatening to create an increasingly unequal society. To overcome this issue we devise a simple, multi-objective algorithm, which maximises both influence and information equity. Our work demonstrates how to find fairer influencer sets, highlighting that in our search for maximizing information, we do not need to compromise on information equality."}, "https://arxiv.org/abs/2405.12797": {"title": "Refined Graph Encoder Embedding via Self-Training and Latent Community Recovery", "link": "https://arxiv.org/abs/2405.12797", "description": "arXiv:2405.12797v1 Announce Type: new \nAbstract: This paper introduces a refined graph encoder embedding method, enhancing the original graph encoder embedding using linear transformation, self-training, and hidden community recovery within observed communities. We provide the theoretical rationale for the refinement procedure, demonstrating how and why our proposed method can effectively identify useful hidden communities via stochastic block models, and how the refinement method leads to improved vertex embedding and better decision boundaries for subsequent vertex classification. The efficacy of our approach is validated through a collection of simulated and real-world graph data."}, "https://arxiv.org/abs/2405.12340": {"title": "Cascade-based Randomization for Inferring Causal Effects under Diffusion Interference", "link": "https://arxiv.org/abs/2405.12340", "description": "arXiv:2405.12340v1 Announce Type: cross \nAbstract: The presence of interference, where the outcome of an individual may depend on the treatment assignment and behavior of neighboring nodes, can lead to biased causal effect estimation. Current approaches to network experiment design focus on limiting interference through cluster-based randomization, in which clusters are identified using graph clustering, and cluster randomization dictates the node assignment to treatment and control. However, cluster-based randomization approaches perform poorly when interference propagates in cascades, whereby the response of individuals to treatment propagates to their multi-hop neighbors. When we have knowledge of the cascade seed nodes, we can leverage this interference structure to mitigate the resulting causal effect estimation bias. With this goal, we propose a cascade-based network experiment design that initiates treatment assignment from the cascade seed node and propagates the assignment to their multi-hop neighbors to limit interference during cascade growth and thereby reduce the overall causal effect estimation error. Our extensive experiments on real-world and synthetic datasets demonstrate that our proposed framework outperforms the existing state-of-the-art approaches in estimating causal effects in network data."}, "https://arxiv.org/abs/2405.12474": {"title": "How Universal Polynomial Bases Enhance Spectral Graph Neural Networks: Heterophily, Over-smoothing, and Over-squashing", "link": "https://arxiv.org/abs/2405.12474", "description": "arXiv:2405.12474v1 Announce Type: cross \nAbstract: Spectral Graph Neural Networks (GNNs), alternatively known as graph filters, have gained increasing prevalence for heterophily graphs. Optimal graph filters rely on Laplacian eigendecomposition for Fourier transform. In an attempt to avert prohibitive computations, numerous polynomial filters have been proposed. However, polynomials in the majority of these filters are predefined and remain fixed across different graphs, failing to accommodate the varying degrees of heterophily. Addressing this gap, we demystify the intrinsic correlation between the spectral property of desired polynomial bases and the heterophily degrees via thorough theoretical analyses. Subsequently, we develop a novel adaptive heterophily basis wherein the basis vectors mutually form angles reflecting the heterophily degree of the graph. We integrate this heterophily basis with the homophily basis to construct a universal polynomial basis UniBasis, which devises a polynomial filter based graph neural network - UniFilter. It optimizes the convolution and propagation in GNN, thus effectively limiting over-smoothing and alleviating over-squashing. Our extensive experiments, conducted on a diverse range of real-world and synthetic datasets with varying degrees of heterophily, support the superiority of UniFilter. These results not only demonstrate the universality of UniBasis but also highlight its proficiency in graph explanation."}, "https://arxiv.org/abs/2311.09262": {"title": "Disentangling the Potential Impacts of Papers into Diffusion, Conformity, and Contribution Values", "link": "https://arxiv.org/abs/2311.09262", "description": "arXiv:2311.09262v3 Announce Type: replace \nAbstract: The potential impact of an academic paper is determined by various factors, including its popularity and contribution. Existing models usually estimate original citation counts based on static graphs and fail to differentiate values from nuanced perspectives. In this study, we propose a novel graph neural network to Disentangle the Potential impacts of Papers into Diffusion, Conformity, and Contribution values (called DPPDCC). Given a target paper, DPPDCC encodes temporal and structural features within the constructed dynamic heterogeneous graph. Particularly, to capture the knowledge flow, we emphasize the importance of comparative and co-cited/citing information between papers and aggregate snapshots evolutionarily. To unravel popularity, we contrast augmented graphs to extract the essence of diffusion and predict the accumulated citation binning to model conformity. We further apply orthogonal constraints to encourage distinct modeling of each perspective and preserve the inherent value of contribution. To evaluate models' generalization for papers published at various times, we reformulate the problem by partitioning data based on specific time points to mirror real-world conditions. Extensive experimental results on three datasets demonstrate that DPPDCC significantly outperforms baselines for previously, freshly, and immediately published papers. Further analyses confirm its robust capabilities. We will make our datasets and codes publicly available."}, "https://arxiv.org/abs/2401.09310": {"title": "Asymmetric games on networks: mapping to Ising models and bounded rationality", "link": "https://arxiv.org/abs/2401.09310", "description": "arXiv:2401.09310v2 Announce Type: replace \nAbstract: We investigate the dynamics of coordination and consensus in an agent population. Considering agents endowed with bounded rationality, we study asymmetric coordination games using a mapping to random field Ising models. In doing so, we investigate the relationship between group coordination and agent rationality. Analytical calculations and numerical simulations of the proposed model lead to novel insight into opinion dynamics. For instance, we find that bounded rationality and preference intensity can determine a series of possible scenarios with different levels of opinion polarization. To conclude, we deem our investigation opens a new avenue for studying game dynamics through methods of statistical physics."}, "https://arxiv.org/abs/2403.02867": {"title": "Scalable Continuous-time Diffusion Framework for Network Inference and Influence Estimation", "link": "https://arxiv.org/abs/2403.02867", "description": "arXiv:2403.02867v2 Announce Type: replace \nAbstract: The study of continuous-time information diffusion has been an important area of research for many applications in recent years. When only the diffusion traces (cascades) are accessible, cascade-based network inference and influence estimation are two essential problems to explore. Alas, existing methods exhibit limited capability to infer and process networks with more than a few thousand nodes, suffering from scalability issues. In this paper, we view the diffusion process as a continuous-time dynamical system, based on which we establish a continuous-time diffusion model. Subsequently, we instantiate the model to a scalable and effective framework (FIM) to approximate the diffusion propagation from available cascades, thereby inferring the underlying network structure. Furthermore, we undertake an analysis of the approximation error of FIM for network inference. To achieve the desired scalability for influence estimation, we devise an advanced sampling technique and significantly boost the efficiency. We also quantify the effect of the approximation error on influence estimation theoretically. Experimental results showcase the effectiveness and superior scalability of FIM on network inference and influence estimation."}, "https://arxiv.org/abs/2405.13094": {"title": "KPG: Key Propagation Graph Generator for Rumor Detection based on Reinforcement Learning", "link": "https://arxiv.org/abs/2405.13094", "description": "arXiv:2405.13094v1 Announce Type: new \nAbstract: The proliferation of rumors on social media platforms during significant events, such as the US elections and the COVID-19 pandemic, has a profound impact on social stability and public health. Existing approaches for rumor detection primarily rely on propagation graphs to enhance model effectiveness. However, the presence of noisy and irrelevant structures during the propagation process limits the efficacy of these approaches. To tackle this issue, techniques such as weight adjustment and data augmentation have been proposed. However, these techniques heavily depend on rich original propagation structures, thus hindering performance when dealing with rumors that lack sufficient propagation information in the early propagation stages. In this paper, we propose Key Propagation Graph Generator (KPG), a novel reinforcement learning-based rumor detection framework that generates contextually coherent and informative propagation patterns for events with insufficient topology information, while also identifies indicative substructures for events with redundant and noisy propagation structures. KPG consists of two key components: the Candidate Response Generator (CRG) and the Ending Node Selector (ENS). CRG learns the latent distribution from refined propagation patterns, filtering out noise and generating new candidates for ENS. Simultaneously, ENS identifies the most influential substructures within propagation graphs and generates training data for CRG. Moreover, we introduce an end-to-end framework that utilizes rewards to guide the entire training process via a pre-trained graph neural network. Extensive experiments conducted on four datasets demonstrate the superiority of our KPG compared to the state-of-the-art approaches."}, "https://arxiv.org/abs/2405.13224": {"title": "Integrating behavioral experimental findings into dynamical models to inform social change interventions", "link": "https://arxiv.org/abs/2405.13224", "description": "arXiv:2405.13224v1 Announce Type: new \nAbstract: Addressing global challenges -- from public health to climate change -- often involves stimulating the large-scale adoption of new products or behaviors. Research traditions that focus on individual decision making suggest that achieving this objective requires better identifying the drivers of individual adoption choices. On the other hand, computational approaches rooted in complexity science focus on maximizing the propagation of a given product or behavior throughout social networks of interconnected adopters. The integration of these two perspectives -- although advocated by several research communities -- has remained elusive so far. Here we show how achieving this integration could inform seeding policies to facilitate the large-scale adoption of a given behavior or product. Drawing on complex contagion and discrete choice theories, we propose a method to estimate individual-level thresholds to adoption, and validate its predictive power in two choice experiments. By integrating the estimated thresholds into computational simulations, we show that state-of-the-art seeding methods for social influence maximization might be suboptimal if they neglect individual-level behavioral drivers, which can be corrected through the proposed experimental method."}, "https://arxiv.org/abs/2405.13480": {"title": "What is a typical signalized intersection in a city? A pipeline for intersection data imputation from OpenStreetMap", "link": "https://arxiv.org/abs/2405.13480", "description": "arXiv:2405.13480v1 Announce Type: new \nAbstract: Signalized intersections, arguably the most complicated type of traffic scenario, are essential to urban mobility systems. With recent advancements in intelligent transportation technologies, signalized intersections have great prospects for making transportation greener, safer, and faster. Several studies have been conducted focusing on intersection-level control and optimization. However, arbitrarily structured signalized intersections that are often used do not represent the ground-truth distribution, and there is no standardized way that exists to extract information about real-world signalized intersections. As the largest open-source map in the world, OpenStreetMap (OSM) has been used by many transportation researchers for a variety of studies, including intersection-level research such as adaptive traffic signal control and eco-driving. However, the quality of OSM data has been a serious concern.\n  In this paper, we propose a pipeline for effectively extracting information about signalized intersections from OSM and constructing a comprehensive dataset. We thoroughly discuss challenges related to this task and we propose our solution for each challenge. We also use Salt Lake City as an example to demonstrate the performance of our methods. The pipeline has been published as an open-source Python library so everyone can freely download and use it to facilitate their research. Hopefully, this paper can serve as a starting point that inspires more efforts to build a standardized and systematic data pipeline for various types of transportation problems."}, "https://arxiv.org/abs/2405.13530": {"title": "Through energy droughts: hydropower's ability to sustain a high output", "link": "https://arxiv.org/abs/2405.13530", "description": "arXiv:2405.13530v1 Announce Type: new \nAbstract: Previous research has raised concerns about energy droughts in renewables-based energy systems. This study explores the ability of reservoir hydropower to sustain a high output and, thereby, mitigate such energy droughts. Using detailed modelling, we estimate that Swedish hydropower can sustain 67-92% of its installed capacity for 3 weeks, with higher values possible in springtime. The variation of the sustained output, equivalent to the capacity of 3-4 Swedish nuclear reactors, under-scores the importance of understanding the potential output levels when devising strategies to counteract energy droughts. Moreover, we find that regulations imposed on the flows in river bottlenecks hinder higher sustained output levels. With the upcoming renewal of environmental permits for hydropower plants in Sweden, these findings provide valuable insights for policymakers. Furthermore, the sustained output capabilities demonstrated in this study challenge the prevalent simplified representations of hydropower in energy models, suggesting a need for more-sophisticated modelling approaches."}, "https://arxiv.org/abs/2405.13670": {"title": "GNN-based Anomaly Detection for Encoded Network Traffic", "link": "https://arxiv.org/abs/2405.13670", "description": "arXiv:2405.13670v1 Announce Type: new \nAbstract: The early research report explores the possibility of using Graph Neural Networks (GNNs) for anomaly detection in internet traffic data enriched with information. While recent studies have made significant progress in using GNNs for anomaly detection in finance, multivariate time-series, and biochemistry domains, there is limited research in the context of network flow data. In this report, we explore the idea that leverages information-enriched features extracted from network flow packet data to improve the performance of GNN in anomaly detection. The idea is to utilize feature encoding (binary, numerical, and string) to capture the relationships between the network components, allowing the GNN to learn latent relationships and better identify anomalies."}, "https://arxiv.org/abs/2405.14100": {"title": "Water Management Considerations for a Self-Sustaining Moonbase", "link": "https://arxiv.org/abs/2405.14100", "description": "arXiv:2405.14100v1 Announce Type: new \nAbstract: The most pragmatic first step in the all-but-inevitable 3rd-millennium V\\\"olkerwanderung of humanity throughout the Solar System is the establishment of a permanent human presence on the Moon. This research examines: 1. the human, agricultural, and technical water needs of a 100-person, 500 m x 100 m x 6 m self-sustaining lunar colony; 2. choosing a strategic location for the moonbase; 3. a heat drill model by which the needed lunar water ice could be sublimated; and 4. the robust water treatment and recovery infrastructure and water management personnel that would be needed for a self-sustaining moonbase."}, "https://arxiv.org/abs/2405.14168": {"title": "A generative model for community types in directed networks", "link": "https://arxiv.org/abs/2405.14168", "description": "arXiv:2405.14168v1 Announce Type: new \nAbstract: Large complex networks are often organized into groups or communities. In this paper, we introduce and investigate a generative model of network evolution that reproduces all four pairwise community types that exist in directed networks: assortative, core-periphery, disassortative, and the newly introduced source-basin type. We fix the number of nodes and the community membership of each node, allowing node connectivity to change through rewiring mechanisms that depend on the community membership of the involved nodes. We determine the dependence of the community relationship on the model parameters using a mean-field solution. It reveals that a difference in the swap probabilities of the two communities is a necessary condition to obtain a core-periphery relationship and that a difference in the average in-degree of the communities is a necessary condition for a source-basin relationship. More generally, our analysis reveals multiple possible scenarios for the transition between the different structure types, and sheds light on the mechanisms underlying the observation of the different types of communities in network data."}, "https://arxiv.org/abs/2405.14194": {"title": "Graphlets correct for the topological information missed by random walks", "link": "https://arxiv.org/abs/2405.14194", "description": "arXiv:2405.14194v1 Announce Type: new \nAbstract: Random walks are widely used for mining networks due to the computational efficiency of computing them. For instance, graph representation learning learns a d-dimensional embedding space, so that the nodes that tend to co-occur on random walks (a proxy of being in the same network neighborhood) are close in the embedding space. Specific local network topology (i.e., structure) influences the co-occurrence of nodes on random walks, so random walks of limited length capture only partial topological information, hence diminishing the performance of downstream methods. We explicitly capture all topological neighborhood information and improve performance by introducing orbit adjacencies that quantify the adjacencies of two nodes as co-occurring on a given pair of graphlet orbits, which are symmetric positions on graphlets (small, connected, non-isomorphic, induced subgraphs of a large network). Importantly, we mathematically prove that random walks on up to k nodes capture only a subset of all the possible orbit adjacencies for up to k-node graphlets. Furthermore, we enable orbit adjacency-based analysis of networks by developing an efficient GRaphlet-orbit ADjacency COunter (GRADCO), which exhaustively computes all 28 orbit adjacency matrices for up to four-node graphlets. Note that four-node graphlets suffice, because real networks are usually small-world. In large networks on around 20,000 nodes, GRADCOcomputesthe28matricesinminutes. Onsixrealnetworksfromvarious domains, we compare the performance of node-label predictors obtained by using the network embeddings based on our orbit adjacencies to those based on random walks. We find that orbit adjacencies, which include those unseen by random walks, outperform random walk-based adjacencies, demonstrating the importance of the inclusion of the topological neighborhood information that is unseen by random walks."}, "https://arxiv.org/abs/2405.14503": {"title": "Radial analysis and scaling of housing prices in French urban areas", "link": "https://arxiv.org/abs/2405.14503", "description": "arXiv:2405.14503v1 Announce Type: new \nAbstract: Urban scaling laws summarize how urban attributes evolve with city size. Recent criticism questions notably the aggregate view of this approach, which leads to neglecting the internal structure of cities. This is all the more relevant for housing prices due to their important variations across space. Based on a dataset compiling millions of real estate transactions over the period 2017-2021, we investigate the regularities of the radial (center-periphery) profiles of housing prices across cities, with respect to their size. Results are threefold. First, they corroborate prior findings in the urban scaling literature stating that largest cities agglomerate higher housing prices. Second, we find that housing price radial profiles scale in three dimensions with the power 1/5 of city population. After rescaling, great regularities between radial profiles can be observed, although some locational amenities have a significant impact on prices. Third, it appears that our rescaled profiles approach fails to explain housing price variations in the city center across cities. In fact, prices near the city center rise much faster with city size than those in the periphery. This has strong implications for low-income households seeking homeownership, because prohibitive prices in the center may contribute to pushing them out into peripheral locations."}, "https://arxiv.org/abs/2405.14543": {"title": "Initial Burst of Disruptive Efforts over Individual Scientific Careers", "link": "https://arxiv.org/abs/2405.14543", "description": "arXiv:2405.14543v1 Announce Type: new \nAbstract: Despite persistent efforts to understand the dynamics of creativity of scientists over careers in terms of productivity, impact, and prize, little is known about the dynamics of scientists' disruptive efforts that affect individual academic careers and drive scientific advance. Drawing on millions of data over six decades and across nineteen disciplines, associating the publication records of individual scientists with the disruption index, we systematically quantify the temporal pattern of disruptive ideas over individual scientific careers, providing a detailed understanding of the macro phenomenon of scientific stagnation from the individual perspective. We start by checking the relationship between disruption-based and citation-based publication profiles. Next, we observe the finite inequality in the disruptive productivity of scientists, diminishing gradually as the level of disruption increases. We then identify the initial burst phenomenon in disruption dynamics. It is further revealed that while early engagement in high disruption frictions away initial productivity, compared to initial advantage in productivity or impact, initial high disruption ensures more subsequent academic viability evidenced by a longer career span and relatively final higher productivity, but does not necessarily guarantee academic success throughout careers. Further analysis shows that increasing disruptive work is uncorrelated to overall productivity but negatively correlated with the overall impact. However, increasing disruptive work in the early career is associated with higher overall productivity, yet lower overall productivity in the later career. Our research underscores the urgent need for a policy shift that encourages a balance between the pursuit of disruptive efforts and the achievement of impactful outcomes."}, "https://arxiv.org/abs/2405.14717": {"title": "The impact of temporal hydrogen regulation on hydrogen exporters and their domestic energy transition", "link": "https://arxiv.org/abs/2405.14717", "description": "arXiv:2405.14717v1 Announce Type: new \nAbstract: As global demand for green hydrogen rises, potential hydrogen exporters move into the spotlight. However, the large-scale installation of on-grid hydrogen electrolysis for export can have profound impacts on domestic energy prices and energy-related emissions. Our investigation explores the interplay of hydrogen exports, domestic energy transition and temporal hydrogen regulation, employing a sector-coupled energy model in Morocco. We find substantial co-benets of domestic climate change mitigation and hydrogen exports, whereby exports can reduce domestic electricity prices while mitigation reduces hydrogen export prices. However, increasing hydrogen exports quickly in a system that is still dominated by fossil fuels can substantially raise domestic electricity prices, if green hydrogen production is not regulated. Surprisingly, temporal matching of hydrogen production lowers domestic electricity cost by up to 31% while the effect on exporters is minimal. This policy instrument can steer the welfare (re-)distribution between hydrogen exporting firms, hydrogen importers, and domestic electricity consumers and hereby increases acceptance among actors."}, "https://arxiv.org/abs/2310.08029": {"title": "Increasing the Earth's Albedo: The K\\\"ohler Equation at Sea", "link": "https://arxiv.org/abs/2310.08029", "description": "arXiv:2310.08029v2 Announce Type: cross \nAbstract: Increasing marine haze and clouds has been considered as a possible means of increasing the Earth's albedo. This would reduce Solar heating and global warming, counteracting the effects of the anthropogenic increase in greenhouse gases. One proposed method of doing so would inject small droplets of seawater or condensation nuclei into the marine boundary layer, creating artificial haze and cloud. The equilibrium size of such droplets is described by the K\\\"{o}hler equation that includes the vapor pressure reduction attributable to the solute according to Raoult's law and the vapor pressure increase of a small droplet as a result of surface tension according to Kelvin. Here we apply this classic result to small droplets in the marine boundary layer, where the partial pressure of water vapor is less than the equilibrium vapor pressure because it is in equilibrium with the saline ocean. We calculate the equilibrium size of a droplet containing dissolved ions and find that the radius of a droplet of seawater shrinks greatly before it achieves equilibrium."}, "https://arxiv.org/abs/2405.13005": {"title": "Understanding the Rare Inflammatory Disease Using Large Language Models and Social Media Data", "link": "https://arxiv.org/abs/2405.13005", "description": "arXiv:2405.13005v1 Announce Type: cross \nAbstract: Sarcoidosis is a rare inflammatory disease characterized by the formation of granulomas in various organs. The disease presents diagnostic and treatment challenges due to its diverse manifestations and unpredictable nature. In this study, we employed a Large Language Model (LLM) to analyze sarcoidosis-related discussions on the social media platform Reddit. Our findings underscore the efficacy of LLMs in accurately identifying sarcoidosis-related content. We discovered a wide array of symptoms reported by patients, with fatigue, swollen lymph nodes, and shortness of breath as the most prevalent. Prednisone was the most prescribed medication, while infliximab showed the highest effectiveness in improving prognoses. Notably, our analysis revealed disparities in prognosis based on age and gender, with women and younger patients experiencing good and polarized outcomes, respectively. Furthermore, unsupervised clustering identified three distinct patient subgroups (phenotypes) with unique symptom profiles, prognostic outcomes, and demographic distributions. Finally, sentiment analysis revealed a moderate negative impact on patients' mental health post-diagnosis, particularly among women and younger individuals. Our study represents the first application of LLMs to understand sarcoidosis through social media data. It contributes to understanding the disease by providing data-driven insights into its manifestations, treatments, prognoses, and impact on patients' lives. Our findings have direct implications for improving personalized treatment strategies and enhancing the quality of care for individuals living with sarcoidosis."}, "https://arxiv.org/abs/2405.13071": {"title": "A Novel Method for News Article Event-Based Embedding", "link": "https://arxiv.org/abs/2405.13071", "description": "arXiv:2405.13071v1 Announce Type: cross \nAbstract: Embedding news articles is a crucial tool for multiple fields, such as media bias detection, identifying fake news, and news recommendations. However, existing news embedding methods are not optimized for capturing the latent context of news events. In many cases, news embedding methods rely on full-textual information and neglect the importance of time-relevant embedding generation. Here, we aim to address these shortcomings by presenting a novel lightweight method that optimizes news embedding generation by focusing on the entities and themes mentioned in the articles and their historical connections to specific events. We suggest a method composed of three stages. First, we process and extract the events, entities, and themes for the given news articles. Second, we generate periodic time embeddings for themes and entities by training timely separated GloVe models on current and historical data. Lastly, we concatenate the news embeddings generated by two distinct approaches: Smooth Inverse Frequency (SIF) for article-level vectors and Siamese Neural Networks for embeddings with nuanced event-related information. To test and evaluate our method, we leveraged over 850,000 news articles and 1,000,000 events from the GDELT project. For validation purposes, we conducted a comparative analysis of different news embedding generation methods, applying them twice to a shared event detection task - first on articles published within the same day and subsequently on those published within the same month. Our experiments show that our method significantly improves the Precision-Recall (PR) AUC across all tasks and datasets. Specifically, we observed an average PR AUC improvement of 2.15% and 2.57% compared to SIF, as well as 2.57% and 2.43% compared to the semi-supervised approach for daily and monthly shared event detection tasks, respectively."}, "https://arxiv.org/abs/2405.13099": {"title": "The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach", "link": "https://arxiv.org/abs/2405.13099", "description": "arXiv:2405.13099v1 Announce Type: cross \nAbstract: This study explores the relationship between informational support seeking questions, responses, and helpfulness ratings in online health communities. We created a labeled data set of question-response pairs and developed multimodal machine learning and deep learning models to reliably predict informational support questions and responses. We employed explainable AI to reveal the emotions embedded in informational support exchanges, demonstrating the importance of emotion in providing informational support. This complex interplay between emotional and informational support has not been previously researched. The study refines social support theory and lays the groundwork for the development of user decision aids. Further implications are discussed."}, "https://arxiv.org/abs/2405.13341": {"title": "Wealth inequality and utility: Effect evaluation of redistribution and consumption morals using macro-econophysical coupled approach", "link": "https://arxiv.org/abs/2405.13341", "description": "arXiv:2405.13341v1 Announce Type: cross \nAbstract: Reducing wealth inequality and increasing utility are critical issues. This study reveals the effects of redistribution and consumption morals on wealth inequality and utility. To this end, we present a novel approach that couples the dynamic model of capital, consumption, and utility in macroeconomics with the interaction model of joint business and redistribution in econophysics. With this approach, we calculate the capital (wealth), the utility based on consumption, and the Gini index of these inequality using redistribution and consumption thresholds as moral parameters. The results show that: under-redistribution and waste exacerbate inequality; conversely, over-redistribution and stinginess reduce utility; and a balanced moderate moral leads to achieve both reduced inequality and increased utility. These findings provide renewed economic and numerical support for the moral importance known from philosophy, anthropology, and religion. The revival of redistribution and consumption morals should promote the transformation to a human mutual-aid economy, as indicated by philosopher and anthropologist, instead of the capitalist economy that has produced the current inequality. The practical challenge is to implement bottom-up social business, on a foothold of worker coops and platform cooperatives as a community against the state and the market, with moral consensus and its operation."}, "https://arxiv.org/abs/2405.13744": {"title": "A Privacy Measure Turned Upside Down? Investigating the Use of HTTP Client Hints on the Web", "link": "https://arxiv.org/abs/2405.13744", "description": "arXiv:2405.13744v1 Announce Type: cross \nAbstract: HTTP client hints are a set of standardized HTTP request headers designed to modernize and potentially replace the traditional user agent string. While the user agent string exposes a wide range of information about the client's browser and device, client hints provide a controlled and structured approach for clients to selectively disclose their capabilities and preferences to servers. Essentially, client hints aim at more effective and privacy-friendly disclosure of browser or client properties than the user agent string.\n  We present a first long-term study of the use of HTTP client hints in the wild. We found that despite being implemented in almost all web browsers, server-side usage of client hints remains generally low. However, in the context of third-party websites, which are often linked to trackers, the adoption rate is significantly higher. This is concerning because client hints allow the retrieval of more data from the client than the user agent string provides, and there are currently no mechanisms for users to detect or control this potential data leakage. Our work provides valuable insights for web users, browser vendors, and researchers by exposing potential privacy violations via client hints and providing help in developing remediation strategies as well as further research."}, "https://arxiv.org/abs/2405.14043": {"title": "Attitudes Towards Migration in a COVID-19 Context: Testing a Behavioral Immune System Hypothesis with Twitter Data", "link": "https://arxiv.org/abs/2405.14043", "description": "arXiv:2405.14043v1 Announce Type: cross \nAbstract: The COVID-19 outbreak implied many changes in the daily life of most of the world's population for a long time, prompting severe restrictions on sociality. The Behavioral Immune System (BIS) suggests that when facing pathogens, a psychological mechanism would be activated that, among other things, would generate an increase in prejudice and discrimination towards marginalized groups, including immigrants. This study aimed to test if people tend to enhance their rejection of minorities and foreign groups under the threat of contagious diseases, using the users' attitudes towards migrants in Twitter data from Chile, for pre-pandemic and pandemic contexts. Our results only partially support the BIS hypothesis, since threatened users increased their tweet production in the pandemic period, compared to empathetic users, but the latter grew in number and also increased the reach of their tweets between the two periods. We also found differences in the use of language between these types of users. Alternative explanations for these results may be context-dependent."}, "https://arxiv.org/abs/2405.14403": {"title": "Representative electricity price profiles for European day-ahead and intraday spot markets", "link": "https://arxiv.org/abs/2405.14403", "description": "arXiv:2405.14403v1 Announce Type: cross \nAbstract: We propose a method to construct representative price profiles of the day-ahead (DA) and the intraday (ID) electricity spot markets and use this method to provide examples of ready-to-use price data sets. In contrast to common scenario generation approaches, the method is deterministic and relies on a small number of degrees of freedom, with the aim to be well defined and easy to use. We thereby target an enhanced comparability of future research studies on demand-side management and energy cost optimization. We construct the price profiles based on historical time series from the spot markets of interest, e.g., European Power Exchange (EPEX) spot. To this end, we extract key price components from the data while also accounting for known dominant mechanisms in the price variation. Further, the method is able to preserve key statistical features of the historical data (e.g., mean and standard deviation) when constructing the benchmark profile. Finally, our approach ensures comparability of ID and DA price profiles by design, as their cumulative (integral) price can be made identical if needed."}, "https://arxiv.org/abs/2405.14761": {"title": "Effective & Ethical Mentorship in Physics and Astronomy through Grassroots Organizations", "link": "https://arxiv.org/abs/2405.14761", "description": "arXiv:2405.14761v1 Announce Type: cross \nAbstract: Effective and ethical mentorship practices are crucial to improving recruitment and retention especially for historically minoritized groups (HMGs). Spectrum is a diversity, inclusion, equity, and accessibility (DEIA) grassroots organization committed to empowering equitable excellence through sustainable change. By improving transparency and DEIA within the fields of physics and astronomy, we can empower the next generation of diverse scientists and increase field retention. Starting within our home department at George Mason University and moving outwards, we ensure our students leave as advocates for DEIA and AJEDI (access, justice, equity, diversity, and inclusion) through education and mentorship. Spectrum is providing professionally trained peer mentors to aid students in all facets of their academic and personal lives. Although the peer mentoring program existed since the creation of Spectrum in Spring 2020, we have recently developed and implemented a formal mentorship training for both student and faculty mentors thus increasing the quality, trustworthiness, and confidence of our mentors. Using the latest mentorship research available, this training is developed by Spectrum for George Mason University, with the ability to implement the training at any institution."}, "https://arxiv.org/abs/2108.01727": {"title": "Scalable Community Detection in Massive Networks Using Aggregated Relational Data", "link": "https://arxiv.org/abs/2108.01727", "description": "arXiv:2108.01727v3 Announce Type: replace \nAbstract: The mixed membership stochastic blockmodel (MMSB) is a popular Bayesian network model for community detection. Fitting such large Bayesian network models quickly becomes computationally infeasible when the number of nodes grows into hundreds of thousands and millions. In this paper we propose a novel mini-batch strategy based on aggregated relational data that leverages nodal information to fit MMSB to massive networks. We describe a scalable inference method that can utilize nodal information that often accompanies real-world networks. Conditioning on this extra information leads to a model that admits a parallel stochastic variational inference algorithm, utilizing stochastic gradients of bipartite graph formed from aggregated network ties between node subpopulations. We apply our method to a citation network with over two million nodes and 25 million edges, capturing explainable structure in this network. Our method recovers parameters and achieves better convergence on simulated networks generated according to the MMSB."}, "https://arxiv.org/abs/2401.08539": {"title": "Mapping low-resolution edges to high-resolution paths: the case of traffic measurements in cities", "link": "https://arxiv.org/abs/2401.08539", "description": "arXiv:2401.08539v2 Announce Type: replace \nAbstract: We consider the following problem : we have a high-resolution street network of a given city, and low-resolution measurements of traffic within this city. We want to associate to each measurement the set of streets corresponding to the observed traffic. To do so, we take benefit of specific properties of these data to match measured links to links in the street network. We propose several success criteria for the obtained matching. They show that the matching algorithm generally performs very well, and they give complementary ways to detect data discrepancies that makes any matching highly dubious."}, "https://arxiv.org/abs/2401.09647": {"title": "Large Language Models Help Reveal Unhealthy Diet and Body Concerns in Online Eating Disorders Communities", "link": "https://arxiv.org/abs/2401.09647", "description": "arXiv:2401.09647v2 Announce Type: replace \nAbstract: Eating disorders (ED), a severe mental health condition with high rates of mortality and morbidity, affect millions of people globally, especially adolescents. The proliferation of online communities that promote and normalize ED has been linked to this public health crisis. However, identifying harmful communities is challenging due to the use of coded language and other obfuscations. To address this challenge, we propose a novel framework to surface implicit attitudes of online communities by adapting large language models (LLMs) to the language of the community. We describe an alignment method and evaluate results along multiple dimensions of semantics and affect. We then use the community-aligned LLM to respond to psychometric questionnaires designed to identify ED in individuals. We demonstrate that LLMs can effectively adopt community-specific perspectives and reveal significant variations in eating disorder risks in different online communities. These findings highlight the utility of LLMs to reveal implicit attitudes and collective mindsets of communities, offering new tools for mitigating harmful content on social media."}, "https://arxiv.org/abs/2401.16504": {"title": "Effect of recommending users and opinions on the network connectivity and idea generation process", "link": "https://arxiv.org/abs/2401.16504", "description": "arXiv:2401.16504v2 Announce Type: replace \nAbstract: The growing reliance on online services underscores the crucial role of recommendation systems, especially on social media platforms seeking increased user engagement. This study investigates how recommendation systems influence the impact of personal behavioral traits on social network dynamics. It explores the interplay between homophily, users' openness to novel ideas, and recommendation-driven exposure to new opinions. Additionally, the research examines the impact of recommendation systems on the diversity of newly generated ideas, shedding light on the challenges and opportunities in designing effective systems that balance the exploration of new ideas with the risk of reinforcing biases or filtering valuable, unconventional concepts."}, "https://arxiv.org/abs/2402.19157": {"title": "Broken detailed balance and entropy production in directed networks", "link": "https://arxiv.org/abs/2402.19157", "description": "arXiv:2402.19157v3 Announce Type: replace \nAbstract: The structure of a complex network plays a crucial role in determining its dynamical properties. In this work, we show that the the degree to which a network is directed and hierarchically organised is closely associated with the degree to which its dynamics break detailed balance and produce entropy. We consider a range of dynamical processes and show how different directed network features affect their entropy production rate. We begin with an analytical treatment of a 2-node network followed by numerical simulations of synthetic networks using the preferential attachment and Erd\\\"os-Renyi algorithms. Next, we analyse a collection of 97 empirical networks to determine the effect of complex real-world topologies. Finally, we present a simple method for inferring broken detailed balance and directed network structure from multivariate time-series and apply our method to identify non-equilibrium dynamics and hierarchical organisation in both human neuroimaging and financial time-series. Overall, our results shed light on the consequences of directed network structure on non-equilibrium dynamics and highlight the importance and ubiquity of hierarchical organisation and non-equilibrium dynamics in real-world systems."}, "https://arxiv.org/abs/2404.00754": {"title": "Imitation dynamics and the replicator equation", "link": "https://arxiv.org/abs/2404.00754", "description": "arXiv:2404.00754v2 Announce Type: replace \nAbstract: Evolutionary game theory has impacted many fields of research by providing a mathematical framework for studying the evolution and maintenance of social and moral behaviors. This success is owed in large part to the demonstration that the central equation of this theory - the replicator equation - is the deterministic limit of a stochastic imitation (social learning) dynamics. Here we offer an alternative elementary proof of this result, which holds for the scenario where players compare their instantaneous (not average) payoffs to decide whether to maintain or change their strategies, and only more successful individuals can be imitated."}, "https://arxiv.org/abs/2404.04307": {"title": "PREDIS-MHI Thermal Data", "link": "https://arxiv.org/abs/2404.04307", "description": "arXiv:2404.04307v2 Announce Type: replace \nAbstract: Tertiary buildings could be an important lever to meet the goals necessitated by the energy transition. The availability of high-quality datasets from this sector will be a crucial enabler in meeting these goals by developing and testing new energy management approaches in the buildings. In this paper, we present the thermal energy datasets available and published online for the PREDIS-MHI zone of the GreEn-ER building, a tertiary building with more than a thousand sensors used for research, teaching, and administrative activities in Grenoble. PREDIS-MHI platform is a net-zero sub-section that is energetically isolated from the rest of the building. Its data has been used in a wide range of applications from indoor temperature forecasting, thermal simulation calibration, and even occupant comfort experiments"}, "https://arxiv.org/abs/2404.11465": {"title": "X-posing Free Speech: Examining the Impact of Moderation Relaxation on Online Social Networks", "link": "https://arxiv.org/abs/2404.11465", "description": "arXiv:2404.11465v2 Announce Type: replace \nAbstract: We investigate the impact of free speech and the relaxation of moderation on online social media platforms using Elon Musk's takeover of Twitter as a case study. By curating a dataset of over 10 million tweets, our study employs a novel framework combining content and network analysis. Our findings reveal a significant increase in the distribution of certain forms of hate content, particularly targeting the LGBTQ+ community and liberals. Network analysis reveals the formation of cohesive hate communities facilitated by influential bridge users, with substantial growth in interactions hinting at increased hate production and diffusion. By tracking the temporal evolution of PageRank, we identify key influencers, primarily self-identified far-right supporters disseminating hate against liberals and woke culture. Ironically, embracing free speech principles appears to have enabled hate speech against the very concept of freedom of expression and free speech itself. Our findings underscore the delicate balance platforms must strike between open expression and robust moderation to curb the proliferation of hate online."}, "https://arxiv.org/abs/2405.02856": {"title": "A tale of two emergent games: opinion dynamics in dynamical directed networks", "link": "https://arxiv.org/abs/2405.02856", "description": "arXiv:2405.02856v2 Announce Type: replace \nAbstract: Uni-directional social interactions are ubiquitous in real social networks whereas undirected interactions are intensively studied. We establish a voter model in a dynamical directed network. We analytically obtain the degree distribution of the evolving network at any given time. Furthermore, we find that the average degree is captured by an emergent game. On the other hand, we find that the fate of opinions is captured by another emergent game. Beyond expectation, the two emergent games are typically different due to the unidirectionality of the evolving networks. The Nash equilibrium analysis of the two games facilitates us to give the criterion under which the minority opinion with few disciples initially takes over the population eventually for in-group bias. Our work fosters the understanding of opinion dynamics ranging from methodology to research content."}, "https://arxiv.org/abs/2204.04510": {"title": "Translating Subgraphs to Nodes Makes Simple GNNs Strong and Efficient for Subgraph Representation Learning", "link": "https://arxiv.org/abs/2204.04510", "description": "arXiv:2204.04510v4 Announce Type: replace-cross \nAbstract: Subgraph representation learning has emerged as an important problem, but it is by default approached with specialized graph neural networks on a large global graph. These models demand extensive memory and computational resources but challenge modeling hierarchical structures of subgraphs. In this paper, we propose Subgraph-To-Node (S2N) translation, a novel formulation for learning representations of subgraphs. Specifically, given a set of subgraphs in the global graph, we construct a new graph by coarsely transforming subgraphs into nodes. Demonstrating both theoretical and empirical evidence, S2N not only significantly reduces memory and computational costs compared to state-of-the-art models but also outperforms them by capturing both local and global structures of the subgraph. By leveraging graph coarsening methods, our method outperforms baselines even in a data-scarce setting with insufficient subgraphs. Our experiments on eight benchmarks demonstrate that fined-tuned models with S2N translation can process 183 -- 711 times more subgraph samples than state-of-the-art models at a better or similar performance level."}, "https://arxiv.org/abs/2301.10960": {"title": "Visiting Distant Neighbors in Graph Convolutional Networks", "link": "https://arxiv.org/abs/2301.10960", "description": "arXiv:2301.10960v3 Announce Type: replace-cross \nAbstract: We extend the graph convolutional network method for deep learning on graph data to higher order in terms of neighboring nodes. In order to construct representations for a node in a graph, in addition to the features of the node and its immediate neighboring nodes, we also include more distant nodes in the calculations. In experimenting with a number of publicly available citation graph datasets, we show that this higher order neighbor visiting pays off by outperforming the original model especially when we have a limited number of available labeled data points for the training of the model."}, "https://arxiv.org/abs/2311.06840": {"title": "Omitted Labels in Causality: A Study of Paradoxes", "link": "https://arxiv.org/abs/2311.06840", "description": "arXiv:2311.06840v3 Announce Type: replace-cross \nAbstract: We explore what we call ``omitted label contexts,'' in which training data is limited to a subset of the possible labels. This setting is common among specialized human experts or specific focused studies. We lean on well-studied paradoxes (Simpson's and Condorcet) to illustrate the more general difficulties of causal inference in omitted label contexts. Contrary to the fundamental principles on which much of causal inference is built, we show that ``correct'' adjustments sometimes require non-exchangeable treatment and control groups. These pitfalls lead us to the study networks of conclusions drawn from different contexts and the structures the form, proving an interesting connection between these networks and social choice theory."}, "https://arxiv.org/abs/2312.09041": {"title": "Graph Neural Networks with Diverse Spectral Filtering", "link": "https://arxiv.org/abs/2312.09041", "description": "arXiv:2312.09041v3 Announce Type: replace-cross \nAbstract: Spectral Graph Neural Networks (GNNs) have achieved tremendous success in graph machine learning, with polynomial filters applied for graph convolutions, where all nodes share the identical filter weights to mine their local contexts. Despite the success, existing spectral GNNs usually fail to deal with complex networks (e.g., WWW) due to such homogeneous spectral filtering setting that ignores the regional heterogeneity as typically seen in real-world networks. To tackle this issue, we propose a novel diverse spectral filtering (DSF) framework, which automatically learns node-specific filter weights to exploit the varying local structure properly. Particularly, the diverse filter weights consist of two components -- A global one shared among all nodes, and a local one that varies along network edges to reflect node difference arising from distinct graph parts -- to balance between local and global information. As such, not only can the global graph characteristics be captured, but also the diverse local patterns can be mined with awareness of different node positions. Interestingly, we formulate a novel optimization problem to assist in learning diverse filters, which also enables us to enhance any spectral GNNs with our DSF framework. We showcase the proposed framework on three state-of-the-arts including GPR-GNN, BernNet, and JacobiConv. Extensive experiments over 10 benchmark datasets demonstrate that our framework can consistently boost model performance by up to 4.92% in node classification tasks, producing diverse filters with enhanced interpretability. Code is available at \\url{https://github.com/jingweio/DSF}."}, "https://arxiv.org/abs/2403.15855": {"title": "Initialisation and Topology Effects in Decentralised Federated Learning", "link": "https://arxiv.org/abs/2403.15855", "description": "arXiv:2403.15855v2 Announce Type: replace-cross \nAbstract: Fully decentralised federated learning enables collaborative training of individual machine learning models on distributed devices on a communication network while keeping the training data localised. This approach enhances data privacy and eliminates both the single point of failure and the necessity for central coordination. Our research highlights that the effectiveness of decentralised federated learning is significantly influenced by the network topology of connected devices. We propose a strategy for uncoordinated initialisation of the artificial neural networks, which leverages the distribution of eigenvector centralities of the nodes of the underlying communication network, leading to a radically improved training efficiency. Additionally, our study explores the scaling behaviour and choice of environmental parameters under our proposed initialisation strategy. This work paves the way for more efficient and scalable artificial neural network training in a distributed and uncoordinated environment, offering a deeper understanding of the intertwining roles of network structure and learning dynamics."}, "https://arxiv.org/abs/2405.14884": {"title": "The story around the first 4n signal", "link": "https://arxiv.org/abs/2405.14884", "description": "arXiv:2405.14884v1 Announce Type: new \nAbstract: The GANIL campaign around the first 4n signal was very peculiar. The beginning and end were both dictated by unexpected events that, unfortunately, do not fit within the streamlined format of standard scientific publications. However, they illustrate many aspects of how basic research should work, or at least does work. Therefore, I take this opportunity to share them with those not involved in the campaign, hoping that they will offer a better perspective of that research in particular and of basic research in general. As a disclaimer, this is only a personal recollection of those events."}, "https://arxiv.org/abs/2405.14902": {"title": "Global urban activity changes from COVID-19 physical distancing restrictions", "link": "https://arxiv.org/abs/2405.14902", "description": "arXiv:2405.14902v1 Announce Type: new \nAbstract: During the COVID-19 pandemic changes in human activity became widespread through official policies and organically in response to the virus's transmission, which in turn, impacted the environment and the economy. The pandemic has been described as a natural experiment that tested how social and economic disruptions impacted different components of the global Earth System. To move this beyond hypotheses, locally-resolved, globally-available measures of how, where, and when human activity changed are critically needed. Here we use satellite-derived nighttime lights to quantify and map daily changes in human activity that are atypical for each urban area globally for two years after the onset of the pandemic using machine learning anomaly detectors. Metrics characterizing changes in lights from pre-COVID baseline in human settlements and quality assurance measures are reported. This dataset, TRacking Anomalous COVID-19 induced changEs in NTL (TRACE-NTL), is the first to resolve COVID-19 disruptions for all metropolitan regions globally, daily. It is suitable to support a variety of post-pandemic studies that assess how changes in human activity impact environmental systems."}, "https://arxiv.org/abs/2405.14985": {"title": "Implicit degree bias in the link prediction task", "link": "https://arxiv.org/abs/2405.14985", "description": "arXiv:2405.14985v1 Announce Type: new \nAbstract: Link prediction -- a task of distinguishing actual hidden edges from random unconnected node pairs -- is one of the quintessential tasks in graph machine learning. Despite being widely accepted as a universal benchmark and a downstream task for representation learning, the validity of the link prediction benchmark itself has been rarely questioned. Here, we show that the common edge sampling procedure in the link prediction task has an implicit bias toward high-degree nodes and produces a highly skewed evaluation that favors methods overly dependent on node degree, to the extent that a ``null'' link prediction method based solely on node degree can yield nearly optimal performance. We propose a degree-corrected link prediction task that offers a more reasonable assessment that aligns better with the performance in the recommendation task. Finally, we demonstrate that the degree-corrected benchmark can more effectively train graph machine-learning models by reducing overfitting to node degrees and facilitating the learning of relevant structures in graphs."}, "https://arxiv.org/abs/2405.15498": {"title": "Node Accessibility Characterization of Radially-Grown Structures", "link": "https://arxiv.org/abs/2405.15498", "description": "arXiv:2405.15498v1 Announce Type: new \nAbstract: Complex systems have motivated continuing interest from the scientific community, leading to new concepts and methods. Growing systems represent a case of particular interest, as their topological, geometrical, and also dynamical properties change along time, as new elements are incorporated into the existing structure. In the present work, an approach is the case in which systems grown radially around some straight axis of reference, such as particle deposition on electrodes, or urban expansion along avenues, roads, coastline, or rivers, among several other possibilities. More specifically, we aim at characterizing the topological properties of simulated growing structures, which are represented as graphs, in terms of a measurement corresponding to the accessibility of each involved node. The incorporation of new elements (nodes and links) is performed preferentially to the angular orientation respectively to the reference axis. Several interesting results are reported, including the tendency of structures grown preferentially to the orientation normal to the axis to have smaller accessibility."}, "https://arxiv.org/abs/2405.15473": {"title": "Encoder Embedding for General Graph and Node Classification", "link": "https://arxiv.org/abs/2405.15473", "description": "arXiv:2405.15473v1 Announce Type: cross \nAbstract: Graph encoder embedding, a recent technique for graph data, offers speed and scalability in producing vertex-level representations from binary graphs. In this paper, we extend the applicability of this method to a general graph model, which includes weighted graphs, distance matrices, and kernel matrices. We prove that the encoder embedding satisfies the law of large numbers and the central limit theorem on a per-observation basis. Under certain condition, it achieves asymptotic normality on a per-class basis, enabling optimal classification through discriminant analysis. These theoretical findings are validated through a series of experiments involving weighted graphs, as well as text and image data transformed into general graph representations using appropriate distance metrics."}, "https://arxiv.org/abs/2405.15739": {"title": "Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias", "link": "https://arxiv.org/abs/2405.15739", "description": "arXiv:2405.15739v1 Announce Type: cross \nAbstract: Citation practices are crucial in shaping the structure of scientific knowledge, yet they are often influenced by contemporary norms and biases. The emergence of Large Language Models (LLMs) like GPT-4 introduces a new dynamic to these practices. Interestingly, the characteristics and potential biases of references recommended by LLMs that entirely rely on their parametric knowledge, and not on search or retrieval-augmented generation, remain unexplored. Here, we analyze these characteristics in an experiment using a dataset of 166 papers from AAAI, NeurIPS, ICML, and ICLR, published after GPT-4's knowledge cut-off date, encompassing 3,066 references in total. In our experiment, GPT-4 was tasked with suggesting scholarly references for the anonymized in-text citations within these papers. Our findings reveal a remarkable similarity between human and LLM citation patterns, but with a more pronounced high citation bias in GPT-4, which persists even after controlling for publication year, title length, number of authors, and venue. Additionally, we observe a large consistency between the characteristics of GPT-4's existing and non-existent generated references, indicating the model's internalization of citation patterns. By analyzing citation graphs, we show that the references recommended by GPT-4 are embedded in the relevant citation context, suggesting an even deeper conceptual internalization of the citation networks. While LLMs can aid in citation generation, they may also amplify existing biases and introduce new ones, potentially skewing scientific knowledge dissemination. Our results underscore the need for identifying the model's biases and for developing balanced methods to interact with LLMs in general."}, "https://arxiv.org/abs/2311.10837": {"title": "Evaluating the Relationship Between News Source Sharing and Political Beliefs", "link": "https://arxiv.org/abs/2311.10837", "description": "arXiv:2311.10837v2 Announce Type: replace \nAbstract: In an era marked by an abundance of news sources, access to information significantly influences public opinion. Notably, the bias of news sources often serves as an indicator of individuals' political leanings. This study explores this hypothesis by examining the news sharing behavior of politically active social media users, whose political ideologies were identified in a previous study. Using correspondence analysis, we estimate the Media Sharing Index (MSI), a measure that captures bias in media outlets and user preferences within a hidden space. During Argentina's 2019 election on Twitter, we observed a predictable pattern: center-right individuals predominantly shared media from center-right biased outlets. However, it is noteworthy that those with center-left inclinations displayed a more diverse media consumption, which is a significant finding. Despite a noticeable polarization based on political affiliation observed in a retweet network analysis, center-left users showed more diverse media sharing preferences, particularly concerning the MSI. Although these findings are specific to Argentina, the developed methodology can be applied in other countries to assess the correlation between users' political leanings and the media they share."}, "https://arxiv.org/abs/2302.00360": {"title": "Faster maximal clique enumeration in large real-world link streams", "link": "https://arxiv.org/abs/2302.00360", "description": "arXiv:2302.00360v3 Announce Type: replace-cross \nAbstract: Link streams offer a good model for representing interactions over time. They consist of links $(b,e,u,v)$, where $u$ and $v$ are vertices interacting during the whole time interval $[b,e]$. In this paper, we deal with the problem of enumerating maximal cliques in link streams. A clique is a pair $(C,[t_0,t_1])$, where $C$ is a set of vertices that all interact pairwise during the full interval $[t_0,t_1]$. It is maximal when neither its set of vertices nor its time interval can be increased. Some of the main works solving this problem are based on the famous Bron-Kerbosch algorithm for enumerating maximal cliques in graphs. We take this idea as a starting point to propose a new algorithm which matches the cliques of the instantaneous graphs formed by links existing at a given time $t$ to the maximal cliques of the link stream. We prove its validity and compute its complexity, which is better than the state-of-the art ones in many cases of interest. We also study the output-sensitive complexity, which is close to the output size, thereby showing that our algorithm is efficient. To confirm this, we perform experiments on link streams used in the state of the art, and on massive link streams, up to 100 million links. In all cases our algorithm is faster, mostly by a factor of at least 10 and up to a factor of $10^4$. Moreover, it scales to massive link streams for which the existing algorithms are not able to provide the solution."}, "https://arxiv.org/abs/2403.04679": {"title": "Canadian Physics Counts: An exploration of the diverse identities of physics students and professionals in Canada", "link": "https://arxiv.org/abs/2403.04679", "description": "arXiv:2403.04679v2 Announce Type: replace-cross \nAbstract: The lack of diversity in physics remains a persistent worldwide problem. Despite being a quantitative discipline which relies on measurements to construct and validate hypotheses, there remains a paucity of data on both demographics and experiences of marginalized groups. In Canada, there has never been a nationwide assessment of those studying or working in physics. Here, we present findings from Canadian Physics Counts: the first national survey of equity, diversity, and inclusion (EDI) in the Canadian physics community. Our intersectional approach allowed us to gather a wealth of information on gender identity, sexual orientation, race, disability, and more. Analyses revealed key findings, including the first data on physicists who identify as non-binary or gender diverse, as well as the first data on Black and Indigenous scholars. Black physicists (1.2%) and Indigenous physicists (.3%) were found to be the most underrepresented, while White men were overrepresented across all sectors. Among respondents with a disability, 5% reported receiving full accommodations for their required needs at their place of work or study. One in four respondents from BIPOC gender diverse backgrounds identified as being disabled, and the proportion of sexually diverse students who reported having a disability was more than three times higher than the proportion of heterosexual students with a disability. The data also revealed that students represented more demographic diversity than working professionals, highlighting the importance of acting today in order to retain the diverse physicists of tomorrow. Our analysis identifies areas for intervention and offers recommendations for building a diverse and inclusive physics community in Canada that can be a global exemplar."}, "https://arxiv.org/abs/2404.01679": {"title": "Event Detection from Social Media for Epidemic Prediction", "link": "https://arxiv.org/abs/2404.01679", "description": "arXiv:2404.01679v2 Announce Type: replace-cross \nAbstract: Social media is an easy-to-access platform providing timely updates about societal trends and events. Discussions regarding epidemic-related events such as infections, symptoms, and social interactions can be crucial for informing policymaking during epidemic outbreaks. In our work, we pioneer exploiting Event Detection (ED) for better preparedness and early warnings of any upcoming epidemic by developing a framework to extract and analyze epidemic-related events from social media posts. To this end, we curate an epidemic event ontology comprising seven disease-agnostic event types and construct a Twitter dataset SPEED with human-annotated events focused on the COVID-19 pandemic. Experimentation reveals how ED models trained on COVID-based SPEED can effectively detect epidemic events for three unseen epidemics of Monkeypox, Zika, and Dengue; while models trained on existing ED datasets fail miserably. Furthermore, we show that reporting sharp increases in the extracted events by our framework can provide warnings 4-9 weeks earlier than the WHO epidemic declaration for Monkeypox. This utility of our framework lays the foundations for better preparedness against emerging epidemics."}, "https://arxiv.org/abs/2405.04428": {"title": "BBK: a simpler, faster algorithm for enumerating maximal bicliques in large sparse bipartite graphs", "link": "https://arxiv.org/abs/2405.04428", "description": "arXiv:2405.04428v2 Announce Type: replace-cross \nAbstract: Bipartite graphs are a prevalent modeling tool for real-world networks, capturing interactions between vertices of two different types. Within this framework, bicliques emerge as crucial structures when studying dense subgraphs: they are sets of vertices such that all vertices of the first type interact with all vertices of the second type. Therefore, they allow identifying groups of closely related vertices of the network, such as individuals with similar interests or webpages with similar contents. This article introduces a new algorithm designed for the exhaustive enumeration of maximal bicliques within a bipartite graph. This algorithm, called BBK for Bipartite Bron-Kerbosch, is a new extension to the bipartite case of the Bron-Kerbosch algorithm, which enumerates the maximal cliques in standard (non-bipartite) graphs. It is faster than the state-of-the-art algorithms and allows the enumeration on massive bipartite graphs that are not manageable with existing implementations. We analyze it theoretically to establish two complexity formulas: one as a function of the input and one as a function of the output characteristics of the algorithm. We also provide an open-access implementation of BBK in C++, which we use to experiment and validate its efficiency on massive real-world datasets and show that its execution time is shorter in practice than state-of-the art algorithms. These experiments also show that the order in which the vertices are processed, as well as the choice of one of the two types of vertices on which to initiate the enumeration have an impact on the computation time."}, "https://arxiv.org/abs/2405.15838": {"title": "What You Shouldn't Know About Quantum Computers", "link": "https://arxiv.org/abs/2405.15838", "description": "arXiv:2405.15838v1 Announce Type: new \nAbstract: Whether you're a CEO strategizing the future of your company, a tech enthusiast debating your next career move, a high school teacher eager to enlighten your students, or simply tired of the relentless quantum hype, this is crafted just for you. Cutting through the complex jargon to deliver the straight facts on quantum computing, peeling away the layers of mystique to reveal the true potential and limitations of this groundbreaking technology. Prepare to have your misconceptions challenged, and your understanding deepened in this clear-eyed view of the quantum future, written to inform and inspire readers across the spectrum of curiosity and need."}, "https://arxiv.org/abs/2405.15893": {"title": "Quantifying Influencer Effects on Affective Polarization", "link": "https://arxiv.org/abs/2405.15893", "description": "arXiv:2405.15893v1 Announce Type: new \nAbstract: In an era where digital platforms increasingly mediate public discourse, grasping the complexities and nuances in affective polarization--especially as influenced by key figures on social media--has never been more vital. This study delves into the intricate web of interactions on Twitter, now rebranded as 'X', to unravel how influencer-led conversations catalyze shifts in public sentiment, laying bare the complex dynamics that underpin online polarization. Employing a novel methodological framework that includes counterfactual analysis, we analyze scenarios with and without specific influencer-led conversations. Our findings illuminate the significant role influencers play in shaping public discourse, offering insights into the mechanisms of online polarization and suggesting pathways for future research to mitigate divisiveness and explore new methods for quantifying affective polarization. This research contributes to the broader understanding of digital communication's impact on societal polarization, underscoring the importance of detailed analysis in developing strategies to foster a more cohesive digital public sphere."}, "https://arxiv.org/abs/2405.15930": {"title": "ArguSense: Argument-Centric Analysis of Online Discourse", "link": "https://arxiv.org/abs/2405.15930", "description": "arXiv:2405.15930v1 Announce Type: new \nAbstract: How can we model arguments and their dynamics in online forum discussions? The meteoric rise of online forums presents researchers across different disciplines with an unprecedented opportunity: we have access to texts containing discourse between groups of users generated in a voluntary and organic fashion. Most prior work so far has focused on classifying individual monological comments as either argumentative or not argumentative. However, few efforts quantify and describe the dialogical processes between users found in online forum discourse: the structure and content of interpersonal argumentation. Modeling dialogical discourse requires the ability to identify the presence of arguments, group them into clusters, and summarize the content and nature of clusters of arguments within a discussion thread in the forum. In this work, we develop ArguSense, a comprehensive and systematic framework for understanding arguments and debate in online forums. Our framework consists of methods for, among other things: (a) detecting argument topics in an unsupervised manner; (b) describing the structure of arguments within threads with powerful visualizations; and (c) quantifying the content and diversity of threads using argument similarity and clustering algorithms. We showcase our approach by analyzing the discussions of four communities on the Reddit platform over a span of 21 months. Specifically, we analyze the structure and content of threads related to GMOs in forums related to agriculture or farming to demonstrate the value of our framework."}, "https://arxiv.org/abs/2405.16059": {"title": "Interpretable Transformer Hawkes Processes: Unveiling Complex Interactions in Social Networks", "link": "https://arxiv.org/abs/2405.16059", "description": "arXiv:2405.16059v1 Announce Type: new \nAbstract: Social networks represent complex ecosystems where the interactions between users or groups play a pivotal role in information dissemination, opinion formation, and social interactions. Effectively harnessing event sequence data within social networks to unearth interactions among users or groups has persistently posed a challenging frontier within the realm of point processes. Current deep point process models face inherent limitations within the context of social networks, constraining both their interpretability and expressive power. These models encounter challenges in capturing interactions among users or groups and often rely on parameterized extrapolation methods when modelling intensity over non-event intervals, limiting their capacity to capture intricate intensity patterns, particularly beyond observed events. To address these challenges, this study proposes modifications to Transformer Hawkes processes (THP), leading to the development of interpretable Transformer Hawkes processes (ITHP). ITHP inherits the strengths of THP while aligning with statistical nonlinear Hawkes processes, thereby enhancing its interpretability and providing valuable insights into interactions between users or groups. Additionally, ITHP enhances the flexibility of the intensity function over non-event intervals, making it better suited to capture complex event propagation patterns in social networks. Experimental results, both on synthetic and real data, demonstrate the effectiveness of ITHP in overcoming the identified limitations. Moreover, they highlight ITHP's applicability in the context of exploring the complex impact of users or groups within social networks."}, "https://arxiv.org/abs/2405.16100": {"title": "Congestion transition on random walks on graphs", "link": "https://arxiv.org/abs/2405.16100", "description": "arXiv:2405.16100v1 Announce Type: new \nAbstract: The congestion formation on a urban road network is one of the key issue for the development of a sustainable mobility in the future smart cities. In this work we propose a reductionist approach studying the stationary states of a simple transport model using of a random process on a graph, where each node represents a location and the weight links give the transition rates to move from one node to another that represent the mobility demand. Each node has a finite transport capacity and a maximum load capacity and we assume that the average. In the approximation of the single step process we are able to analytically characterize the traffic load distribution on the single nodes, using a local Maximum Entropy Principle. Our results explain how the congested nodes emerge when the total traffic load increases in analogous way to a percolation transition where the appearance of a congested node is a independent random event, However, using numerical simulations, we show that in the more realistic case of the synchronous dynamics for the nodes, there are entropic forces that introduce correlation among the node state and favor the clustering of the empty and congested nodes. Our aim is to highlight universal properties of the congestion formation and, in particular, to understand the role traffic load fluctuations as a possible precursor of congestion in a transport network."}, "https://arxiv.org/abs/2405.16352": {"title": "Quantifying Multipolar Polarization", "link": "https://arxiv.org/abs/2405.16352", "description": "arXiv:2405.16352v1 Announce Type: new \nAbstract: Studying and understanding social networks is crucial for accurately defining ideological polarization, since they enable precise modeling of social structures. One of the limitations of many methods for quantifying polarization on networks is the assumption of a two-dimensional opinion space. This prevents accurate study of multipolar systems like multi-party political systems, where modeling more than two opinion poles is beneficial. Here, I experimentally compare methods for quantifying multipolar polarization on a network, and find that the average pairwise distance extension of generalized Euclidean distance conforms to several desired properties, showing its advantages over other methods. This allows study of multipolar polarized systems based on an empirically and intuitively good metric."}, "https://arxiv.org/abs/2405.16606": {"title": "Link Prediction on Textual Edge Graphs", "link": "https://arxiv.org/abs/2405.16606", "description": "arXiv:2405.16606v1 Announce Type: new \nAbstract: Textual-edge Graphs (TEGs), characterized by rich text annotations on edges, are increasingly significant in network science due to their ability to capture rich contextual information among entities. Existing works have proposed various edge-aware graph neural networks (GNNs) or let language models directly make predictions. However, they often fall short of fully capturing the contextualized semantics on edges and graph topology, respectively. This inadequacy is particularly evident in link prediction tasks that require a comprehensive understanding of graph topology and semantics between nodes. In this paper, we present a novel framework - Link2Doc, designed especially for link prediction on textual-edge graphs. Specifically, we propose to summarize neighborhood information between node pairs as a human-written document to preserve both semantic and topology information. A self-supervised learning model is then utilized to enhance GNN's text-understanding ability from language models. Empirical evaluations, including link prediction, edge classification, parameter analysis, runtime comparison, and ablation studies, on four real-world datasets demonstrate that Link2Doc achieves generally better performance against existing edge-aware GNNs and pre-trained language models in predicting links on TEGs."}, "https://arxiv.org/abs/2405.16772": {"title": "Balancing User Preferences by Social Networks: A Condition-Guided Social Recommendation Model for Mitigating Popularity Bias", "link": "https://arxiv.org/abs/2405.16772", "description": "arXiv:2405.16772v1 Announce Type: new \nAbstract: Social recommendation models weave social interactions into their design to provide uniquely personalized recommendation results for users. However, social networks not only amplify the popularity bias in recommendation models, resulting in more frequent recommendation of hot items and fewer long-tail items, but also include a substantial amount of redundant information that is essentially meaningless for the model's performance. Existing social recommendation models fail to address the issues of popularity bias and the redundancy of social information, as they directly characterize social influence across the entire social network without making targeted adjustments. In this paper, we propose a Condition-Guided Social Recommendation Model (named CGSoRec) to mitigate the model's popularity bias by denoising the social network and adjusting the weights of user's social preferences. More specifically, CGSoRec first includes a Condition-Guided Social Denoising Model (CSD) to remove redundant social relations in the social network for capturing users' social preferences with items more precisely. Then, CGSoRec calculates users' social preferences based on denoised social network and adjusts the weights in users' social preferences to make them can counteract the popularity bias present in the recommendation model. At last, CGSoRec includes a Condition-Guided Diffusion Recommendation Model (CGD) to introduce the adjusted social preferences as conditions to control the recommendation results for a debiased direction. Comprehensive experiments on three real-world datasets demonstrate the effectiveness of our proposed method. The code is in: https://github.com/hexin5515/CGSoRec."}, "https://arxiv.org/abs/2405.16913": {"title": "Chasing the eternal sun: Does a global super grid favor the deployment of solar power?", "link": "https://arxiv.org/abs/2405.16913", "description": "arXiv:2405.16913v1 Announce Type: new \nAbstract: The One Sun One World One Grid (OSOWOG) initiative advocates the development of a global Super grid for sharing renewable energy, especially solar energy. This study evaluates the economic benefits of such a Super grid, which connects six large regions spanning from Australia to the US, utilizing a detailed energy system optimization model and considering heterogeneous discount rates among countries. Integrating the six regions into a Super grid reduces the electricity system cost by 3.8% compared to isolating them. In contrast, grid expansion within each region reduces the electricity system cost by 12% on average. The economic benefits of the OSOWOG initiative's global Super grid expansion seem to be rather limited. Moreover, the allowance for a Super grid consistently results in decreased investments in solar power, indicating that it is not an effective strategy for enhancing the deployment of solar power, even when transmission grids covering 18 time zones are available."}, "https://arxiv.org/abs/2405.16928": {"title": "TopoLa: a novel embedding framework for understanding complex networks", "link": "https://arxiv.org/abs/2405.16928", "description": "arXiv:2405.16928v1 Announce Type: new \nAbstract: Complex networks, which are the abstractions of many real-world systems, present a persistent challenge across disciplines for people to decipher their underlying information. Recently, hyperbolic geometry of latent spaces has gained traction in network analysis, due to its ability to preserve certain local intrinsic properties of the nodes. In this study, we explore the problem from a much broader perspective: understanding the impact of nodes' global topological structures on latent space placements. Our investigations reveal a direct correlation between the topological structure of nodes and their positioning within the latent space. Building on this deep and strong connection between node distance and network topology, we propose a novel embedding framework called Topology-encoded Latent Hyperbolic Geometry (TopoLa) for analyzing complex networks. With the encoded topological information in the latent space, TopoLa is capable of enhancing both conventional and low-rank networks, using the singular value gap to clarify the mathematical principles behind this enhancement. Meanwhile, we show that the equipped TopoLa distance can also help augment pivotal deep learning models encompassing knowledge distillation and contrastive learning."}, "https://arxiv.org/abs/2405.17182": {"title": "Exploring the Performance of Continuous-Time Dynamic Link Prediction Algorithms", "link": "https://arxiv.org/abs/2405.17182", "description": "arXiv:2405.17182v1 Announce Type: new \nAbstract: Dynamic Link Prediction (DLP) addresses the prediction of future links in evolving networks. However, accurately portraying the performance of DLP algorithms poses challenges that might impede progress in the field. Importantly, common evaluation pipelines usually calculate ranking or binary classification metrics, where the scores of observed interactions (positives) are compared with those of randomly generated ones (negatives). However, a single metric is not sufficient to fully capture the differences between DLP algorithms, and is prone to overly optimistic performance evaluation. Instead, an in-depth evaluation should reflect performance variations across different nodes, edges, and time segments. In this work, we contribute tools to perform such a comprehensive evaluation. (1) We propose Birth-Death diagrams, a simple but powerful visualization technique that illustrates the effect of time-based train-test splitting on the difficulty of DLP on a given dataset. (2) We describe an exhaustive taxonomy of negative sampling methods that can be used at evaluation time. (3) We carry out an empirical study of the effect of the different negative sampling strategies. Our comparison between heuristics and state-of-the-art memory-based methods on various real-world datasets confirms a strong effect of using different negative sampling strategies on the test Area Under the Curve (AUC). Moreover, we conduct a visual exploration of the prediction, with additional insights on which different types of errors are prominent over time."}, "https://arxiv.org/abs/2405.17189": {"title": "Rebound in epidemic control: How misaligned vaccination timing amplifies infection peaks", "link": "https://arxiv.org/abs/2405.17189", "description": "arXiv:2405.17189v1 Announce Type: new \nAbstract: In this study, we explore the dynamic interplay between the timing of vaccination campaigns and the trajectory of disease spread in a population. Through comprehensive data analysis and modeling, we have uncovered a counter-intuitive phenomenon: initiating a vaccination process at an inopportune moment can paradoxically result in a more pronounced second peak of infections. This \"rebound\" phenomenon challenges the conventional understanding of vaccination impacts on epidemic dynamics. We provide a detailed examination of how improperly timed vaccination efforts can inadvertently reduce the overall immunity level in a population, considering both natural and vaccine-induced immunity. Our findings reveal that such a decrease in population-wide immunity can lead to a delayed, yet more severe, resurgence of cases. This study not only adds a critical dimension to our understanding of vaccination strategies in controlling pandemics but also underscores the necessity for strategically timed interventions to optimize public health outcomes. Furthermore, we compute which vaccination strategies are optimal for a COVID-19 tailored mathematical model, and find that there are two types of optimal strategies. The first type prioritizes vaccinating early and rapidly to reduce the number of deaths, while the second type acts later and more slowly to reduce the number of cases; both of them target primarily the elderly population. Our results hold significant implications for the formulation of vaccination policies, particularly in the context of rapidly evolving infectious diseases."}, "https://arxiv.org/abs/2405.17268": {"title": "Suppressing defection by increasing temptation: the impact of smart cooperators on a social dilemma situation", "link": "https://arxiv.org/abs/2405.17268", "description": "arXiv:2405.17268v1 Announce Type: new \nAbstract: In a social dilemma situation, where individual and collective interests are in conflict, it sounds a reasonable assumption that the presence of super or smart players, who simultaneously punish defection and reward cooperation without allowing exploitation, could solve the basic problem. The behavior of such a multi-strategy system, however, is more subtle than it is firstly anticipated. When exploring the complete parameter space, we find that the emergence of cyclic dominance among strategies is rather common, which results in several counter-intuitive phenomena. For example, the defection level can be lowered at higher temptation, or weaker punishment provides better conditions for smart players. Our study indicates that smart cooperators can unexpectedly thrive under high temptation, emphasizing the complexity of strategic interactions. This study suggests that the principles governing these interactions can be applied to other moral behaviors, such as truth-telling and honesty, providing valuable insights for future research in multi-agent systems."}, "https://arxiv.org/abs/2405.17282": {"title": "R-ODE: Ricci Curvature Tells When You Will be Informed", "link": "https://arxiv.org/abs/2405.17282", "description": "arXiv:2405.17282v1 Announce Type: new \nAbstract: Information diffusion prediction is fundamental to understand the structure and organization of the online social networks, and plays a crucial role to blocking rumor spread, influence maximization, political propaganda, etc. So far, most existing solutions primarily predict the next user who will be informed with historical cascades, but ignore an important factor in the diffusion process - the time. Such limitation motivates us to pose the problem of the time-aware personalized information diffusion prediction for the first time, telling the time when the target user will be informed. In this paper, we address this problem from a fresh geometric perspective of Ricci curvature, and propose a novel Ricci-curvature regulated Ordinary Differential Equation (R-ODE). In the diffusion process, R-ODE considers that the inter-correlated users are organized in a dynamic system in the representation space, and the cascades give the observations sampled from the continuous realm. At each infection time, the message diffuses along the largest Ricci curvature, signifying less transportation effort. In the continuous realm, the message triggers users' movement, whose trajectory in the space is parameterized by an ODE with graph neural network. Consequently, R-ODE predicts the infection time of a target user by the movement trajectory learnt from the observations. Extensive experiments evaluate the personalized time prediction ability of R-ODE, and show R-ODE outperforms the state-of-the-art baselines."}, "https://arxiv.org/abs/2405.17410": {"title": "The Peripatetic Hater: Predicting Movement Among Hate Subreddits", "link": "https://arxiv.org/abs/2405.17410", "description": "arXiv:2405.17410v1 Announce Type: new \nAbstract: Many online hate groups exist to disparage others based on race, gender identity, sex, or other characteristics. The accessibility of these communities allows users to join multiple types of hate groups (e.g., a racist community and misogynistic community), which calls into question whether these peripatetic users could be further radicalized compared to users that stay in one type of hate group. However, little is known about the dynamics of joining multiple types of hate groups, nor the effect of these groups on peripatetic users. In this paper, we develop a new method to classify hate subreddits, and the identities they disparage, which we use to better understand how users become peripatetic (join different types of hate subreddits). The hate classification technique utilizes human-validated LLMs to extract the protected identities attacked, if any, across 168 subreddits. We then cluster identity-attacking subreddits to discover three broad categories of hate: racist, anti-LGBTQ, and misogynistic. We show that becoming active in a user's first hate subreddit can cause them to become active in additional hate subreddits of a different category. We also find that users who join additional hate subreddits, especially of a different category, become more active in hate subreddits as a whole and develop a wider hate group lexicon. We are therefore motivated to train an AI model that we find usefully predicts the hate categories users will become active in based on post text read and written. The accuracy of this model may be partly driven by peripatetic users often using the language of hate subreddits they eventually join. Overall, these results highlight the unique risks associated with hate communities on a social media platform, as discussion of alternative targets of hate may lead users to target more protected identities."}, "https://arxiv.org/abs/2405.16346": {"title": "A modular and scalable web platform for computational phylogenetics", "link": "https://arxiv.org/abs/2405.16346", "description": "arXiv:2405.16346v1 Announce Type: cross \nAbstract: Phylogenetic analysis, which allow to understand the evolution of bacterial and viral epidemics, requires large quantities of data to be analysed and processed for knowledge extraction. One of the major challenges consists on the integration of the results from typing and phylogenetic inference methods with epidemiological data, namely in what concerns their integrated and simultaneous analysis and visualization. Numerous approaches to support phylogenetic analysis have been proposed, varying from standalone tools to integrative web applications that include tools and/or algorithms for executing the common analysis tasks for this kind of data. However, most of them lack the capacity to integrate epidemiological data. Others provide the ability for visualizing and analyzing such data, allowing the integration of epidemiological data but they do not scale for large data analysis and visualization. Namely, most of them run inference and/or visualization optimization tasks on the client side, which becomes often unfeasible for large amounts of data, usually implying transferring data from existing databases in order to be analysed. Moreover, the results and optimizations are not stored for reuse. We propose the PHYLOViZ Web Platform, a cloud based tool for phylogenetic analysis, that not only unifies the features of both existing versions of PHYLOViZ, but also supports structured and customized workflows for executing data processing and analyses tasks, and promotes the reproducibility of previous phylogenetic analyses. This platform supports large scale analyses by relying on a workflow system that enables the distribution of parallel computations on cloud and HPC environments. Moreover, it has a modular architecture, allowing easy integration of new methods and tools, as well as customized workflows, making it flexible and extensible."}, "https://arxiv.org/abs/2405.16616": {"title": "DPHGNN: A Dual Perspective Hypergraph Neural Networks", "link": "https://arxiv.org/abs/2405.16616", "description": "arXiv:2405.16616v1 Announce Type: cross \nAbstract: Message passing on hypergraphs has been a standard framework for learning higher-order correlations between hypernodes. Recently-proposed hypergraph neural networks (HGNNs) can be categorized into spatial and spectral methods based on their design choices. In this work, we analyze the impact of change in hypergraph topology on the suboptimal performance of HGNNs and propose DPHGNN, a novel dual-perspective HGNN that introduces equivariant operator learning to capture lower-order semantics by inducing topology-aware spatial and spectral inductive biases. DPHGNN employs a unified framework to dynamically fuse lower-order explicit feature representations from the underlying graph into the super-imposed hypergraph structure. We benchmark DPHGNN over eight benchmark hypergraph datasets for the semi-supervised hypernode classification task and obtain superior performance compared to seven state-of-the-art baselines. We also provide a theoretical framework and a synthetic hypergraph isomorphism test to express the power of spatial HGNNs and quantify the expressivity of DPHGNN beyond the Generalized Weisfeiler Leman (1-GWL) test. Finally, DPHGNN was deployed by our partner e-commerce company for the Return-to-Origin (RTO) prediction task, which shows ~7% higher macro F1-Score than the best baseline."}, "https://arxiv.org/abs/2405.16631": {"title": "Let Silence Speak: Enhancing Fake News Detection with Generated Comments from Large Language Models", "link": "https://arxiv.org/abs/2405.16631", "description": "arXiv:2405.16631v1 Announce Type: cross \nAbstract: Fake news detection plays a crucial role in protecting social media users and maintaining a healthy news ecosystem. Among existing works, comment-based fake news detection methods are empirically shown as promising because comments could reflect users' opinions, stances, and emotions and deepen models' understanding of fake news. Unfortunately, due to exposure bias and users' different willingness to comment, it is not easy to obtain diverse comments in reality, especially for early detection scenarios. Without obtaining the comments from the ``silent'' users, the perceived opinions may be incomplete, subsequently affecting news veracity judgment. In this paper, we explore the possibility of finding an alternative source of comments to guarantee the availability of diverse comments, especially those from silent users. Specifically, we propose to adopt large language models (LLMs) as a user simulator and comment generator, and design GenFEND, a generated feedback-enhanced detection framework, which generates comments by prompting LLMs with diverse user profiles and aggregating generated comments from multiple subpopulation groups. Experiments demonstrate the effectiveness of GenFEND and further analysis shows that the generated comments cover more diverse users and could even be more effective than actual comments."}, "https://arxiv.org/abs/2302.01397": {"title": "Waiting for Q: An Exploration of QAnon Users' Online Migration to Poal in the Wake of Voat's Demise", "link": "https://arxiv.org/abs/2302.01397", "description": "arXiv:2302.01397v4 Announce Type: replace \nAbstract: Online communities are groups of people who interact primarily via the Internet, often sharing common interests. Some of these groups, particularly supporters of Q who created the far-right conspiracy theory known as QAnon, are highly toxic and controversial. These communities are often banned from various mainstream online social networks due to their controversy. This study examines the deplatforming and subsequent migrations of QAnon adherents, following a two-step process. We analyze Reddit data, finding that users opt for Voat as an alternative following the Reddit bans, particularly influenced by Q's postings on 4chan. Subsequently, upon Voat's shutdown announcement, we observe users recommending Poal. Among several insights, we compare the effects of abrupt permanent bans and announced shutdowns on the migration patterns of these conspiracists. Specifically, we find that almost half of Poal's active users are Voat migrants who registered after the shutdown was announced. This contradicts the patterns observed after the Reddit bans, suggesting that advance warning can facilitate more coordinated migrations. Lastly, our research uncovers evidence of discussions and planning related to the January 6th, 2021, attack on the US Capitol, which emerged shortly after Voat's shutdown, predominantly on Poal. This underscores the continued activity of the conspiracy, albeit at a diminished scale due to various bans and a shutdown, while also exposing Poal as a platform that hosts dangerous individuals."}, "https://arxiv.org/abs/2305.15413": {"title": "Proper Interpretation of Heaps' and Zipf's Laws", "link": "https://arxiv.org/abs/2305.15413", "description": "arXiv:2305.15413v2 Announce Type: replace \nAbstract: We checked that the distribution of words in text should uniform, which gives Heaps' law as natural result, that is, the number of types of words can be expressed as a power law of the number of tokens within text. We developed a ``superposition'' model, which leads to an asymptotic power-law distribution of the number of occurrences (or frequency) of words, that is, Zipf's law. The model is well consistent with observations."}, "https://arxiv.org/abs/2401.09425": {"title": "Quantifying Attrition in Science: A Cohort-Based, Longitudinal Study of Scientists in 38 OECD Countries", "link": "https://arxiv.org/abs/2401.09425", "description": "arXiv:2401.09425v3 Announce Type: replace \nAbstract: In this paper, we explore how members of the scientific community leave academic science and how attrition (defined as ceasing to publish) differs across genders, academic disciplines, and over time. Our approach is cohort based and longitudinal: We track individual male and female scientists over time and quantify the phenomenon traditionally referred to as 'leaving science.' Using publication metadata from Scopus - a global bibliometric database of publications and citations - we follow the details of the publishing careers of scientists from 38 OECD countries who started publishing in 2000 (N = 142,776) and 2010 (N = 232,843). Our study is restricted to 16 STEMM disciplines (science, technology, engineering, mathematics, and medicine), and we track the individual scholarly output of the two cohorts until 2022. Survival analyses show that attrition becomes less gendered. In addition to the combined aggregated changes at the level of all STEMM disciplines, widely nuanced changes were found to occur at the discipline level and over time. Attrition in science means different things for men versus women depending on the discipline; moreover, it means different things for scientists from different cohorts entering the scientific workforce. Finally, global bibliometric datasets were tested in the current study, opening new opportunities to explore gender and disciplinary differences in attrition."}, "https://arxiv.org/abs/2301.01926": {"title": "Auditing citation polarization during the early COVID-19 pandemic", "link": "https://arxiv.org/abs/2301.01926", "description": "arXiv:2301.01926v2 Announce Type: replace-cross \nAbstract: The recent pandemic stimulated scientists to publish a significant amount of research that created a surge of citations of COVID-19-related publications in a short time, leading to an abrupt inflation of the journal impact factor (IF). By auditing the complete set of COVID-19-related publications in the Web of Science, we reveal here that COVID-19-related research worsened the polarization of academic journals: the IF before the pandemic was proportional to the increment of IF, which had the effect of increasing inequality while retaining the journal rankings. We also found that the most highly cited studies related to COVID-19 were published in prestigious journals at the onset of the epidemic. Through the present quantitative investigation, our findings caution against the belief that quantitative metrics, particularly IF, can indicate the significance of individual papers. Rather, such metrics reflect the social attention given to a particular study."}, "https://arxiv.org/abs/2308.11129": {"title": "Enhancing Graph Transformers with Hierarchical Distance Structural Encoding", "link": "https://arxiv.org/abs/2308.11129", "description": "arXiv:2308.11129v4 Announce Type: replace-cross \nAbstract: Graph transformers need strong inductive biases to derive meaningful attention scores. Yet, current methods often fall short in capturing longer ranges, hierarchical structures, or community structures, which are common in various graphs such as molecules, social networks, and citation networks. This paper presents a Hierarchical Distance Structural Encoding (HDSE) method to model node distances in a graph, focusing on its multi-level, hierarchical nature. We introduce a novel framework to seamlessly integrate HDSE into the attention mechanism of existing graph transformers, allowing for simultaneous application with other positional encodings. To apply graph transformers with HDSE to large-scale graphs, we further propose a high-level HDSE that effectively biases the linear transformers towards graph hierarchies. We theoretically prove the superiority of HDSE over shortest path distances in terms of expressivity and generalization. Empirically, we demonstrate that graph transformers with HDSE excel in graph classification, regression on 7 graph-level datasets, and node classification on 11 large-scale graphs, including those with up to a billion nodes."}, "https://arxiv.org/abs/2403.16049": {"title": "Improving Demand Forecasting in Open Systems with Cartogram-Enhanced Deep Learning", "link": "https://arxiv.org/abs/2403.16049", "description": "arXiv:2403.16049v2 Announce Type: replace-cross \nAbstract: Predicting temporal patterns across various domains poses significant challenges due to their nuanced and often nonlinear trajectories. To address this challenge, prediction frameworks have been continuously refined, employing data-driven statistical methods, mathematical models, and machine learning. Recently, as one of the challenging systems, shared transport systems such as public bicycles have gained prominence due to urban constraints and environmental concerns. Predicting rental and return patterns at bicycle stations remains a formidable task due to the system's openness and imbalanced usage patterns across stations. In this study, we propose a deep learning framework to predict rental and return patterns by leveraging cartogram approaches. The cartogram approach facilitates the prediction of demand for newly installed stations with no training data as well as long-period prediction, which has not been achieved before. We apply this method to public bicycle rental-and-return data in Seoul, South Korea, employing a spatial-temporal convolutional graph attention network. Our improved architecture incorporates batch attention and modified node feature updates for better prediction accuracy across different time scales. We demonstrate the effectiveness of our framework in predicting temporal patterns and its potential applications."}, "https://arxiv.org/abs/2404.14192": {"title": "Swap distance minimization beyond entropy minimization in word order variation", "link": "https://arxiv.org/abs/2404.14192", "description": "arXiv:2404.14192v3 Announce Type: replace-cross \nAbstract: Here we consider the problem of all the possible orders of a linguistic structure formed by $n$ elements, for instance, subject, direct object and verb ($n=3$) or subject, direct object, indirect object and verb ($n=4$). We investigate if the frequency of the $n!$ possible orders is constrained by two principles. First, entropy minimization, a principle that has been suggested to shape natural communication systems at distinct levels of organization. Second, swap distance minimization, namely a preference for word orders that require fewer swaps of adjacent elements to be produced from a source order. Here we present average swap distance, a novel score for research on swap distance minimization, and investigate the theoretical distribution of that score for any $n$: its minimum and maximum values and its expected value in die rolling experiments or when the word order frequencies are shuffled. We investigate whether entropy and average swap distance are significantly small in distinct linguistic structures with $n=3$ or $n=4$ in agreement with the corresponding minimization principles. We find strong evidence of entropy minimization and swap distance minimization with respect to a die rolling experiment. The evidence of these two forces with respect to a Polya urn process is strong for $n=4$ but weaker for $n=3$. We still find evidence of swap distance minimization when word order frequencies are shuffled, indicating that swap distance minimization effects are beyond pressure to minimize word order entropy."}, "https://arxiv.org/abs/2405.17511": {"title": "On the Analogy of Gauge Theory of Plasticity and Economics", "link": "https://arxiv.org/abs/2405.17511", "description": "arXiv:2405.17511v1 Announce Type: new \nAbstract: We demonstrated the analogy between Economics and Gauge Theory of Plasticity and used it to describe the relationship between money supply and inflation at the economic market. The received equations of economical dynamics in phase space are similar to the plasticity equations and economic variables - choice, competition and profit correspond to the state of the market with inflation. We described the meaning of equations and the role of its variables in the stabilization mechanism of the market with inflation. The equation of market equilibrium including the Profit turnover, time changes of competition, capital and choice was discussed in detail."}, "https://arxiv.org/abs/2405.17571": {"title": "Bluesky: Network Topology, Polarisation, and Algorithmic Curation", "link": "https://arxiv.org/abs/2405.17571", "description": "arXiv:2405.17571v1 Announce Type: new \nAbstract: Bluesky is a nascent ``Twitter-like'' and decentralized social media network with novel features and unprecedented data access. This paper provides a characterization of the network, studying the political leaning, polarization, network structure, and algorithmic curation mechanisms of five million users. The dataset spans from the website's first release in February of 2023. Users of the new social media site are predominantly left-center leaning and share little to no links associated with questionable sources. In contrast to the homogeneous political stance, we find significant issues-based divergence by studying opinions related to the Israel-Palestine conflict. Two clear homophilic clusters emerge: Pro-Palestinian voices make up the plurality of messages related to the conflict and the proportion has increased with a lessening of interest. We investigate multiple layers of the multi-scale Bluesky network based on replies, likes, reposts, and follows, highlighting differences and similarities between the layers. We differentiate between persistent and non-persistent interactions and measure metrics of network topology over time. All networks are heavy-tailed, clustered, and connected by short paths. We showcase all feeds - algorithmic content recommenders - created for and by users. A large number of custom feeds have been created but their uptake by users is limited. Multiple popular feeds aim to provide similar feeds that are neither topical nor chronological. We conclude by claiming that Bluesky - for all its novel features - is very similar in terms of its network structure to existing and larger social media sites and provides unprecedented research opportunities for social scientists, network scientists, and political scientists alike."}, "https://arxiv.org/abs/2405.17710": {"title": "Does Geo-co-location Matter? A Case Study of Public Health Conversations during COVID-19", "link": "https://arxiv.org/abs/2405.17710", "description": "arXiv:2405.17710v1 Announce Type: new \nAbstract: Social media platforms like Twitter (now X) have been pivotal in information dissemination and public engagement, especially during COVID-19. A key goal for public health experts was to encourage prosocial behavior that could impact local outcomes such as masking and social distancing. Given the importance of local news and guidance during COVID-19, the objective of our research is to analyze the effect of localized engagement, on social media conversations. This study examines the impact of geographic co-location, as a proxy for localized engagement between public health experts (PHEs) and the public, on social media. We analyze a Twitter conversation dataset from January 2020 to November 2021, comprising over 19 K tweets from nearly five hundred PHEs, along with approximately 800 K replies from 350 K participants. Our findings reveal that geo-co-location is associated with higher engagement rates, especially in conversations on topics including masking, lockdowns, and education, and in conversations with academic and medical professionals. Lexical features associated with emotion and personal experiences were more common in geo-co-located contexts. This research provides insights into how geographic co-location influences social media engagement and can inform strategies to improve public health messaging."}, "https://arxiv.org/abs/2405.18059": {"title": "Rank-Refining Seed Selection Methods for Budget Constrained Influence Maximisation in Multilayer Networks under Linear Threshold Model", "link": "https://arxiv.org/abs/2405.18059", "description": "arXiv:2405.18059v1 Announce Type: new \nAbstract: The problem of selecting an optimal seed set to maximise influence in networks has been a subject of intense research in recent years. However, despite numerous works addressing this area, it remains a topic that requires further elaboration. Most often, it is considered within the scope of classically defined graphs with a spreading model in the form of Independent Cascades. In this work, we focus on the problem of budget-constrained influence maximisation in multilayer networks using a Linear Threshold Model. Both the graph model and the spreading process we employ are less prevalent in the literature, even though their application allows for a more precise representation of the opinion dynamics in social networks. This paper aims to answer which of the sixteen evaluated seed selection methods is the most effective and how similar they are. Additionally, we focus our analysis on the impact of spreading model parameters, network characteristics, a budget, and the seed selection methods on the diffusion effectiveness in multilayer networks. Our contribution also includes extending several centrality measures and heuristics to the case of such graphs. The results indicate that all the factors mentioned above collectively contribute to the effectiveness of influence maximisation. Moreover, there is no seed selection method which always provides the best results. However, the seeds chosen with VoteRank-based methods (especially with the $v-rnk-m$ variant we propose) usually provide the most extensive diffusion."}, "https://arxiv.org/abs/2405.18085": {"title": "Network Diffusion -- Framework to Simulate Spreading Processes in Complex Networks", "link": "https://arxiv.org/abs/2405.18085", "description": "arXiv:2405.18085v1 Announce Type: new \nAbstract: With the advancement of computational network science, its research scope has significantly expanded beyond static graphs to encompass more complex structures. The introduction of streaming, temporal, multilayer, and hypernetwork approaches has brought new possibilities and imposed additional requirements. For instance, by utilising these advancements, one can model structures such as social networks in a much more refined manner, which is particularly relevant in simulations of the spreading processes. Unfortunately, the pace of advancement is often too rapid for existing computational packages to keep up with the functionality updates. This results in a significant proliferation of tools used by researchers and, consequently, a lack of a universally accepted technological stack that would standardise experimental methods (as seen, e.g. in machine learning). This article addresses that issue by presenting an extended version of the Network Diffusion library. First, a survey of the existing approaches and toolkits for simulating spreading phenomena is shown and then, an overview of the framework functionalities. Finally, we report four case studies conducted with the package to demonstrate its usefulness: the impact of sanitary measures on the spread of COVID-19, the comparison of information diffusion on two temporal network models, and the effectiveness of seed selection methods in the task of influence maximisation in multilayer networks. We conclude the paper with a critical assessment of the library and the outline of still awaiting challenges to standardise research environments in computational network science."}, "https://arxiv.org/abs/2405.17473": {"title": "Repeat-Aware Neighbor Sampling for Dynamic Graph Learning", "link": "https://arxiv.org/abs/2405.17473", "description": "arXiv:2405.17473v1 Announce Type: cross \nAbstract: Dynamic graph learning equips the edges with time attributes and allows multiple links between two nodes, which is a crucial technology for understanding evolving data scenarios like traffic prediction and recommendation systems. Existing works obtain the evolving patterns mainly depending on the most recent neighbor sequences. However, we argue that whether two nodes will have interaction with each other in the future is highly correlated with the same interaction that happened in the past. Only considering the recent neighbors overlooks the phenomenon of repeat behavior and fails to accurately capture the temporal evolution of interactions. To fill this gap, this paper presents RepeatMixer, which considers evolving patterns of first and high-order repeat behavior in the neighbor sampling strategy and temporal information learning. Firstly, we define the first-order repeat-aware nodes of the source node as the destination nodes that have interacted historically and extend this concept to high orders as nodes in the destination node's high-order neighbors. Then, we extract neighbors of the source node that interacted before the appearance of repeat-aware nodes with a slide window strategy as its neighbor sequence. Next, we leverage both the first and high-order neighbor sequences of source and destination nodes to learn temporal patterns of interactions via an MLP-based encoder. Furthermore, considering the varying temporal patterns on different orders, we introduce a time-aware aggregation mechanism that adaptively aggregates the temporal representations from different orders based on the significance of their interaction time sequences. Experimental results demonstrate the superiority of RepeatMixer over state-of-the-art models in link prediction tasks, underscoring the effectiveness of the proposed repeat-aware neighbor sampling strategy."}, "https://arxiv.org/abs/2405.17530": {"title": "Universal deterministic patterns in stochastic count data", "link": "https://arxiv.org/abs/2405.17530", "description": "arXiv:2405.17530v1 Announce Type: cross \nAbstract: We report the existence of deterministic patterns in plots showing the relationship between the mean and the Fano factor (ratio of variance and mean) of stochastic count data. These patterns are found in a wide variety of datasets, including those from genomics, paper citations, commerce, ecology, disease outbreaks, and employment statistics. We develop a theory showing that the patterns naturally emerge when data sampled from discrete probability distributions is organised in matrix form. The theory precisely predicts the patterns and shows that they are a function of only one variable - the sample size."}, "https://arxiv.org/abs/2405.17735": {"title": "State Feedback as a Strategy for Control and Analysis of COVID-19", "link": "https://arxiv.org/abs/2405.17735", "description": "arXiv:2405.17735v1 Announce Type: cross \nAbstract: This paper presents a study on a compartmental epidemic model for COVID-19, examining the stability of its equilibrium points upon the introduction of vaccination as a strategy to mitigate the spread of the disease. Initially, the SIQR (Susceptible-Infectious-Quarantine-Recovered) mathematical model and its technical aspects are introduced. Subsequently, vaccination is incorporated as a control measure within the model scope. Equilibrium points and the basic reproductive number are determined, followed by an analysis of their stability. Furthermore, controllability characteristics and Optimal Control strategies for the system are investigated, supplemented by numerical simulations."}, "https://arxiv.org/abs/2405.17768": {"title": "Revisiting the Message Passing in Heterophilous Graph Neural Networks", "link": "https://arxiv.org/abs/2405.17768", "description": "arXiv:2405.17768v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) have demonstrated strong performance in graph mining tasks due to their message-passing mechanism, which is aligned with the homophily assumption that adjacent nodes exhibit similar behaviors. However, in many real-world graphs, connected nodes may display contrasting behaviors, termed as heterophilous patterns, which has attracted increased interest in heterophilous GNNs (HTGNNs). Although the message-passing mechanism seems unsuitable for heterophilous graphs due to the propagation of class-irrelevant information, it is still widely used in many existing HTGNNs and consistently achieves notable success. This raises the question: why does message passing remain effective on heterophilous graphs? To answer this question, in this paper, we revisit the message-passing mechanisms in heterophilous graph neural networks and reformulate them into a unified heterophilious message-passing (HTMP) mechanism. Based on HTMP and empirical analysis, we reveal that the success of message passing in existing HTGNNs is attributed to implicitly enhancing the compatibility matrix among classes. Moreover, we argue that the full potential of the compatibility matrix is not completely achieved due to the existence of incomplete and noisy semantic neighborhoods in real-world heterophilous graphs. To bridge this gap, we introduce a new approach named CMGNN, which operates within the HTMP mechanism to explicitly leverage and improve the compatibility matrix. A thorough evaluation involving 10 benchmark datasets and comparative analysis against 13 well-established baselines highlights the superior performance of the HTMP mechanism and CMGNN method."}, "https://arxiv.org/abs/2405.18116": {"title": "Emergent Inequalities in a Primitive Agent-Based Good-Exchange Model", "link": "https://arxiv.org/abs/2405.18116", "description": "arXiv:2405.18116v1 Announce Type: cross \nAbstract: Rising inequalities around the globe bring into question our economic systems and the origin of such inequalities. Here we propose a toy agent-based model where each entity is simultaneously producing and consuming indivisible goods. We find that the system exhibits a non-trivial phase transition beyond which a market clearing equilibrium exists but becomes dynamically unreachable. When production capacity exceeds a threshold and adapts too slowly, some agents cannot sell all their goods. This leads to global price deflation and induces strong wealth inequalities, with the spontaneous separation of the population into a rich class and a poor class. We explore ways to alleviate poverty in this model and whether they have real life significance."}, "https://arxiv.org/abs/2405.18255": {"title": "Channel Reciprocity Based Attack Detection for Securing UWB Ranging by Autoencoder", "link": "https://arxiv.org/abs/2405.18255", "description": "arXiv:2405.18255v1 Announce Type: cross \nAbstract: A variety of ranging threats represented by Ghost Peak attack have raised concerns regarding the security performance of Ultra-Wide Band (UWB) systems with the finalization of the IEEE 802.15.4z standard. Based on channel reciprocity, this paper proposes a low complexity attack detection scheme that compares Channel Impulse Response (CIR) features of both ranging sides utilizing an autoencoder with the capability of data compression and feature extraction. Taking Ghost Peak attack as an example, this paper demonstrates the effectiveness, feasibility and generalizability of the proposed attack detection scheme through simulation and experimental validation. The proposed scheme achieves an attack detection success rate of over 99% and can be implemented in current systems at low cost."}, "https://arxiv.org/abs/2405.18414": {"title": "Don't Forget to Connect! Improving RAG with Graph-based Reranking", "link": "https://arxiv.org/abs/2405.18414", "description": "arXiv:2405.18414v1 Announce Type: cross \nAbstract: Retrieval Augmented Generation (RAG) has greatly improved the performance of Large Language Model (LLM) responses by grounding generation with context from existing documents. These systems work well when documents are clearly relevant to a question context. But what about when a document has partial information, or less obvious connections to the context? And how should we reason about connections between documents? In this work, we seek to answer these two core questions about RAG generation. We introduce G-RAG, a reranker based on graph neural networks (GNNs) between the retriever and reader in RAG. Our method combines both connections between documents and semantic information (via Abstract Meaning Representation graphs) to provide a context-informed ranker for RAG. G-RAG outperforms state-of-the-art approaches while having smaller computational footprint. Additionally, we assess the performance of PaLM 2 as a reranker and find it to significantly underperform G-RAG. This result emphasizes the importance of reranking for RAG even when using Large Language Models."}, "https://arxiv.org/abs/2405.18419": {"title": "Exploring the Evolution of Altruistic Punishment with a PDE Model of Cultural Multilevel Selection", "link": "https://arxiv.org/abs/2405.18419", "description": "arXiv:2405.18419v1 Announce Type: cross \nAbstract: Two mechanisms that have been used to study the evolution of cooperative behavior are altruistic punishment, in which cooperative individuals pay additional costs to punish defection, and multilevel selection, in which competition between groups can help to counteract individual-level incentives to cheat. Boyd, Gintis, Bowles, and Richerson have used simulation models of cultural evolution to suggest that altruistic punishment and pairwise group-level competition can work in concert to promote cooperation, even when neither mechanism can do so on its own. In this paper, we formulate a PDE model for multilevel selection motivated by the approach of Boyd and coauthors, modeling individual-level birth-death competition with a replicator equation based on individual payoffs and describing group-level competition with pairwise conflicts based on differences in the average payoffs of the competing groups. Building off of existing PDE models for multilevel selection with frequency-independent group-level competition, we use analytical and numerical techniques to understand how the forms of individual and average payoffs can impact the long-time ability to sustain altruistic punishment in group-structured populations. We find several interesting differences between the behavior of our new PDE model with pairwise group-level competition and existing multilevel PDE models, including the observation that our new model can feature a non-monotonic dependence of the long-time collective payoff on the strength of altruistic punishment. Going forward, our PDE framework can serve as a way to connect and compare disparate approaches for understanding multilevel selection across the literature in evolutionary biology and anthropology."}, "https://arxiv.org/abs/2401.06872": {"title": "Disease Transmission on Random Graphs Using Edge-Based Percolation", "link": "https://arxiv.org/abs/2401.06872", "description": "arXiv:2401.06872v2 Announce Type: replace \nAbstract: Edge-based percolation methods can be used to analyze disease transmission on complex social networks. This allows us to include complex social heterogeneity in our models while maintaining tractability. Here we review the seminal works on this field by Newman et al (2001); Newman (2002, 2003), and Miller et al (2012). We present a systematic discussion of the theoretical background behind these models, including an extensive derivation of the major results. We also connect these results relate back to the classical literature in random graph theory Molloy and Reed (1995, 1998). Finally, we also present an accompanying R package that takes epidemic and network parameters as input and generates estimates of the epidemic trajectory and final size. This manuscript and the R package was developed to help researchers easily understand and use network models to investigate the interaction between different community structures and disease transmission."}, "https://arxiv.org/abs/2401.11254": {"title": "The Great Ban: Efficacy and Unintended Consequences of a Massive Deplatforming Operation on Reddit", "link": "https://arxiv.org/abs/2401.11254", "description": "arXiv:2401.11254v5 Announce Type: replace \nAbstract: In the current landscape of online abuses and harms, effective content moderation is necessary to cultivate safe and inclusive online spaces. Yet, the effectiveness of many moderation interventions is still unclear. Here, we assess the effectiveness of The Great Ban, a massive deplatforming operation that affected nearly 2,000 communities on Reddit. By analyzing 16M comments posted by 17K users during 14 months, we provide nuanced results on the effects, both desired and otherwise, of the ban. Among our main findings is that 15.6% of the affected users left Reddit and that those who remained reduced their toxicity by 6.6% on average. The ban also caused 5% users to increase their toxicity by more than 70% of their pre-ban level. Overall, our multifaceted results provide new insights into the efficacy of deplatforming. As such, our findings can inform the development of future moderation interventions and the policing of online platforms."}, "https://arxiv.org/abs/2403.00603": {"title": "Modeling of obstacle avoidance by a dense crowd as a Mean-Field Game", "link": "https://arxiv.org/abs/2403.00603", "description": "arXiv:2403.00603v2 Announce Type: replace \nAbstract: In this paper we use a minimal model based on Mean-Field Games (a mathematical framework apt to describe situations where a large number of agents compete strategically) to simulate the scenario where a static dense human crowd is crossed by a cylindrical intruder. After a brief explanation of the mathematics behind it, we compare our model directly against the empirical data collected during a controlled experiment replicating the aforementioned situation. We then summarize the features that make the model adhere so well to the experiment and clarify the anticipation time in this framework."}, "https://arxiv.org/abs/2403.01168": {"title": "Mean-Field Games Modeling of Anticipation in Dense Crowds", "link": "https://arxiv.org/abs/2403.01168", "description": "arXiv:2403.01168v2 Announce Type: replace \nAbstract: Understanding and modeling pedestrian dynamics in dense crowds is a complex yet essential aspect of crowd management and urban planning. In this work, we investigate the dynamics of a dense crowd crossed by a cylindrical intruder using a Mean-Field Game (MFG) model. By incorporating a discount factor to account for pedestrians' limited anticipation and information processing, we examine the model's ability to simulate two distinct experimental configurations: pedestrians facing the obstacle and pedestrians giving their back to the intruder. Through a comprehensive comparison with experimental data, we demonstrate that the MFG model effectively captures essential crowd behaviors, including anticipatory motion and collision avoidance."}, "https://arxiv.org/abs/2301.10856": {"title": "Partial Mobilization: Tracking Multilingual Information Flows Amongst Russian Media Outlets and Telegram", "link": "https://arxiv.org/abs/2301.10856", "description": "arXiv:2301.10856v5 Announce Type: replace-cross \nAbstract: In response to disinformation and propaganda from Russian online media following the invasion of Ukraine, Russian media outlets such as Russia Today and Sputnik News were banned throughout Europe. To maintain viewership, many of these Russian outlets began to heavily promote their content on messaging services like Telegram. In this work, we study how 16 Russian media outlets interacted with and utilized 732 Telegram channels throughout 2022. Leveraging the foundational model MPNet, DP-means clustering, and Hawkes processes, we trace how narratives spread between news sites and Telegram channels. We show that news outlets not only propagate existing narratives through Telegram but that they source material from the messaging platform. For example, across the websites in our study, between 2.3% (ura.news) and 26.7% (ukraina.ru) of articles discussed content that originated/resulted from activity on Telegram. Finally, tracking the spread of individual topics, we measure the rate at which news outlets and Telegram channels disseminate content within the Russian media ecosystem, finding that websites like ura.news and Telegram channels such as @genshab are the most effective at disseminating their content."}, "https://arxiv.org/abs/2308.08012": {"title": "Comprehensive Analysis of Network Robustness Evaluation Based on Convolutional Neural Networks with Spatial Pyramid Pooling", "link": "https://arxiv.org/abs/2308.08012", "description": "arXiv:2308.08012v2 Announce Type: replace-cross \nAbstract: Connectivity robustness, a crucial aspect for understanding, optimizing, and repairing complex networks, has traditionally been evaluated through time-consuming and often impractical simulations. Fortunately, machine learning provides a new avenue for addressing this challenge. However, several key issues remain unresolved, including the performance in more general edge removal scenarios, capturing robustness through attack curves instead of directly training for robustness, scalability of predictive tasks, and transferability of predictive capabilities. In this paper, we address these challenges by designing a convolutional neural networks (CNN) model with spatial pyramid pooling networks (SPP-net), adapting existing evaluation metrics, redesigning the attack modes, introducing appropriate filtering rules, and incorporating the value of robustness as training data. The results demonstrate the thoroughness of the proposed CNN framework in addressing the challenges of high computational time across various network types, failure component types and failure scenarios. However, the performance of the proposed CNN model varies: for evaluation tasks that are consistent with the trained network type, the proposed CNN model consistently achieves accurate evaluations of both attack curves and robustness values across all removal scenarios. When the predicted network type differs from the trained network, the CNN model still demonstrates favorable performance in the scenario of random node failure, showcasing its scalability and performance transferability. Nevertheless, the performance falls short of expectations in other removal scenarios. This observed scenario-sensitivity in the evaluation of network features has been overlooked in previous studies and necessitates further attention and optimization. Lastly, we discuss important unresolved questions and further investigation."}, "https://arxiv.org/abs/2310.19697": {"title": "A nonlinear spectral core-periphery detection method for multiplex networks", "link": "https://arxiv.org/abs/2310.19697", "description": "arXiv:2310.19697v2 Announce Type: replace-cross \nAbstract: Core-periphery detection aims to separate the nodes of a complex network into two subsets: a core that is densely connected to the entire network and a periphery that is densely connected to the core but sparsely connected internally. The definition of core-periphery structure in multiplex networks that record different types of interactions between the same set of nodes on different layers is nontrivial since a node may belong to the core in some layers and to the periphery in others. We propose a nonlinear spectral method for multiplex networks that simultaneously optimises a node and a layer coreness vector by maximising a suitable nonconvex homogeneous objective function by a provably convergent alternating fixed point iteration. We derive a quantitative measure for the quality of a given multiplex core-periphery structure that allows the determination of the optimal core size. Numerical experiments on synthetic and real-world networks illustrate that our approach is robust against noisy layers and significantly outperforms baseline methods while improving the latter with our novel optimised layer coreness weights. As the runtime of our method depends linearly on the number of edges of the network it is scalable to large-scale multiplex networks."}, "https://arxiv.org/abs/2405.04773": {"title": "Hypergraph-enhanced Dual Semi-supervised Graph Classification", "link": "https://arxiv.org/abs/2405.04773", "description": "arXiv:2405.04773v2 Announce Type: replace-cross \nAbstract: In this paper, we study semi-supervised graph classification, which aims at accurately predicting the categories of graphs in scenarios with limited labeled graphs and abundant unlabeled graphs. Despite the promising capability of graph neural networks (GNNs), they typically require a large number of costly labeled graphs, while a wealth of unlabeled graphs fail to be effectively utilized. Moreover, GNNs are inherently limited to encoding local neighborhood information using message-passing mechanisms, thus lacking the ability to model higher-order dependencies among nodes. To tackle these challenges, we propose a Hypergraph-Enhanced DuAL framework named HEAL for semi-supervised graph classification, which captures graph semantics from the perspective of the hypergraph and the line graph, respectively. Specifically, to better explore the higher-order relationships among nodes, we design a hypergraph structure learning to adaptively learn complex node dependencies beyond pairwise relations. Meanwhile, based on the learned hypergraph, we introduce a line graph to capture the interaction between hyperedges, thereby better mining the underlying semantic structures. Finally, we develop a relational consistency learning to facilitate knowledge transfer between the two branches and provide better mutual guidance. Extensive experiments on real-world graph datasets verify the effectiveness of the proposed method against existing state-of-the-art methods."}, "https://arxiv.org/abs/2405.18555": {"title": "Multigraph reconstruction via nonlinear random walk", "link": "https://arxiv.org/abs/2405.18555", "description": "arXiv:2405.18555v1 Announce Type: new \nAbstract: Over the last few years, network science has proved to be useful in modeling a variety of complex systems, composed of a large number of interconnected units. The intricate pattern of interactions often allows the system to achieve complex tasks, such as synchronization or collective motions. In this regard, the interplay between network structure and dynamics has long been recognized as a cornerstone of network science. Among dynamical processes, random walks are undoubtedly among the most studied stochastic processes. While traditionally, the random walkers are assumed to be independent, this assumption breaks down if nodes are endowed with a finite carrying capacity, a feature shared by many real-life systems. Recently, a class of nonlinear diffusion processes accounting for the finite carrying capacities of the nodes was introduced. The stationary nodes densities were shown to be nonlinearly correlated with the nodes degrees, allowing to uncover the network structure by performing a few measurements of the stationary density at the level of a single arbitrary node and by solving an inverse problem. In this work, we extend this class of nonlinear diffusion processes to the case of multigraphs, in which links between nodes carry distinct attributes. Assuming the knowledge of the pattern of interactions associated with one type of links, we show how the degree distribution of the whole multigraph can be reconstructed. The effectiveness of the reconstruction algorithm is demonstrated through simulations on various multigraph topologies."}, "https://arxiv.org/abs/2405.18748": {"title": "Equity Implications of Net-Zero Emissions: A Multi-Model Analysis of Energy Expenditures Across Income Classes Under Economy-Wide Deep Decarbonization Policies", "link": "https://arxiv.org/abs/2405.18748", "description": "arXiv:2405.18748v1 Announce Type: new \nAbstract: With companies, states, and countries targeting net-zero emissions around midcentury, there are questions about how these targets alter household welfare and finances, including distributional effects across income groups. This paper examines the distributional dimensions of technology transitions and net-zero policies with a focus on welfare impacts across household incomes. The analysis uses a model intercomparison with a range of energy-economy models using harmonized policy scenarios reaching economy-wide, net-zero CO2 emissions across the United States in 2050. We employ a novel linking approach that connects output from detailed energy system models with survey microdata on energy expenditures across income classes to provide distributional analysis of net-zero policies. Although there are differences in model structure and input assumptions, we find broad agreement in qualitative trends in policy incidence and energy burdens across income groups. Models generally agree that direct energy expenditures for many households will likely decline over time with reference and net-zero policies. However, there is variation in the extent of changes relative to current levels, energy burdens relative to reference levels, and electricity expenditures. Policy design, primarily how climate policy revenues are used, has first-order impacts on distributional outcomes. Net-zero policy costs, in both absolute and relative terms, are unevenly distributed across households, and relative increases in energy expenditures are higher for lowest-income households. However, we also find that recycled revenues from climate policies have countervailing effects when rebated on a per-capita basis, offsetting higher energy burdens and potentially even leading to net progressive outcomes."}, "https://arxiv.org/abs/2405.18803": {"title": "Information Dynamics in Evolving Networks Based on the Birth-Death Process: Random Drift and Natural Selection Perspective", "link": "https://arxiv.org/abs/2405.18803", "description": "arXiv:2405.18803v1 Announce Type: new \nAbstract: Dynamic processes in complex networks are crucial for better understanding collective behavior in human societies, biological systems, and the internet. In this paper, we first focus on the continuous Markov-based modeling of evolving networks with the birth-death of individuals. A new individual arrives at the group by the Poisson process, while new links are established in the network through either uniform connection or preferential attachment. Moreover, an existing individual has a limited lifespan before leaving the network. We determine stationary topological properties of these networks, including their size and mean degree. To address the effect of the birth-death evolution, we further study the information dynamics in the proposed network model from the random drift and natural selection perspective, based on assumptions of total-stochastic and fitness-driven evolution, respectively. In simulations, we analyze the fixation probability of individual information and find that means of new connections affect the random drift process but do not affect the natural selection process."}, "https://arxiv.org/abs/2405.19141": {"title": "Resilience of mobility network to dynamic population response across COVID-19 interventions: evidences from Chile", "link": "https://arxiv.org/abs/2405.19141", "description": "arXiv:2405.19141v1 Announce Type: new \nAbstract: The COVID19 pandemic highlighted the importance of non-traditional data sources, such as mobile phone data, to inform effective public health interventions and monitor adherence to such measures. Previous studies showed how socioeconomic characteristics shaped population response during restrictions and how repeated interventions eroded adherence over time. Less is known about how different population strata changed their response to repeated interventions and how this impacted the resulting mobility network. We study population response during the first and second infection waves of the COVID-19 pandemic in Chile and Spain. Via spatial lag and regression models, we investigate the adherence to mobility interventions at the municipality level in Chile, highlighting the significant role of wealth, labor structure, COVID-19 incidence, and network metrics characterizing business-as-usual municipality connectivity in shaping mobility changes during the two waves. We assess network structural similarities in the two periods by defining mobility hotspots and traveling probabilities in the two countries. As a proof of concept, we simulate and compare outcomes of an epidemic diffusion occurring in the two waves. Our analysis reveals the resilience of the mobility network across waves. We test the robustness of our findings recovering similar results for Spain. Finally, epidemic modeling suggests that historical mobility data from past waves can be leveraged to inform future disease spatial invasion models in repeated interventions. This study highlights the value of historical mobile phone data for building pandemic preparedness and lessens the need for real-time data streams for risk assessment and outbreak response. Our work provides valuable insights into the complex interplay of factors driving mobility across repeated interventions, aiding in developing targeted mitigation strategies."}, "https://arxiv.org/abs/2405.19199": {"title": "A statistical analysis of drug seizures and opioid overdose deaths in Ohio from 2014 to 2018", "link": "https://arxiv.org/abs/2405.19199", "description": "arXiv:2405.19199v1 Announce Type: new \nAbstract: This paper examines the association between police drug seizures and drug overdose deaths in Ohio from 2014 to 2018. We use linear regression, ARIMA models, and categorical data analysis to quantify the effect of drug seizure composition and weight on drug overdose deaths, to quantify the lag between drug seizures and overdose deaths, and to compare the weight distributions of drug seizures conducted by different types of law enforcement (national, local, and drug task forces). We find that drug seizure composition and weight have strong predictive value for drug overdose deaths (F = 27.14, p < 0.0001, R^2 = .7799). A time series analysis demonstrates no statistically significant lag between drug seizures and overdose deaths or weight. Histograms and Kolmogorov-Smirnov tests demonstrate stark differences between seizure weight distributions of different types of law enforcement (p < 0.0001 for each pairwise comparison). We include a discussion of what our conclusions mean for law enforcement and harm reduction efforts."}, "https://arxiv.org/abs/2405.18526": {"title": "Unlocking the Potential of Renewable Energy Through Curtailment Prediction", "link": "https://arxiv.org/abs/2405.18526", "description": "arXiv:2405.18526v1 Announce Type: cross \nAbstract: A significant fraction (5-15%) of renewable energy generated goes into waste in the grids around the world today due to oversupply issues and transmission constraints. Being able to predict when and where renewable curtailment occurs would improve renewable utilization. The core of this work is to enable the machine learning community to help decarbonize electricity grids by unlocking the potential of renewable energy through curtailment prediction."}, "https://arxiv.org/abs/2405.18873": {"title": "A Return to Biased Nets: New Specifications and Approximate Bayesian Inference", "link": "https://arxiv.org/abs/2405.18873", "description": "arXiv:2405.18873v1 Announce Type: cross \nAbstract: The biased net paradigm was the first general and empirically tractable scheme for parameterizing complex patterns of dependence in networks, expressing deviations from uniform random graph structure in terms of latent ``bias events,'' whose realizations enhance reciprocity, transitivity, or other structural features. Subsequent developments have introduced local specifications of biased nets, which reduce the need for approximations required in early specifications based on tracing processes. Here, we show that while one such specification leads to inconsistencies, a closely related Markovian specification both evades these difficulties and can be extended to incorporate new types of effects. We introduce the notion of inhibitory bias events, with satiation as an example, which are useful for avoiding degeneracies that can arise from closure bias terms. Although our approach does not lead to a computable likelihood, we provide a strategy for approximate Bayesian inference using random forest prevision. We demonstrate our approach on a network of friendship ties among college students, recapitulating a relationship between the sibling bias and tie strength posited in earlier work by Fararo."}, "https://arxiv.org/abs/2405.19125": {"title": "Early Detection of Critical Urban Events using Mobile Phone Network Data", "link": "https://arxiv.org/abs/2405.19125", "description": "arXiv:2405.19125v1 Announce Type: cross \nAbstract: Network Signalling Data (NSD) have the potential to provide continuous spatio-temporal information about the presence, mobility, and usage patterns of cell phone services by individuals. Such information is invaluable for monitoring large urban areas and supporting the implementation of decision-making services. When analyzed in real time, NSD can enable the early detection of critical urban events, including fires, large accidents, stampedes, terrorist attacks, and sports and leisure gatherings, especially if these events significantly impact mobile phone network activity in the affected areas. This paper presents empirical evidence that advanced NSD can detect anomalies in mobile traffic service consumption, attributable to critical urban events, with fine spatial and temporal resolutions. We introduce two methodologies for real-time anomaly detection from multivariate time series extracted from large-scale NSD, utilizing a range of algorithms adapted from the state-of-the-art in unsupervised machine learning techniques for anomaly detection. Our research includes a comprehensive quantitative evaluation of these algorithms on a large-scale dataset of NSD service consumption for the Paris region. The evaluation uses an original dataset of documented critical or unusual urban events. This dataset has been built as a ground truth basis for assessing the algorithms performance. The obtained results demonstrate that our framework can detect unusual events almost instantaneously and locate the affected areas with high precision, largely outperforming random classifiers. This efficiency and effectiveness underline the potential of NSD-based anomaly detection in significantly enhancing emergency response strategies and urban planning."}, "https://arxiv.org/abs/2405.19242": {"title": "Modeling public opinion control by a charismatic leader", "link": "https://arxiv.org/abs/2405.19242", "description": "arXiv:2405.19242v1 Announce Type: cross \nAbstract: We study the average long-time behavior of the binary opinions of a social group with peer-to-peer interactions under the influence of an external bias and a persuadable leader, a strongly-biased agent with a dynamic opinion with the intention of spreading it across the system. We use a generalized, fully-connected Ising model, with each spin representing the binary opinion of an agent at a given time and a single, super spin representing the opinion of the leader. External fields and interaction constants model the opinion bias and peer-to-peer interactions, respectively, while the temperature $T$ models an idealized social climate, representing an authoritarian regime if $T$ is low or a liberal one if $T$ is high. We derive a mean-field solution for the average magnetization $m$, the \"social mood\", and investigate how $m$ and the super spin magnetization vary as a function of $T$. We find that, depending on the initial conditions, due to the presence of metastable states, the sign of the average magnetization depends on the temperature. Finally, we verify that this effect is also present even if we consider only nearest-neighbor interactions within the social group."}, "https://arxiv.org/abs/2207.14016": {"title": "Cascades towards noise-induced transitions on networks revealed using information flows", "link": "https://arxiv.org/abs/2207.14016", "description": "arXiv:2207.14016v4 Announce Type: replace \nAbstract: Abrupt, system-wide transitions can be endogenously generated by seemingly stable networks of interacting dynamical units, such as mode switching in neuronal networks or public opinion changes in social systems. However, it remains poorly understood how such `noise-induced transitions' emerge from the interplay of network structure and dynamics on the network. Here, we report on two key roles that nodes can play in the progression towards noise-induced tipping points. The models used are dynamical networks where the nodes are governed by the Boltzmann-Gibbs distribution, but the concept is easily generalized. First, so-called `initiator nodes' absorb and then transmit short-lived fluctuations to neighboring nodes, making them temporarily more dynamic. These neighbor nodes can then in turn transmit fluctuations to their neighbors, and so on, leading to a domino-effect where the more stable a node is (i.e., high average free energy barrier), the more neighbors are needed that have become temporarily dynamic. Interestingly, towards the tipping point we identify so-called `stabilizer nodes' whose state information becomes part of the long-term memory of the system, after which the domino-effect is reversed and settles the node in their new stable attractor. We validate these roles by targeted interventions that make tipping points more (or less) likely to begin or lead to systemic change. This opens up possibilities for understanding and controlling endogenously generated metastable behavior."}, "https://arxiv.org/abs/2311.03275": {"title": "HetCAN: A Heterogeneous Graph Cascade Attention Network with Dual-Level Awareness", "link": "https://arxiv.org/abs/2311.03275", "description": "arXiv:2311.03275v2 Announce Type: replace-cross \nAbstract: Heterogeneous graph neural networks(HGNNs) have recently shown impressive capability in modeling heterogeneous graphs that are ubiquitous in real-world applications. Most existing methods for heterogeneous graphs mainly learn node embeddings by stacking multiple convolutional or attentional layers, which can be considered as capturing the high-order information from node-level aspect. However, different types of nodes in heterogeneous graphs have diverse features, it is also necessary to capture interactions among node features, namely the high-order information from feature-level aspect. In addition, most methods first align node features by mapping them into one same low-dimensional space, while they may lose some type information of nodes in this way. To address these problems, in this paper, we propose a novel Heterogeneous graph Cascade Attention Network (HetCAN) composed of multiple cascade blocks. Each cascade block includes two components, the type-aware encoder and the dimension-aware encoder. Specifically, the type-aware encoder compensates for the loss of node type information and aims to make full use of graph heterogeneity. The dimension-aware encoder is able to learn the feature-level high-order information by capturing the interactions among node features. With the assistance of these components, HetCAN can comprehensively encode information of node features, graph heterogeneity and graph structure in node embeddings. Extensive experiments demonstrate the superiority of HetCAN over advanced competitors and also exhibit its efficiency and robustness."}, "https://arxiv.org/abs/2401.03390": {"title": "Dynamics-based Feature Augmentation of Graph Neural Networks for Variant Emergence Prediction", "link": "https://arxiv.org/abs/2401.03390", "description": "arXiv:2401.03390v2 Announce Type: replace-cross \nAbstract: During the COVID-19 pandemic, a major driver of new surges has been the emergence of new variants. When a new variant emerges in one or more countries, other nations monitor its spread in preparation for its potential arrival. The impact of the new variant and the timings of epidemic peaks in a country highly depend on when the variant arrives. The current methods for predicting the spread of new variants rely on statistical modeling, however, these methods work only when the new variant has already arrived in the region of interest and has a significant prevalence. Can we predict when a variant existing elsewhere will arrive in a given region? To address this question, we propose a variant-dynamics-informed Graph Neural Network (GNN) approach. First, we derive the dynamics of variant prevalence across pairs of regions (countries) that apply to a large class of epidemic models. The dynamics motivate the introduction of certain features in the GNN. We demonstrate that our proposed dynamics-informed GNN outperforms all the baselines, including the currently pervasive framework of Physics-Informed Neural Networks (PINNs). To advance research in this area, we introduce a benchmarking tool to assess a user-defined model's prediction performance across 87 countries and 36 variants."}, "https://arxiv.org/abs/2401.04133": {"title": "SynHING: Synthetic Heterogeneous Information Network Generation for Graph Learning and Explanation", "link": "https://arxiv.org/abs/2401.04133", "description": "arXiv:2401.04133v2 Announce Type: replace-cross \nAbstract: Graph Neural Networks (GNNs) excel in delineating graph structures in diverse domains, including community analysis and recommendation systems. As the interpretation of GNNs becomes increasingly important, the demand for robust baselines and expansive graph datasets is accentuated, particularly in the context of Heterogeneous Information Networks (HIN). Addressing this, we introduce SynHING, a novel framework for Synthetic Heterogeneous Information Network Generation aimed at enhancing graph learning and explanation. SynHING systematically identifies major motifs in a target HIN and employs a bottom-up generation process with intra-cluster and inter-cluster merge modules. This process, supplemented by post-pruning techniques, ensures the synthetic HIN closely mirrors the original graph's structural and statistical properties. Crucially, SynHING provides ground-truth motifs for evaluating GNN explainer models, setting a new standard for explainable, synthetic HIN generation and contributing to the advancement of interpretable machine learning in complex networks."}, "https://arxiv.org/abs/2402.02464": {"title": "A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer", "link": "https://arxiv.org/abs/2402.02464", "description": "arXiv:2402.02464v3 Announce Type: replace-cross \nAbstract: Can we model Non-Euclidean graphs as pure language or even Euclidean vectors while retaining their inherent information? The Non-Euclidean property have posed a long term challenge in graph modeling. Despite recent graph neural networks and graph transformers efforts encoding graphs as Euclidean vectors, recovering the original graph from vectors remains a challenge. In this paper, we introduce GraphsGPT, featuring an Graph2Seq encoder that transforms Non-Euclidean graphs into learnable Graph Words in the Euclidean space, along with a GraphGPT decoder that reconstructs the original graph from Graph Words to ensure information equivalence. We pretrain GraphsGPT on $100$M molecules and yield some interesting findings: (1) The pretrained Graph2Seq excels in graph representation learning, achieving state-of-the-art results on $8/9$ graph classification and regression tasks. (2) The pretrained GraphGPT serves as a strong graph generator, demonstrated by its strong ability to perform both few-shot and conditional graph generation. (3) Graph2Seq+GraphGPT enables effective graph mixup in the Euclidean space, overcoming previously known Non-Euclidean challenges. (4) The edge-centric pretraining framework GraphsGPT demonstrates its efficacy in graph domain tasks, excelling in both representation and generation. Code is available at \\href{https://github.com/A4Bio/GraphsGPT}{GitHub}."}, "https://arxiv.org/abs/2405.19369": {"title": "Sublinear Cuts are the Exception in BDF-GIRGs", "link": "https://arxiv.org/abs/2405.19369", "description": "arXiv:2405.19369v1 Announce Type: new \nAbstract: The introduction of geometry has proven instrumental in the efforts towards more realistic models for real-world networks. In Geometric Inhomogeneous Random Graphs (GIRGs), Euclidean Geometry induces clustering of the vertices, which is widely observed in networks in the wild. Euclidean Geometry in multiple dimensions however restricts proximity of vertices to those cases where vertices are close in each coordinate. We introduce a large class of GIRG extensions, called BDF-GIRGs, which capture arbitrary hierarchies of the coordinates within the distance function of the vertex feature space. These distance functions have the potential to allow more realistic modeling of the complex formation of social ties in real-world networks, where similarities between people lead to connections. Here, similarity with respect to certain features, such as familial kinship or a shared workplace, suffices for the formation of ties. It is known that - while many key properties of GIRGs, such as log-log average distance and sparsity, are independent of the distance function - the Euclidean metric induces small separators, i.e. sublinear cuts of the unique giant component in GIRGs, whereas no such sublinear separators exist under the component-wise minimum distance. Building on work of Lengler and Todorovi\\'{c}, we give a complete classification for the existence of small separators in BDF-GIRGs. We further show that BDF-GIRGs all fulfill a stochastic triangle inequality and thus also exhibit clustering."}, "https://arxiv.org/abs/2405.19375": {"title": "Improving global awareness of linkset predictions using Cross-Attentive Modulation tokens", "link": "https://arxiv.org/abs/2405.19375", "description": "arXiv:2405.19375v1 Announce Type: new \nAbstract: Most of multiple link prediction or graph generation techniques rely on the attention mechanism or on Graph Neural Networks (GNNs), which consist in leveraging node-level information exchanges in order to form proper link predictions. Such node-level interactions do not process nodes as an ordered sequence, which would imply some kind of natural ordering of the nodes: they are said to be permutation invariant mechanisms. They are well suited for graph problems, but struggle at providing a global orchestration of the predicted links, which can result in a loss of performance. Some typical issues can be the difficulty to ensure high-level properties such as global connectedness, fixed diameter or to avoid information bottleneck effects such as oversmoothing and oversquashing, which respectively consist in abundant smoothing in dense areas leading to a loss of information and a tendency to exclude isolated nodes from the message passing scheme, and often result in irrelevant, unbalanced link predictions. To tackle this problem, we hereby present Cross-Attentive Modulation (CAM) tokens, which introduce cross-attentive units used to condition node and edge-level modulations in order to enable context-aware computations that improve the global consistency of the prediction links. We will implement it on a few permutation invariant architectures, and showcase benchmarks that prove the merits of our work."}, "https://arxiv.org/abs/2405.19383": {"title": "Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation", "link": "https://arxiv.org/abs/2405.19383", "description": "arXiv:2405.19383v1 Announce Type: new \nAbstract: Money laundering presents a pervasive challenge, burdening society by financing illegal activities. To more effectively combat and detect money laundering, the use of network information is increasingly being explored, exploiting that money laundering necessarily involves interconnected parties. This has lead to a surge in literature on network analytics (NA) for anti-money laundering (AML). The literature, however, is fragmented and a comprehensive overview of existing work is missing. This results in limited understanding of the methods that may be applied and their comparative detection power. Therefore, this paper presents an extensive and systematic review of the literature. We identify and analyse 97 papers in the Web of Science and Scopus databases, resulting in a taxonomy of approaches following the fraud analytics framework of Bockel-Rickermann et al.. Moreover, this paper presents a comprehensive experimental framework to evaluate and compare the performance of prominent NA methods in a uniform setup. The framework is applied on the publicly available Elliptic data set and implements manual feature engineering, random walk-based methods, and deep learning GNNs. We conclude from the results that network analytics increases the predictive power of the AML model with graph neural networks giving the best results. An open source implementation of the experimental framework is provided to facilitate researchers and practitioners to extend upon these results and experiment on proprietary data. As such, we aim to promote a standardised approach towards the analysis and evaluation of network analytics for AML."}, "https://arxiv.org/abs/2405.19459": {"title": "Math behind everyday life: on distribution of \"black days\" and beyond", "link": "https://arxiv.org/abs/2405.19459", "description": "arXiv:2405.19459v1 Announce Type: new \nAbstract: In our daily lives, we encounter numerous independent events, each occurring with varying probabilities over time. This letter delves into the scientific background behind the inhomogeneous distribution of these events over time, often resulting in what we refer to as ``black days'', where multiple events seem to converge at once. In the first part of the work we have performed an analysis involving $D$ independent periodic and random sequences of events. Employing the Uniform Manifold Approximation and Projection (UMAP) technique, we observed a clustering of sequences of events on a 2D manifold ${\\cal M}$ at some large $D_{cr}$, which we interpret as the manifestation of ``black days'' and which occurs in a narrow interval around $D_{cr}$. We found that increasing the number of sequences within rather wide interval below $D_{cr}$ leads to a plateau in the clustering on ${\\cal M}$. In the second part of the work we examined in detail clustering patterns of independently distributed $N$ points within the corners of a $D$-dimensional cube when $1\\ll N<D$. Our findings revealed that a transition to a single-component cluster occurs at a critical dimensionality, $D_{cr}$, via a nearly third-order phase transition. Finally, we have addressed the question ``How the infinite-dimensional space could look like?'' Considering the eigenvalue problem for the hyperspherical Laplacian $\\nabla^2_D$ in the limit $D\\to\\infty$, we conjectured about the topology of a target space representing the hyperspherical layer."}, "https://arxiv.org/abs/2405.19552": {"title": "Point process analysis of geographical diffusion of news in Argentina", "link": "https://arxiv.org/abs/2405.19552", "description": "arXiv:2405.19552v1 Announce Type: new \nAbstract: The diffusion of information plays a crucial role in a society, characterizing the diffusion process is challenging because it is highly non-stationary and varies with the media type. To understand the spreading of newspaper news in Argentina, we collected data from more than 27000 articles published in six main provinces during four months. We classified the articles into 20 thematic axes and obtained a set of 120 time series that capture daily newspaper attention on different topics in different provinces. To analyze the data we use a point process approach. For each topic, $n$, and for all pairs of provinces, $i$ and $j$, we use two measures to quantify the synchronicity of the events, $Q_s(i,j)$, which quantifies the number of events that occur almost simultaneously in $i$ and $j$, and $Q_a(i,j)$, which quantifies the direction of news spreading. We also analyze the dataset using well-known measures to detect correlations and dependencies, computed from the raw time series: undirected measures (linear cross-correlation, $CC$, and nonlinear mutual information, $MI$) and directed measures (linear Granger causality, $GC$, and nonlinear Transfer entropy, $TE$). Our analysis unveils how fast the information diffusion process is, as high values of $Q_{s}$, $CC$, and $MI$ reveal pairs of provinces with very similar and almost simultaneous temporal variations of media attention. On the other hand, $GC$ and $TE$ do not perform well in this context because they often return opposite directions of information transfer. We interpret this as due to three main factors: the characteristics of the data, which is highly non-stationary, the characteristics of the information diffusion process, which is very fast and probably acts at a sub-resolution time scale, and the action of large media companies that act as global, external drivers of information dissemination."}, "https://arxiv.org/abs/2405.19565": {"title": "Unbending strategies shepherd cooperation and suppress extortion in spatial populations", "link": "https://arxiv.org/abs/2405.19565", "description": "arXiv:2405.19565v1 Announce Type: new \nAbstract: Evolutionary game dynamics on networks typically consider the competition among simple strategies such as cooperation and defection in the Prisoner's Dilemma and summarize the effect of population structure as network reciprocity. However, it remains largely unknown regarding the evolutionary dynamics involving multiple powerful strategies typically considered in repeated games, such as the zero-determinant (ZD) strategies that are able to enforce a linear payoff relationship between them and their co-players. Here, we consider the evolutionary dynamics of always cooperate (AllC), extortionate ZD (extortioners), and unbending players in lattice populations based on the commonly used death-birth updating. Out of the class of unbending strategies, we consider a particular candidate, PSO Gambler, a machine-learning-optimized memory-one strategy, which can foster reciprocal cooperation and fairness among extortionate players. We derive analytical results under weak selection and rare mutations, including pairwise fixation probabilities and long-term frequencies of strategies. In the absence of the third unbending type, extortioners can achieve a half-half split in equilibrium with unconditional cooperators for sufficiently large extortion factors. However, the presence of unbending players fundamentally changes the dynamics and tilts the system to favor unbending cooperation. Most surprisingly, extortioners cannot dominate at all regardless of how large their extortion factor is, and the long-term frequency of unbending players is maintained almost as a constant. Our analytical method is applicable to studying the evolutionary dynamics of multiple strategies in structured populations. Our work provides insights into the interplay between network reciprocity and direct reciprocity, revealing the role of unbending strategies in enforcing fairness and suppressing extortion."}, "https://arxiv.org/abs/2405.20166": {"title": "An approximation for return time distributions of random walks on sparse networks", "link": "https://arxiv.org/abs/2405.20166", "description": "arXiv:2405.20166v1 Announce Type: new \nAbstract: We propose an approximation for the first return time distribution of random walks on undirected networks. We combine a message-passing solution with a mean-field approximation, to account for the short- and long-term behaviours respectively. We test this approximation on several classes of large graphs and find excellent agreement between our approximations and the true distributions. While the statistical properties of a random walk will depend on the structure of the network, the observed agreement between our approximations and numerical calculations implies that while local structure is clearly very influential, global structure is only important in a relatively superficial way, namely through the total number of edges."}, "https://arxiv.org/abs/2405.20277": {"title": "Pre-train and Refine: Towards Higher Efficiency in K-Agnostic Community Detection without Quality Degradation", "link": "https://arxiv.org/abs/2405.20277", "description": "arXiv:2405.20277v1 Announce Type: new \nAbstract: Community detection (CD) is a classic graph inference task that partitions nodes of a graph into densely connected groups. While many CD methods have been proposed with either impressive quality or efficiency, balancing the two aspects remains a challenge. This study explores the potential of deep graph learning to achieve a better trade-off between the quality and efficiency of K-agnostic CD, where the number of communities K is unknown. We propose PRoCD (Pre-training & Refinement fOr Community Detection), a simple yet effective method that reformulates K-agnostic CD as the binary node pair classification. PRoCD follows a pre-training & refinement paradigm inspired by recent advances in pre-training techniques. We first conduct the offline pre-training of PRoCD on small synthetic graphs covering various topology properties. Based on the inductive inference across graphs, we then generalize the pre-trained model (with frozen parameters) to large real graphs and use the derived CD results as the initialization of an existing efficient CD method (e.g., InfoMap) to further refine the quality of CD results. In addition to benefiting from the transfer ability regarding quality, the online generalization and refinement can also help achieve high inference efficiency, since there is no time-consuming model optimization. Experiments on public datasets with various scales demonstrate that PRoCD can ensure higher efficiency in K-agnostic CD without significant quality degradation."}, "https://arxiv.org/abs/2405.19436": {"title": "Traffic Modeling and Forecast based on Stochastic Cell-Automata and Distributed Fiber-Optic Sensing -- A Numerical Experiment", "link": "https://arxiv.org/abs/2405.19436", "description": "arXiv:2405.19436v1 Announce Type: cross \nAbstract: This paper demonstrates accurate traffic modeling and forecast using stochastic cell-automata (CA) and distributed fiber-optic sensing (DFOS). Traffic congestion is a dominant issue in highways. To reduce congestion, real-time traffic control by short-term forecast is necessary. For achieving this, data assimilation using a stochastic CA model and DFOS is promising. Data assimilation with a CA enables us to model real-time traffic flow with simple processes even when rare or sudden events occur, which is challenging for usual machine learning-based methods. DFOS overcomes issues of conventional point sensors that have dead zones of observation. By estimating optimal model parameters that reproduce observed traffic flow in the simulation, future traffic flow is forecasted from the simulation. We propose an optimal model parameter estimation method using mean velocity as an extracted feature and the particle filter. In addition, an estimation methodology for the microscopic traffic situation is developed to set the initial condition of simulation for forecast in accordance with observation. The proposed methods are verified by simulation-based traffic flow. The simulation adopts the stochastic Nishinari-Fukui-Schadschneider model. The optimal model parameters are successfully derived from posterior probability distributions (PPDs) estimated from DFOS data. In contrast, those estimated from point sensors fail. The PPDs of model parameters also indicate that each parameter has different sensitivities to traffic flow. A traffic forecast up to 60 minutes later is carried out. Using optimal model parameters estimated from DFOS, the forecast error of mean velocity is approximately $\\pm$10 km/h (percentage error is 18%). The error attains half of it when conventional point sensors are used. We conclude that DFOS is a powerful technique for traffic modeling and short-term forecast."}, "https://arxiv.org/abs/2402.07656": {"title": "Low Cost Carriers induce specific and identifiable delay propagation patterns: an analysis of the EU and US systems", "link": "https://arxiv.org/abs/2402.07656", "description": "arXiv:2402.07656v2 Announce Type: replace \nAbstract: The impact of air transport delays and their propagation has long been studied, mainly from environmental and mobility viewpoints, using a wide range of data analysis tools and simulations. Less attention has nevertheless been devoted to how delays create meso-scale structures around each airport. In this work we tackle this issue by reconstructing functional networks of delay propagation centred at each airport, and studying their identifiability (i.e. how unique they are) using Deep Learning models. We find that such delay propagation neighbourhoods are highly unique when they correspond to airports with a high share of Low Cost Carriers operations; and demonstrate the robustness of these findings for the EU and US systems, and to different methodological choices. We further discuss some operational implications of this uniqueness."}, "https://arxiv.org/abs/2405.20457": {"title": "Online network topology shapes personal narratives and hashtag generation", "link": "https://arxiv.org/abs/2405.20457", "description": "arXiv:2405.20457v1 Announce Type: new \nAbstract: While narratives have shaped cognition and cultures for centuries, digital media and online social networks have introduced new narrative phenomena. With increased narrative agency, networked groups of individuals can directly contribute and steer narratives that center our collective discussions of politics, science, and morality. We report the results of an online network experiment on narrative and hashtag generation, in which networked groups of participants interpreted a text-based narrative of a disaster event, and were incentivized to produce matching hashtags with their network neighbors. We found that network structure not only influences the emergence of dominant beliefs through coordination with network neighbors, but also impacts participants' use of causal language in their personal narratives."}, "https://arxiv.org/abs/2405.20740": {"title": "Discrete Lanchester attrition models: the case of precautionary surrender", "link": "https://arxiv.org/abs/2405.20740", "description": "arXiv:2405.20740v1 Announce Type: new \nAbstract: Discrete Lanchester-type attrition models describe many types of antagonistic situations; the preferred interpretation is two fleets of battleships, each trying to sink the other. Such models may be characterised by a bivariate recurrence relation. Here I consider a restricted case in which a fleet that finds itself two or three units behind its opponent immediately surrenders. I present some theoretical and numerical results and suggest lines for further work."}, "https://arxiv.org/abs/2405.20918": {"title": "Flexible inference in heterogeneous and attributed multilayer networks", "link": "https://arxiv.org/abs/2405.20918", "description": "arXiv:2405.20918v1 Announce Type: new \nAbstract: Networked datasets are often enriched by different types of information about individual nodes or edges. However, most existing methods for analyzing such datasets struggle to handle the complexity of heterogeneous data, often requiring substantial model-specific analysis. In this paper, we develop a probabilistic generative model to perform inference in multilayer networks with arbitrary types of information. Our approach employs a Bayesian framework combined with the Laplace matching technique to ease interpretation of inferred parameters. Furthermore, the algorithmic implementation relies on automatic differentiation, avoiding the need for explicit derivations. This makes our model scalable and flexible to adapt to any combination of input data. We demonstrate the effectiveness of our method in detecting overlapping community structures and performing various prediction tasks on heterogeneous multilayer data, where nodes and edges have different types of attributes. Additionally, we showcase its ability to unveil a variety of patterns in a social support network among villagers in rural India by effectively utilizing all input information in a meaningful way."}, "https://arxiv.org/abs/2405.20445": {"title": "GraphAny: A Foundation Model for Node Classification on Any Graph", "link": "https://arxiv.org/abs/2405.20445", "description": "arXiv:2405.20445v1 Announce Type: cross \nAbstract: Foundation models that can perform inference on any new task without requiring specific training have revolutionized machine learning in vision and language applications. However, applications involving graph-structured data remain a tough nut for foundation models, due to challenges in the unique feature- and label spaces associated with each graph. Traditional graph ML models such as graph neural networks (GNNs) trained on graphs cannot perform inference on a new graph with feature and label spaces different from the training ones. Furthermore, existing models learn functions specific to the training graph and cannot generalize to new graphs. In this work, we tackle these two challenges with a new foundational architecture for inductive node classification named GraphAny. GraphAny models inference on a new graph as an analytical solution to a LinearGNN, thereby solving the first challenge. To solve the second challenge, we learn attention scores for each node to fuse the predictions of multiple LinearGNNs. Specifically, the attention module is carefully parameterized as a function of the entropy-normalized distance-features between multiple LinearGNNs predictions to ensure generalization to new graphs. Empirically, GraphAny trained on the Wisconsin dataset with only 120 labeled nodes can effectively generalize to 30 new graphs with an average accuracy of 67.26\\% in an inductive manner, surpassing GCN and GAT trained in the supervised regime, as well as other inductive baselines."}, "https://arxiv.org/abs/2405.20640": {"title": "Heterophilous Distribution Propagation for Graph Neural Networks", "link": "https://arxiv.org/abs/2405.20640", "description": "arXiv:2405.20640v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) have achieved remarkable success in various graph mining tasks by aggregating information from neighborhoods for representation learning. The success relies on the homophily assumption that nearby nodes exhibit similar behaviors, while it may be violated in many real-world graphs. Recently, heterophilous graph neural networks (HeterGNNs) have attracted increasing attention by modifying the neural message passing schema for heterophilous neighborhoods. However, they suffer from insufficient neighborhood partition and heterophily modeling, both of which are critical but challenging to break through. To tackle these challenges, in this paper, we propose heterophilous distribution propagation (HDP) for graph neural networks. Instead of aggregating information from all neighborhoods, HDP adaptively separates the neighbors into homophilous and heterphilous parts based on the pseudo assignments during training. The heterophilous neighborhood distribution is learned with orthogonality-oriented constraint via a trusted prototype contrastive learning paradigm. Both the homophilous and heterophilous patterns are propagated with a novel semantic-aware message passing mechanism. We conduct extensive experiments on 9 benchmark datasets with different levels of homophily. Experimental results show that our method outperforms representative baselines on heterophilous datasets."}, "https://arxiv.org/abs/2405.20702": {"title": "Effect of antibody levels on the spread of disease in multiple infections", "link": "https://arxiv.org/abs/2405.20702", "description": "arXiv:2405.20702v1 Announce Type: cross \nAbstract: There are complex interactions between antibody levels and epidemic propagation, the antibody level of an individual influences the probability of infection, and the spread of the virus influences the antibody level of each individual. There exist some viruses that, in their natural state, cause antibody levels in an infected individual to gradually decay. When these antibody levels decay to a certain point, the individual can be reinfected, such as with COVID 19. To describe their interaction, we introduce a novel mathematical model that incorporates the presence of an antibody retention rate to investigate the infection patterns of individuals who survive multiple infections. The model is composed of a system of stochastic differential equations to derive the equilibrium point and threshold of the model and presents rich experimental results of numerical simulations to further elucidate the propagation properties of the model. We find that the antibody decay rate strongly affects the propagation process, and also that different network structures have different sensitivities to the antibody decay rate, and that changes in the antibody decay rate cause stronger changes in the propagation process in Barabasi Albert networks. Furthermore, we investigate the stationary distribution of the number of infection states and the final antibody levels, and find that they both satisfy the normal distribution, but the standard deviation is small in the Barabasi Albert network. Finally, we explore the effect of individual antibody differences and decay rates on the final population antibody levels, and uncover that individual antibody differences do not affect the final mean antibody levels. The study offers valuable insights for epidemic prevention and control in practical applications."}, "https://arxiv.org/abs/2405.20724": {"title": "Learning on Large Graphs using Intersecting Communities", "link": "https://arxiv.org/abs/2405.20724", "description": "arXiv:2405.20724v1 Announce Type: cross \nAbstract: Message Passing Neural Networks (MPNNs) are a staple of graph machine learning. MPNNs iteratively update each node's representation in an input graph by aggregating messages from the node's neighbors, which necessitates a memory complexity of the order of the number of graph edges. This complexity might quickly become prohibitive for large graphs provided they are not very sparse. In this paper, we propose a novel approach to alleviate this problem by approximating the input graph as an intersecting community graph (ICG) -- a combination of intersecting cliques. The key insight is that the number of communities required to approximate a graph does not depend on the graph size. We develop a new constructive version of the Weak Graph Regularity Lemma to efficiently construct an approximating ICG for any input graph. We then devise an efficient graph learning algorithm operating directly on ICG in linear memory and time with respect to the number of nodes (rather than edges). This offers a new and fundamentally different pipeline for learning on very large non-sparse graphs, whose applicability is demonstrated empirically on node classification tasks and spatio-temporal data processing."}, "https://arxiv.org/abs/2404.01489": {"title": "Perceived Social Influence on Vaccination Decisions: A COVID-19 Case Study", "link": "https://arxiv.org/abs/2404.01489", "description": "arXiv:2404.01489v2 Announce Type: replace \nAbstract: In this study, we examine the perceived influence of others, across both strong and weak social ties, on COVID-19 vaccination decisions in the United States. We add context to social influence by measuring related concepts, such as perceived agreement of others and perceived danger of COVID-19 to others. We find that vaccinated populations perceived more influence from their social circles than unvaccinated populations. This finding holds true across various social groups, including family, close friends, and neighbors. Vaccinated participants perceived that others agreed with their decision to get vaccinated more than unvaccinated participants perceived others to agree with their decision to not get vaccinated. Despite the clear differences in perceived social influence and agreement across the groups, the majority of participants across both vaccinated and unvaccinated populations perceived no social influence from all social group in their decisions. Aligning with this result, we find through open-ended responses that both vaccinated and unvaccinated participants frequently cited fear as a motivating factor in their decision, rather than social influence: vaccinated participants feared COVID-19, while unvaccinated participants feared the vaccine itself."}, "https://arxiv.org/abs/2211.04634": {"title": "Learning Optimal Graph Filters for Clustering of Attributed Graphs", "link": "https://arxiv.org/abs/2211.04634", "description": "arXiv:2211.04634v2 Announce Type: replace-cross \nAbstract: Many real-world systems can be represented as graphs where the different entities in the system are presented by nodes and their interactions by edges. An important task in studying large datasets with graphical structure is graph clustering. While there has been a lot of work on graph clustering using the connectivity between the nodes, many real-world networks also have node attributes. Clustering attributed graphs requires joint modeling of graph structure and node attributes. Recent work has focused on combining these two complementary sources of information through graph convolutional networks and graph filtering. However, these methods are mostly limited to lowpass filtering and do not explicitly learn the filter parameters for the clustering task. In this paper, we introduce a graph signal processing based approach, where we learn the parameters of Finite Impulse Response (FIR) and Autoregressive Moving Average (ARMA) graph filters optimized for clustering. The proposed approach is formulated as a two-step iterative optimization problem, focusing on learning interpretable graph filters that are optimal for the given data and that maximize the separation between different clusters. The proposed approach is evaluated on attributed networks and compared to the state-of-the-art methods."}, "https://arxiv.org/abs/2305.09938": {"title": "Mastering Long-Tail Complexity on Graphs: Characterization, Learning, and Generalization", "link": "https://arxiv.org/abs/2305.09938", "description": "arXiv:2305.09938v4 Announce Type: replace-cross \nAbstract: In the context of long-tail classification on graphs, the vast majority of existing work primarily revolves around the development of model debiasing strategies, intending to mitigate class imbalances and enhance the overall performance. Despite the notable success, there is very limited literature that provides a theoretical tool for characterizing the behaviors of long-tail classes in graphs and gaining insight into generalization performance in real-world scenarios. To bridge this gap, we propose a generalization bound for long-tail classification on graphs by formulating the problem in the fashion of multi-task learning, i.e., each task corresponds to the prediction of one particular class. Our theoretical results show that the generalization performance of long-tail classification is dominated by the overall loss range and the task complexity. Building upon the theoretical findings, we propose a novel generic framework HierTail for long-tail classification on graphs. In particular, we start with a hierarchical task grouping module that allows us to assign related tasks into hypertasks and thus control the complexity of the task space; then, we further design a balanced contrastive learning module to adaptively balance the gradients of both head and tail classes to control the loss range across all tasks in a unified fashion. Extensive experiments demonstrate the effectiveness of HierTail in characterizing long-tail classes on real graphs, which achieves up to 12.9% improvement over the leading baseline method in accuracy."}, "https://arxiv.org/abs/2406.00344": {"title": "Efficient Historical Butterfly Counting in Large Temporal Bipartite Networks via Graph Structure-aware Index", "link": "https://arxiv.org/abs/2406.00344", "description": "arXiv:2406.00344v1 Announce Type: new \nAbstract: Bipartite graphs are ubiquitous in many domains, e.g., e-commerce platforms, social networks, and academia, by modeling interactions between distinct entity sets. Within these graphs, the butterfly motif, a complete 2*2 biclique, represents the simplest yet significant subgraph structure, crucial for analyzing complex network patterns. Counting the butterflies offers significant benefits across various applications, including community analysis and recommender systems. Additionally, the temporal dimension of bipartite graphs, where edges activate within specific time frames, introduces the concept of historical butterfly counting, i.e., counting butterflies within a given time interval. This temporal analysis sheds light on the dynamics and evolution of network interactions, offering new insights into their mechanisms. Despite its importance, no existing algorithm can efficiently solve the historical butterfly counting task. To address this, we design two novel indices whose memory footprints are dependent on #butterflies and #wedges, respectively. Combining these indices, we propose a graph structure-aware indexing approach that significantly reduces memory usage while preserving exceptional query speed. We theoretically prove that our approach is particularly advantageous on power-law graphs, a common characteristic of real-world bipartite graphs, by surpassing traditional complexity barriers for general graphs. Extensive experiments reveal that our query algorithms outperform existing methods by up to five magnitudes, effectively balancing speed with manageable memory requirements."}, "https://arxiv.org/abs/2406.01113": {"title": "Bridging the Digital Divide: Mapping Internet Connectivity Evolution, Inequalities, and Resilience in six Brazilian Cities", "link": "https://arxiv.org/abs/2406.01113", "description": "arXiv:2406.01113v1 Announce Type: new \nAbstract: We investigate the evolution of Internet speed and its implications for access to key digital services, as well as the resilience of the network during crises, focusing on six major Brazilian cities: Belo Horizonte, Bras\\'ilia, Fortaleza, Manaus, Rio de Janeiro, and S\\~ao Paulo. Leveraging a unique dataset of Internet Speedtest results provided by Ookla, we analyze Internet speed trends from 2017 to 2023. Our findings reveal significant improvements in Internet speed across all cities. However, we find that prosperous areas generally exhibit better Internet access, and that the dependence of Internet quality on wealth have increased over time. Additionally, we investigate the impact of Internet quality on access to critical online services, focusing on e-learning. Our analysis shows that nearly 13% of catchment areas around educational facilities have Internet speeds below the threshold required for e-learning, with less rich areas experiencing more significant challenges. Moreover, we investigate the network's resilience during the COVID-19 pandemic, finding a sharp decline in network quality following the declaration of national emergency. We also find that less wealthy areas experience larger drops in network quality during crises. Overall, this study underscores the importance of addressing disparities in Internet access to ensure equitable access to digital services and enhance network resilience during crises"}, "https://arxiv.org/abs/2406.01341": {"title": "Important node identification for complex networks based on improved Electre Multi-Attribute fusion", "link": "https://arxiv.org/abs/2406.01341", "description": "arXiv:2406.01341v1 Announce Type: new \nAbstract: Influence maximization problem involves selecting a subset of seed nodes within a social network to maximize information spread under a given diffusion model, so how to identify the important nodes is the problem to be considered in this paper. Due to the great differences in the reality of the network, a class of multi-attribute decision fusion methods is often used to solve this problem. Electre is mostly used to solve the problems of investment order, benefit, and risk assessment of projects in economics, which supports the decision maker to make choices by comparing the differences between a set of alternatives. In this paper, we propose a multi-attribute decision fusion method named SK-E, which construct local and global metrics for different networks, use the improved Electre to make decision fusion between local and global metrics of nodes, to get the optimal weight between local and global metrics, and then identify the important nodes. The proposed method demonstrates superior accuracy compared to other methods, as evaluated through three experiments: the SIR epidemic model, the independent cascade model, and constraint efficiency. These experiments were conducted across six different real networks selected as the experimental dataset."}, "https://arxiv.org/abs/2406.01367": {"title": "Structural prediction of super-diffusion in multiplex networks", "link": "https://arxiv.org/abs/2406.01367", "description": "arXiv:2406.01367v1 Announce Type: new \nAbstract: Diffusion dynamics in multiplex networks can model a diverse number of real-world processes. In some specific configurations of these systems, the super-diffusion phenomenon arises, in which the diffusion is faster in the multiplex network than in any of its layers. Many studies attempt to characterize this phenomenon by examining its dependency on structural properties of the network, such as overlap, average degree, network dissimilarity, and others. While certain properties show a correlation with super-diffusion in specific networks, a broader characterization is still missing. Here, we introduce a structural parameter based on the minimum node strength that effectively predicts the occurrence of super-diffusion in multiplex networks. Additionally, we propose a novel framework for deriving analytical bounds for several multiplex networks structures. Finally, we analyze and justify why certain arrangements of the inter-layer connections induce super-diffusion. These findings provide novel insights into the super-diffusion phenomenon and the interplay between network structure and dynamics."}, "https://arxiv.org/abs/2406.01517": {"title": "Beyond symmetrization: effective adjacency matrices and renormalization for (un)singed directed graphs", "link": "https://arxiv.org/abs/2406.01517", "description": "arXiv:2406.01517v1 Announce Type: new \nAbstract: To address the peculiarities of directed and/or signed graphs, new Laplacian operators have emerged. For instance, in the case of directionality, we encounter the magnetic operator, dilation (which is underexplored), operators based on random walks, and so forth. The definition of these new operators leads to the need for new studies and concepts, and consequently, the development of new computational tools. But is this really necessary? In this work, we define the concept of effective adjacency matrices that arise from the definition of deformed Laplacian operators such as magnetic, dilation, and signal. These effective matrices allow mapping generic graphs to a family of unsigned, undirected graphs, enabling the application of the well-explored toolkit of measures, machine learning methods, and renormalization groups of undirected graphs. To explore the interplay between deformed operators and effective matrices, we show how the Hodge-Helmholtz decomposition can assist us in navigating this complexity."}, "https://arxiv.org/abs/2406.00617": {"title": "Maximum $k$-Plex Search: An Alternated Reduction-and-Bound Method", "link": "https://arxiv.org/abs/2406.00617", "description": "arXiv:2406.00617v1 Announce Type: cross \nAbstract: $k$-plexes relax cliques by allowing each vertex to disconnect to at most $k$ vertices. Finding a maximum $k$-plex in a graph is a fundamental operator in graph mining and has been receiving significant attention from various domains. The state-of-the-art algorithms all adopt the branch-reduction-and-bound (BRB) framework where a key step, called reduction-and-bound (RB), is used for narrowing down the search space. A common practice of RB in existing works is SeqRB, which sequentially conducts the reduction process followed by the bounding process once at a branch. However, these algorithms suffer from the efficiency issues. In this paper, we propose a new alternated reduction-and-bound method AltRB for conducting RB. AltRB first partitions a branch into two parts and then alternatively and iteratively conducts the reduction process and the bounding process at each part of a branch. With newly-designed reduction rules and bounding methods, AltRB is superior to SeqRB in effectively narrowing down the search space in both theory and practice. Further, to boost the performance of BRB algorithms, we develop efficient and effective pre-processing methods which reduce the size of the input graph and heuristically compute a large $k$-plex as the lower bound. We conduct extensive experiments on 664 real and synthetic graphs. The experimental results show that our proposed algorithm kPEX with AltRB and novel pre-processing techniques runs up to two orders of magnitude faster and solves more instances than state-of-the-art algorithms."}, "https://arxiv.org/abs/2406.00864": {"title": "Optimal Control of General Impulsive VS-EIAR Epidemic Models with Application to Covid-19", "link": "https://arxiv.org/abs/2406.00864", "description": "arXiv:2406.00864v1 Announce Type: cross \nAbstract: In this work, we are interested in a VS-EIAR epidemiological model considering vaccinated individuals ${V_i: i=1,\\ldots,n}$, where $n\\in \\mathbb{N}^{*}$. The dynamic of the VS-EIAR model involves several ordinary differential equations that describe the changes in the vaccinated, susceptible, infected, exposed, asymptomatic, and deceased population groups. Our aim is to reduce the number of susceptible, exposed, infected, and asymptomatic individuals by administering vaccination doses to susceptible individuals and treatment to infected population. To achieve this, we utilize optimal control theory to regulate the dynamic of our considered epidemic model within a terminal optimal time $\\tau^{*}$. Pontryagin's maximum principle (PMP) will be employed to establish the existence of an optimal control time $(v^{*}(t), u^{*}(t))$. We also incorporate an impulsive VS-EIAR epidemic model, with special attention given to immigration or the travel of certain population groups. Finally, we provide a numerical simulation to demonstrate the practical implementation of the theoretical findings."}, "https://arxiv.org/abs/2406.00987": {"title": "Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement", "link": "https://arxiv.org/abs/2406.00987", "description": "arXiv:2406.00987v1 Announce Type: cross \nAbstract: Graph anomaly detection (GAD) is increasingly crucial in various applications, ranging from financial fraud detection to fake news detection. However, current GAD methods largely overlook the fairness problem, which might result in discriminatory decisions skewed toward certain demographic groups defined on sensitive attributes (e.g., gender, religion, ethnicity, etc.). This greatly limits the applicability of these methods in real-world scenarios in light of societal and ethical restrictions. To address this critical gap, we make the first attempt to integrate fairness with utility in GAD decision-making. Specifically, we devise a novel DisEntangle-based FairnEss-aware aNomaly Detection framework on the attributed graph, named DEFEND. DEFEND first introduces disentanglement in GNNs to capture informative yet sensitive-irrelevant node representations, effectively reducing societal bias inherent in graph representation learning. Besides, to alleviate discriminatory bias in evaluating anomalous nodes, DEFEND adopts a reconstruction-based anomaly detection, which concentrates solely on node attributes without incorporating any graph structure. Additionally, given the inherent association between input and sensitive attributes, DEFEND constrains the correlation between the reconstruction error and the predicted sensitive attributes. Our empirical evaluations on real-world datasets reveal that DEFEND performs effectively in GAD and significantly enhances fairness compared to state-of-the-art baselines. To foster reproducibility, our code is available at https://github.com/AhaChang/DEFEND."}, "https://arxiv.org/abs/2406.01101": {"title": "Fast and Robust Flocking of Protesters on Street Networks", "link": "https://arxiv.org/abs/2406.01101", "description": "arXiv:2406.01101v1 Announce Type: cross \nAbstract: We propose a simple model of protesters scattered throughout a city who want to gather into large and mobile groups. This model relies on random walkers on a street network that follow tactics built from a set of basic rules. Our goal is to identify the most important rules for fast and robust flocking of walkers. We explore a wide set of tactics and show the central importance of a specific rule based on alignment. Other rules alone perform poorly, but our experiments show that combining alignment with them enhances flocking, and that obtained groups are then remarkably robust."}, "https://arxiv.org/abs/2010.12303": {"title": "Random hyperbolic graphs in $d+1$ dimensions", "link": "https://arxiv.org/abs/2010.12303", "description": "arXiv:2010.12303v4 Announce Type: replace \nAbstract: We consider random hyperbolic graphs in hyperbolic spaces of any dimension $d+1\\geq 2$. We present a rescaling of model parameters that casts the random hyperbolic graph model of any dimension to a unified mathematical framework, leaving the degree distribution invariant with respect to the dimension. Unlike the degree distribution, clustering does depend on the dimension, decreasing to 0 at $d \\rightarrow \\infty$. We analyze all of the other limiting regimes of the model, and we release a software package that generates random hyperbolic graphs and their limits in hyperbolic spaces of any dimension."}, "https://arxiv.org/abs/2206.01393": {"title": "Simulation of Crowd Egress with Environmental Stressors", "link": "https://arxiv.org/abs/2206.01393", "description": "arXiv:2206.01393v5 Announce Type: replace \nAbstract: This article introduces a modeling framework to characterize evacuee response to environmental stimuli during emergency egress. The model is developed in consistency with stress theory, which explains how an organism reacts to environmental stressors. We integrate the theory into the well-known social-force model, and develop a framework to simulate crowd evacuation behavior in multi-compartment buildings. Our method serves as a theoretical basis to study crowd movement at bottlenecks, and simulate their herding and way-finding behavior in normal and hazardous conditions. The pre-movement behavior is also briefly investigated by using opinion dynamics with social group model. The algorithms have been partly tested in FDS+EVAC as well as our simulation platform crowdEgress."}, "https://arxiv.org/abs/2212.11051": {"title": "Correlation distances in social networks", "link": "https://arxiv.org/abs/2212.11051", "description": "arXiv:2212.11051v2 Announce Type: replace \nAbstract: In this work we explore degree assortativity in complex networks, and extend its usual definition beyond that of nearest neighbours. We apply this definition to model networks, and describe a rewiring algorithm that induces assortativity. We compare these results to real networks. Social networks in particular tend to be assortatively mixed by degree in contrast to many other types of complex networks. However, we show here that these positive correlations diminish after one step and in most of the empirical networks analysed. Properties besides degree support this, such as the number of papers in scientific coauthorship networks, with no correlations beyond nearest neighbours. Beyond next-nearest neighbours we also observe a diasassortative tendency for nodes three steps away indicating that nodes at that distance are more likely different than similar."}, "https://arxiv.org/abs/2305.09601": {"title": "Operationalizing content moderation \"accuracy\" in the Digital Services Act", "link": "https://arxiv.org/abs/2305.09601", "description": "arXiv:2305.09601v4 Announce Type: replace \nAbstract: The Digital Services Act, recently adopted by the EU, requires social media platforms to report the \"accuracy\" of their automated content moderation systems. The colloquial term is vague, or open-textured -- the literal accuracy (number of correct predictions divided by the total) is not suitable for problems with large class imbalance, and the ground truth and dataset to measure accuracy against is unspecified. Without further specification, the regulatory requirement allows for deficient reporting. In this interdisciplinary work, we operationalize \"accuracy\" reporting by refining legal concepts and relating them to technical implementation. We start by elucidating the legislative purpose of the Act to legally justify an interpretation of \"accuracy\" as precision and recall. These metrics remain informative in class imbalanced settings, and reflect the proportional balancing of Fundamental Rights of the EU Charter. We then focus on the estimation of recall, as its naive estimation can incur extremely high annotation costs and disproportionately interfere with the platform's right to conduct business. Through a simulation study, we show that recall can be efficiently estimated using stratified sampling with trained classifiers, and provide concrete recommendations for its application. Finally, we present a case study of recall reporting for a subset of Reddit under the Act. Based on the language in the Act, we identify a number of ways recall could be reported due to underspecification. We report on one possibility using our improved estimator, and discuss the implications and areas for further legal clarification."}, "https://arxiv.org/abs/2402.10659": {"title": "Network Formation and Dynamics Among Multi-LLMs", "link": "https://arxiv.org/abs/2402.10659", "description": "arXiv:2402.10659v3 Announce Type: replace \nAbstract: Social networks shape opinions, behaviors, and information dissemination in human societies. As large language models (LLMs) increasingly integrate into social and professional environments, understanding their behavior within the context of social interactions and networks becomes essential. Our study analyzes LLMs' network formation behavior to examine whether the dynamics of multiple LLMs are similar to or different from human social dynamics. We observe that LLMs exhibit key social network principles, including preferential attachment, triadic closure, homophily, community structure, and the small-world phenomenon, when asked about their preferences in network formation. We also investigate LLMs' decision-making based on real-world networks, revealing that triadic closure and homophily have a stronger influence than preferential attachment and that LLMs perform well in network formation predictions. Overall, our study opens up new possibilities for using LLMs in network science research and helps develop socially aware LLMs by shedding light on their social interaction behaviors and exploring their impacts on social dynamics."}, "https://arxiv.org/abs/2403.08372": {"title": "Negative Impact of Online Political Incivility on Willingness to See Political Comments", "link": "https://arxiv.org/abs/2403.08372", "description": "arXiv:2403.08372v2 Announce Type: replace \nAbstract: Recently, there has been significant attention on online political incivility. While previous research suggests that uncivil political comments lead people to be less willing to see more comments on the same issue, two critical questions have received limited exploration: (1) Are people exposed to uncivil political comments less willing to see other comments from the person who posted the uncivil comment?; (2) Are people exposed to uncivil political comments less willing to see comments from people who have different thoughts than them? To address these questions, the present study conducted a preregistered online survey experiment targeting Japanese citizens, focusing on the pro- vs anti-Kishida cabinet conflict in Japan. The results show that the participants were less willing to see other comments by the person who posted the comment when the comment was uncivil than when it was civil. In addition, the anti-Kishida participants were less willing to see political opinions posted online by people who have different thoughts than them when the comment was uncivil than when it was civil, while the participants in the other subgroups did not show a similar tendency. These findings suggest that uncivil expressions in online political communication might prompt people to avoid reading opinions from those who have different thoughts than them, which might promote political echo chambers."}, "https://arxiv.org/abs/2004.03925": {"title": "Word frequency and sentiment analysis of twitter messages during Coronavirus pandemic", "link": "https://arxiv.org/abs/2004.03925", "description": "arXiv:2004.03925v2 Announce Type: replace-cross \nAbstract: The COVID-19 epidemic has had a great impact on social media conversation, especially on sites like Twitter, which has emerged as a hub for public reaction and information sharing. This paper deals by analyzing a vast dataset of Twitter messages related to this disease, starting from January 2020. Two approaches were used: a statistical analysis of word frequencies and a sentiment analysis to gauge user attitudes. Word frequencies are modeled using unigrams, bigrams, and trigrams, with power law distribution as the fitting model. The validity of the model is confirmed through metrics like Sum of Squared Errors (SSE), R-squared ($R^2$), and Root Mean Squared Error (RMSE). High $R^2$ and low SSE/RMSE values indicate a good fit for the model. Sentiment analysis is conducted to understand the general emotional tone of Twitter users messages. The results reveal that a majority of tweets exhibit neutral sentiment polarity, with only 2.57\\% expressing negative polarity."}, "https://arxiv.org/abs/2204.12095": {"title": "PyGOD: A Python Library for Graph Outlier Detection", "link": "https://arxiv.org/abs/2204.12095", "description": "arXiv:2204.12095v3 Announce Type: replace-cross \nAbstract: PyGOD is an open-source Python library for detecting outliers in graph data. As the first comprehensive library of its kind, PyGOD supports a wide array of leading graph-based methods for outlier detection under an easy-to-use, well-documented API designed for use by both researchers and practitioners. PyGOD provides modularized components of the different detectors implemented so that users can easily customize each detector for their purposes. To ease the construction of detection workflows, PyGOD offers numerous commonly used utility functions. To scale computation to large graphs, PyGOD supports functionalities for deep models such as sampling and mini-batch processing. PyGOD uses best practices in fostering code reliability and maintainability, including unit testing, continuous integration, and code coverage. To facilitate accessibility, PyGOD is released under a BSD 2-Clause license at https://pygod.org and at the Python Package Index (PyPI)."}, "https://arxiv.org/abs/2304.10578": {"title": "Quantifying the Benefit of Artificial Intelligence for Scientific Research", "link": "https://arxiv.org/abs/2304.10578", "description": "arXiv:2304.10578v2 Announce Type: replace-cross \nAbstract: The ongoing artificial intelligence (AI) revolution has the potential to change almost every line of work. As AI capabilities continue to improve in accuracy, robustness, and reach, AI may outperform and even replace human experts across many valuable tasks. Despite enormous effort devoted to understanding the impact of AI on labor and the economy and AI's recent successes in accelerating scientific discovery and progress, we lack a systematic understanding of how AI advances may benefit scientific research across disciplines and fields. Here, drawing from the literature on the future of work and the science of science, we develop a measurement framework to estimate both the direct use of AI and the potential benefit of AI in scientific research, applying natural language processing techniques to 74.6 million publications and 7.1 million patents. We find that the use of AI in research is widespread throughout the sciences, growing especially rapidly since 2015, and papers that use AI exhibit a citation premium, more likely to be highly cited both within and outside their disciplines. Moreover, our analysis reveals considerable potential for AI to benefit numerous scientific fields, yet a notable disconnect exists between AI education and its research applications, highlighting a mismatch between the supply of AI expertise and its demand in research. Lastly, we examine demographic disparities in AI's benefits across scientific disciplines and find that disciplines with a higher proportion of women or Black scientists tend to be associated with less benefit, suggesting that AI's growing impact on research may further exacerbate existing inequalities in science. As the connection between AI and scientific research deepens, our findings may become increasingly important, with implications for the equity and sustainability of the research enterprise."}, "https://arxiv.org/abs/2305.15927": {"title": "Parameter Estimation in DAGs from Incomplete Data via Optimal Transport", "link": "https://arxiv.org/abs/2305.15927", "description": "arXiv:2305.15927v4 Announce Type: replace-cross \nAbstract: Estimating the parameters of a probabilistic directed graphical model from incomplete data is a long-standing challenge. This is because, in the presence of latent variables, both the likelihood function and posterior distribution are intractable without assumptions about structural dependencies or model classes. While existing learning methods are fundamentally based on likelihood maximization, here we offer a new view of the parameter learning problem through the lens of optimal transport. This perspective licenses a general framework that operates on any directed graphs without making unrealistic assumptions on the posterior over the latent variables or resorting to variational approximations. We develop a theoretical framework and support it with extensive empirical evidence demonstrating the versatility and robustness of our approach. Across experiments, we show that not only can our method effectively recover the ground-truth parameters but it also performs comparably or better than competing baselines on downstream applications."}, "https://arxiv.org/abs/2306.00488": {"title": "Reconstructing Graph Diffusion History from a Single Snapshot", "link": "https://arxiv.org/abs/2306.00488", "description": "arXiv:2306.00488v4 Announce Type: replace-cross \nAbstract: Diffusion on graphs is ubiquitous with numerous high-impact applications. In these applications, complete diffusion histories play an essential role in terms of identifying dynamical patterns, reflecting on precaution actions, and forecasting intervention effects. Despite their importance, complete diffusion histories are rarely available and are highly challenging to reconstruct due to ill-posedness, explosive search space, and scarcity of training data. To date, few methods exist for diffusion history reconstruction. They are exclusively based on the maximum likelihood estimation (MLE) formulation and require to know true diffusion parameters. In this paper, we study an even harder problem, namely reconstructing Diffusion history from A single SnapsHot} (DASH), where we seek to reconstruct the history from only the final snapshot without knowing true diffusion parameters. We start with theoretical analyses that reveal a fundamental limitation of the MLE formulation. We prove: (a) estimation error of diffusion parameters is unavoidable due to NP-hardness of diffusion parameter estimation, and (b) the MLE formulation is sensitive to estimation error of diffusion parameters. To overcome the inherent limitation of the MLE formulation, we propose a novel barycenter formulation: finding the barycenter of the posterior distribution of histories, which is provably stable against the estimation error of diffusion parameters. We further develop an effective solver named DIffusion hiTting Times with Optimal proposal (DITTO) by reducing the problem to estimating posterior expected hitting times via the Metropolis--Hastings Markov chain Monte Carlo method (M--H MCMC) and employing an unsupervised graph neural network to learn an optimal proposal to accelerate the convergence of M--H MCMC. We conduct extensive experiments to demonstrate the efficacy of the proposed method."}, "https://arxiv.org/abs/2311.06835": {"title": "Open-Set Graph Anomaly Detection via Normal Structure Regularisation", "link": "https://arxiv.org/abs/2311.06835", "description": "arXiv:2311.06835v3 Announce Type: replace-cross \nAbstract: This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to train a detection model using a small number of normal and anomaly nodes (referred to as seen anomalies) to detect both seen anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the training anomalies). The availability of those labelled training data provides crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current methods tend to over-emphasise fitting the seen anomalies, leading to a weak generalisation ability to detect the unseen anomalies. Further, they were introduced to handle Euclidean data, failing to effectively capture important information on graph structure and node attributes for GAD. In this work, we propose a novel open-set GAD approach, namely Normal Structure Regularisation (NSReg) to achieve generalised detection ability to unseen anomalies, while maintaining its effectiveness on detecting seen anomalies. The key idea in NSReg is to introduce a regularisation term that enforces the learning of compact, semantically-rich representations of normal nodes based on their structural relations to other nodes. When being optimised with supervised anomaly detection losses, the regularisation term helps incorporate strong normality into the modelling, and thus, it effectively avoids the overfitting the seen anomalies solely. In doing so, it helps learn better normality decision boundary, reducing the errors of detecting unseen anomalies as normal. Extensive empirical results on seven real-world datasets show the superiority of NSReg for open-set GAD."}, "https://arxiv.org/abs/2403.02630": {"title": "FedHCDR: Federated Cross-Domain Recommendation with Hypergraph Signal Decoupling", "link": "https://arxiv.org/abs/2403.02630", "description": "arXiv:2403.02630v3 Announce Type: replace-cross \nAbstract: In recent years, Cross-Domain Recommendation (CDR) has drawn significant attention, which utilizes user data from multiple domains to enhance the recommendation performance. However, current CDR methods require sharing user data across domains, thereby violating the General Data Protection Regulation (GDPR). Consequently, numerous approaches have been proposed for Federated Cross-Domain Recommendation (FedCDR). Nevertheless, the data heterogeneity across different domains inevitably influences the overall performance of federated learning. In this study, we propose FedHCDR, a novel Federated Cross-Domain Recommendation framework with Hypergraph signal decoupling. Specifically, to address the data heterogeneity across domains, we introduce an approach called hypergraph signal decoupling (HSD) to decouple the user features into domain-exclusive and domain-shared features. The approach employs high-pass and low-pass hypergraph filters to decouple domain-exclusive and domain-shared user representations, which are trained by the local-global bi-directional transfer algorithm. In addition, a hypergraph contrastive learning (HCL) module is devised to enhance the learning of domain-shared user relationship information by perturbing the user hypergraph. Extensive experiments conducted on three real-world scenarios demonstrate that FedHCDR outperforms existing baselines significantly."}, "https://arxiv.org/abs/2403.11332": {"title": "Graph Machine Learning based Doubly Robust Estimator for Network Causal Effects", "link": "https://arxiv.org/abs/2403.11332", "description": "arXiv:2403.11332v2 Announce Type: replace-cross \nAbstract: We address the challenge of inferring causal effects in social network data. This results in challenges due to interference -- where a unit's outcome is affected by neighbors' treatments -- and network-induced confounding factors. While there is extensive literature focusing on estimating causal effects in social network setups, a majority of them make prior assumptions about the form of network-induced confounding mechanisms. Such strong assumptions are rarely likely to hold especially in high-dimensional networks. We propose a novel methodology that combines graph machine learning approaches with the double machine learning framework to enable accurate and efficient estimation of direct and peer effects using a single observational social network. We demonstrate the semiparametric efficiency of our proposed estimator under mild regularity conditions, allowing for consistent uncertainty quantification. We demonstrate that our method is accurate, robust, and scalable via an extensive simulation study. We use our method to investigate the impact of Self-Help Group participation on financial risk tolerance."}, "https://arxiv.org/abs/2404.07797": {"title": "Illicit Promotion on Twitter", "link": "https://arxiv.org/abs/2404.07797", "description": "arXiv:2404.07797v2 Announce Type: replace-cross \nAbstract: In this paper, we present an extensive study of the promotion of illicit goods and services on Twitter, a popular online social network(OSN). This study is made possible through the design and implementation of multiple novel tools for detecting and analyzing illicit promotion activities as well as their underlying campaigns. As the results, we observe that illicit promotion is prevalent on Twitter, along with noticeable existence on other three popular OSNs including Youtube, Facebook, and TikTok. Particularly, 12 million distinct posts of illicit promotion (PIPs) have been observed on the Twitter platform, which are widely distributed in 5 major natural languages and 10 categories of illicit goods and services, e.g., drugs, data leakage, gambling, and weapon sales. What are also observed are 580K Twitter accounts publishing PIPs as well as 37K distinct instant messaging (IM) accounts that are embedded in PIPs and serve as next hops of communication, which strongly indicates that the campaigns underpinning PIPs are also of a large scale. Also, an arms race between Twitter and illicit promotion operators is also observed. On one hand, Twitter is observed to conduct content moderation in a continuous manner and almost 80% PIPs will get gradually unpublished within six months since posted. However, in the meantime, miscreants adopt various evasion tactics to masquerade their PIPs, which renders more than 90% PIPs keeping hidden from the detection radar for two months or longer."}, "https://arxiv.org/abs/2405.19919": {"title": "Unraveling the Impact of Heterophilic Structures on Graph Positive-Unlabeled Learning", "link": "https://arxiv.org/abs/2405.19919", "description": "arXiv:2405.19919v2 Announce Type: replace-cross \nAbstract: While Positive-Unlabeled (PU) learning is vital in many real-world scenarios, its application to graph data still remains under-explored. We unveil that a critical challenge for PU learning on graph lies on the edge heterophily, which directly violates the irreducibility assumption for Class-Prior Estimation (class prior is essential for building PU learning algorithms) and degenerates the latent label inference on unlabeled nodes during classifier training. In response to this challenge, we introduce a new method, named Graph PU Learning with Label Propagation Loss (GPL). Specifically, GPL considers learning from PU nodes along with an intermediate heterophily reduction, which helps mitigate the negative impact of the heterophilic structure. We formulate this procedure as a bilevel optimization that reduces heterophily in the inner loop and efficiently learns a classifier in the outer loop. Extensive experiments across a variety of datasets have shown that GPL significantly outperforms baseline methods, confirming its effectiveness and superiority."}, "https://arxiv.org/abs/2406.01610": {"title": "Graph structural complexity", "link": "https://arxiv.org/abs/2406.01610", "description": "arXiv:2406.01610v1 Announce Type: new \nAbstract: Introduced the quantitative measure of the structural complexity of the graph (complex network, etc.) based on a procedure similar to the renormalization process, considering the difference between actual and averaged graph structures on different scales. The proposed concept of the graph structural complexity corresponds to qualitative comprehension of the complexity. The proposed measure can be obtained for the weighted graphs also. The structural complexities for various graph types were found - the deterministic infinite and finite size graphs, artificial graphs of different natures including percolation structures, and the time series of cardiac rhythms mapped to complex networks using the parametric visibility graph algorithm. The latter reaches a maximum near the formation of a giant component in the graph or at the percolation threshold for 2D and 3D square lattices when a giant cluster having a fractal structure has emerged. Therefore, the graph structural complexity allows us to detect and study the processes similar to a second-order phase transition in complex networks. A new node centrality index, characterizing the structural complexity of a certain node within the graph structure is introduced also, it can serve as a good auxiliary or generalization to the local clustering coefficient. Such an index provides another new ranking manner for the graph nodes. Being an easily computable measure, the graph structural complexity might help to reveal different features of complex systems and processes of the real world."}, "https://arxiv.org/abs/2406.01612": {"title": "Universal behavior of the Covid-19 tails: Inverse power-law distribution", "link": "https://arxiv.org/abs/2406.01612", "description": "arXiv:2406.01612v1 Announce Type: new \nAbstract: Power-law distribution is one of the most important laws known in nature. Such a special universal behavior is known to occur in very few physical systems. In this work, we analyzed the mortality distribution of the Covid-19 pandemic tails for different countries and continents to discuss the possible universal behavior of the pandemic. Surprisingly, we found that the mortality distribution of Covid-19 follows inverse power-law decays. These universal behaviors for the pandemic are reported in the present work for the first time. Additionally, we showed that mortality tails also decay with time obeying to the inverse power law."}, "https://arxiv.org/abs/2406.01621": {"title": "Susceptibility to Misinformation about COVID-19 Vaccines: A Signal Detection Analysis", "link": "https://arxiv.org/abs/2406.01621", "description": "arXiv:2406.01621v1 Announce Type: new \nAbstract: An analysis drawing on Signal Detection Theory suggests that people may fall for misinformation because they are unable to discern true from false information (truth insensitivity) or because they tend to accept information with a particular slant regardless of whether it is true or false (belief bias). Three preregistered experiments with participants from the United States and the United Kingdom (N = 961) revealed that (i) truth insensitivity in responses to (mis)information about COVID-19 vaccines differed as a function of prior attitudes toward COVID-19 vaccines; (ii) participants exhibited a strong belief bias favoring attitude-congruent information; (iii) truth insensitivity and belief bias jointly predicted acceptance of false information about COVID-19 vaccines, but belief bias was a much stronger predictor; (iv) cognitive elaboration increased truth sensitivity without reducing belief bias; and (v) higher levels of confidence in one's beliefs were associated with greater belief bias. The findings provide insights into why people fall for misinformation, which is essential for individual-level interventions to reduce susceptibility to misinformation."}, "https://arxiv.org/abs/2406.01639": {"title": "Apparent structural changes in contact patterns during COVID-19 were driven by survey design and long-term demographic trends", "link": "https://arxiv.org/abs/2406.01639", "description": "arXiv:2406.01639v1 Announce Type: new \nAbstract: Social contact patterns are key drivers of infectious disease transmission. During the COVID-19 pandemic, differences between pre-COVID and COVID-era contact rates were widely attributed to non-pharmaceutical interventions such as lockdowns. However, the factors that drive changes in the distribution of contacts between different subpopulations remain poorly understood. Here, we present a clustering analysis of 33 contact matrices generated from surveys conducted before and during the COVID-19 pandemic, and analyse key features distinguishing their topological structures. While we expected to identify aspects of pandemic scenarios responsible for these features, our analysis demonstrates that they can be explained by differences in study design and long-term demographic trends. Our results caution against using survey data from different studies in counterfactual analysis of epidemic mitigation strategies. Doing so risks attributing differences stemming from methodological choices or long-term changes to the short-term effects of interventions."}, "https://arxiv.org/abs/2406.01642": {"title": "The Entropy of Knowledge (EoN): Complexity, Uncertainty, and the Quest for Scientific Knowledge", "link": "https://arxiv.org/abs/2406.01642", "description": "arXiv:2406.01642v1 Announce Type: new \nAbstract: This paper explores the concept of \"entropy of knowledge\" (EoN) as a framework for understanding the challenges and complexities of scientific discovery. Drawing from principles in thermodynamics and information theory, I propose that the pursuit of knowledge is characterized by a natural tendency towards disorder, uncertainty, and false conclusions. My central argument is that this entropy of knowledge is not merely an obstacle to be overcome but a fundamental feature of the scientific process, necessary for the exploration of new ideas and the ultimate attainment of truth. The implications of this perspective for the management of scientific inquiry is considered and the same suggests a cyclical approach that balances periods of openness and disorder with phases of consolidation and consensus-building. An attempt is made to situate the EoM model within the broader context of theories of scientific progress, drawing connections to Thomas Kuhn's concept of paradigm shifts and the notion of punctuated equilibrium in the history of science."}, "https://arxiv.org/abs/2406.01911": {"title": "Influence Maximization in Hypergraphs by Stratified Sampling for Efficient Generation of Reverse Reachable Sets", "link": "https://arxiv.org/abs/2406.01911", "description": "arXiv:2406.01911v1 Announce Type: new \nAbstract: Given a hypergraph, influence maximization (IM) is to discover a seed set containing $k$ vertices that have the maximal influence. Although the existing vertex-based IM algorithms perform better than the hyperedge-based algorithms by generating random reverse researchable (RR) sets, they are inefficient because (i) they ignore important structural information associated with hyperedges and thus obtain inferior results, (ii) the frequently-used sampling methods for generating RR sets have low efficiency because of a large number of required samplings along with high sampling variances, and (iii) the vertex-based IM algorithms have large overheads in terms of running time and memory costs. To overcome these shortcomings, this paper proposes a novel approach, called \\emph{HyperIM}. The key idea behind \\emph{HyperIM} is to differentiate structural information of vertices for developing stratified sampling combined with highly-efficient strategies to generate the RR sets. With theoretical guarantees, \\emph{HyperIM} is able to accelerate the influence spread, improve the sampling efficiency, and cut down the expected running time. To further reduce the running time and memory costs, we optimize \\emph{HyperIM} by inferring the bound of the required number of RR sets in conjunction with stratified sampling. Experimental results on real-world hypergraphs show that \\emph{HyperIM} is able to reduce the number of required RR sets and running time by orders of magnitude while increasing the influence spread by up to $2.73X$ on average, compared to the state-of-the-art IM algorithms."}, "https://arxiv.org/abs/2406.02307": {"title": "Traffic Response Functions: Patterns, Propagation and Congestion", "link": "https://arxiv.org/abs/2406.02307", "description": "arXiv:2406.02307v1 Announce Type: new \nAbstract: Using empirical data gathered on motorways in Germany, we follow a new approach by further exploring response functions as a possible tool to study traffic dynamics in motorway networks. We uncover the basic characteristics of responses of flow and density to given signals and the capability of responses to capture the correlation between these fundamental observables. Furthermore, we uncover the potential use of responses to characterize traffic patterns. We are able to demonstrate the differentiation of congestion patterns and the determination of the propagation velocity of moving congestion."}, "https://arxiv.org/abs/2406.01629": {"title": "RecDiff: Diffusion Model for Social Recommendation", "link": "https://arxiv.org/abs/2406.01629", "description": "arXiv:2406.01629v1 Announce Type: cross \nAbstract: Social recommendation has emerged as a powerful approach to enhance personalized recommendations by leveraging the social connections among users, such as following and friend relations observed in online social platforms. The fundamental assumption of social recommendation is that socially-connected users exhibit homophily in their preference patterns. This means that users connected by social ties tend to have similar tastes in user-item activities, such as rating and purchasing. However, this assumption is not always valid due to the presence of irrelevant and false social ties, which can contaminate user embeddings and adversely affect recommendation accuracy. To address this challenge, we propose a novel diffusion-based social denoising framework for recommendation (RecDiff). Our approach utilizes a simple yet effective hidden-space diffusion paradigm to alleivate the noisy effect in the compressed and dense representation space. By performing multi-step noise diffusion and removal, RecDiff possesses a robust ability to identify and eliminate noise from the encoded user representations, even when the noise levels vary. The diffusion module is optimized in a downstream task-aware manner, thereby maximizing its ability to enhance the recommendation process. We conducted extensive experiments to evaluate the efficacy of our framework, and the results demonstrate its superiority in terms of recommendation accuracy, training efficiency, and denoising effectiveness. The source code for the model implementation is publicly available at: https://github.com/HKUDS/RecDiff."}, "https://arxiv.org/abs/2406.01842": {"title": "GraphWeaver: Billion-Scale Cybersecurity Incident Correlation", "link": "https://arxiv.org/abs/2406.01842", "description": "arXiv:2406.01842v1 Announce Type: cross \nAbstract: In the dynamic landscape of large enterprise cybersecurity, accurately and efficiently correlating billions of security alerts into comprehensive incidents is a substantial challenge. Traditional correlation techniques often struggle with maintenance, scaling, and adapting to emerging threats and novel sources of telemetry. We introduce GraphWeaver, an industry-scale framework that shifts the traditional incident correlation process to a data-optimized, geo-distributed graph based approach. GraphWeaver introduces a suite of innovations tailored to handle the complexities of correlating billions of shared evidence alerts across hundreds of thousands of enterprises. Key among these innovations are a geo-distributed database and PySpark analytics engine for large-scale data processing, a minimum spanning tree algorithm to optimize correlation storage, integration of security domain knowledge and threat intelligence, and a human-in-the-loop feedback system to continuously refine key correlation processes and parameters. GraphWeaver is integrated into the Microsoft Defender XDR product and deployed worldwide, handling billions of correlations with a 99% accuracy rate, as confirmed by customer feedback and extensive investigations by security experts. This integration has not only maintained high correlation accuracy but reduces traditional correlation storage requirements by 7.4x. We provide an in-depth overview of the key design and operational features of GraphWeaver, setting a precedent as the first cybersecurity company to openly discuss these critical capabilities at this level of depth."}, "https://arxiv.org/abs/2406.01865": {"title": "The influence of active agent motility on SIRS epidemiological dynamics", "link": "https://arxiv.org/abs/2406.01865", "description": "arXiv:2406.01865v1 Announce Type: cross \nAbstract: Active Brownian disks moving in two dimensions that exchange information about their internal state stochastically are chosen to model epidemic spread in a self-propelled population of agents under the susceptible-infected-recovered-susceptible (SIRS) framework. The state of infection of an agent, or disk, governs its self-propulsion speed; consequently, the activity of the agents in the system varies in time. Two different protocols (one-to-one and one-to-many) are considered for the transmission of disease from the infected to susceptible populations. The effectiveness of the two protocols are practically identical at high values of the infection transmission rate. The one-to-many protocol, however, outperforms the one-to-one protocol at lower values of the infection transmission rate. Salient features of the macroscopic SIRS model are revisited, and compared to predictions from the agent-based model. Lastly, the motility induced phase separation in a population of such agents with a fluctuating fraction of active disks is found to be well-described by theories governing phase separation in a mixture of active and passive particles with a constant fraction of passive disks."}, "https://arxiv.org/abs/2406.01866": {"title": "#EpiTwitter: Public Health Messaging During the COVID-19 Pandemic", "link": "https://arxiv.org/abs/2406.01866", "description": "arXiv:2406.01866v1 Announce Type: cross \nAbstract: Effective communication during health crises is critical, with social media serving as a key platform for public health experts (PHEs) to engage with the public. However, it also amplifies pseudo-experts promoting contrarian views. Despite its importance, the role of emotional and moral language in PHEs' communication during COVID-19 remains under explored. This study examines how PHEs and pseudo-experts communicated on Twitter during the pandemic, focusing on emotional and moral language and their engagement with political elites. Analyzing tweets from 489 PHEs and 356 pseudo-experts from January 2020 to January 2021, alongside public responses, we identified key priorities and differences in messaging strategy. PHEs prioritize masking, healthcare, education, and vaccines, using positive emotional language like optimism. In contrast, pseudo-experts discuss therapeutics and lockdowns more frequently, employing negative emotions like pessimism and disgust. Negative emotional and moral language tends to drive engagement, but positive language from PHEs fosters positivity in public responses. PHEs exhibit liberal partisanship, expressing more positivity towards liberals and negativity towards conservative elites, while pseudo-experts show conservative partisanship. These findings shed light on the polarization of COVID-19 discourse and underscore the importance of strategic use of emotional and moral language by experts to mitigate polarization and enhance public trust."}, "https://arxiv.org/abs/2406.01957": {"title": "Backward bifurcation arising from decline of immunity against emerging infectious diseases", "link": "https://arxiv.org/abs/2406.01957", "description": "arXiv:2406.01957v1 Announce Type: cross \nAbstract: Decline of immunity is a phenomenon characterized by immunocompromised host and plays a crucial role in the epidemiology of emerging infectious diseases (EIDs) such as COVID-19. In this paper, we propose an age-structured model with vaccination and reinfection of immune individuals. We prove that the disease-free equilibrium of the model undergoes backward and forward transcritical bifurcations at the critical value of the basic reproduction number for different values of parameters. We illustrate the results by numerical computations, and also find that the endemic equilibrium exhibits a saddle-node bifurcation on the extended branch of the forward transcritical bifurcation. These results allow us to understand the interplay between the decline of immunity and EIDs, and are able to provide strategies for mitigating the impact of EIDs on global health."}, "https://arxiv.org/abs/2406.01999": {"title": "Random Abstract Cell Complexes", "link": "https://arxiv.org/abs/2406.01999", "description": "arXiv:2406.01999v1 Announce Type: cross \nAbstract: We define a model for random (abstract) cell complexes (CCs), similiar to the well-known Erd\\H{o}s-R\\'enyi model for graphs and its extensions for simplicial complexes. To build a random cell complex, we first draw from an Erd\\H{o}s-R\\'enyi graph, and consecutively augment the graph with cells for each dimension with a specified probability. As the number of possible cells increases combinatorially -- e.g., 2-cells can be represented as cycles, or permutations -- we derive an approximate sampling algorithm for this model limited to two-dimensional abstract cell complexes. Since there is a large variance in the number of simple cycles on graphs drawn from the same configuration of ER, we also provide an efficient method to approximate that number, which is of independent interest. Moreover, it enables us to specify the expected number of 2-cells of each boundary length we want to sample. We provide some initial analysis into the properties of random CCs drawn from this model. We further showcase practical applications for our random CCs as null models, and in the context of (random) liftings of graphs to cell complexes. Both the sampling and cycle count estimation algorithms are available in the package `py-raccoon` on the Python Packaging Index."}, "https://arxiv.org/abs/2406.02362": {"title": "Temporal Graph Rewiring with Expander Graphs", "link": "https://arxiv.org/abs/2406.02362", "description": "arXiv:2406.02362v1 Announce Type: cross \nAbstract: Evolving relations in real-world networks are often modelled by temporal graphs. Graph rewiring techniques have been utilised on Graph Neural Networks (GNNs) to improve expressiveness and increase model performance. In this work, we propose Temporal Graph Rewiring (TGR), the first approach for graph rewiring on temporal graphs. TGR enables communication between temporally distant nodes in a continuous time dynamic graph by utilising expander graph propagation to construct a message passing highway for message passing between distant nodes. Expander graphs are suitable candidates for rewiring as they help overcome the oversquashing problem often observed in GNNs. On the public tgbl-wiki benchmark, we show that TGR improves the performance of a widely used TGN model by a significant margin. Our code repository is accessible at https://anonymous.4open.science/r/TGR-254C."}, "https://arxiv.org/abs/2208.06251": {"title": "Identifying User Profiles Via User Footprints", "link": "https://arxiv.org/abs/2208.06251", "description": "arXiv:2208.06251v2 Announce Type: replace \nAbstract: User identification has been a major field of research in privacy and security topics. Users might utilize multiple Online Social Networks (OSNs) to access a variety of text, videos, and links, and connect to their friends. Identifying user profiles corresponding to multiple virtual activities of users across social networks is significant for the development of related fields, such as network security, user behavior patterns analysis, and user recommendation systems. In addition, predicting personal attributes based on public content is a challenging topic. In this work, we perform an empirical study and proposed a scheme with considerable performance. In this work, we investigate Reddit, a famous social network for questioning and answering. By considering available personal and non-personal attributes, we discuss our main findings based on mapping the different features such as user activities to a special user profile. we collected a dataset with wide distribution consisting of 5000 samples. To map non-personal attributes to personal attributes, a classification approach based on support vector machines (SVM), Random Forests (RF), and deep belief network has been used. Experimental results demonstrate the effectiveness of the proposed methodology and achieved classification accuracy higher than 89%."}, "https://arxiv.org/abs/2303.18051": {"title": "Synergistic Graph Fusion via Encoder Embedding", "link": "https://arxiv.org/abs/2303.18051", "description": "arXiv:2303.18051v3 Announce Type: replace \nAbstract: In this paper, we introduce a method called graph fusion embedding, designed for multi-graph embedding with shared vertex sets. Under the framework of supervised learning, our method exhibits a remarkable and highly desirable synergistic effect: for sufficiently large vertex size, the accuracy of vertex classification consistently benefits from the incorporation of additional graphs. We establish the mathematical foundation for the method, including the asymptotic convergence of the embedding, a sufficient condition for asymptotic optimal classification, and the proof of the synergistic effect for vertex classification. Our comprehensive simulations and real data experiments provide compelling evidence supporting the effectiveness of our proposed method, showcasing the pronounced synergistic effect for multiple graphs from disparate sources."}, "https://arxiv.org/abs/2309.10486": {"title": "Infection patterns in simple and complex contagion processes on networks", "link": "https://arxiv.org/abs/2309.10486", "description": "arXiv:2309.10486v2 Announce Type: replace \nAbstract: Contagion processes, representing the spread of infectious diseases, information, or social behaviors, are often schematized as taking place on networks, which encode for instance the interactions between individuals. The impact of the network structure on spreading process has been widely investigated, but not the reverse question: do different processes unfolding on a given network lead to different infection patterns? How do the infection patterns depend on a model's parameters or on the nature of the contagion processes? Here we address this issue by investigating the infection patterns for a variety of models. In simple contagion processes, where contagion events involve one connection at a time, we find that the infection patterns are extremely robust across models and parameters. In complex contagion models instead, in which multiple interactions are needed for a contagion event, non-trivial dependencies on models parameters emerge, as the infection pattern depends on the interplay between pairwise and group contagions. In models involving threshold mechanisms moreover, slight parameter changes can significantly impact the spreading paths. Our results show that it is possible to study crucial features of a spread from schematized models, and inform us on the variations between spreading patterns in processes of different nature."}, "https://arxiv.org/abs/2309.16717": {"title": "A mobile observer method for the estimation of road traffic using communicating vehicles", "link": "https://arxiv.org/abs/2309.16717", "description": "arXiv:2309.16717v2 Announce Type: replace \nAbstract: Estimation of road traffic is a fundamental problem which has been addressed with a variety of methods. In the present paper, a variant of the mobile observer method is proposed. It is assumed that some vehicles composing the road traffic are communicating vehicles. These communicating vehicles broadcast periodically beacon messages. The proposed method uses only these beacon messages as input data, and needs no additional equipment such as radar or GPS device in order to estimate the road traffic. The model is tested with the bi-directional simulation framework VEINS, which combines a microscopic road traffic simulator and a communication simulator. The preliminary results show the potential of the method and confirm the validity of the approach."}, "https://arxiv.org/abs/2312.16878": {"title": "Voting power in the Council of the European Union: A comprehensive sensitivity analysis", "link": "https://arxiv.org/abs/2312.16878", "description": "arXiv:2312.16878v2 Announce Type: replace \nAbstract: The Council of the European Union (EU) is one of the main decision-making bodies of the EU. Many decisions require a qualified majority: the support of 55% of the member states (currently 15) that represent at least 65% of the total population. We investigate how the power distribution, based on the Shapley-Shubik index, and the proportion of winning coalitions change if these criteria are modified within reasonable bounds. The power of the two countries with about 4% of the total population each is found to be almost flat. The level of decisiveness decreases if the population criterion is above 68\\% or the states criterion is at least 17. The proportion of winning coalitions can be increased from 13.2% to 20.8% (30.1%) such that the maximal relative change in the Shapley-Shubik indices remains below 3.5% (5.5%). Our results are indispensable to evaluate any proposal for reforming the qualified majority voting system."}, "https://arxiv.org/abs/2401.11415": {"title": "A Fast Parallel Approach for Neighborhood-based Link Prediction by Disregarding Large Hubs", "link": "https://arxiv.org/abs/2401.11415", "description": "arXiv:2401.11415v3 Announce Type: replace \nAbstract: Link prediction can help rectify inaccuracies in various graph algorithms, stemming from unaccounted-for or overlooked links within networks. However, many existing works use a baseline approach, which incurs unnecessary computational costs due to its high time complexity. Further, many studies focus on smaller graphs, which can lead to misleading conclusions. Here, we study the prediction of links using neighborhood-based similarity measures on large graphs. In particular, we improve upon the baseline approach (IBase), and propose a heuristic approach that additionally disregards large hubs (DLH), based on the idea that high-degree nodes contribute little similarity among their neighbors. On a server equipped with dual 16-core Intel Xeon Gold 6226R processors, DLH is on average 1019x faster than IBase, especially on web graphs and social networks, while maintaining similar prediction accuracy. Notably, DLH achieves a link prediction rate of 38.1M edges/s and improves performance by 1.6x for every doubling of threads."}, "https://arxiv.org/abs/2302.00890": {"title": "Neural Common Neighbor with Completion for Link Prediction", "link": "https://arxiv.org/abs/2302.00890", "description": "arXiv:2302.00890v4 Announce Type: replace-cross \nAbstract: In this work, we propose a novel link prediction model and further boost it by studying graph incompleteness. First, we introduce MPNN-then-SF, an innovative architecture leveraging structural feature (SF) to guide MPNN's representation pooling, with its implementation, namely Neural Common Neighbor (NCN). NCN exhibits superior expressiveness and scalability compared with existing models, which can be classified into two categories: SF-then-MPNN, augmenting MPNN's input with SF, and SF-and-MPNN, decoupling SF and MPNN. Second, we investigate the impact of graph incompleteness -- the phenomenon that some links are unobserved in the input graph -- on SF, like the common neighbor. Through dataset visualization, we observe that incompleteness reduces common neighbors and induces distribution shifts, significantly affecting model performance. To address this issue, we propose to use a link prediction model to complete the common neighbor structure. Combining this method with NCN, we propose Neural Common Neighbor with Completion (NCNC). NCN and NCNC outperform recent strong baselines by large margins, and NCNC further surpasses state-of-the-art models in standard link prediction benchmarks. Our code is available at https://github.com/GraphPKU/NeuralCommonNeighbor."}, "https://arxiv.org/abs/2304.05223": {"title": "Inhomogeneous graph trend filtering via a l2,0 cardinality penalty", "link": "https://arxiv.org/abs/2304.05223", "description": "arXiv:2304.05223v3 Announce Type: replace-cross \nAbstract: We study estimation of piecewise smooth signals over a graph. We propose a $\\ell_{2,0}$-norm penalized Graph Trend Filtering (GTF) model to estimate piecewise smooth graph signals that exhibit inhomogeneous levels of smoothness across the nodes. We prove that the proposed GTF model is simultaneously a k-means clustering on the signal over the nodes and a minimum graph cut on the edges of the graph, where the clustering and the cut share the same assignment matrix. We propose two methods to solve the proposed GTF model: a spectral decomposition method and a method based on simulated annealing. In the experiment on synthetic and real-world datasets, we show that the proposed GTF model has a better performances compared with existing approaches on the tasks of denoising, support recovery and semi-supervised classification. We also show that the proposed GTF model can be solved more efficiently than existing models for the dataset with a large edge set."}, "https://arxiv.org/abs/2305.16102": {"title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks", "link": "https://arxiv.org/abs/2305.16102", "description": "arXiv:2305.16102v4 Announce Type: replace-cross \nAbstract: Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models, including random walk GCNs, Graph Attention Networks (GATs) and (graph) transformers. In particular, our analysis accounts for asymmetric, state-dependent and time-varying aggregation operators and a wide range of common nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU."}, "https://arxiv.org/abs/2404.14928": {"title": "Graph Machine Learning in the Era of Large Language Models (LLMs)", "link": "https://arxiv.org/abs/2404.14928", "description": "arXiv:2404.14928v2 Announce Type: replace-cross \nAbstract: Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graph structures. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML's generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field."}, "https://arxiv.org/abs/2406.02801": {"title": "SenTopX: Benchmark for User Sentiment on Various Topics", "link": "https://arxiv.org/abs/2406.02801", "description": "arXiv:2406.02801v1 Announce Type: new \nAbstract: Toxic sentiment analysis on Twitter (X) often focuses on specific topics and events such as politics and elections. Datasets of toxic users in such research are typically gathered through lexicon-based techniques, providing only a cross-sectional view. his approach has a tight confine for studying toxic user behavior and effective platform moderation. To identify users consistently spreading toxicity, a longitudinal analysis of their tweets is essential. However, such datasets currently do not exist.\n  This study addresses this gap by collecting a longitudinal dataset from 143K Twitter users, covering the period from 2007 to 2021, amounting to a total of 293 million tweets. Using topic modeling, we extract all topics discussed by each user and categorize users into eight groups based on the predominant topic in their timelines. We then analyze the sentiments of each group using 16 toxic scores. Our research demonstrates that examining users longitudinally reveals a distinct perspective on their comprehensive personality traits and their overall impact on the platform. Our comprehensive dataset is accessible to researchers for additional analysis."}, "https://arxiv.org/abs/2406.03139": {"title": "Patterns of co-occurrent skills in UK job adverts", "link": "https://arxiv.org/abs/2406.03139", "description": "arXiv:2406.03139v1 Announce Type: new \nAbstract: A job usually involves the application of several complementary or synergistic skills to perform its required tasks. Such relationships are implicitly recognised by employers in the skills they demand when recruiting new employees. Here we construct a skills network based on their co-occurrence in a national level data set of 65 million job postings from the UK spanning 2016 to 2022. We then apply multiscale graph-based community detection to obtain data-driven skill clusters at different levels of resolution that reveal a modular structure across scales. Skill clusters display diverse levels of demand and occupy varying roles within the skills network: some have broad reach across the network (high closeness centrality) while others have higher levels of within-cluster containment, yet with high interconnection across clusters and no skill silos. The skill clusters also display varying levels of semantic similarity, highlighting the difference between co-occurrence in adverts and intrinsic thematic consistency. Clear geographic variation is evident in the demand for each skill cluster across the UK, broadly reflecting the industrial characteristics of each region, e.g., London appears as an outlier as an international hub for finance, education and business. Comparison of data from 2016 and 2022 reveals employers are demanding a broader range of skills over time, with more adverts featuring skills spanning different clusters. We also show that our data-driven clusters differ from expert-authored categorisations of skills, indicating that important relationships between skills are not captured by expert assessment alone."}, "https://arxiv.org/abs/2406.03340": {"title": "Analyzing and Estimating Support for U", "link": "https://arxiv.org/abs/2406.03340", "description": "arXiv:2406.03340v1 Announce Type: new \nAbstract: Polls posted on social media have emerged in recent years as an important tool for estimating public opinion, e.g., to gauge public support for business decisions and political candidates in national elections. Here, we examine nearly two thousand Twitter polls gauging support for U.S. presidential candidates during the 2016 and 2020 election campaigns. First, we describe the rapidly emerging prevalence of social polls. Second, we characterize social polls in terms of their heterogeneity and response options. Third, leveraging machine learning models for user attribute inference, we describe the demographics, political leanings, and other characteristics of the users who author and interact with social polls. Finally, we study the relationship between social poll results, their attributes, and the characteristics of users interacting with them. Our findings reveal that Twitter polls are biased in various ways, starting from the position of the presidential candidates among the poll options to biases in demographic attributes and poll results. The 2016 and 2020 polls were predominantly crafted by older males and manifested a pronounced bias favoring candidate Donald Trump, in contrast to traditional surveys, which favored Democratic candidates. We further identify and explore the potential reasons for such biases in social polling and discuss their potential repercussions. Finally, we show that biases in social media polls can be corrected via regression and poststratification. The errors of the resulting election estimates can be as low as 1%-2%, suggesting that social media polls can become a promising source of information about public opinion."}, "https://arxiv.org/abs/2406.03354": {"title": "Can Social Media Platforms Transcend Political Labels? An Analysis of Neutral Conservations on Truth Social", "link": "https://arxiv.org/abs/2406.03354", "description": "arXiv:2406.03354v1 Announce Type: new \nAbstract: There is a prevailing perception that content on a social media platform generally have the same political leaning. These platforms are often viewed as ideologically congruent entities, reflecting the majority opinion of their users; a prime example of this is Truth Social. While this perception may exist, it is essential to verify the platform's credibility, acknowledging that such platforms contain meaningful insights with neutral stances. To this end, we examine the dissemination of Wikipedia links on the alt-right platform, Truth Social. Wikipedia is recognized for enforcing content neutrality and serves as a unique lens to analyze the objectivity of user-generated content on Truth Social. By scrutinizing Truths with and without Wikipedia links, identifying toxicity trends & recognizing coordinated networks, we observe a lower level of engagement and a tendency for Truths shared on Truth Social to cover more neutral topics when it includes Wikipedia links (Wiki Truths). Given the significantly different engagement and nature of content shared of Wiki Truths against Non-Wiki Truths, we emphasize that we should not generalize the techno-political affiliation of a social media platform, but rather should investigate the content closely."}, "https://arxiv.org/abs/2406.03443": {"title": "Investigating the Relationship Between User Specialization and Toxicity on Reddit: A Sentiment Analysis Approach", "link": "https://arxiv.org/abs/2406.03443", "description": "arXiv:2406.03443v1 Announce Type: new \nAbstract: Online platforms host a diverse user base, which can be broadly categorized into \"specialist users\" with focused interests and \"generalist users\" who engage in a wide range of topics. This study explores the behavioral differences between these two user types on the popular platform Reddit, focusing on the level of toxicity in their posts and the associated sentiment scores across 24 emotional categories and a neutral state. By employing community embeddings to represent users in a high-dimensional space, we measure activity diversity using the GS score. We analyze a dataset of 16,291,992 posts from 4,926,237 users spanning the period from 2019 to 2021, assessing the degree of toxicity and sentiment scores for each post. Our findings indicate that specialist users exhibit higher levels of toxic behavior compared to generalist users. Furthermore, specialist users demonstrate elevated scores for annoyance, sadness, and fear, while generalist users show higher scores for curiosity, admiration, and love. These insights contribute to a better understanding of user behavior on online platforms and can inform strategies for fostering healthier online communities."}, "https://arxiv.org/abs/2406.02794": {"title": "PriME: Privacy-aware Membership profile Estimation in networks", "link": "https://arxiv.org/abs/2406.02794", "description": "arXiv:2406.02794v1 Announce Type: cross \nAbstract: This paper presents a novel approach to estimating community membership probabilities for network vertices generated by the Degree Corrected Mixed Membership Stochastic Block Model while preserving individual edge privacy. Operating within the $\\varepsilon$-edge local differential privacy framework, we introduce an optimal private algorithm based on a symmetric edge flip mechanism and spectral clustering for accurate estimation of vertex community memberships. We conduct a comprehensive analysis of the estimation risk and establish the optimality of our procedure by providing matching lower bounds to the minimax risk under privacy constraints. To validate our approach, we demonstrate its performance through numerical simulations and its practical application to real-world data. This work represents a significant step forward in balancing accurate community membership estimation with stringent privacy preservation in network data analysis."}, "https://arxiv.org/abs/2406.03245": {"title": "Reconfiguring Participatory Design to Resist AI Realism", "link": "https://arxiv.org/abs/2406.03245", "description": "arXiv:2406.03245v1 Announce Type: cross \nAbstract: The growing trend of artificial intelligence (AI) as a solution to social and technical problems reinforces AI Realism -- the belief that AI is an inevitable and natural order. In response, this paper argues that participatory design (PD), with its focus on democratic values and processes, can play a role in questioning and resisting AI Realism. I examine three concerning aspects of AI Realism: the facade of democratization that lacks true empowerment, demands for human adaptability in contrast to AI systems' inflexibility, and the obfuscation of essential human labor enabling the AI system. I propose resisting AI Realism by reconfiguring PD to continue engaging with value-centered visions, increasing its exploration of non-AI alternatives, and making the essential human labor underpinning AI systems visible. I position PD as a means to generate friction against AI Realism and open space for alternative futures centered on human needs and values."}, "https://arxiv.org/abs/2406.03390": {"title": "Author, Content or Sharers? Estimating Spread Dynamics with Bayesian Mixture Hawkes", "link": "https://arxiv.org/abs/2406.03390", "description": "arXiv:2406.03390v1 Announce Type: cross \nAbstract: The spread of content on social media is shaped by intertwining factors on three levels: the source, the content itself, and the pathways of content spread. At the lowest level, the popularity of the sharing user determines its eventual reach. However, higher-level factors such as the nature of the online item and the credibility of its source also play crucial roles in determining how widely and rapidly the online item spreads. In this work, we propose the Bayesian Mixture Hawkes (BMH) model to jointly learn the influence of source, content and spread. We formulate the BMH model as a hierarchical mixture model of separable Hawkes processes, accommodating different classes of Hawkes dynamics and the influence of feature sets on these classes. We test the BMH model on two learning tasks, cold-start popularity prediction and temporal profile generalization performance, applying to two real-world retweet cascade datasets referencing articles from controversial and traditional media publishers. The BMH model outperforms the state-of-the-art models and predictive baselines on both datasets and utilizes cascade- and item-level information better than the alternatives. Lastly, we perform a counter-factual analysis where we apply the trained publisher-level BMH models to a set of article headlines and show that effectiveness of headline writing style (neutral, clickbait, inflammatory) varies across publishers. The BMH model unveils differences in style effectiveness between controversial and reputable publishers, where we find clickbait to be notably more effective for reputable publishers as opposed to controversial ones, which links to the latter's overuse of clickbait."}, "https://arxiv.org/abs/2208.06370": {"title": "Mitigating an epidemic on a geographic network using vaccination", "link": "https://arxiv.org/abs/2208.06370", "description": "arXiv:2208.06370v3 Announce Type: replace \nAbstract: We consider a mathematical model describing the propagation of an epidemic on a geographical network. The size of the outbreak is governed by the initial growth rate of the disease given by the maximal eigenvalue of the epidemic matrix formed by the susceptibles and the graph Laplacian representing the mobility. We use matrix perturbation theory to analyze the epidemic matrix and define a vaccination strategy, assuming the vaccination reduces the susceptibles. When mobility and local disease dynamics have similar time scales, it is most efficient to vaccinate the whole network because the disease grows uniformly. However, if only a few vertices can be vaccinated then which ones do we choose? We answer this question, and show that it is most efficient to vaccinate along an eigenvector corresponding to the largest eigenvalue of the Laplacian. We illustrate these general results on a 7 vertex graph and a realistic example of the french rail network. When mobility is slower than local disease dynamics, the epidemic grows on the vertex with largest susceptibles. The epidemic growth rate is more reduced when vaccinating a larger degree vertex; it also depends on the neighboring vertices. This study and its conclusions provides guidelines for the planning of vaccination on a network at the onset of an epidemic."}, "https://arxiv.org/abs/2312.01565": {"title": "Finding mixed memberships in categorical data", "link": "https://arxiv.org/abs/2312.01565", "description": "arXiv:2312.01565v2 Announce Type: replace \nAbstract: Latent class analysis, a fundamental problem in categorical data analysis, often encounters overlapping latent classes that introduce further challenges. This paper presents a solution to this problem by focusing on finding latent mixed memberships of subjects in categorical data with polytomous responses. We employ the Grade of Membership (GoM) model, which assigns each subject a membership score in each latent class. To address this, we propose two efficient spectral algorithms for estimating these mixed memberships and other GoM parameters. Our algorithms are based on the singular value decomposition of a regularized Laplacian matrix. We establish their convergence rates under a mild condition on data sparsity. Additionally, we introduce a metric to evaluate the quality of estimated mixed memberships for real-world categorical data and determine the optimal number of latent classes based on this metric. Finally, we demonstrate the practicality of our methods through experiments on both computer-generated and real-world categorical datasets."}, "https://arxiv.org/abs/2402.13392": {"title": "An SEIR network epidemic model with manual and digital contact tracing allowing delays", "link": "https://arxiv.org/abs/2402.13392", "description": "arXiv:2402.13392v4 Announce Type: replace \nAbstract: We consider an SEIR epidemic model on a network also allowing random contacts, where recovered individuals could either recover naturally or be diagnosed. Upon diagnosis, manual contact tracing is triggered such that each infected network contact is reported, tested and isolated with some probability and after a random delay. Additionally, digital tracing (based on a tracing app) is triggered if the diagnosed individual is an app-user, and then all of its app-using infectees are immediately notified and isolated. The early phase of the epidemic with manual and/or digital tracing is approximated by different multi-type branching processes, and three respective reproduction numbers are derived. The effectiveness of both contact tracing mechanisms is numerically quantified through the reduction of the reproduction number. This shows that app-using fraction plays an essential role in the overall effectiveness of contact tracing. The relative effectiveness of manual tracing compared to digital tracing increases if: more of the transmission occurs on the network, when the tracing delay is shortened, and when the network degree distribution is heavy-tailed. For realistic values, the combined tracing case can reduce $R_0$ by $20-30\\%$, so other preventive measures are needed to reduce the reproduction number down to $1.2-1.4$ for contact tracing to make it successful in avoiding big outbreaks."}, "https://arxiv.org/abs/2404.12451": {"title": "Assessing the Risk of Proliferation via Fissile Material Breeding in ARC-class Fusion Power Plants", "link": "https://arxiv.org/abs/2404.12451", "description": "arXiv:2404.12451v2 Announce Type: replace \nAbstract: Construction of a nuclear weapon requires access to kilogram-scale quantities of fissile material, which can be bred from fertile material like U-238 and Th-232 via neutron capture. Future fusion power plants, with total neutron source rates in excess of $10^{20}$ n/s, could breed weapons-relevant quantities of fissile material on short timescales, posing a breakout proliferation risk. The ARC-class fusion reactor design is characterized by demountable high temperature superconducting magnets, a FLiBe liquid immersion blanket, and a relatively small size ($\\sim$ 4 m major radius, $\\sim$ 1 m minor radius). We use the open-source Monte Carlo neutronics code OpenMC to perform self-consistent time-dependent simulations of a representative ARC-class blanket to assess the feasibility of a fissile breeding breakout scenario. We find that a significant quantity of fissile material can be bred in less than six months of full power operation for initial fertile inventories ranging from 5 to 50 metric tons, representing a non-negligible proliferation risk. We further study the feasibility of this scenario by examining other consequences of fissile breeding such as reduced tritium breeding ratio, extra heat from fission and decay heat, isotopic purity of bred material, and self-protection time of irradiated blanket material. We also examine the impact of Li-6 enrichment on fissile breeding and find that it substantially reduces breeding rate, motivating its use as a proliferation resistance tool."}, "https://arxiv.org/abs/2305.15745": {"title": "Robust Ante-hoc Graph Explainer using Bilevel Optimization", "link": "https://arxiv.org/abs/2305.15745", "description": "arXiv:2305.15745v2 Announce Type: replace-cross \nAbstract: Explaining the decisions made by machine learning models for high-stakes applications is critical for increasing transparency and guiding improvements to these decisions. This is particularly true in the case of models for graphs, where decisions often depend on complex patterns combining rich structural and attribute data. While recent work has focused on designing so-called post-hoc explainers, the broader question of what constitutes a good explanation remains open. One intuitive property is that explanations should be sufficiently informative to reproduce the predictions given the data. In other words, a good explainer can be repurposed as a predictor. Post-hoc explainers do not achieve this goal as their explanations are highly dependent on fixed model parameters (e.g., learned GNN weights). To address this challenge, we propose RAGE (Robust Ante-hoc Graph Explainer), a novel and flexible ante-hoc explainer designed to discover explanations for graph neural networks using bilevel optimization, with a focus on the chemical domain. RAGE can effectively identify molecular substructures that contain the full information needed for prediction while enabling users to rank these explanations in terms of relevance. Our experiments on various molecular classification tasks show that RAGE explanations are better than existing post-hoc and ante-hoc approaches."}, "https://arxiv.org/abs/2309.08631": {"title": "Large Language Models Can Infer Psychological Dispositions of Social Media Users", "link": "https://arxiv.org/abs/2309.08631", "description": "arXiv:2309.08631v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) demonstrate increasingly human-like abilities across a wide variety of tasks. In this paper, we investigate whether LLMs like ChatGPT can accurately infer the psychological dispositions of social media users and whether their ability to do so varies across socio-demographic groups. Specifically, we test whether GPT-3.5 and GPT-4 can derive the Big Five personality traits from users' Facebook status updates in a zero-shot learning scenario. Our results show an average correlation of r = .29 (range = [.22, .33]) between LLM-inferred and self-reported trait scores - a level of accuracy that is similar to that of supervised machine learning models specifically trained to infer personality. Our findings also highlight heterogeneity in the accuracy of personality inferences across different age groups and gender categories: predictions were found to be more accurate for women and younger individuals on several traits, suggesting a potential bias stemming from the underlying training data or differences in online self-expression. The ability of LLMs to infer psychological dispositions from user-generated text has the potential to democratize access to cheap and scalable psychometric assessments for both researchers and practitioners. On the one hand, this democratization might facilitate large-scale research of high ecological validity and spark innovation in personalized services. On the other hand, it also raises ethical concerns regarding user privacy and self-determination, highlighting the need for stringent ethical frameworks and regulation."}, "https://arxiv.org/abs/2309.17417": {"title": "Networked Inequality: Preferential Attachment Bias in Graph Neural Network Link Prediction", "link": "https://arxiv.org/abs/2309.17417", "description": "arXiv:2309.17417v2 Announce Type: replace-cross \nAbstract: Graph neural network (GNN) link prediction is increasingly deployed in citation, collaboration, and online social networks to recommend academic literature, collaborators, and friends. While prior research has investigated the dyadic fairness of GNN link prediction, the within-group (e.g., queer women) fairness and \"rich get richer\" dynamics of link prediction remain underexplored. However, these aspects have significant consequences for degree and power imbalances in networks. In this paper, we shed light on how degree bias in networks affects Graph Convolutional Network (GCN) link prediction. In particular, we theoretically uncover that GCNs with a symmetric normalized graph filter have a within-group preferential attachment bias. We validate our theoretical analysis on real-world citation, collaboration, and online social networks. We further bridge GCN's preferential attachment bias with unfairness in link prediction and propose a new within-group fairness metric. This metric quantifies disparities in link prediction scores within social groups, towards combating the amplification of degree and power disparities. Finally, we propose a simple training-time strategy to alleviate within-group unfairness, and we show that it is effective on citation, social, and credit networks."}, "https://arxiv.org/abs/2404.03528": {"title": "BanglaAutoKG: Automatic Bangla Knowledge Graph Construction with Semantic Neural Graph Filtering", "link": "https://arxiv.org/abs/2404.03528", "description": "arXiv:2404.03528v3 Announce Type: replace-cross \nAbstract: Knowledge Graphs (KGs) have proven essential in information processing and reasoning applications because they link related entities and give context-rich information, supporting efficient information retrieval and knowledge discovery; presenting information flow in a very effective manner. Despite being widely used globally, Bangla is relatively underrepresented in KGs due to a lack of comprehensive datasets, encoders, NER (named entity recognition) models, POS (part-of-speech) taggers, and lemmatizers, hindering efficient information processing and reasoning applications in the language. Addressing the KG scarcity in Bengali, we propose BanglaAutoKG, a pioneering framework that is able to automatically construct Bengali KGs from any Bangla text. We utilize multilingual LLMs to understand various languages and correlate entities and relations universally. By employing a translation dictionary to identify English equivalents and extracting word features from pre-trained BERT models, we construct the foundational KG. To reduce noise and align word embeddings with our goal, we employ graph-based polynomial filters. Lastly, we implement a GNN-based semantic filter, which elevates contextual understanding and trims unnecessary edges, culminating in the formation of the definitive KG. Empirical findings and case studies demonstrate the universal effectiveness of our model, capable of autonomously constructing semantically enriched KGs from any text."}, "https://arxiv.org/abs/2406.03587": {"title": "Subsuming Complex Networks by Node Walks", "link": "https://arxiv.org/abs/2406.03587", "description": "arXiv:2406.03587v1 Announce Type: new \nAbstract: The concept of node walk in graphs and complex networks has been addressed, consisting of one or more nodes that move into adjacent nodes, henceforth incorporating the respective connections. This type of dynamics is then applied to subsume complex networks. Three types of networks (Erd\\'os- R\\'eny, Barab\\'asi-Albert, as well as a geometric model) are considered, while three node walks heuristics (uniformly random, largest degree, and smallest degree) are taken into account. Several interesting results are obtained and described, including the identification that the subsuming dynamics depend strongly on both the specific topology of the networks as well as the criteria controlling the node walks. The use of node walks as a model for studying the relationship between network topology and dynamics is motivated by this result. In addition, relatively high correlations between the initial node degree and the accumulated strength of the walking node were observed for some combinations of network types and dynamic rules, allowing some of the properties of the subsumption to be roughly predicted from the initial topology around the waking node which has been found, however, not to be enough for full determination of the subsumption dynamics. Another interesting result regards the quite distinct signatures (along the iterations) of walking node strengths obtained for the several considered combinations of network type and subsumption rules."}, "https://arxiv.org/abs/2406.03763": {"title": "The impact of nodes of information dissemination on epidemic spreading in dynamic multiplex networks", "link": "https://arxiv.org/abs/2406.03763", "description": "arXiv:2406.03763v1 Announce Type: new \nAbstract: Epidemic spreading processes on dynamic multiplex networks provide a more accurate description of natural spreading processes than those on single layered networks. To describe the influence of different individuals in the awareness layer on epidemic spreading, we propose a two-layer network-based epidemic spreading model, including some individuals who neglect the epidemic, and we explore how individuals with different properties in the awareness layer will affect the spread of epidemics. The two-layer network model is divided into an information transmission layer and a disease spreading layer. Each node in the layer represents an individual with different connections in different layers. Individuals with awareness will be infected with a lower probability compared to unaware individuals, which corresponds to the various epidemic prevention measures in real life. We adopt the micro-Markov chain approach to analytically derive the threshold for the proposed epidemic model, which demonstrates that the awareness layer affects the threshold of disease spreading. We then explore how individuals with different properties would affect the disease spreading process through extensive Monte Carlo numerical simulations. We find that individuals with high centrality in the awareness layer would significantly inhibit the transmission of infectious diseases. Additionally, we propose conjectures and explanations for the approximately linear effect of individuals with low centrality in the awareness layer on the number of infected individuals."}, "https://arxiv.org/abs/2406.03796": {"title": "Beyond a binary theorizing of prosociality", "link": "https://arxiv.org/abs/2406.03796", "description": "arXiv:2406.03796v1 Announce Type: new \nAbstract: A stylized experiment, the public goods game, has taught us the peculiar reproducible fact that humans tend to contribute more to shared resources than expected from economically rational assumptions. There have been two competing explanations for this phenomenon: either contributing to the public good is an innate human trait (the prosocial preference hypothesis) or a transitory effect while learning the game (the confused learner hypothesis). We use large-scale experimental data from a novel experimental design to distinguish between these two hypotheses. By monitoring the effects of zealots (persistently cooperating bots) and varying the participants' awareness of them, we find a considerably more complex scenario than previously reported. People indeed have a prosocial bias, but not to the degree that they always forego taking action to increase their profit. While our findings end the simplistic theorizing of prosociality in the public goods game, an observed positive, cooperative response to zealots has actionable policy implications."}, "https://arxiv.org/abs/2406.03852": {"title": "Why the Metric Backbone Preserves Community Structure", "link": "https://arxiv.org/abs/2406.03852", "description": "arXiv:2406.03852v1 Announce Type: new \nAbstract: The metric backbone of a weighted graph is the union of all-pairs shortest paths. It is obtained by removing all edges $(u,v)$ that are not the shortest path between $u$ and $v$. In networks with well-separated communities, the metric backbone tends to preserve many inter-community edges, because these edges serve as bridges connecting two communities, but tends to delete many intra-community edges because the communities are dense. This suggests that the metric backbone would dilute or destroy the community structure of the network. However, this is not borne out by prior empirical work, which instead showed that the metric backbone of real networks preserves the community structure of the original network well. In this work, we analyze the metric backbone of a broad class of weighted random graphs with communities, and we formally prove the robustness of the community structure with respect to the deletion of all the edges that are not in the metric backbone. An empirical comparison of several graph sparsification techniques confirms our theoretical finding and shows that the metric backbone is an efficient sparsifier in the presence of communities."}, "https://arxiv.org/abs/2406.03921": {"title": "Knowledge Transfer, Knowledge Gaps, and Knowledge Silos in Citation Networks", "link": "https://arxiv.org/abs/2406.03921", "description": "arXiv:2406.03921v1 Announce Type: new \nAbstract: The advancement of science relies on the exchange of ideas across disciplines and the integration of diverse knowledge domains. However, tracking knowledge flows and interdisciplinary integration in rapidly evolving, multidisciplinary fields remains a significant challenge. This work introduces a novel network analysis framework to study the dynamics of knowledge transfer directly from citation data. By applying dynamic community detection to cumulative, time-evolving citation networks, we can identify research areas as groups of papers sharing knowledge sources and outputs. Our analysis characterises the life-cycles and knowledge transfer patterns of these dynamic communities over time. We demonstrate our approach through a case study of eXplainable Artificial Intelligence (XAI) research, an emerging interdisciplinary field at the intersection of machine learning, statistics, and psychology. Key findings include: (i) knowledge transfer between these important foundational topics and the contemporary topics in XAI research is limited, and the extent of knowledge transfer varies across different contemporary research topics; (ii) certain application domains exist as isolated \"knowledge silos\"; (iii) significant \"knowledge gaps\" are identified between related XAI research areas, suggesting opportunities for cross-pollination and improved knowledge integration. By mapping interdisciplinary integration and bridging knowledge gaps, this work can inform strategies to synthesise ideas from disparate sources and drive innovation. More broadly, our proposed framework enables new insights into the evolution of knowledge ecosystems directly from citation data, with applications spanning literature review, research planning, and science policy."}, "https://arxiv.org/abs/2406.04005": {"title": "The Failed Migration of Academic Twitter", "link": "https://arxiv.org/abs/2406.04005", "description": "arXiv:2406.04005v1 Announce Type: new \nAbstract: Following change in Twitter's ownership and subsequent changes to content moderation policies, many in academia looked to move their discourse elsewhere and migration to Mastodon was pursued by some. Our study looks at the dynamics of this migration. Utilizing publicly available user account data, we track the posting activity of academics on Mastodon over a one year period. Our analyses reveal significant challenges sustaining user engagement on Mastodon due to its decentralized structure as well as competition from other platforms such as Bluesky and Threads. The movement lost momentum after an initial surge of enthusiasm as most users did not maintain their activity levels, and those who did faced lower levels of engagement compared to Twitter. Our findings highlight the challenges involved in transitioning professional communities to decentralized platforms, emphasizing the need for focusing on migrating social connections for long-term user engagement."}, "https://arxiv.org/abs/2406.04039": {"title": "Shaping History: Advanced Machine Learning Techniques for the Analysis and Dating of Cuneiform Tablets over Three Millennia", "link": "https://arxiv.org/abs/2406.04039", "description": "arXiv:2406.04039v1 Announce Type: cross \nAbstract: Cuneiform tablets, emerging in ancient Mesopotamia around the late fourth millennium BCE, represent one of humanity's earliest writing systems. Characterized by wedge-shaped marks on clay tablets, these artifacts provided insight into Mesopotamian civilization across various domains. Traditionally, the analysis and dating of these tablets rely on subjective assessment of shape and writing style, leading to uncertainties in pinpointing their exact temporal origins. Recent advances in digitization have revolutionized the study of cuneiform by enhancing accessibility and analytical capabilities. Our research uniquely focuses on the silhouette of tablets as significant indicators of their historical periods, diverging from most studies that concentrate on textual content. Utilizing an unprecedented dataset of over 94,000 images from the Cuneiform Digital Library Initiative collection, we apply deep learning methods to classify cuneiform tablets, covering over 3,000 years of history. By leveraging statistical, computational techniques, and generative modeling through Variational Auto-Encoders (VAEs), we achieve substantial advancements in the automatic classification of these ancient documents, focusing on the tablets' silhouettes as key predictors. Our classification approach begins with a Decision Tree using height-to-width ratios and culminates with a ResNet50 model, achieving a 61% macro F1-score for tablet silhouettes. Moreover, we introduce novel VAE-powered tools to enhance explainability and enable researchers to explore changes in tablet shapes across different eras and genres. This research contributes to document analysis and diplomatics by demonstrating the value of large-scale data analysis combined with statistical methods. These insights offer valuable tools for historians and epigraphists, enriching our understanding of cuneiform tablets and the cultures that produced them."}, "https://arxiv.org/abs/2406.04299": {"title": "NoisyGL: A Comprehensive Benchmark for Graph Neural Networks under Label Noise", "link": "https://arxiv.org/abs/2406.04299", "description": "arXiv:2406.04299v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) exhibit strong potential in node classification task through a message-passing mechanism. However, their performance often hinges on high-quality node labels, which are challenging to obtain in real-world scenarios due to unreliable sources or adversarial attacks. Consequently, label noise is common in real-world graph data, negatively impacting GNNs by propagating incorrect information during training. To address this issue, the study of Graph Neural Networks under Label Noise (GLN) has recently gained traction. However, due to variations in dataset selection, data splitting, and preprocessing techniques, the community currently lacks a comprehensive benchmark, which impedes deeper understanding and further development of GLN. To fill this gap, we introduce NoisyGL in this paper, the first comprehensive benchmark for graph neural networks under label noise. NoisyGL enables fair comparisons and detailed analyses of GLN methods on noisy labeled graph data across various datasets, with unified experimental settings and interface. Our benchmark has uncovered several important insights that were missed in previous research, and we believe these findings will be highly beneficial for future studies. We hope our open-source benchmark library will foster further advancements in this field. The code of the benchmark can be found in https://github.com/eaglelab-zju/NoisyGL."}, "https://arxiv.org/abs/2207.12264": {"title": "Dynamics and triggers of misinformation on vaccines", "link": "https://arxiv.org/abs/2207.12264", "description": "arXiv:2207.12264v3 Announce Type: replace \nAbstract: The Covid-19 pandemic has sparked renewed attention on the prevalence of misinformation online, whether intentional or not, underscoring the potential risks posed to individuals' quality of life associated with the dissemination of misconceptions and enduring myths on health-related subjects. In this study, we analyze 6 years (2016-2021) of Italian vaccine debate across diverse social media platforms (Facebook, Instagram, Twitter, YouTube), encompassing all major news sources - both questionable and reliable. We first use the symbolic transfer entropy analysis of news production time-series to dynamically determine which category of sources, questionable or reliable, causally drives the agenda on vaccines. Then, leveraging deep learning models capable to accurately classify vaccine-related content based on the conveyed stance and discussed topic, respectively, we evaluate the focus on various topics by news sources promoting opposing views and compare the resulting user engagement. Aside from providing valuable resources for further investigation of vaccine-related misinformation, particularly in a language (Italian) that receives less attention in scientific research compared to languages like English, our study uncovers misinformation not as a parasite of the news ecosystem that merely opposes the perspectives offered by mainstream media, but as an autonomous force capable of even overwhelming the production of vaccine-related content from the latter. While the pervasiveness of misinformation is evident in the significantly higher engagement of questionable sources compared to reliable ones, our findings underscore the importance of consistent and thorough pro-vax coverage. This is especially crucial in addressing the most sensitive topics where the risk of misinformation spreading and potentially exacerbating negative attitudes toward vaccines among the users involved is higher."}, "https://arxiv.org/abs/2307.02818": {"title": "Degree Heterogeneity in Higher-Order Networks: Inference in the Hypergraph $\\boldsymbol{\\beta}$-Model", "link": "https://arxiv.org/abs/2307.02818", "description": "arXiv:2307.02818v4 Announce Type: replace-cross \nAbstract: The $\\boldsymbol{\\beta}$-model for random graphs is commonly used for representing pairwise interactions in a network with degree heterogeneity. Going beyond pairwise interactions, Stasi et al. (2014) introduced the hypergraph $\\boldsymbol{\\beta}$-model for capturing degree heterogeneity in networks with higher-order (multi-way) interactions. In this paper we initiate the rigorous study of the hypergraph $\\boldsymbol{\\beta}$-model with multiple layers, which allows for hyperedges of different sizes across the layers. To begin with, we derive the rates of convergence of the maximum likelihood (ML) estimate and establish their minimax rate optimality. We also derive the limiting distribution of the ML estimate and construct asymptotically valid confidence intervals for the model parameters. Next, we consider the goodness-of-fit problem in the hypergraph $\\boldsymbol{\\beta}$-model. Specifically, we establish the asymptotic normality of the likelihood ratio (LR) test under the null hypothesis, derive its detection threshold, and also its limiting power at the threshold. Interestingly, the detection threshold of the LR test turns out to be minimax optimal, that is, all tests are asymptotically powerless below this threshold. The theoretical results are further validated in numerical experiments. In addition to developing the theoretical framework for estimation and inference for hypergraph $\\boldsymbol{\\beta}$-models, the above results fill a number of gaps in the graph $\\boldsymbol{\\beta}$-model literature, such as the minimax optimality of the ML estimates and the non-null properties of the LR test, which, to the best of our knowledge, have not been studied before."}, "https://arxiv.org/abs/2403.13872": {"title": "Spatial-Temporal Graph Representation Learning for Tactical Networks Future State Prediction", "link": "https://arxiv.org/abs/2403.13872", "description": "arXiv:2403.13872v2 Announce Type: replace-cross \nAbstract: Resource allocation in tactical ad-hoc networks presents unique challenges due to their dynamic and multi-hop nature. Accurate prediction of future network connectivity is essential for effective resource allocation in such environments. In this paper, we introduce the Spatial-Temporal Graph Encoder-Decoder (STGED) framework for Tactical Communication Networks that leverages both spatial and temporal features of network states to learn latent tactical behaviors effectively. STGED hierarchically utilizes graph-based attention mechanism to spatially encode a series of communication network states, leverages a recurrent neural network to temporally encode the evolution of states, and a fully-connected feed-forward network to decode the connectivity in the future state. Through extensive experiments, we demonstrate that STGED consistently outperforms baseline models by large margins across different time-steps input, achieving an accuracy of up to 99.2\\% for the future state prediction task of tactical communication networks."}, "https://arxiv.org/abs/2406.04462": {"title": "Adaptive Algorithmic Interventions for Escaping Pessimism Traps in Dynamic Sequential Decisions", "link": "https://arxiv.org/abs/2406.04462", "description": "arXiv:2406.04462v1 Announce Type: new \nAbstract: In this paper, we relate the philosophical literature on pessimism traps to information cascades, a formal model derived from the economics and mathematics literature. A pessimism trap is a social pattern in which individuals in a community, in situations of uncertainty, begin to copy the sub-optimal actions of others, despite their individual beliefs. This maps nicely onto the concept of an information cascade, which involves a sequence of agents making a decision between two alternatives, with a private signal of the superior alternative and a public history of others' actions. Key results from the economics literature show that information cascades occur with probability one in many contexts, and depending on the strength of the signal, populations can fall into the incorrect cascade very easily and quickly. Once formed, in the absence of external perturbation, a cascade cannot be broken -- therefore, we derive an intervention that can be used to nudge a population from an incorrect to a correct cascade and, importantly, maintain the cascade once the subsidy is discontinued. We study this both theoretically and empirically."}, "https://arxiv.org/abs/2406.04543": {"title": "Function and form of U", "link": "https://arxiv.org/abs/2406.04543", "description": "arXiv:2406.04543v1 Announce Type: new \nAbstract: The relationship between urban form and function is a complex challenge that can be examined from multiple perspectives. In this study, we propose a method to characterize the urban function of U.S. metropolitan areas by analyzing trip patterns extracted from the 2017 National Household Travel Survey (NHTS). To characterize urban form, we employ measures that capture road network topology. We cluster cities based on both form and function and subsequently compare these clusters. Our analysis of 52 U.S. metropolitan areas identifies 7 distinct clusters of cities that exhibit similar travel behavior, suggesting that diverse mobility patterns can be effectively grouped into a few universal classes. The observed disparity between the urban-function clustering and the urban-form clustering suggests that travel behavior in the U.S. is not strongly influenced by the physical infrastructure of the city."}, "https://arxiv.org/abs/2406.04962": {"title": "Mapping the Global Election Landscape on Social Media in 2024", "link": "https://arxiv.org/abs/2406.04962", "description": "arXiv:2406.04962v1 Announce Type: new \nAbstract: In 2024, half of the global population is expected to participate in elections, offering researchers a unique opportunity to study online information diffusion and user behavior. This study investigates the media landscape on social media by analyzing Facebook posts from national political parties and major news agencies across Europe, Mexico, and India. Our methodology identifies key topics and evaluates public interaction, reflecting broader trends in political engagement. Using Principal Component Analysis, we distil these topics to uncover patterns of correlation and differentiation. This approach reveals dominant themes that engage global audiences, providing critical insights into the interplay between public opinion and digital narratives during a major electoral cycle. Our findings highlight how different topics resonate across political spectrums, shaping political debate and offering a comprehensive view of the interaction between media content, political ideology, and audience engagement."}, "https://arxiv.org/abs/2406.05021": {"title": "From cryptomarkets to the surface web: Scouting eBay for counterfeits", "link": "https://arxiv.org/abs/2406.05021", "description": "arXiv:2406.05021v1 Announce Type: new \nAbstract: Detecting counterfeits on online marketplaces is challenging, and current methods struggle with the volume of sales on platforms like eBay, while cryptomarkets openly sell counterfeits. Leveraging information from 453 cryptomarket counterfeits, we automated a search for corresponding products on eBay, utilizing image and text similarity metrics. We collected data twice over 4-months to analyze changes with an average of 159 eBay products per cryptomarket item, totaling 134k products. We found identical products, which would warrant further investigation as to whether they are counterfeits. Results indicate increasing difficulty finding similar products over time, moderated by product type and origin. Future improved versions of the current system could be used to examine possible connections between cryptomarket and surface web listings more closely and could hold practical value in supporting the detection of counterfeits on the surface web."}, "https://arxiv.org/abs/2406.05026": {"title": "Higher-order modeling of face-to-face interactions", "link": "https://arxiv.org/abs/2406.05026", "description": "arXiv:2406.05026v1 Announce Type: new \nAbstract: The most fundamental social interactions among humans occur face to face. Their features have been extensively studied in recent years, owing to the availability of high-resolution data on individuals' proximity. Mathematical models based on mobile agents have been crucial to understand the spatio-temporal organization of face-to-face interactions. However, these models focus on dyadic relationships only, failing to characterize interactions in larger groups of individuals. Here, we propose a model in which agents interact with each other by forming groups of different sizes. Each group has a degree of social attractiveness, based on which neighboring agents decide whether to join. Our framework reproduces different properties of groups in face-to-face interactions, including their distribution, the correlation in their number, and their persistence in time, which cannot be replicated by dyadic models. Furthermore, it captures homophilic patterns at the level of higher-order interactions, going beyond standard pairwise approaches. Our work sheds light on the higher-order mechanisms at the heart of human face-to-face interactions, paving the way for further investigation of how group dynamics at a microscopic scale affects social phenomena at a macroscopic scale."}, "https://arxiv.org/abs/2406.04423": {"title": "Determining the Number of Communities in Sparse and Imbalanced Settings", "link": "https://arxiv.org/abs/2406.04423", "description": "arXiv:2406.04423v1 Announce Type: cross \nAbstract: Community structures represent a crucial aspect of network analysis, and various methods have been developed to identify these communities. However, a common hurdle lies in determining the number of communities K, a parameter that often requires estimation in practice. Existing approaches for estimating K face two notable challenges: the weak community signal present in sparse networks and the imbalance in community sizes or edge densities that result in unequal per-community expected degree. We propose a spectral method based on a novel network operator whose spectral properties effectively overcome both challenges. This operator is a refined version of the non-backtracking operator, adapted from a \"centered\" adjacency matrix. Its leading eigenvalues are more concentrated than those of the adjacency matrix for sparse networks, while they also demonstrate enhanced signal under imbalance scenarios, a benefit attributed to the centering step. This is justified, either theoretically or numerically, under the null model K = 1, in both dense and ultra-sparse settings. A goodness-of-fit test based on the leading eigenvalue can be applied to determine the number of communities K."}, "https://arxiv.org/abs/2406.04548": {"title": "GNNAnatomy: Systematic Generation and Evaluation of Multi-Level Explanations for Graph Neural Networks", "link": "https://arxiv.org/abs/2406.04548", "description": "arXiv:2406.04548v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) have proven highly effective in various machine learning (ML) tasks involving graphs, such as node/graph classification and link prediction. However, explaining the decisions made by GNNs poses challenges because of the aggregated relational information based on graph structure, leading to complex data transformations. Existing methods for explaining GNNs often face limitations in systematically exploring diverse substructures and evaluating results in the absence of ground truths. To address this gap, we introduce GNNAnatomy, a model- and dataset-agnostic visual analytics system designed to facilitate the generation and evaluation of multi-level explanations for GNNs. In GNNAnatomy, we employ graphlets to elucidate GNN behavior in graph-level classification tasks. By analyzing the associations between GNN classifications and graphlet frequencies, we formulate hypothesized factual and counterfactual explanations. To validate a hypothesized graphlet explanation, we introduce two metrics: (1) the correlation between its frequency and the classification confidence, and (2) the change in classification confidence after removing this substructure from the original graph. To demonstrate the effectiveness of GNNAnatomy, we conduct case studies on both real-world and synthetic graph datasets from various domains. Additionally, we qualitatively compare GNNAnatomy with a state-of-the-art GNN explainer, demonstrating the utility and versatility of our design."}, "https://arxiv.org/abs/2406.04612": {"title": "Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks", "link": "https://arxiv.org/abs/2406.04612", "description": "arXiv:2406.04612v1 Announce Type: cross \nAbstract: The self-attention mechanism has been adopted in several widely-used message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls the amount of information that flows along the edges of the underlying graph. This usage of attention has made such models a baseline for studies on explainable AI (XAI) since interpretations via attention have been popularized in various domains (e.g., natural language processing and computer vision). However, existing studies often use naive calculations to derive attribution scores from attention, and do not take the precise and careful calculation of edge attribution into consideration. In our study, we aim to fill the gap between the widespread usage of attention-enabled MPNNs and their potential in largely under-explored explainability, a topic that has been actively investigated in other areas. To this end, as the first attempt, we formalize the problem of edge attribution from attention weights in GNNs. Then, we propose GATT, an edge attribution calculation method built upon the computation tree. Through comprehensive experiments, we demonstrate the effectiveness of our proposed method when evaluating attributions from GATs. Conversely, we empirically validate that simply averaging attention weights over graph attention layers is insufficient to interpret the GAT model's behavior. Code is publicly available at https://github.com/jordan7186/GAtt/tree/main."}, "https://arxiv.org/abs/2406.04701": {"title": "Transition to synchronization in adaptive Sakaguchi-Kuramoto model with higher-order interactions", "link": "https://arxiv.org/abs/2406.04701", "description": "arXiv:2406.04701v1 Announce Type: cross \nAbstract: We investigate the phenomenon of transition to synchronization in Sakaguchi-Kuramoto model in the presence of higher-order interactions and global order parameter adaptation. The investigation is done by performing extensive numerical simulations and low dimensional modeling of the system. Numerical simulations of the full system show both continuous (second order) as well as discontinuous transitions. The discontinuous transitions can either be associated with explosive (first order) or with tiered synchronization states depending on the choice of parameters. To develop an in depth understanding of the transition scenario in the parameter space we derive a reduced order model (ROM) using the Ott-Antonsen ansatz, the results of which closely matches with that of the numerical simulations of the full system. The simplicity and analytical accessibility of the ROM helps to conveniently unfold the transition scenario in the system having complex dependence on the parameters. Simultaneous analysis of the full system and the ROM clearly identifies the regions of the parameter space exhibiting different types of transitions. It is observed that the second order continuous transition is connected with a supercritical pitchfork bifurcation (PB) of the ROM. On the other hand, the discontinuous teired transition is associated with multiple saddle-node (SN) bifurcations along with a supercritical PB and the first order explosive transition involves a subcritical PB alongside a SN bifurcation."}, "https://arxiv.org/abs/2406.04916": {"title": "Combinatorial Complex Score-based Diffusion Modelling through Stochastic Differential Equations", "link": "https://arxiv.org/abs/2406.04916", "description": "arXiv:2406.04916v1 Announce Type: cross \nAbstract: Graph structures offer a versatile framework for representing diverse patterns in nature and complex systems, applicable across domains like molecular chemistry, social networks, and transportation systems. While diffusion models have excelled in generating various objects, generating graphs remains challenging. This thesis explores the potential of score-based generative models in generating such objects through a modelization as combinatorial complexes, which are powerful topological structures that encompass higher-order relationships.\n  In this thesis, we propose a unified framework by employing stochastic differential equations. We not only generalize the generation of complex objects such as graphs and hypergraphs, but we also unify existing generative modelling approaches such as Score Matching with Langevin dynamics and Denoising Diffusion Probabilistic Models. This innovation overcomes limitations in existing frameworks that focus solely on graph generation, opening up new possibilities in generative AI.\n  The experiment results showed that our framework could generate these complex objects, and could also compete against state-of-the-art approaches for mere graph and molecule generation tasks."}, "https://arxiv.org/abs/2305.16488": {"title": "Assessing inequities in electrification via heat pumps across the U", "link": "https://arxiv.org/abs/2305.16488", "description": "arXiv:2305.16488v3 Announce Type: replace \nAbstract: Heat pumps are an energy-efficient and increasingly cost-effective solution for reducing greenhouse gas emissions in the building sector. However, other clean energy technologies such as rooftop solar are less likely to be adopted in underserved communities, and thus policies incentivizing their adoption may funnel tax dollars to well-resourced communities. Unlike previously-studied technologies, the effects of heat pumps on household energy bills may be positive or negative depending on local climate, fuel availability and costs, and other factors. Here we propose a framework for assessing heat pump inequities across the U.S. We find that households in communities of color and with higher percentages of renters are less likely to use heat pumps across the board. Moreover, communities of color are least likely to use heat pumps in regions where they are most likely to reduce energy bills. Public policies must address these inequities to advance beneficial electrification and energy justice."}, "https://arxiv.org/abs/2404.17082": {"title": "Evolutionary game dynamics with environmental feedback in a network with two communities", "link": "https://arxiv.org/abs/2404.17082", "description": "arXiv:2404.17082v2 Announce Type: replace \nAbstract: Recent developments of eco-evolutionary models have shown that evolving feedbacks between behavioral strategies and the environment of game interactions, leading to changes in the underlying payoff matrix, can impact the underlying population dynamics in various manners. We propose and analyze an eco-evolutionary game dynamics model on a network with two communities such that players interact with other players in the same community and those in the opposite community at different rates. In our model, we consider two-person matrix games with pairwise interactions occurring on individual edges and assume that the environmental state depends on edges rather than on nodes or being globally shared in the population. We analytically determine the equilibria and their stability under a symmetric population structure assumption, and we also numerically study the replicator dynamics of the general model. The model shows rich dynamical behavior, such as multiple transcritical bifurcations, multistability, and anti-synchronous oscillations. Our work offers insights into understanding how the presence of community structure impacts the eco-evolutionary dynamics within and between niches."}, "https://arxiv.org/abs/2403.07294": {"title": "Graph Data Condensation via Self-expressive Graph Structure Reconstruction", "link": "https://arxiv.org/abs/2403.07294", "description": "arXiv:2403.07294v2 Announce Type: replace-cross \nAbstract: With the increasing demands of training graph neural networks (GNNs) on large-scale graphs, graph data condensation has emerged as a critical technique to relieve the storage and time costs during the training phase. It aims to condense the original large-scale graph to a much smaller synthetic graph while preserving the essential information necessary for efficiently training a downstream GNN. However, existing methods concentrate either on optimizing node features exclusively or endeavor to independently learn node features and the graph structure generator. They could not explicitly leverage the information of the original graph structure and failed to construct an interpretable graph structure for the synthetic dataset. To address these issues, we introduce a novel framework named \\textbf{G}raph Data \\textbf{C}ondensation via \\textbf{S}elf-expressive Graph Structure \\textbf{R}econstruction (\\textbf{GCSR}). Our method stands out by (1) explicitly incorporating the original graph structure into the condensing process and (2) capturing the nuanced interdependencies between the condensed nodes by reconstructing an interpretable self-expressive graph structure. Extensive experiments and comprehensive analysis validate the efficacy of the proposed method across diverse GNN models and datasets. Our code is available at \\url{https://github.com/zclzcl0223/GCSR}."}, "https://arxiv.org/abs/2404.13468": {"title": "A Grassroots Architecture to Supplant Global Digital Platforms by a Global Digital Democracy", "link": "https://arxiv.org/abs/2404.13468", "description": "arXiv:2404.13468v4 Announce Type: replace-cross \nAbstract: We present an architectural alternative to global digital platforms termed grassroots, designed to serve the social, economic, civic, and political needs of local digital communities, as well as their federation. Grassroots platforms may offer local communities an alternative to global digital platforms while operating solely on the smartphones of their members, forsaking any global resources other than the network itself. Such communities may form digital economies without initial capital or external credit, exercise sovereign democratic governance, and federate, ultimately resulting in the grassroots formation of a global digital democracy."}, "https://arxiv.org/abs/2406.05809": {"title": "The Paradox of Collective Certainty in Science", "link": "https://arxiv.org/abs/2406.05809", "description": "arXiv:2406.05809v1 Announce Type: new \nAbstract: We explore a paradox of collective action and certainty in science wherein the more scientists research together, the less that work contributes to the value of their collective certainty. When scientists address similar problems and share data, methods, and collaborators, their understanding of and trust in their colleagues' research rises, a quality required for scientific advance. This increases the positive reinforcement scientists receive for shared beliefs as they become more dependent on their colleagues' knowledge, interests, and findings. This collective action increases the potential for scientists to reside in epistemic ''bubbles'' that limit their capacity to make new discoveries or have their discoveries generalize. In short, as scientists grow closer, their experience of scientific validity rises as the likelihood of genuine replication falls, creating a trade-off between certainty and truth."}, "https://arxiv.org/abs/2406.05884": {"title": "Revisiting institutional punishment in the $N$-person prisoner's dilemma", "link": "https://arxiv.org/abs/2406.05884", "description": "arXiv:2406.05884v1 Announce Type: new \nAbstract: The conflict between individual and collective interests makes fostering cooperation in human societies a challenging task, requiring drastic measures such as the establishment of sanctioning institutions. These institutions are costly because they have to be maintained regardless of the presence or absence of offenders. Here, we propose realistic improvements to the standard $N$-person prisoner's dilemma formulation with institutional punishment by eliminating overpunishment, requiring a minimum number of contributors to establish the sanctioning institution, and sharing the cost among them once this minimum number is reached. In addition, we focus on large groups or communities for which sanctioning institutions are ubiquitous. Using the replicator equation framework for an infinite population, we find that by sufficiently fining players who fail to contribute either to the public good or to the sanctioning institution, a population of contributors immune to invasion by these free riders can be established, provided that the contributors are sufficiently numerous. In a finite population, we use finite-size scaling to show that, for some parameter settings, demographic noise helps to fixate the strategy that contributes to the public good but not to the sanctioning institution even for infinitely large populations when, somewhat counterintuitively, its proportion in the initial population vanishes with a small power of the population size."}, "https://arxiv.org/abs/2406.06084": {"title": "Ecological Data Reveal Imbalances in Collision Avoidance Due to Groups' Social Interaction", "link": "https://arxiv.org/abs/2406.06084", "description": "arXiv:2406.06084v1 Announce Type: new \nAbstract: The relative dynamics in collision avoidance between individual pedestrians and dyads has been recently studied, and it was shown that individuals may intrude dyads that are not socially interacting. Building on this, our current study examines how much each party contributes to collision avoidance by measuring deviations from their intended paths. Our findings suggest that individuals prioritise trajectory efficiency in undisturbed situations, but prioritise safety when encountering dyads, deviating more from their intended path. Non-interacting dyads present a similar behavior, although their trajectories appear to be even more efficient than those of individuals in undisturbed situations, and their deviations during encounters less pronounced. On the other hand, socially interacting dyads are not very efficient in undisturbed situations, and their behavior is mostly unaffected by encounters. These results strongly suggest that group dynamics affects in two ways the behavior of pedestrians, namely it has a dynamical and a social effect. The dynamical effect stabilises their trajectory, while the social one decreases the ability to focus on the external environment, leading to reduced efficiency and safety. Another finding concerns the tendency of individuals to avoid in a more prominent way the interacting dyads as compared to non-interacting ones. This suggests that individuals may assess others' contribution to collision avoidance. An impact parameter analysis reveals that collision risk influences path deviations in pedestrian encounters. For individuals, larger behavioral differences between low and high interaction levels of the dyad occur both when the collision risk is high and during less critical encounters. For dyads, the deviation differences between low and high interaction levels are most pronounced when the individual is on course to pass close to the dyad."}, "https://arxiv.org/abs/2406.06200": {"title": "Inequalities of energy release rates in compression of nano-porous materials predict its imminent breakdown", "link": "https://arxiv.org/abs/2406.06200", "description": "arXiv:2406.06200v1 Announce Type: new \nAbstract: We show that the divergent acoustic energy release rate in a quasi-statically compressed nano-porous material can be used as a precursor to failure in such materials. A quantification of the inequality of the energy release rate using social inequality measure indices help constructing a warning signal for large bursts of energy release. We also verify similar behavior for simulations of viscoelastic fiber bundle models that mimic the strain-hardening dynamics of the samples. The results demonstrate experimental applicability of the precursory signal formulation for any diverging response function near a transition point using social inequality indices."}, "https://arxiv.org/abs/2406.06440": {"title": "Messengers: Breaking Echo Chambers in Collective Opinion Dynamics with Homophily", "link": "https://arxiv.org/abs/2406.06440", "description": "arXiv:2406.06440v1 Announce Type: new \nAbstract: Collective estimation manifests computational intelligence emerging from inter-individual local interactions, e.g., by aggregating opinions from neighbors to estimate a quantity. Use cases of collective estimation may include directed motion in physical space, such that agents, for example, have to collectively explore a distributed feature, and collectively agree on a numerical value. In doing so, collectives face several challenges in achieving precise estimations. These challenges exhibit complex behaviors, particularly when the interaction network and opinion of agents evolve simultaneously. We take homophilic networks as an example, where disproportionate interaction with like-minded neighbors leads to the emergence of echo chambers, preventing collective consensus. Our simulation results confirm that, besides a lack of exposure to attitude-challenging opinions, seeking reaffirming information entraps agents in echo chambers. We propose a generic novel approach based on a Dichotomous Markov Process (DMP) where stubborn agents (called Messengers) connect the disconnected clusters by physically transporting their opinions to other clusters to inform and direct the other agents. We show that diverse collective behaviors arise from the DMP and study a continuum between task specialization with no switching (full-time Messengers), generalization with slow task switching (part-time Messengers), and rapid task switching (short-time Messengers) and its impact on system performance. Our results show that stubborn agents can, in various ways, break the echo chambers and promote consensus in collective opinion."}, "https://arxiv.org/abs/2406.06490": {"title": "How much longer do you have to drive than the crow has to fly?", "link": "https://arxiv.org/abs/2406.06490", "description": "arXiv:2406.06490v1 Announce Type: new \nAbstract: When we travel by car from one location to another, our route is constrained by the road network. The resulting network distance is generally longer than the geodetic distance, i.e. the distance as the crow flies, between the two locations. We report a systematic relation between the statistical properties of these two distances. In empirical analyses for large motorway networks in various countries and areas, we work out distributions of network and geodetic distances and identify a surprisingly robust scaling property between them. A simple consequence is that we typically have to drive $1.3\\pm0.1$ times longer than the crow flies. Moreover, we show that this scaling is not present in standard random networks; rather, it requires a certain non-randomness, namely adjacency. We develop a set of rules to build a realistic motorway network, also consistent with the scaling properties found empirically. We hypothesize that the scaling reflects, in a rather universal fashion, a compromise between two societal needs: high efficiency and accessibility on the one hand, and limitation of costs and other burdens on the other."}, "https://arxiv.org/abs/2406.05246": {"title": "Blended Bots: Infiltration through Identity Deception on Social Media", "link": "https://arxiv.org/abs/2406.05246", "description": "arXiv:2406.05246v1 Announce Type: cross \nAbstract: Bots are automated social media users that can be used to amplify (mis)information and sow harmful discourse. In order to effectively influence users, bots can be generated to reproduce human user behavior. Indeed, people tend to trust information coming from users with profiles that fit roles they expect to exist, such as users with gender role stereotypes. In this work, we examine differences in the types of identities in profiles of human and bot accounts with a focus on combinations of identities that represent gender role stereotypes. We find that some types of identities differentiate between human and bot profiles, confirming this approach can be a useful in distinguishing between human and bot accounts on social media. However, contrary to our expectations, we reveal that gender bias is expressed more in human accounts than bots overall. Despite having less gender bias overall, we provide examples of identities with strong associations with gender identities in bot profiles, such as those related to technology, finance, sports, and horoscopes. Finally, we discuss implications for designing constructive social media bot detection training materials."}, "https://arxiv.org/abs/2406.05560": {"title": "A Shape Change Enhancing Hierarchical Layout for the Pairwise Comparison of Directed Acyclic Graphs", "link": "https://arxiv.org/abs/2406.05560", "description": "arXiv:2406.05560v1 Announce Type: cross \nAbstract: Comparing directed acyclic graphs is essential in various fields such as healthcare, social media, finance, biology, and marketing. DAGs often result from contagion processes over networks, including information spreading, retweet activity, disease transmission, financial crisis propagation, malware spread, and gene mutations. For instance, in disease spreading, an infected patient can transmit the disease to contacts, making it crucial to analyze and predict scenarios. Similarly, in finance, understanding the effects of saving or not saving specific banks during a crisis is vital. Experts often need to identify small differences between DAGs, such as changes in a few nodes or edges. Even the presence or absence of a single edge can be significant. Visualization plays a crucial role in facilitating these comparisons. However, standard hierarchical layout algorithms struggle to visualize subtle changes effectively. The typical hierarchical layout, with the root on top, is preferred due to its performance in comparison to other layouts. Nevertheless, these standard algorithms prioritize single-graph aesthetics over comparison suitability, making it challenging for users to spot changes. To address this issue, we propose a layout that enhances shape changes in DAGs while minimizing the impact on aesthetics. Our approach involves outwardly swapping changes, altering the DAG's shape. We introduce new drawing criteria. Our layout builds upon a Sugiyama-like hierarchical layout and implements these criteria through two extensions. We designed it this way to maintain interchangeability and accommodate future optimizations, such as pseudo-nodes for edge crossing minimization. In our evaluations, our layout achieves excellent results, with edge crossing aesthetics averaging around 0.8 (on a scale of 0 to 1). Additionally, our layout outperforms the base implementation by an average of 60-75\\%."}, "https://arxiv.org/abs/2406.05582": {"title": "On the Role of Communications for Space Domain Awareness", "link": "https://arxiv.org/abs/2406.05582", "description": "arXiv:2406.05582v1 Announce Type: cross \nAbstract: Space Domain Awareness (SDA) has become increasingly vital with the rapid growth of commercial space activities and the expansion of New Space. This paper stresses the necessity of transitioning from centralized to distributed SDA architectures. The current architecture predominantly relies on individual downhaul, which we propose to transition to on-orbit distribution. Our results demonstrate that the individual downhaul architecture does not scale efficiently with the increasing number of nodes, while on-orbit distribution offers significant improvements. By comparing the centralized architecture with the proposed distributed architecture, we highlight the advantages of enhanced coverage and resilience. Our findings show that on-orbit distribution greatly outperforms individual downhaul in terms of latency and scalability. Specifically, the latency results for on-orbit distribution are substantially lower and more consistent, even as the number of satellites increases. In addition, we address the inherent challenges associated with on-orbit distribution architecture, particularly cybersecurity concerns. We focus on link security to ensure the availability and integrity of data transmission in these advanced SDA systems. Future expectations include further refinement of on-orbit distribution strategies and the development of robust cybersecurity measures to support the scalability and resilience of SDA systems."}, "https://arxiv.org/abs/2406.06014": {"title": "Network two-sample test for block models", "link": "https://arxiv.org/abs/2406.06014", "description": "arXiv:2406.06014v1 Announce Type: cross \nAbstract: We consider the two-sample testing problem for networks, where the goal is to determine whether two sets of networks originated from the same stochastic model. Assuming no vertex correspondence and allowing for different numbers of nodes, we address a fundamental network testing problem that goes beyond simple adjacency matrix comparisons. We adopt the stochastic block model (SBM) for network distributions, due to their interpretability and the potential to approximate more general models. The lack of meaningful node labels and vertex correspondence translate to a graph matching challenge when developing a test for SBMs. We introduce an efficient algorithm to match estimated network parameters, allowing us to properly combine and contrast information within and across samples, leading to a powerful test. We show that the matching algorithm, and the overall test are consistent, under mild conditions on the sparsity of the networks and the sample sizes, and derive a chi-squared asymptotic null distribution for the test. Through a mixture of theoretical insights and empirical validations, including experiments with both synthetic and real-world data, this study advances robust statistical inference for complex network data."}, "https://arxiv.org/abs/2406.06346": {"title": "Dynamical Mean-Field Theory of Complex Systems on Sparse Directed Networks", "link": "https://arxiv.org/abs/2406.06346", "description": "arXiv:2406.06346v1 Announce Type: cross \nAbstract: Although real-world complex systems typically interact through sparse and heterogeneous networks, analytic solutions of their dynamics are limited to models with all-to-all interactions. Here, we solve the dynamics of a broad range of nonlinear models of complex systems on sparse directed networks with a random structure. By generalizing dynamical mean-field theory to sparse systems, we derive an exact equation for the path-probability describing the effective dynamics of a single degree of freedom. Our general solution applies to key models in the study of neural networks, ecosystems, epidemic spreading, and synchronization. Using the population dynamics algorithm, we solve the path-probability equation to determine the phase diagram of a seminal neural network model in the sparse regime, showing that this model undergoes a transition from a fixed-point phase to chaos as a function of the network topology."}, "https://arxiv.org/abs/2103.01093": {"title": "Quantifying Indirect Gender Discrimination on Collaborative Platforms", "link": "https://arxiv.org/abs/2103.01093", "description": "arXiv:2103.01093v3 Announce Type: replace \nAbstract: Digital collaborative platforms have become crucial venues of career advancement and individual success in many creative fields, from engineering to the arts. Indirect gender discrimination is a key component to gendered disadvantage on platforms. Such platforms carried the promise of opening avenues of advancement to previously discriminated groups, such as women, as platforms lack managerial gatekeepers with conventional prejudice. We analyzed the extent of indirect gender discriminatory on two diverse platforms, GitHub and Behance, focused on software development and fine arts and design. We found that the main cause of women's disadvantage in attention, success, and survival is largely due to indirect discrimination that varies between 60-90\\% of total female disadvantage. Men and women are penalized if they follow highly female-like behavior, while categorical gender's impact varies by outcome and field. As platforms employ algorithmic tools and AI systems to manage users' activity, visibility and recommend new projects to collaborate, stereotypes rooted in behavior can have long-lasting consequences."}, "https://arxiv.org/abs/2303.00927": {"title": "QuickCent: a fast and frugal heuristic for harmonic centrality estimation on scale-free networks", "link": "https://arxiv.org/abs/2303.00927", "description": "arXiv:2303.00927v2 Announce Type: replace \nAbstract: We present a simple and quick method to approximate network centrality indexes. Our approach, called QuickCent, is inspired by so-called fast and frugal heuristics, which are heuristics initially proposed to model some human decision and inference processes. The centrality index that we estimate is the harmonic centrality, which is a measure based on shortest-path distances, so infeasible to compute on large networks. We compare QuickCent with known machine learning algorithms on synthetic data generated with preferential attachment, and some empirical networks. Our experiments show that QuickCent is able to make estimates that are competitive in accuracy with the best alternative methods tested, either on synthetic scale-free networks or empirical networks. QuickCent has the feature of achieving low error variance estimates, even with a small training set. Moreover, QuickCent is comparable in efficiency -- accuracy and time cost -- to those produced by more complex methods. We discuss and provide some insight into how QuickCent exploits the fact that in some networks, such as those generated by preferential attachment, local density measures such as the in-degree, can be a proxy for the size of the network region to which a node has access, opening up the possibility of approximating centrality indices based on size such as the harmonic centrality. Our initial results show that simple heuristics and biologically inspired computational methods are a promising line of research in the context of network measure estimations."}, "https://arxiv.org/abs/2308.12743": {"title": "Video Recommendation Using Social Network Analysis and User Viewing Patterns", "link": "https://arxiv.org/abs/2308.12743", "description": "arXiv:2308.12743v2 Announce Type: replace \nAbstract: This study proposes a novel video recommendation approach that leverages implicit user feedback in the form of viewing percentages and social network analysis techniques. By constructing a video similarity network based on user viewing patterns and computing centrality measures, the methodology identifies important and well-connected videos. Modularity analysis is then used to cluster closely related videos, forming the basis for personalized recommendations. For each user, candidate videos are selected from the cluster containing their preferred items and ranked using an ego-centric index that measures proximity to the user's likes and dislikes. The proposed approach was evaluated on real user data from an Asian video-on-demand platform. Offline experiments demonstrated improved accuracy compared to conventional methods such as Naive Bayes, SVM, decision trees, and nearest neighbor algorithms. An online user study further validated the effectiveness of the recommendations, with significant increases observed in click-through rate, view completion rate, and user satisfaction scores relative to the platform's existing system. These results underscore the value of incorporating implicit feedback and social network analysis for video recommendations. The key contributions of this research include a novel video recommendation framework that integrates implicit user data and social network analysis, the use of centrality measures and modularity-based clustering, an ego-centric ranking approach, and rigorous offline and online evaluation demonstrating superior performance compared to existing techniques. This study opens new avenues for enhancing video recommendations and user engagement in VOD platforms."}, "https://arxiv.org/abs/2310.08909": {"title": "Evading Community Detection via Counterfactual Neighborhood Search", "link": "https://arxiv.org/abs/2310.08909", "description": "arXiv:2310.08909v2 Announce Type: replace \nAbstract: Community detection techniques are useful for social media platforms to discover tightly connected groups of users who share common interests. However, this functionality often comes at the expense of potentially exposing individuals to privacy breaches by inadvertently revealing their tastes or preferences. Therefore, some users may wish to preserve their anonymity and opt out of community detection for various reasons, such as affiliation with political or religious organizations, without leaving the platform. In this study, we address the challenge of community membership hiding, which involves strategically altering the structural properties of a network graph to prevent one or more nodes from being identified by a given community detection algorithm. We tackle this problem by formulating it as a constrained counterfactual graph objective, and we solve it via deep reinforcement learning. Extensive experiments demonstrate that our method outperforms existing baselines, striking the best balance between accuracy and cost."}, "https://arxiv.org/abs/2401.09368": {"title": "Feature-aware ultra-low dimensional reduction of real networks", "link": "https://arxiv.org/abs/2401.09368", "description": "arXiv:2401.09368v2 Announce Type: replace \nAbstract: In existing models and embedding methods of networked systems, node features describing their qualities are usually overlooked in favor of focusing solely on node connectivity. This study introduces $FiD$-Mercator, a model-based ultra-low dimensional reduction technique that integrates node features with network structure to create $D$-dimensional maps of complex networks in a hyperbolic space. This embedding method efficiently uses features as an initial condition, guiding the search of nodes' coordinates towards an optimal solution. The research reveals that downstream task performance improves with the correlation between network connectivity and features, emphasizing the importance of such correlation for enhancing the description and predictability of real networks. Simultaneously, hyperbolic embedding's ability to reproduce local network properties remains unaffected by the inclusion of features. The findings highlight the necessity for developing network embedding techniques capable of exploiting such correlations to optimize both network structure and feature association jointly in the future."}, "https://arxiv.org/abs/2311.11282": {"title": "Individual misinformation tagging reinforces echo chambers; Collective tagging does not", "link": "https://arxiv.org/abs/2311.11282", "description": "arXiv:2311.11282v2 Announce Type: replace-cross \nAbstract: Fears about the destabilizing impact of misinformation online have motivated individuals and platforms to respond. Individuals have become empowered to challenge others' online claims with fact-checks in pursuit of a healthier information ecosystem and to break down echo chambers of self-reinforcing opinion. Using Twitter data, here we show the consequences of individual misinformation tagging: tagged posters had explored novel political information and expanded topical interests immediately prior, but being tagged caused posters to retreat into information bubbles. These unintended consequences were softened by a collective verification system for misinformation moderation. In Twitter's new platform, Community Notes, misinformation tagging was peer-reviewed by other fact-checkers before exposure to the poster. With collective misinformation tagging, posters were less likely to retreat from diverse information engagement. Detailed comparison suggests differences in toxicity, sentiment, readability, and delay in individual versus collective misinformation tagging messages. These findings provide evidence for differential impacts from individual versus collective moderation strategies on the diversity of information engagement and mobility across the information ecosystem."}, "https://arxiv.org/abs/2311.11344": {"title": "Unveiling Deception: Establishing a Taxonomic Framework for Disinformation within Scientific Discourse", "link": "https://arxiv.org/abs/2311.11344", "description": "arXiv:2311.11344v2 Announce Type: replace-cross \nAbstract: Disinformation spreads among the public and in scientific discourse through the actions of individuals, organizations, and governments that distort scholarly communications, media narratives, and institutional trust. This taxonomy introduces a structured framework and specialized set of definitions to elucidate the key participants, platforms, and strategies employed in the propagation of disinformation. Enhanced comprehension of the mechanisms and pathways of scientific disinformation equips journalists and policymakers with the tools necessary to more effectively recognize and address these issues. The authors developed this taxonomy of disinformation through a multi-faceted approach, encompassing a literature review, expert review, and case study analysis. The literature review revealed a scarcity of taxonomical models amidst prevalent algorithmic detection studies. Subsequently, an expert review process refined our taxonomy through collaborative analysis of twenty-two cases of identified disinformation, categorized by their methods, motives, and impacts. Finally, we validated and fine-tuned our taxonomy through detailed case studies of twelve diverse disinformation instances, assessing the taxonomy's effectiveness in capturing the essential characteristics of each case and making necessary adjustments to ensure its relevance and accuracy in real-world applications."}, "https://arxiv.org/abs/2311.11456": {"title": "The Arrow of Time is Alive and Well but Forbidden Under the Received View of Physics", "link": "https://arxiv.org/abs/2311.11456", "description": "arXiv:2311.11456v2 Announce Type: replace-cross \nAbstract: This essay offers a meta-level analysis in the sociology and history of physics in the context of the so-called \"Arrow of Time Problem\" or \"Two Times Problem,\" which asserts that the empirically observed directionality of time is in conflict with physical theory. I argue that there is actually no necessary conflict between physics and the arrow of time, and that the observed directionality of time is perfectly consistent with physics unconstrained by certain optional metaphysical, epistemological and methodological beliefs and practices characterizing the conventional or Received View."}, "https://arxiv.org/abs/2402.11804": {"title": "LLM as Prompter: Low-resource Inductive Reasoning on Arbitrary Knowledge Graphs", "link": "https://arxiv.org/abs/2402.11804", "description": "arXiv:2402.11804v2 Announce Type: replace-cross \nAbstract: Knowledge Graph (KG) inductive reasoning, which aims to infer missing facts from new KGs that are not seen during training, has been widely adopted in various applications. One critical challenge of KG inductive reasoning is handling low-resource scenarios with scarcity in both textual and structural aspects. In this paper, we attempt to address this challenge with Large Language Models (LLMs). Particularly, we utilize the state-of-the-art LLMs to generate a graph-structural prompt to enhance the pre-trained Graph Neural Networks (GNNs), which brings us new methodological insights into the KG inductive reasoning methods, as well as high generalizability in practice. On the methodological side, we introduce a novel pretraining and prompting framework ProLINK, designed for low-resource inductive reasoning across arbitrary KGs without requiring additional training. On the practical side, we experimentally evaluate our approach on 36 low-resource KG datasets and find that ProLINK outperforms previous methods in three-shot, one-shot, and zero-shot reasoning tasks, exhibiting average performance improvements by 20%, 45%, and 147%, respectively. Furthermore, ProLINK demonstrates strong robustness for various LLM promptings as well as full-shot scenarios."}, "https://arxiv.org/abs/2404.17128": {"title": "Simple Network Mechanism Leads to Quasi-Real Brain Activation Patterns with Drosophila Connectome", "link": "https://arxiv.org/abs/2404.17128", "description": "arXiv:2404.17128v2 Announce Type: replace-cross \nAbstract: Considering the high computational demands of most methods, using network communication models to simulate the brain is a more economical way. However, there is still insufficient evidence that they can effectively replicate the brains' real activation patterns. Moreover, it remains unclear whether actual network structures are crucial in simulating intelligence. Addressing these issues, we propose a large scale network communication model based on simple rules and design criteria to assess the differences between network models and real situations. To enhance the connection with the real world, we also incorporate an improved neuron dynamic model. We conduct research on the biggest adult Drosophila connectome data set. Experimental results show significant activation in neurons that should respond to stimulus and slight activation in irrelevant ones, which we call quasi-real activation pattern. Besides, when changing the network structure, the quasi-activation patterns disappear. Interestingly, activation regions have shorter network distances to their input neurons, implying that the network structure (not spatial distance) is the core to form brain functionality. In addition, giving input neurons a unilateral stimulus, we observe a bilateral response, which is consistent with reality. Then we find that both hemispheres have extremely similar statistical indicators. We also develop real-time 3D large spatial network visualization software to observe experimental phenomena, filling the software gap. This research reveals network models' power: it can reach the quasi-activation pattern with simple rules. Besides, it proves network structure matters in brain activity pattern generation. Future research could fully simulate brain behavior through network models, paving the way for artificial intelligence by developing new propagation rules and optimizing link weights."}, "https://arxiv.org/abs/2406.06617": {"title": "Collaborative Team Recognition: A Core Plus Extension Structure", "link": "https://arxiv.org/abs/2406.06617", "description": "arXiv:2406.06617v1 Announce Type: new \nAbstract: Scientific collaboration is a significant behavior in knowledge creation and idea exchange. To tackle large and complex research questions, a trend of team formation has been observed in recent decades. In this study, we focus on recognizing collaborative teams and exploring inner patterns using scholarly big graph data. We propose a collaborative team recognition (CORE) model with a \"core + extension\" team structure to recognize collaborative teams in large academic networks. In CORE, we combine an effective evaluation index called the collaboration intensity index with a series of structural features to recognize collaborative teams in which members are in close collaboration relationships. Then, CORE is used to guide the core team members to their extension members. CORE can also serve as the foundation for team-based research. The simulation results indicate that CORE reveals inner patterns of scientific collaboration: senior scholars have broad collaborative relationships and fixed collaboration patterns, which are the underlying mechanisms of team assembly. The experimental results demonstrate that CORE is promising compared with state-of-the-art methods."}, "https://arxiv.org/abs/2406.06618": {"title": "PANDORA: Deep graph learning based COVID-19 infection risk level forecasting", "link": "https://arxiv.org/abs/2406.06618", "description": "arXiv:2406.06618v1 Announce Type: new \nAbstract: COVID-19 as a global pandemic causes a massive disruption to social stability that threatens human life and the economy. Policymakers and all elements of society must deliver measurable actions based on the pandemic's severity to minimize the detrimental impact of COVID-19. A proper forecasting system is arguably important to provide an early signal of the risk of COVID-19 infection so that the authorities are ready to protect the people from the worst. However, making a good forecasting model for infection risks in different cities or regions is not an easy task, because it has a lot of influential factors that are difficult to be identified manually. To address the current limitations, we propose a deep graph learning model, called PANDORA, to predict the infection risks of COVID-19, by considering all essential factors and integrating them into a geographical network. The framework uses geographical position relations and transportation frequency as higher-order structural properties formulated by higher-order network structures (i.e., network motifs). Moreover, four significant node attributes (i.e., multiple features of a particular area, including climate, medical condition, economy, and human mobility) are also considered. We propose three different aggregators to better aggregate node attributes and structural features, namely, Hadamard, Summation, and Connection. Experimental results over real data show that PANDORA outperforms the baseline method with higher accuracy and faster convergence speed, no matter which aggregator is chosen. We believe that PANDORA using deep graph learning provides a promising approach to get superior performance in infection risk level forecasting and help humans battle the COVID-19 crisis."}, "https://arxiv.org/abs/2406.06658": {"title": "Link Prediction in Bipartite Networks", "link": "https://arxiv.org/abs/2406.06658", "description": "arXiv:2406.06658v1 Announce Type: new \nAbstract: Bipartite networks serve as highly suitable models to represent systems involving interactions between two distinct types of entities, such as online dating platforms, job search services, or ecommerce websites. These models can be leveraged to tackle a number of tasks, including link prediction among the most useful ones, especially to design recommendation systems. However, if this task has garnered much interest when conducted on unipartite (i.e. standard) networks, it is far from being the case for bipartite ones. In this study, we address this gap by performing an experimental comparison of 19 link prediction methods able to handle bipartite graphs. Some come directly from the literature, and some are adapted by us from techniques originally designed for unipartite networks. We also propose to repurpose recommendation systems based on graph convolutional networks (GCN) as a novel link prediction solution for bipartite networks. To conduct our experiments, we constitute a benchmark of 3 real-world bipartite network datasets with various topologies. Our results indicate that GCN-based personalized recommendation systems, which have received significant attention in recent years, can produce successful results for link prediction in bipartite networks. Furthermore, purely heuristic metrics that do not rely on any learning process, like the Structural Perturbation Method (SPM), can also achieve success."}, "https://arxiv.org/abs/2406.06662": {"title": "Proximity Matters: Analyzing the Role of Geographical Proximity in Shaping AI Research Collaborations", "link": "https://arxiv.org/abs/2406.06662", "description": "arXiv:2406.06662v1 Announce Type: new \nAbstract: The role of geographical proximity in facilitating inter-regional or inter-organizational collaborations has been studied thoroughly in recent years. However, the effect of geographical proximity on forming scientific collaborations at the individual level still needs to be addressed. Using publication data in the field of artificial intelligence from 2001 to 2019, in this work, the effect of geographical proximity on the likelihood of forming future scientific collaborations among researchers is studied. In addition, the interaction between geographical and network proximities is examined to see whether network proximity can substitute geographical proximity in encouraging long-distance scientific collaborations. Employing conventional and machine learning techniques, our results suggest that geographical distance impedes scientific collaboration at the individual level despite the tremendous improvements in transportation and communication technologies during recent decades. Moreover, our findings show that the effect of network proximity on the likelihood of scientific collaboration increases with geographical distance, implying that network proximity can act as a substitute for geographical proximity."}, "https://arxiv.org/abs/2406.06717": {"title": "Analyzing user archetypes in Singapore's Telegram groups on COVID-19 and climate change", "link": "https://arxiv.org/abs/2406.06717", "description": "arXiv:2406.06717v1 Announce Type: new \nAbstract: Social media platforms, particularly Telegram, play a pivotal role in shaping public perceptions and opinions on global and national issues. Unlike traditional news media, Telegram allows for the proliferation of user-generated content with minimal oversight, making it a significant venue for the spread of controversial and misinformative content. During the COVID-19 pandemic, Telegram's popularity surged in Singapore, a country with one of the highest rates of social media use globally. We leverage Singapore-based Telegram data to analyze information flows within groups focused on COVID-19 and climate change. Using k-means clustering, we identified distinct user archetypes, including Skeptic, Engaged Advocate, Observer, and Analyst, each contributing uniquely to the discourse. We developed a model to classify users into these clusters (Precision: Climate change: 0.99; COVID-19: 0.95). By identifying these user archetypes and examining their contributions to information dissemination, we sought to uncover patterns to inform effective strategies for combating misinformation and enhancing public discourse on pressing global issues."}, "https://arxiv.org/abs/2406.06814": {"title": "Temporal Link Prediction in Social Networks Based on Agent Behavior Synchrony and a Cognitive Mechanism", "link": "https://arxiv.org/abs/2406.06814", "description": "arXiv:2406.06814v1 Announce Type: new \nAbstract: Temporality, a crucial characteristic in the formation of social relationships, was used to quantify the long-term time effects of networks for link prediction models, ignoring the heterogeneity of time effects on different time scales. In this work, we propose a novel approach to link prediction in temporal networks, extending existing methods with a cognitive mechanism that captures the dynamics of the interactions. Our approach computes the weight of the edges and their change over time, similar to memory traces in the human brain, by simulating the process of forgetting and strengthening connections depending on the intensity of interactions. We utilized five ground-truth datasets, which were used to predict social ties, missing events, and potential links. We found: (a) the cognitive mechanism enables more accurate capture of the heterogeneity of the temporal effect, leading to an average precision improvement of 9\\% compared to baselines with competitive AUC. (b) the local structure and synchronous agent behavior contribute differently to different types of datasets. (c) appropriately increasing the time intervals, which may reduce the negative impact from noise when dividing time windows to calculate the behavioral synchrony of agents, is effective for link prediction tasks."}, "https://arxiv.org/abs/2406.06889": {"title": "Universal spatial inflation of human mobility", "link": "https://arxiv.org/abs/2406.06889", "description": "arXiv:2406.06889v1 Announce Type: new \nAbstract: Understanding the interplay between egocentric preference and urban structure in shaping human mobility has profound implications for improving epidemic intervention, social equity, and urban resilience. However, numerous existing studies either solely identify the egocentric preferences -- the anchoring effects from home -- or the impact of hierarchical urban structures. Here, we propose a network-based approach to present human mobility in both spatial and topological aspects within the urban system, using cell phone trajectory data from millions of users across three countries. By segmenting mobility trajectories into modules and examining their overlap with urban scales, we have observed the inflation law that the geospatial extent of these modules increases sub-linearly with their distance from home. Moreover, the egocentric preference for higher urban levels leads to this increase. This universal finding indicates that home-based preferences distort the hierarchical scales of human mobility in the urban environment, regardless of demographics or geography."}, "https://arxiv.org/abs/2406.06912": {"title": "Controlling noisy herds", "link": "https://arxiv.org/abs/2406.06912", "description": "arXiv:2406.06912v1 Announce Type: new \nAbstract: The wisdom of the crowd breaks down in small groups. While large flocks exhibit swarm intelligence to evade predators, small groups display erratic behavior, oscillating between unity and discord. We investigate these dynamics using small groups of sheep controlled by shepherd dogs in century-old sheepdog trials, proposing a two-parameter stochastic dynamic framework. Our model employs pressure (stimulus intensity) and lightness (response isotropy) to simulate herding and shedding behaviors. Light sheep rapidly achieve a stable herding state, while heavy sheep exhibit intermittent herding and orthogonal alignment to the dog. High response isotropy enhances group cohesion but complicates group splitting. We construct a unified phase diagram for sheep behavior, identifying three regimes (fleeing, flocking, and grazing) based on group size and stimulus specificity. Increasing stimulus specificity shifts small group behavior from grazing to fleeing, while larger groups exhibit flocking. This transition underscores the challenge of controlling small indecisive collectives. Introducing the Indecisive Collective Algorithm (ICA), we show that deliberate indecisiveness and stochasticity improve control efficiency. ICA outperforms traditional averaging-based algorithms in high-noise settings and excels in tasks requiring group splitting. Our study offers a foundational framework for controlling small, indecisive groups, applicable to biochemical reactions, cell populations, and opinion dynamics."}, "https://arxiv.org/abs/2406.07293": {"title": "Exploring Cognitive Bias Triggers in COVID-19 Misinformation Tweets: A Bot vs", "link": "https://arxiv.org/abs/2406.07293", "description": "arXiv:2406.07293v1 Announce Type: new \nAbstract: During the COVID-19 pandemic, the proliferation of misinformation on social media has been rapidly increasing. Automated Bot authors are believed to be significant contributors of this surge. It is hypothesized that Bot authors deliberately craft online misinformation aimed at triggering and exploiting human cognitive biases, thereby enhancing tweet engagement and persuasive influence. This study investigates this hypothesis by studying triggers of biases embedded in Bot-authored misinformation and comparing them with their counterparts, Human-authored misinformation. We complied a Misinfo Dataset that contains COVID-19 vaccine-related misinformation tweets annotated by author identities, Bots vs Humans, from Twitter during the vaccination period from July 2020 to July 2021. We developed an algorithm to computationally automate the extraction of triggers for eight cognitive biase. Our analysis revealed that the Availability Bias, Cognitive Dissonance, and Confirmation Bias were most commonly present in misinformation, with Bot-authored tweets exhibiting a greater prevalence, with distinct patterns in utilizing bias triggers between Humans and Bots. We further linked these bias triggers with engagement metrics, inferring their potential influence on tweet engagement and persuasiveness. Overall, our findings indicate that bias-triggering tactics have been more influential on Bot-authored tweets than Human-authored tweets. While certain bias triggers boosted engagement for Bot-authored tweets, some other bias triggers unexpectedly decreased it. Conversely, triggers of most biases appeared to be unrelated to the engagement of Human-authored tweets. Our work sheds light on the differential utilization and effect of persuasion strategies between Bot-authored and Human-authored misinformation from the lens of human biases, offering insights for the development of effective counter-measures."}, "https://arxiv.org/abs/2406.06770": {"title": "Optimal control for a SIR model with limited hospitalised patients", "link": "https://arxiv.org/abs/2406.06770", "description": "arXiv:2406.06770v1 Announce Type: cross \nAbstract: This paper analyses the optimal control of infectious disease propagation using a classic susceptible-infected-recovered (SIR) model characterised by permanent immunity and the absence of available vaccines. The control is performed over a time-dependent mean reproduction number, in order to minimise the cumulative number of ever-infected individuals (recovered), under different constraints. We consider constraints on isolation measures ranging from partial lockdown to non-intervention, as well as the social and economic costs associated with such isolation, and the capacity limitations of intensive care units that limits the number of infected individuals to a maximum allowed value. We rigorously derive an optimal quarantine strategy based on necessary optimality conditions. The obtained optimal strategy is of a boundary-bang type, comprising three phases: an initial phase with no intervention, a second phase maintaining the infected population at its maximum possible value, and a final phase of partial lockdown applied over a single interval. The optimal policy is further refined by optimising the transition times between these phases. We show that these results are in excellent agreement with the numerical solution of the problem."}, "https://arxiv.org/abs/2406.06934": {"title": "Decentralized Social Networks and the Future of Free Speech Online", "link": "https://arxiv.org/abs/2406.06934", "description": "arXiv:2406.06934v1 Announce Type: cross \nAbstract: Decentralized social networks like Mastodon and BlueSky are trending topics that have drawn much attention and discussion in recent years. By devolving powers from the central node to the end users, decentralized social networks aim to cure existing pathologies on the centralized platforms and have been viewed by many as the future of the Internet. This article critically and systematically assesses the decentralization project's prospect for communications online. It uses normative theories of free speech to examine whether and how the decentralization design could facilitate users' freedom of expression online. The analysis shows that both promises and pitfalls exist, highlighting the importance of value-based design in this area. Two most salient issues for the design of the decentralized networks are: how to balance the decentralization ideal with constant needs of centralization on the network, and how to empower users to make them truly capable of exercising their control. The article then uses some design examples, such as the shared blocklist and the opt-in search function, to illustrate the value considerations underlying the design choices. Some tentative proposals for law and policy interventions are offered to better facilitate the design of the new network. Rather than providing clear answers, the article seeks to map the value implications of the design choices, highlight the stakes, and point directions for future research."}, "https://arxiv.org/abs/2406.06958": {"title": "Turning the Tide on Dark Pools? Towards Multi-Stakeholder Vulnerability Notifications in the Ad-Tech Supply Chain", "link": "https://arxiv.org/abs/2406.06958", "description": "arXiv:2406.06958v1 Announce Type: cross \nAbstract: Online advertising relies on a complex and opaque supply chain that involves multiple stakeholders, including advertisers, publishers, and ad-networks, each with distinct and sometimes conflicting incentives. Recent research has demonstrated the existence of ad-tech supply chain vulnerabilities such as dark pooling, where low-quality publishers bundle their ad inventory with higher-quality ones to mislead advertisers. We investigate the effectiveness of vulnerability notification campaigns aimed at mitigating dark pooling. Prior research on vulnerability notifications has primarily focused on single-stakeholder scenarios, and it is unclear whether vulnerability notifications can be effective in the multi-stakeholder ad-tech supply chain. We implement an automated vulnerability notification pipeline to systematically evaluate the responsiveness of various stakeholders, including publishers, ad-networks, and advertisers to vulnerability notifications by academics and activists. Our nine-month long multi-stakeholder notification study shows that notifications are an effective method for reducing dark pooling vulnerabilities in the online advertising ecosystem, especially when targeted towards ad-networks. Further, the sender reputation does not impact responses to notifications from activists and academics in a statistically different way. In addition to being the first notification study targeting the online advertising ecosystem, we are also the first to study multi-stakeholder context in vulnerability notifications."}, "https://arxiv.org/abs/2406.07016": {"title": "Delving into ChatGPT usage in academic writing through excess vocabulary", "link": "https://arxiv.org/abs/2406.07016", "description": "arXiv:2406.07016v1 Announce Type: cross \nAbstract: Recent large language models (LLMs) can generate and revise text with human-level performance, and have been widely commercialized in systems like ChatGPT. These models come with clear limitations: they can produce inaccurate information, reinforce existing biases, and be easily misused. Yet, many scientists have been using them to assist their scholarly writing. How wide-spread is LLM usage in the academic literature currently? To answer this question, we use an unbiased, large-scale approach, free from any assumptions on academic LLM usage. We study vocabulary changes in 14 million PubMed abstracts from 2010-2024, and show how the appearance of LLMs led to an abrupt increase in the frequency of certain style words. Our analysis based on excess words usage suggests that at least 10% of 2024 abstracts were processed with LLMs. This lower bound differed across disciplines, countries, and journals, and was as high as 30% for some PubMed sub-corpora. We show that the appearance of LLM-based writing assistants has had an unprecedented impact in the scientific literature, surpassing the effect of major world events such as the Covid pandemic."}, "https://arxiv.org/abs/2406.07155": {"title": "Scaling Large-Language-Model-based Multi-Agent Collaboration", "link": "https://arxiv.org/abs/2406.07155", "description": "arXiv:2406.07155v1 Announce Type: cross \nAbstract: Pioneering advancements in large language model-powered agents have underscored the design pattern of multi-agent collaboration, demonstrating that collective intelligence can surpass the capabilities of each individual. Inspired by the neural scaling law, which posits that increasing neurons leads to emergent abilities, this study investigates whether a similar principle applies to increasing agents in multi-agent collaboration. Technically, we propose multi-agent collaboration networks (MacNet), which utilize directed acyclic graphs to organize agents and streamline their interactive reasoning via topological ordering, with solutions derived from their dialogues. Extensive experiments show that MacNet consistently outperforms baseline models, enabling effective agent collaboration across various network topologies and supporting cooperation among more than a thousand agents. Notably, we observed a small-world collaboration phenomenon, where topologies resembling small-world properties achieved superior performance. Additionally, we identified a collaborative scaling law, indicating that normalized solution quality follows a logistic growth pattern as scaling agents, with collaborative emergence occurring much earlier than previously observed instances of neural emergence. The code and data will be available at https://github.com/OpenBMB/ChatDev."}, "https://arxiv.org/abs/2406.07210": {"title": "The green hydrogen ambition and implementation gap", "link": "https://arxiv.org/abs/2406.07210", "description": "arXiv:2406.07210v1 Announce Type: cross \nAbstract: Green hydrogen is critical for decarbonising hard-to-electrify sectors, but faces high costs and investment risks. Here we define and quantify the green hydrogen ambition and implementation gap, showing that meeting hydrogen expectations will remain challenging despite surging announcements of projects and subsidies. Tracking 137 projects over three years, we identify a wide 2022 implementation gap with only 2% of global capacity announcements finished on schedule. In contrast, the 2030 ambition gap towards 1.5{\\deg}C scenarios is gradually closing as the announced project pipeline has nearly tripled to 441 GW within three years. However, we estimate that, without carbon pricing, realising all these projects would require global subsidies of \\$1.6 trillion (\\$1.2 - 2.6 trillion range), far exceeding announced subsidies. Given past and future implementation gaps, policymakers must prepare for prolonged green hydrogen scarcity. Policy support needs to secure hydrogen investments, but should focus on applications where hydrogen is indispensable."}, "https://arxiv.org/abs/2406.07353": {"title": "Toxic Memes: A Survey of Computational Perspectives on the Detection and Explanation of Meme Toxicities", "link": "https://arxiv.org/abs/2406.07353", "description": "arXiv:2406.07353v1 Announce Type: cross \nAbstract: Internet memes, channels for humor, social commentary, and cultural expression, are increasingly used to spread toxic messages. Studies on the computational analyses of toxic memes have significantly grown over the past five years, and the only three surveys on computational toxic meme analysis cover only work published until 2022, leading to inconsistent terminology and unexplored trends. Our work fills this gap by surveying content-based computational perspectives on toxic memes, and reviewing key developments until early 2024. Employing the PRISMA methodology, we systematically extend the previously considered papers, achieving a threefold result. First, we survey 119 new papers, analyzing 158 computational works focused on content-based toxic meme analysis. We identify over 30 datasets used in toxic meme analysis and examine their labeling systems. Second, after observing the existence of unclear definitions of meme toxicity in computational works, we introduce a new taxonomy for categorizing meme toxicity types. We also note an expansion in computational tasks beyond the simple binary classification of memes as toxic or non-toxic, indicating a shift towards achieving a nuanced comprehension of toxicity. Third, we identify three content-based dimensions of meme toxicity under automatic study: target, intent, and conveyance tactics. We develop a framework illustrating the relationships between these dimensions and meme toxicities. The survey analyzes key challenges and recent trends, such as enhanced cross-modal reasoning, integrating expert and cultural knowledge, the demand for automatic toxicity explanations, and handling meme toxicity in low-resource languages. Also, it notes the rising use of Large Language Models (LLMs) and generative AI for detecting and generating toxic memes. Finally, it proposes pathways for advancing toxic meme detection and interpretation."}, "https://arxiv.org/abs/2401.08428": {"title": "Herd Behaviour in Public Goods Games", "link": "https://arxiv.org/abs/2401.08428", "description": "arXiv:2401.08428v3 Announce Type: replace \nAbstract: The problem of free-riding arises when individuals benefit from a shared resource, service, or public good without contributing proportionately to its provision. This conduct often leads to a collective action problem, as individuals pursue personal gains while relying on the contributions of others. In this study, we present a Bayesian inference model to elucidate the behaviour of participants in a Public Goods Game, a conceptual framework that captures the essence of the free-riding problem. Here, individuals possess information on the distribution of group donations to the public good. Our model is grounded in the premise that individuals strive to harmonise their actions with the group's donation patterns. Our model is able to replicate behavioural patterns that resemble those observed in experiments with midsized groups (100 people), but fails to replicate those for larger scales (1000 people). Our results suggest that, in these scenarios, humans prefer imitation and convergence behaviours over profit optimisation. These insights contribute to understanding how cooperation is achieved through alignment with group behaviour."}, "https://arxiv.org/abs/2403.00311": {"title": "Enhancing social cohesion with cooperative bots in societies of greedy, mobile individuals", "link": "https://arxiv.org/abs/2403.00311", "description": "arXiv:2403.00311v3 Announce Type: replace \nAbstract: Addressing collective issues in social development requires a high level of social cohesion, characterized by cooperation and close social connections. However, social cohesion is challenged by selfish, greedy individuals. With the advancement of artificial intelligence (AI), the dynamics of human-machine hybrid interactions introduce new complexities in fostering social cohesion. This study explores the impact of simple bots on social cohesion from the perspective of human-machine hybrid populations within network. By investigating collective self-organizing movement during migration, results indicate that cooperative bots can promote cooperation, facilitate individual aggregation, and thereby enhance social cohesion. The random exploration movement of bots can break the frozen state of greedy population, help to separate defectors in cooperative clusters, and promote the establishment of cooperative clusters. However, the presence of defective bots can weaken social cohesion, underscoring the importance of carefully designing bot behavior. Our research reveals the potential of bots in guiding social self-organization and provides insights for enhancing social cohesion in the era of human-machine interaction within social networks."}, "https://arxiv.org/abs/2403.10543": {"title": "Mitigating Oversmoothing Through Reverse Process of GNNs for Heterophilic Graphs", "link": "https://arxiv.org/abs/2403.10543", "description": "arXiv:2403.10543v2 Announce Type: replace \nAbstract: Graph Neural Network (GNN) resembles the diffusion process, leading to the over-smoothing of learned representations when stacking many layers. Hence, the reverse process of message passing can produce the distinguishable node representations by inverting the forward message propagation. The distinguishable representations can help us to better classify neighboring nodes with different labels, such as in heterophilic graphs. In this work, we apply the design principle of the reverse process to the three variants of the GNNs. Through the experiments on heterophilic graph data, where adjacent nodes need to have different representations for successful classification, we show that the reverse process significantly improves the prediction performance in many cases. Additional analysis reveals that the reverse mechanism can mitigate the over-smoothing over hundreds of layers. Our code is available at https://github.com/ml-postech/reverse-gnn."}, "https://arxiv.org/abs/2309.05638": {"title": "Errors are Robustly Tamed in Cumulative Knowledge Processes", "link": "https://arxiv.org/abs/2309.05638", "description": "arXiv:2309.05638v3 Announce Type: replace-cross \nAbstract: We study processes of societal knowledge accumulation, where the validity of a new unit of knowledge depends both on the correctness of its derivation and on the validity of the units it depends on. A fundamental question in this setting is: If a constant fraction of the new derivations is wrong, can investing a constant fraction, bounded away from one, of effort ensure that a constant fraction of knowledge in society is valid? Ben-Eliezer, Mikulincer, Mossel, and Sudan (ITCS 2023) introduced a concrete probabilistic model to analyze such questions and showed an affirmative answer to this question. Their study, however, focuses on the simple case where each new unit depends on just one existing unit, and units attach according to a $\\textit{preferential attachment rule}$.\n  In this work, we consider much more general families of cumulative knowledge processes, where new units may attach according to varied attachment mechanisms and depend on multiple existing units. We also allow a (random) fraction of insertions of adversarial nodes.\n  We give a robust affirmative answer to the above question by showing that for $\\textit{all}$ of these models, as long as many of the units follow simple heuristics for checking a bounded number of units they depend on, all errors will be eventually eliminated. Our results indicate that preserving the quality of large interdependent collections of units of knowledge is feasible, as long as careful but not too costly checks are performed when new units are derived/deposited."}, "https://arxiv.org/abs/2406.07574": {"title": "Biharmonic Distance of Graphs and its Higher-Order Variants: Theoretical Properties with Applications to Centrality and Clustering", "link": "https://arxiv.org/abs/2406.07574", "description": "arXiv:2406.07574v1 Announce Type: new \nAbstract: Effective resistance is a distance between vertices of a graph that is both theoretically interesting and useful in applications. We study a variant of effective resistance called the biharmonic distance. While the effective resistance measures how well-connected two vertices are, we prove several theoretical results supporting the idea that the biharmonic distance measures how important an edge is to the global topology of the graph. Our theoretical results connect the biharmonic distance to well-known measures of connectivity of a graph like its total resistance and sparsity. Based on these results, we introduce two clustering algorithms using the biharmonic distance. Finally, we introduce a further generalization of the biharmonic distance that we call the $k$-harmonic distance. We empirically study the utility of biharmonic and $k$-harmonic distance for edge centrality and graph clustering."}, "https://arxiv.org/abs/2406.07805": {"title": "Wiser than the Wisest of Crowds: The Asch Effect Revisited under Friedkin-Johnsen Opinion Dynamics", "link": "https://arxiv.org/abs/2406.07805", "description": "arXiv:2406.07805v1 Announce Type: new \nAbstract: In 1907, Sir Francis Galton independently asked 787 villagers to estimate the weight of an ox. Although none of them guessed the exact weight, the average estimate was remarkably accurate. This phenomenon is known as wisdom of crowds. In a clever experiment, Asch employed actors to demonstrate the human tendency to conform to others' opinions. The question we ask is: what would Sir Francis Galton have observed if Asch had interfered by employing actors? Would the wisdom of crowds become even wiser or not? The problem becomes intriguing when considering the inter-connectedness of the villagers, which is the central theme of this work. We examine a scenario where $n$ agents are interconnected and influence each other. The average of their opinions provides an estimator of a certain quality for some unknown quantity. How can one improve or reduce the quality of the original estimator in terms of the MSE by utilizing Asch's strategy of hiring a few stooges?\n  We present a new formulation of this problem, assuming that nodes adjust their opinions according to the Friedkin-Johnsen opinion dynamics. We demonstrate that selecting $k$ stooges for maximizing and minimizing the MSE is NP-hard. We also demonstrate that our formulation is closely related to maximizing or minimizing polarization and show NP-hardness. We propose an efficient greedy heuristic that scales to large networks and test our algorithm on synthetic and real-world datasets. Although MSE and polarization objectives differ, we find in practice that maximizing polarization often yields solutions that are nearly optimal for minimizing the wisdom of crowds in terms of MSE. Our analysis of real-world data reveals that even a small number of stooges can significantly influence the conversation on the war in Ukraine, resulting in a relative increase of the MSE of 207.80% (maximization) or a decrease of 50.62% (minimization)."}, "https://arxiv.org/abs/2406.07964": {"title": "Political Leaning Inference through Plurinational Scenarios", "link": "https://arxiv.org/abs/2406.07964", "description": "arXiv:2406.07964v1 Announce Type: new \nAbstract: Social media users express their political preferences via interaction with other users, by spontaneous declarations or by participation in communities within the network. This makes a social network such as Twitter a valuable data source to study computational science approaches to political learning inference. In this work we focus on three diverse regions in Spain (Basque Country, Catalonia and Galicia) to explore various methods for multi-party categorization, required to analyze evolving and complex political landscapes, and compare it with binary left-right approaches. We use a two-step method involving unsupervised user representations obtained from the retweets and their subsequent use for political leaning detection. Comprehensive experimentation on a newly collected and curated dataset comprising labeled users and their interactions demonstrate the effectiveness of using Relational Embeddings as representation method for political ideology detection in both binary and multi-party frameworks, even with limited training data. Finally, data visualization illustrates the ability of the Relational Embeddings to capture intricate intra-group and inter-group political affinities."}, "https://arxiv.org/abs/2406.07993": {"title": "How social reinforcement learning can lead to metastable polarisation and the voter model", "link": "https://arxiv.org/abs/2406.07993", "description": "arXiv:2406.07993v1 Announce Type: new \nAbstract: Previous explanations for the persistence of polarization of opinions have typically included modelling assumptions that predispose the possibility of polarization (e.g.\\ repulsive interactions). An exception is recent research showing that polarization is stable when agents form their opinions using reinforcement learning.\n  We show that the polarization observed in this model is not stable, but exhibits consensus asymptotically with probability one. By constructing a link between the reinforcement learning model and the voter model, we argue that the observed polarization is metastable. Finally, we show that a slight modification in the learning process of the agents changes the model from being non-ergodic to being ergodic.\n  Our results show that reinforcement learning may be a powerful method for modelling polarization in opinion dynamics, but that the tools appropriate for analysing such models crucially depend on the properties of the resulting systems. Properties which are determined by the details of the learning process."}, "https://arxiv.org/abs/2406.08034": {"title": "Strong and Weak Random Walks on Signed Networks", "link": "https://arxiv.org/abs/2406.08034", "description": "arXiv:2406.08034v1 Announce Type: new \nAbstract: Random walks play an important role in probing the structure of complex networks. On traditional networks, they can be used to extract community structure, understand node centrality, perform link prediction, or capture the similarity between nodes. On signed networks, where the edge weights can be either positive or negative, it is non-trivial to design a random walk which can be used to extract information about the signed structure of the network, in particular the ability to partition the graph into communities with positive edges inside and negative edges in between. Prior works on signed network random walks focus on the case where there are only two such communities (strong balance), which is rarely the case in empirical networks. In this paper, we propose a signed network random walk which can capture the structure of a network with more than two such communities (weak balance). The walk results in a similarity matrix which can be used to cluster the nodes into antagonistic communities. We compare the characteristics of the so-called strong and weak random walks, in terms of walk length and stationarity. We show through a series of experiments on synthetic and empirical networks that the similarity matrix based on weak walks can be used for both unsupervised and semi-supervised clustering, outperforming the same similarity matrix based on strong walks when the graph has more than two communities, or exhibits asymmetry in the density of links. These results suggest that other random-walk based algorithms for signed networks could be improved simply by running them with weak walks instead of strong walks."}, "https://arxiv.org/abs/2406.08084": {"title": "Characterizing and Detecting Propaganda-Spreading Accounts on Telegram", "link": "https://arxiv.org/abs/2406.08084", "description": "arXiv:2406.08084v1 Announce Type: new \nAbstract: Information-based attacks on social media, such as disinformation campaigns and propaganda, are emerging cybersecurity threats. The security community has focused on countering these threats on social media platforms like X and Reddit. However, they also appear in instant-messaging social media platforms such as WhatsApp, Telegram, and Signal. In these platforms information-based attacks primarily happen in groups and channels, requiring manual moderation efforts by channel administrators. We collect, label, and analyze a large dataset of more than 17 million Telegram comments and messages. Our analysis uncovers two independent, coordinated networks that spread pro-Russian and pro-Ukrainian propaganda, garnering replies from real users. We propose a novel mechanism for detecting propaganda that capitalizes on the relationship between legitimate user messages and propaganda replies and is tailored to the information that Telegram makes available to moderators. Our method is faster, cheaper, and has a detection rate (97.6%) 11.6 percentage points higher than human moderators after seeing only one message from an account. It remains effective despite evolving propaganda."}, "https://arxiv.org/abs/2406.08190": {"title": "CrowdEgress: A Multi-Agent Simulation Platform for Pedestrian Crowd", "link": "https://arxiv.org/abs/2406.08190", "description": "arXiv:2406.08190v1 Announce Type: new \nAbstract: This article introduces a simulation platform to study complex crowd behavior in social context. The agent-based model is extended based on the well-known social force model, and it mainly describes how agents interact with each other, and also with surrounding facilities such as walls, doors and exits. The simulation platform is compatible to FDS+Evac, and the input data in FDS+Evac could be imported into our simulation platform to create single-floor compartment geometry, and a flow solver is used to generate the roadmap towards exits. Most importantly, we plan to integrate advanced social and psychological theory into our simulation platform, especially investigating human behavior in emergency evacuation,such as pre-evacuation behavior, exit-selection activities, social group and herding effect and so forth."}, "https://arxiv.org/abs/2406.08201": {"title": "HTIM: Hybrid Text-Interaction Modeling for Broadening Political Leaning Inference in Social Media", "link": "https://arxiv.org/abs/2406.08201", "description": "arXiv:2406.08201v1 Announce Type: new \nAbstract: Political leaning can be defined as the inclination of an individual towards certain political orientations that align with their personal beliefs. Political leaning inference has traditionally been framed as a binary classification problem, namely, to distinguish between left vs. right or conservative vs liberal. Furthermore, although some recent work considers political leaning inference in a multi-party multi-region framework, their study is limited to the application of social interaction data. In order to address these shortcomings, in this study we propose Hybrid Text-Interaction Modeling (HTIM), a framework that enables hybrid modeling fusioning text and interactions from Social Media to accurately identify the political leaning of users in a multi-party multi-region framework. Access to textual and interaction-based data not only allows us to compare these data sources but also avoids reliance on specific data types. We show that, while state-of-the-art text-based representations on their own are not able to improve over interaction-based representations, a combination of text-based and interaction-based modeling using HTIM considerably improves the performance across the three regions, an improvement that is more prominent when we focus on the most challenging cases involving users who are less engaged in politics."}, "https://arxiv.org/abs/2406.08299": {"title": "Dynamical evolution of social network polarization and its impact on the propagation of a virus", "link": "https://arxiv.org/abs/2406.08299", "description": "arXiv:2406.08299v1 Announce Type: new \nAbstract: The COVID-19 pandemic that emerged in 2020 has highlighted the complex interplay between vaccine hesitancy and societal polarization. In this study, we analyse the dynamical polarization within a social network as well as the network properties before and after a vaccine was made available. Our results show that as the network evolves from a less structured state to one with more clustered communities. Then using an agent-based modeling approach, we simulate the propagation of a virus in a polarized society by assigning vaccines to pro-vaccine individuals and none to the anti-vaccine individuals. We compare this propagation to the case where the same number of vaccines is distributed homogeneously across the population. In polarized networks, we observe a significantly more widespread diffusion of the virus, highlighting the importance of considering polarization for epidemic forecasting."}, "https://arxiv.org/abs/2406.08429": {"title": "A Sticker is Worth a Thousand Words: Characterizing the Use of Stickers in WhatsApp Political Groups in Brazil", "link": "https://arxiv.org/abs/2406.08429", "description": "arXiv:2406.08429v1 Announce Type: new \nAbstract: With the increasing use of smartphones, instant messaging platforms turned into important communication tools. According to WhatsApp, more than 100 billion messages are sent each day on the app. Communication on these platforms has allowed individuals to express themselves in other types of media, rather than simple text, including audio, videos, images, and stickers. Particularly, stickers are a new multimedia format that emerged with messaging apps, promoting new forms of interactions among users, especially in the Brazilian context, transcending their role as a mere form of humor to become a key element in political strategy. In this regard, we investigate how stickers are being used, unveiling unique characteristics that these media bring to WhatsApp chats and the political use of this new media format. To achieve that, we collected a large sample of messages from WhatsApp public political discussion groups in Brazil and analyzed the sticker messages shared in this context"}, "https://arxiv.org/abs/2406.07642": {"title": "Generating Human Understandable Explanations for Node Embeddings", "link": "https://arxiv.org/abs/2406.07642", "description": "arXiv:2406.07642v1 Announce Type: cross \nAbstract: Node embedding algorithms produce low-dimensional latent representations of nodes in a graph. These embeddings are often used for downstream tasks, such as node classification and link prediction. In this paper, we investigate the following two questions: (Q1) Can we explain each embedding dimension with human-understandable graph features (e.g. degree, clustering coefficient and PageRank). (Q2) How can we modify existing node embedding algorithms to produce embeddings that can be easily explained by human-understandable graph features? We find that the answer to Q1 is yes and introduce a new framework called XM (short for eXplain eMbedding) to answer Q2. A key aspect of XM involves minimizing the nuclear norm of the generated explanations. We show that by minimizing the nuclear norm, we minimize the lower bound on the entropy of the generated explanations. We test XM on a variety of real-world graphs and show that XM not only preserves the performance of existing node embedding methods, but also enhances their explainability."}, "https://arxiv.org/abs/2406.07668": {"title": "Python4Physics: A physics outreach program", "link": "https://arxiv.org/abs/2406.07668", "description": "arXiv:2406.07668v1 Announce Type: cross \nAbstract: We describe a summer outreach program developed to cultivate interest in physics in particular and physical sciences more broadly among high school and early college students using small projects in the Python programming language. We discuss the lessons we learned in the hopes that they will be valuable to other physicists in planning their own outreach efforts. We also provide links to resources and materials from the Python4Physics program, which we hope might be useful in other outreach programs."}, "https://arxiv.org/abs/2406.07693": {"title": "A Labelled Dataset for Sentiment Analysis of Videos on YouTube, TikTok, and Other Sources about the 2024 Outbreak of Measles", "link": "https://arxiv.org/abs/2406.07693", "description": "arXiv:2406.07693v1 Announce Type: cross \nAbstract: The work of this paper presents a dataset that contains the data of 4011 videos about the ongoing outbreak of measles published on 264 websites on the internet between January 1, 2024, and May 31, 2024. The dataset is available at https://dx.doi.org/10.21227/40s8-xf63. These websites primarily include YouTube and TikTok, which account for 48.6% and 15.2% of the videos, respectively. The remainder of the websites include Instagram and Facebook as well as the websites of various global and local news organizations. For each of these videos, the URL of the video, title of the post, description of the post, and the date of publication of the video are presented as separate attributes in the dataset. After developing this dataset, sentiment analysis (using VADER), subjectivity analysis (using TextBlob), and fine-grain sentiment analysis (using DistilRoBERTa-base) of the video titles and video descriptions were performed. This included classifying each video title and video description into (i) one of the sentiment classes i.e. positive, negative, or neutral, (ii) one of the subjectivity classes i.e. highly opinionated, neutral opinionated, or least opinionated, and (iii) one of the fine-grain sentiment classes i.e. fear, surprise, joy, sadness, anger, disgust, or neutral. These results are presented as separate attributes in the dataset for the training and testing of machine learning algorithms for performing sentiment analysis or subjectivity analysis in this field as well as for other applications. Finally, this paper also presents a list of open research questions that may be investigated using this dataset."}, "https://arxiv.org/abs/2406.07926": {"title": "Efficient Neural Common Neighbor for Temporal Graph Link Prediction", "link": "https://arxiv.org/abs/2406.07926", "description": "arXiv:2406.07926v1 Announce Type: cross \nAbstract: Temporal graphs are ubiquitous in real-world scenarios, such as social network, trade and transportation. Predicting dynamic links between nodes in a temporal graph is of vital importance. Traditional methods usually leverage the temporal neighborhood of interaction history to generate node embeddings first and then aggregate the source and target node embeddings to predict the link. However, such methods focus on learning individual node representations, but overlook the pairwise representation learning nature of link prediction and fail to capture the important pairwise features of links such as common neighbors (CN). Motivated by the success of Neural Common Neighbor (NCN) for static graph link prediction, we propose TNCN, a temporal version of NCN for link prediction in temporal graphs. TNCN dynamically updates a temporal neighbor dictionary for each node, and utilizes multi-hop common neighbors between the source and target node to learn a more effective pairwise representation. We validate our model on five large-scale real-world datasets from the Temporal Graph Benchmark (TGB), and find that it achieves new state-of-the-art performance on three of them. Additionally, TNCN demonstrates excellent scalability on large datasets, outperforming popular GNN baselines by up to 6.4 times in speed. Our code is available at https: //github.com/GraphPKU/TNCN."}, "https://arxiv.org/abs/2406.08420": {"title": "Designing Child-Centered Content Exposure and Moderation", "link": "https://arxiv.org/abs/2406.08420", "description": "arXiv:2406.08420v1 Announce Type: cross \nAbstract: Research on children's online experience and computer interaction often overlooks the relationship children have with hidden algorithms that control the content they encounter. Furthermore, it is not only about how children interact with targeted content but also how their development and agency are largely affected by these. By engaging with the body of literature at the intersection of i) human-centered design approaches, ii) exclusion and discrimination in A.I., iii) privacy, transparency, and accountability, and iv) children's online citizenship, this article dives into the question of \"How can we approach the design of a child-centered moderation process to (1) include aspects that families value for their children and (2) provide explanations for content appropriateness and removal so that we can scale (according to systems and human needs) the moderation process assisted by A.I.?\".\n  This article contributes a sociotechnical highlight of core challenges and opportunities of designing child-centered content control tools. The article concludes by grounding and characterizing design considerations for a child-centered, family-guided moderation system. We hope this work serves as a stepping stone for designers and researchers pursuing children's safety online with an eye on hidden agents controlling children's online experiences and, by extension, the values and opportunities children are exposed to."}, "https://arxiv.org/abs/2402.08765": {"title": "Who is driving the conversation? Analysing the nodality of British MPs and journalists on Twitter", "link": "https://arxiv.org/abs/2402.08765", "description": "arXiv:2402.08765v2 Announce Type: replace \nAbstract: Who sets the policy agenda? In this paper, we explore the roles of policy actors in agenda setting by studying their relative influence in policy-related discussions. Our approach builds on ``nodality'' \\textemdash a concept in political science that determines the capacity of an actor to share information and to be at the centre of information networks. We propose a novel methodology that quantifies the nodality of all individual actors in any conversation by analysing a comprehensive set of their centrality measures in the related information network. We combine this with the analysis of the activity time-series, of the related conversation (or topic), to demonstrate how nodality scores relate to the capacity to drive topic-related activity. Here we analyse policy-related discussions on X (previously Twitter) and quantify the nodality of two sets of actors in the UK political system \\textemdash Members of Parliament (MPs) and accredited journalists - on four policy topics: The Russia-Ukraine War, the Cost-of-Living Crisis, Brexit and COVID-19. Our results show that the capacity to influence the activity related to a topic is significantly and positively associated with nodality. In particular, we identify two dimensions of nodality that drive the capacity to influence topic-related activity. The first is ``active nodality\", which reflects the level of topic-related engagement an individual actor has on the platform. The second dimension is ``inherent nodality\" which is entirely independent of the platform and reflects the actor's institutional position (such as an MP in a front-bench role, or a journalist's position at a prominent media outlet)."}, "https://arxiv.org/abs/2403.12619": {"title": "Detection of Malicious Agents in Social Learning", "link": "https://arxiv.org/abs/2403.12619", "description": "arXiv:2403.12619v3 Announce Type: replace \nAbstract: Non-Bayesian social learning is a framework for distributed hypothesis testing aimed at learning the true state of the environment. Traditionally, the agents are assumed to receive observations conditioned on the same true state, although it is also possible to examine the case of heterogeneous models across the graph. One important special case is when heterogeneity is caused by the presence of malicious agents whose goal is to move the agents toward a wrong hypothesis. In this work, we propose an algorithm that allows to discover the true state of every individual agent based on the sequence of their beliefs. In so doing, the methodology is also able to locate malicious behavior."}, "https://arxiv.org/abs/2403.13215": {"title": "Leveraging advances in machine learning for the robust classification and interpretation of networks", "link": "https://arxiv.org/abs/2403.13215", "description": "arXiv:2403.13215v2 Announce Type: replace \nAbstract: The ability to simulate realistic networks based on empirical data is an important task across scientific disciplines, from epidemiology to computer science. Often simulation approaches involve selecting a suitable network generative model such as Erd\\\"os-R\\'enyi or small-world. However, few tools are available to quantify if a particular generative model is suitable for capturing a given network structure or organization. We utilize advances in interpretable machine learning to classify simulated networks by our generative models based on various network attributes, using both primary features and their interactions. Our study underscores the significance of specific network features and their interactions in distinguishing generative models, comprehending complex network structures, and the formation of real-world networks."}, "https://arxiv.org/abs/2403.18856": {"title": "Charge de travail du personnel infirmier dans les h{\\^o}pitaux -{\\'e}tude bibliographique", "link": "https://arxiv.org/abs/2403.18856", "description": "arXiv:2403.18856v2 Announce Type: replace \nAbstract: For decades, hospital services have been faced with the challenge of ensuring quality care for patients despite the pressures on staff due to workload overload. Nursing staff are particularly affected by this reality, with a patient/nursing staff ratio so imbalanced that it directly affects the quality of care and the well-being of nurses. This article examines in detail the workload of nursing staff, shedding light on the various factors influencing this workload, including the type of care provided, the characteristics of patients and nursing staff, as well as the organizational context. Furthermore, different methods of calculating and estimating workload are analyzed, ranging from workload calculation systems to advanced predictive models. Finally, reflection is made on future research avenues, particularly concerning the identification of factors influencing workload, data collection and processing, and model validation."}, "https://arxiv.org/abs/2403.05704": {"title": "Non-robustness of diffusion estimates on networks with measurement error", "link": "https://arxiv.org/abs/2403.05704", "description": "arXiv:2403.05704v4 Announce Type: replace-cross \nAbstract: Network diffusion models are used to study things like disease transmission, information spread, and technology adoption. However, small amounts of mismeasurement are extremely likely in the networks constructed to operationalize these models. We show that estimates of diffusions are highly non-robust to this measurement error. First, we show that even when measurement error is vanishingly small, such that the share of missed links is close to zero, forecasts about the extent of diffusion will greatly underestimate the truth. Second, a small mismeasurement in the identity of the initial seed generates a large shift in the locations of expected diffusion path. We show that both of these results still hold when the vanishing measurement error is only local in nature. Such non-robustness in forecasting exists even under conditions where the basic reproductive number is consistently estimable. Possible solutions, such as estimating the measurement error or implementing widespread detection efforts, still face difficulties because the number of missed links are so small. Finally, we conduct Monte Carlo simulations on simulated networks, and real networks from three settings: travel data from the COVID-19 pandemic in the western US, a mobile phone marketing campaign in rural India, and in an insurance experiment in China."}, "https://arxiv.org/abs/2406.08522": {"title": "Predicting Cascading Failures with a Hyperparametric Diffusion Model", "link": "https://arxiv.org/abs/2406.08522", "description": "arXiv:2406.08522v1 Announce Type: new \nAbstract: In this paper, we study cascading failures in power grids through the lens of information diffusion models. Similar to the spread of rumors or influence in an online social network, it has been observed that failures (outages) in a power grid can spread contagiously, driven by viral spread mechanisms. We employ a stochastic diffusion model that is Markovian (memoryless) and local (the activation of one node, i.e., transmission line, can only be caused by its neighbors). Our model integrates viral diffusion principles with physics-based concepts, by correlating the diffusion weights (contagion probabilities between transmission lines) with the hyperparametric Information Cascades (IC) model. We show that this diffusion model can be learned from traces of cascading failures, enabling accurate modeling and prediction of failure propagation. This approach facilitates actionable information through well-understood and efficient graph analysis methods and graph diffusion simulations. Furthermore, by leveraging the hyperparametric model, we can predict diffusion and mitigate the risks of cascading failures even in unseen grid configurations, whereas existing methods falter due to a lack of training data. Extensive experiments based on a benchmark power grid and simulations therein show that our approach effectively captures the failure diffusion phenomena and guides decisions to strengthen the grid, reducing the risk of large-scale cascading failures. Additionally, we characterize our model's sample complexity, improving upon the existing bound."}, "https://arxiv.org/abs/2406.08762": {"title": "LGB: Language Model and Graph Neural Network-Driven Social Bot Detection", "link": "https://arxiv.org/abs/2406.08762", "description": "arXiv:2406.08762v1 Announce Type: new \nAbstract: Malicious social bots achieve their malicious purposes by spreading misinformation and inciting social public opinion, seriously endangering social security, making their detection a critical concern. Recently, graph-based bot detection methods have achieved state-of-the-art (SOTA) performance. However, our research finds many isolated and poorly linked nodes in social networks, as shown in Fig.1, which graph-based methods cannot effectively detect. To address this problem, our research focuses on effectively utilizing node semantics and network structure to jointly detect sparsely linked nodes. Given the excellent performance of language models (LMs) in natural language understanding (NLU), we propose a novel social bot detection framework LGB, which consists of two main components: language model (LM) and graph neural network (GNN). Specifically, the social account information is first extracted into unified user textual sequences, which is then used to perform supervised fine-tuning (SFT) of the language model to improve its ability to understand social account semantics. Next, the semantically enriched node representation is fed into the pre-trained GNN to further enhance the node representation by aggregating information from neighbors. Finally, LGB fuses the information from both modalities to improve the detection performance of sparsely linked nodes. Extensive experiments on two real-world datasets demonstrate that LGB consistently outperforms state-of-the-art baseline models by up to 10.95%. LGB is already online: https://botdetection.aminer.cn/robotmain."}, "https://arxiv.org/abs/2406.08876": {"title": "Heuristics for Influence Maximization with Tiered Influence and Activation thresholds", "link": "https://arxiv.org/abs/2406.08876", "description": "arXiv:2406.08876v1 Announce Type: new \nAbstract: The information flows among the people while they communicate through social media websites. Due to the dependency on digital media, a person shares important information or regular updates with friends and family. The set of persons on social media forms a social network. Influence Maximization (IM) is a known problem in social networks. In social networks, information flows from one person to another using an underlying diffusion model. There are two fundamental diffusion models: the Independent Cascade Model (ICM) and the Linear Threshold Model (LTM). In this paper, we study a variant of the IM problem called Minimum Influential Seeds (MINFS) problem proposed by Qiang et al.[16]. It generalizes the classical IM problem with LTM as the diffusion model. Compared to IM, this variant has additional parameters: the influence threshold for each node and the propagation range. The propagation range is a positive integer that specifies how far the information can propagate from a node. A node on the network is not immediately influenced until it receives the same information from enough number of neighbors (influence threshold). Similarly, any node does not forward information until it receives the same information from a sufficient number of neighbors (activation threshold). Once a node becomes activated, it tries to activate or influence its neighbors. The MINFS problem aims to select the minimum number of initial spreader nodes such that all nodes of the graph are influenced. In this paper, we extend the study of the MINFS problem. We propose heuristics that construct seed sets based on the average degree of non-activated nodes, closest first, and backbone-based heaviest path."}, "https://arxiv.org/abs/2406.08899": {"title": "ESND: An Embedding-based Framework for Signed Network Dismantling", "link": "https://arxiv.org/abs/2406.08899", "description": "arXiv:2406.08899v1 Announce Type: new \nAbstract: Network dismantling aims to maximize the disintegration of a network by removing a specific set of nodes or edges and is applied to various tasks in diverse domains, such as cracking down on crime organizations, delaying the propagation of rumors, and blocking the transmission of viruses. Most of the current network dismantling methods are tailored for unsigned networks, which only consider the connection between nodes without evaluating the nature of the relationships, such as friendship/hostility, enhancing/repressing, and trust/distrust. We here propose an embedding-based algorithm, namely ESND, to solve the signed network dismantling problem. The algorithm generally iterates the following four steps, i.e., giant component detection, network embedding, node clustering, and removal node selection. To illustrate the efficacy and stability of ESND, we conduct extensive experiments on six signed network datasets as well as null models, and compare the performance of our method with baselines. Experimental results consistently show that the proposed ESND is superior to the baselines and displays stable performance with the change in the network structure. Additionally, we examine the impact of sign proportions on network robustness via ESND, observing that networks with a high ratio of negative edges are generally easier to dismantle than networks with high positive edges."}, "https://arxiv.org/abs/2406.09123": {"title": "PSN: Persian Social Norms Dataset for Cross-Cultural AI", "link": "https://arxiv.org/abs/2406.09123", "description": "arXiv:2406.09123v1 Announce Type: new \nAbstract: Datasets capturing cultural norms are essential for developing globally aware AI systems. We present Persian Social Norms (PSN) a novel dataset of over 1.7k Persian social norms, including environments, contexts, and cultural labels, alongside English translations. Leveraging large language models and prompt-engineering techniques, we generated potential norms that were reviewed by native speakers for quality and ethical compliance. As the first Persian dataset of its kind, this resource enables computational modeling of norm adaptation, a crucial challenge for cross-cultural AI informed by diverse cultural perspectives."}, "https://arxiv.org/abs/2406.09142": {"title": "Effects of Antivaccine Tweets on COVID-19 Vaccinations, Cases, and Deaths", "link": "https://arxiv.org/abs/2406.09142", "description": "arXiv:2406.09142v1 Announce Type: new \nAbstract: Vaccines were critical in reducing hospitalizations and mortality during the COVID-19 pandemic. Despite their wide availability in the United States, 62% of Americans chose not to be vaccinated during 2021. While online misinformation about COVID-19 is correlated to vaccine hesitancy, little prior work has explored a causal link between real-world exposure to antivaccine content and vaccine uptake. Here we present a compartmental epidemic model that includes vaccination, vaccine hesitancy, and exposure to antivaccine content. We fit the model to observational data to determine that a geographical pattern of exposure to online antivaccine content across US counties is responsible for a pattern of reduced vaccine uptake in the same counties. We find that exposure to antivaccine content on Twitter caused about 750,000 people to refuse vaccination between February and August 2021 in the US, resulting in at least 29,000 additional cases and 430 additional deaths. This work provides a methodology for linking online speech to offline epidemic outcomes. Our findings should inform social media moderation policy as well as public health interventions."}, "https://arxiv.org/abs/2406.09169": {"title": "Empirical Networks are Sparse: Enhancing Multi-Edge Models with Zero-Inflation", "link": "https://arxiv.org/abs/2406.09169", "description": "arXiv:2406.09169v1 Announce Type: new \nAbstract: Real-world networks are sparse. As we show in this article, even when a large number of interactions is observed most node pairs remain disconnected. We demonstrate that classical multi-edge network models, such as the $G(N,p)$, configuration models, and stochastic block models, fail to accurately capture this phenomenon. To mitigate this issue, zero-inflation must be integrated into these traditional models. Through zero-inflation, we incorporate a mechanism that accounts for the excess number of zeroes (disconnected pairs) observed in empirical data. By performing an analysis on all the datasets from the Sociopatterns repository, we illustrate how zero-inflated models more accurately reflect the sparsity and heavy-tailed edge count distributions observed in empirical data. Our findings underscore that failing to account for these ubiquitous properties in real-world networks inadvertently leads to biased models which do not accurately represent complex systems and their dynamics."}, "https://arxiv.org/abs/2406.09343": {"title": "Frameworks, Modeling and Simulations of Misinformation and Disinformation: A Systematic Literature Review", "link": "https://arxiv.org/abs/2406.09343", "description": "arXiv:2406.09343v1 Announce Type: new \nAbstract: The prevalence of misinformation and disinformation poses a significant challenge in today's digital landscape. That is why several methods and tools are proposed to analyze and understand these phenomena from a scientific perspective. To assess how the mis/disinformation is being conceptualized and evaluated in the literature, this paper surveys the existing frameworks, models and simulations of mis/disinformation dynamics by performing a systematic literature review up to 2023. After applying the PRISMA methodology, 57 research papers are inspected to determine (1) the terminology and definitions of mis/disinformation, (2) the methods used to represent mis/disinformation, (3) the primary purpose beyond modeling and simulating mis/disinformation, (4) the context where the mis/disinformation is studied, and (5) the validation of the proposed methods for understanding mis/disinformation.\n  The main findings reveal a consistent essence definition of misinformation and disinformation across studies, with intent as the key distinguishing factor. Research predominantly uses social frameworks, epidemiological models, and belief updating simulations. These studies aim to estimate the effectiveness of mis/disinformation, primarily in health and politics. The preferred validation strategy is to compare methods with real-world data and statistics. Finally, this paper identifies current trends and open challenges in the mis/disinformation research field, providing recommendations for future work agenda."}, "https://arxiv.org/abs/2406.09348": {"title": "Emergence of Fluctuation Relations in UNO", "link": "https://arxiv.org/abs/2406.09348", "description": "arXiv:2406.09348v1 Announce Type: new \nAbstract: Fluctuation theorems are generalisations of the second law that describe the relations between work, temperature, and free energy in thermodynamic processes and are used extensively in studies of irreversibility and entropy. Many experiments have verified these relations for different physical systems in the setting of thermodynamics. In this study, we observe the same behavior away from physical thermodynamics, namely for the card game UNO, by performing numerical simulations of the game. As the analog of work, we choose the number of steps one player needs to effect a transition in her deck; the other players and the remaining cards play the role of a finite, non-Markovian bath. We also compare our observation with is expected for a Markovian random walk."}, "https://arxiv.org/abs/2406.08594": {"title": "Limiting behaviour of Branching Processes and Online Social Networks", "link": "https://arxiv.org/abs/2406.08594", "description": "arXiv:2406.08594v1 Announce Type: cross \nAbstract: The literature considers multi-type Markov branching processes (BPs), where the offspring distribution depends only on the living (current) population. We analyse the total-current population-dependent BPs where the offspring distribution can also depend on the total (dead and living) population. Such a generalization is inspired by the need to accurately model content propagation over online social networks (OSNs). The key question investigated is the time-asymptotic proportion of the populations, which translates to the proportional visibility of the posts on the OSN. We provide the answer using a stochastic approximation (SA) technique, which has not been used in the existing BP literature. The analysis is derived using a non-trivial autonomous measurable ODE. Interestingly, we prove the possibility of a new limiting behaviour for the stochastic trajectory, named as hovering around. Such a result is not just new to the theory of BPs but also to the SA based literature.\n  Later, we explore three new variants of BPs: (i) any living individual of a population can attack and acquire the living individuals of the other population, in addition to producing its offspring; (ii) the individuals can die due to abnormal circumstances, and not just at the completion of their lifetimes; (iii) the expected number of offspring decreases as the total-population increases, leading to the saturation of the total-population.\n  Such variants aid in analysing unexplored aspects of content propagation over OSNs: (i) competition in advertisement posts for similar products; (ii) controlling fake-post propagation, while not affecting the sharing of real-post; (iii) impact of re-forwarding the posts. We also designed and analysed a participation (mean-field) game where the OSN lures the users with a reward-based scheme to provide their opinion about the actuality of the post (fake or real)."}, "https://arxiv.org/abs/2406.08624": {"title": "A Sublinear Algorithm for Approximate Shortest Paths in Large Networks", "link": "https://arxiv.org/abs/2406.08624", "description": "arXiv:2406.08624v1 Announce Type: cross \nAbstract: Computing distances and finding shortest paths in massive real-world networks is a fundamental algorithmic task in network analysis. There are two main approaches to solving this task. On one hand are traversal-based algorithms like bidirectional breadth-first search (BiBFS) with no preprocessing step and slow individual distance inquiries. On the other hand are indexing-based approaches, which maintain a large index. This allows for answering individual inquiries very fast; however, index creation is prohibitively expensive. We seek to bridge these two extremes: quickly answer distance inquiries without the need for costly preprocessing.\n  In this work, we propose a new algorithm and data structure, WormHole, for approximate shortest path computations. WormHole leverages structural properties of social networks to build a sublinearly sized index, drawing upon the explicit core-periphery decomposition of Ben-Eliezer et al. Empirically, the preprocessing time of WormHole improves upon index-based solutions by orders of magnitude, and individual inquiries are consistently much faster than in BiBFS. The acceleration comes at the cost of a minor accuracy trade-off. Nonetheless, our empirical evidence demonstrates that WormHole accurately answers essentially all inquiries within a maximum additive error of 2. We complement these empirical results with provable theoretical guarantees, showing that WormHole requires $n^{o(1)}$ node queries per distance inquiry in random power-law networks. In contrast, any approach without a preprocessing step requires $n^{\\Omega(1)}$ queries for the same task.\n  WormHole does not require reading the whole graph. Unlike the vast majority of index-based algorithms, it returns paths, not just distances. For faster inquiry times, it can be combined effectively with other index-based solutions, by running them only on the sublinear core."}, "https://arxiv.org/abs/2312.11326": {"title": "Topic Shifts as a Proxy for Assessing Politicization in Social Media", "link": "https://arxiv.org/abs/2312.11326", "description": "arXiv:2312.11326v2 Announce Type: replace \nAbstract: Politicization is a social phenomenon studied by political science characterized by the extent to which ideas and facts are given a political tone. A range of topics, such as climate change, religion and vaccines has been subject to increasing politicization in the media and social media platforms. In this work, we propose a computational method for assessing politicization in online conversations based on topic shifts, i.e., the degree to which people switch topics in online conversations. The intuition is that topic shifts from a non-political topic to politics are a direct measure of politicization -- making something political, and that the more people switch conversations to politics, the more they perceive politics as playing a vital role in their daily lives. A fundamental challenge that must be addressed when one studies politicization in social media is that, a priori, any topic may be politicized. Hence, any keyword-based method or even machine learning approaches that rely on topic labels to classify topics are expensive to run and potentially ineffective. Instead, we learn from a seed of political keywords and use Positive-Unlabeled (PU) Learning to detect political comments in reaction to non-political news articles posted on Twitter, YouTube, and TikTok during the 2022 Brazilian presidential elections. Our findings indicate that all platforms show evidence of politicization as discussion around topics adjacent to politics such as economy, crime and drugs tend to shift to politics. Even the least politicized topics had the rate in which their topics shift to politics increased in the lead up to the elections and after other political events in Brazil -- an evidence of politicization."}, "https://arxiv.org/abs/2312.16708": {"title": "Capital Inequality Induced Business Cycles", "link": "https://arxiv.org/abs/2312.16708", "description": "arXiv:2312.16708v2 Announce Type: replace \nAbstract: In this letter we present a stochastic dynamic model which can explain economic cycles. We show that the macroscopic description yields a complex dynamical landscape consisting of multiple stable fixed points, each corresponding to a split of the population into a large low and a small high income group. The stochastic fluctuations induce switching between the resulting metastable states, and excitation oscillations just below a deterministic bifurcation. The shocks are caused by the decisions of a few agents who have a disproportionate influence over the macroscopic state of the economy due to the unequal distribution of wealth among the population. The fluctuations have a long-term effect on the growth of economic output and lead to business cycle oscillations exhibiting coherence resonance, where the correlation time is controlled by the population size which is inversely proportional to the noise intensity."}, "https://arxiv.org/abs/2403.06689": {"title": "Dynamics of matrix coupled Kuramoto oscillators on modular networks: excitable behavior and global decoherence", "link": "https://arxiv.org/abs/2403.06689", "description": "arXiv:2403.06689v2 Announce Type: replace \nAbstract: Synchronization is observed in many natural systems, with examples ranging from neuronal activation to walking pedestrians. The models proposed by Winfree and Kuramoto stand as the classic frameworks for investigating these phenomena. The Kuramoto model, in particular, has been extended in different ways since its original formulation to account for more general scenarios. One such extension replaces the coupling parameter with a coupling matrix, describing a form of generalized frustration with broken rotational symmetry. A key feature of this model is the existence of {\\it phase tuned states}, characterized by having the phase of the order parameter pointing in the direction of the dominant eigenvector of the coupling matrix. Here we investigate the matrix coupled Kuramoto model on networks with two modules, such that one module is in the phase tuned state and the other in a state where the order parameter rotates. We identified different regimes in which one or the other module dominates the dynamics. We found, in particular, that the phase tuned module can create a bottleneck for the oscillation of the rotating module, leading to a behavior similar to the charge and fire regimes of excitable systems. We also found an extended region in the parameter space where motion is globally disordered, even though one of the modules presented high levels of synchronization when uncoupled."}, "https://arxiv.org/abs/2404.03685": {"title": "Cooperative Evolutionary Pressure and Diminishing Returns Might Explain the Fermi Paradox: On What Super-AIs Are Like", "link": "https://arxiv.org/abs/2404.03685", "description": "arXiv:2404.03685v3 Announce Type: replace \nAbstract: With an evolutionary approach, the basis of morality can be explained as adaptations to problems of cooperation. With 'evolution' taken in a broad sense, evolving AIs that satisfy the conditions for evolution to apply will be subject to the same cooperative evolutionary pressure as biological entities. Here the adaptiveness of increased cooperation as material safety and wealth increase is discussed -- for humans, for other societies, and for AIs. Diminishing beneficial returns from increased access to material resources also suggests the possibility that, on the whole, there will be no incentive to for instance colonize entire galaxies, thus providing a possible explanation of the Fermi paradox, wondering where everybody is. It is further argued that old societies could engender, give way to, super-AIs, since it is likely that super-AIs are feasible, and fitter. Closing is an aside on effective ways for morals and goals to affect life and society, emphasizing environments, cultures, and laws, and exemplified by how to eat.\n  Appended are an algorithm for colonizing for example a galaxy quickly, models of the evolution of cooperation and fairness under diminishing returns, and software for simulating signaling development. It is also noted that there can be no exponential colonization or reproduction, for mathematical reasons, as each entity takes up a certain amount of space."}, "https://arxiv.org/abs/2402.02520": {"title": "A minimal model of cognition based on oscillatory and reinforcement processes", "link": "https://arxiv.org/abs/2402.02520", "description": "arXiv:2402.02520v2 Announce Type: replace-cross \nAbstract: Building mathematical models of brains is difficult because of the sheer complexity of the problem. One potential starting point is through basal cognition, which give abstract representation of a range of organisms without central nervous systems, including fungi, slime moulds and bacteria. We propose one such model, demonstrating how a combination of oscillatory and current-based reinforcement processes can be used to couple resources in an efficient manner, mimicking the way these organisms function. A key ingredient in our model, not found in previous basal cognition models, is that we explicitly model oscillations in the number of particles (i.e. the nutrients, chemical signals or similar, which make up the biological system) and the flow of these particles within the modelled organisms. Using this approach, we find that our model builds efficient solutions, provided the environmental oscillations are sufficiently out of phase. We further demonstrate that amplitude differences can promote efficient solutions and that the system is robust to frequency differences. In the context of these findings, we discuss connections between our model and basal cognition in biological systems and slime moulds, in particular, how oscillations might contribute to self-organised problem-solving by these organisms."}, "https://arxiv.org/abs/2406.09907": {"title": "Balance with Memory in Signed Networks via Mittag-Leffler Matrix Functions", "link": "https://arxiv.org/abs/2406.09907", "description": "arXiv:2406.09907v1 Announce Type: new \nAbstract: Structural balance is an important characteristic of graphs/networks where edges can be positive or negative, with direct impact on the study of real-world complex systems. When a network is not structurally balanced, it is important to know how much balance still exists in it. Although several measures have been proposed to characterize the degree of balance, the use of matrix functions of the signed adjacency matrix emerges as a very promising area of research. Here, we take a step forward to using Mittag-Leffler (ML) matrix functions to quantify the notion of balance of signed networks. We show that the ML balance index can be obtained from first principles on the basis of a nonconservative diffusion dynamic, and that it accounts for the memory of the system about the past, by diminishing the penalization that long cycles typically receive in other matrix functions. Finally, we demonstrate the important information in the ML balance index with both artificial signed networks and real-world networks in various contexts, ranging from biological and ecological to social ones."}, "https://arxiv.org/abs/2406.09983": {"title": "Epidemic-induced local awareness behavior inferred from surveys and genetic sequence data", "link": "https://arxiv.org/abs/2406.09983", "description": "arXiv:2406.09983v1 Announce Type: new \nAbstract: Behavior-disease models suggest that if individuals are aware and take preventive actions when the prevalence of the disease increases among their close contacts, then the pandemic can be contained in a cost-effective way. To measure the true impact of local awareness behavior on epidemic spreading, we propose an efficient approach to identify superspreading events and assign corresponding Event Containment Scores (ECSs) in clinical genetic sequence data. We validate ECS as a measure of local awareness in simulation experiments, and we find that ECS was correlated positively with policy stringency during the COVID-19 pandemic. Finally, we observe a temporary drop in ECS during the Omicron wave in most European countries, matching a survey experiment we carried out at the same time. Our findings bring important insight into the field of awareness modeling through the analysis of large-scale genetic sequence data, one of the most promising data sources in epidemics research."}, "https://arxiv.org/abs/2406.09639": {"title": "TGB 2", "link": "https://arxiv.org/abs/2406.09639", "description": "arXiv:2406.09639v1 Announce Type: cross \nAbstract: Multi-relational temporal graphs are powerful tools for modeling real-world data, capturing the evolving and interconnected nature of entities over time. Recently, many novel models are proposed for ML on such graphs intensifying the need for robust evaluation and standardized benchmark datasets. However, the availability of such resources remains scarce and evaluation faces added complexity due to reproducibility issues in experimental protocols. To address these challenges, we introduce Temporal Graph Benchmark 2.0 (TGB 2.0), a novel benchmarking framework tailored for evaluating methods for predicting future links on Temporal Knowledge Graphs and Temporal Heterogeneous Graphs with a focus on large-scale datasets, extending the Temporal Graph Benchmark. TGB 2.0 facilitates comprehensive evaluations by presenting eight novel datasets spanning five domains with up to 53 million edges. TGB 2.0 datasets are significantly larger than existing datasets in terms of number of nodes, edges, or timestamps. In addition, TGB 2.0 provides a reproducible and realistic evaluation pipeline for multi-relational temporal graphs. Through extensive experimentation, we observe that 1) leveraging edge-type information is crucial to obtain high performance, 2) simple heuristic baselines are often competitive with more complex methods, 3) most methods fail to run on our largest datasets, highlighting the need for research on more scalable methods."}, "https://arxiv.org/abs/1907.06130": {"title": "Quantifying the Vulnerabilities of the Online Public Square to Adversarial Manipulation Tactics", "link": "https://arxiv.org/abs/1907.06130", "description": "arXiv:1907.06130v5 Announce Type: replace-cross \nAbstract: Social media, seen by some as the modern public square, is vulnerable to manipulation. By controlling inauthentic accounts impersonating humans, malicious actors can amplify disinformation within target communities. The consequences of such operations are difficult to evaluate due to the challenges posed by collecting data and carrying out ethical experiments that would influence online communities. Here we use a social media model that simulates information diffusion in an empirical network to quantify the impacts of several adversarial manipulation tactics on the quality of content. We find that the presence of influential accounts, a hallmark of social media, exacerbates the vulnerabilities of online communities to manipulation. Among the explored tactics that bad actors can employ, infiltrating a community is the most likely to make low-quality content go viral. Such harm can be further compounded by inauthentic agents flooding the network with low-quality, yet appealing content, but is mitigated when bad actors focus on specific targets, such as influential or vulnerable individuals. These insights suggest countermeasures that platforms could employ to increase the resilience of social media users to manipulation."}, "https://arxiv.org/abs/2310.14533": {"title": "Context-Aware Prediction of User Engagement on Online Social Platforms", "link": "https://arxiv.org/abs/2310.14533", "description": "arXiv:2310.14533v2 Announce Type: replace-cross \nAbstract: The success of online social platforms hinges on their ability to predict and understand user behavior at scale. Here, we present data suggesting that context-aware modeling approaches may offer a holistic yet lightweight and potentially privacy-preserving representation of user engagement on online social platforms. Leveraging deep LSTM neural networks to analyze more than 100 million Snapchat sessions from almost 80.000 users, we demonstrate that patterns of active and passive use are predictable from past behavior (R2=0.345) and that the integration of context features substantially improves predictive performance compared to the behavioral baseline model (R2=0.522). Features related to smartphone connectivity status, location, temporal context, and weather were found to capture non-redundant variance in user engagement relative to features derived from histories of in-app behaviors. Further, we show that a large proportion of variance can be accounted for with minimal behavioral histories if momentary context is considered (R2=0.442). These results indicate the potential of context-aware approaches for making models more efficient and privacy-preserving by reducing the need for long data histories. Finally, we employ model explainability techniques to glean preliminary insights into the underlying behavioral mechanisms. Our findings are consistent with the notion of context-contingent, habit-driven patterns of active and passive use, underscoring the value of contextualized representations of user behavior for predicting user engagement on social platforms."}, "https://arxiv.org/abs/2311.18526": {"title": "HOT: Higher-Order Dynamic Graph Representation Learning with Efficient Transformers", "link": "https://arxiv.org/abs/2311.18526", "description": "arXiv:2311.18526v2 Announce Type: replace-cross \nAbstract: Many graph representation learning (GRL) problems are dynamic, with millions of edges added or removed per second. A fundamental workload in this setting is dynamic link prediction: using a history of graph updates to predict whether a given pair of vertices will become connected. Recent schemes for link prediction in such dynamic settings employ Transformers, modeling individual graph updates as single tokens. In this work, we propose HOT: a model that enhances this line of works by harnessing higher-order (HO) graph structures; specifically, k-hop neighbors and more general subgraphs containing a given pair of vertices. Harnessing such HO structures by encoding them into the attention matrix of the underlying Transformer results in higher accuracy of link prediction outcomes, but at the expense of increased memory pressure. To alleviate this, we resort to a recent class of schemes that impose hierarchy on the attention matrix, significantly reducing memory footprint. The final design offers a sweetspot between high accuracy and low memory utilization. HOT outperforms other dynamic GRL schemes, for example achieving 9%, 7%, and 15% higher accuracy than - respectively - DyGFormer, TGN, and GraphMixer, for the MOOC dataset. Our design can be seamlessly extended towards other dynamic GRL workloads."}, "https://arxiv.org/abs/2312.15489": {"title": "Browsing behavior exposes identities on the Web", "link": "https://arxiv.org/abs/2312.15489", "description": "arXiv:2312.15489v2 Announce Type: replace-cross \nAbstract: How easy is it to uniquely identify a person based solely on their web browsing behavior? Here we show that when people navigate the Web, their online traces produce fingerprints that identify them. Merely the four most visited web domains are enough to identify 95% of the individuals. These digital fingerprints are stable and render high re-identifiability. We demonstrate that we can re-identify 80% of the individuals in separate time slices of data. Such a privacy threat persists even with limited information about individuals' browsing behavior, reinforcing existing concerns around online privacy."}, "https://arxiv.org/abs/2406.10240": {"title": "Indicators of the human origin of numbers", "link": "https://arxiv.org/abs/2406.10240", "description": "arXiv:2406.10240v1 Announce Type: new \nAbstract: Researchers have demonstrated that humans are unable to generate a sequence of random numbers that corresponds in a statistical sense to a simple distribution such as the uniform distribution. The purpose of this article is to present the results of research on the generation of random number sequences by humans. The article describes 10 effects found in such studies, mechanisms explaining these effects, and 14 measures (not including modifications) used to detect deviations from randomness in the sequences. The analysis of numerical sequences is not only of academic interest; it can also be used for the purpose of data validation (auditing)."}, "https://arxiv.org/abs/2406.10241": {"title": "Shape patterns in popularity series of video games", "link": "https://arxiv.org/abs/2406.10241", "description": "arXiv:2406.10241v1 Announce Type: new \nAbstract: In recent years, digital games have become increasingly present in people's lives both as a leisure activity or in gamified activities of everyday life. Despite this growing presence, large-scale, data-driven analyses of video games remain a small fraction of the related literature. In this sense, the present work constitutes an investigation of patterns in popularity series of video games based on monthly popularity series, spanning eleven years, for close to six thousand games listed on the online platform Steam. Utilizing these series, after a preprocessing stage, we perform a clustering task in order to group the series solely based on their shape. Our results indicate the existence of five clusters of shape patterns named decreasing, hilly, increasing, valley, and bursty, with approximately half of the games showing a decreasing popularity pattern, 20.7% being hilly, 11.8% increasing, 11.0% bursty, and 9.1% valley. Finally, we have probed the prevalence and persistence of shape patterns by comparing the shapes of longer popularity series during their early stages and after completion. We have found the majority of games tend to maintain their pattern over time, except for a constant pattern that appears early in popularity series only to later originate hilly and bursty popularity series."}, "https://arxiv.org/abs/2406.10369": {"title": "On the Preservation of Input/Output Directed Graph Informativeness under Crossover", "link": "https://arxiv.org/abs/2406.10369", "description": "arXiv:2406.10369v1 Announce Type: new \nAbstract: There is a broad class of networks which connect inputs to outputs. While evolutionary operators have been applied to a wide array of complex problems, methods to apply such operators to these networks remain ill-defined. We aim to remedy this. We define Input/Output Directed Graphs (or IOD Graphs) as graphs with nodes $N$ and directed edges $E$, where $N$ contains (a) a set of ``input nodes'' $I \\subset N$, where each $i \\in I$ has no incoming edges and any number of outgoing edges, and (b) a set of ``output nodes'' $O \\subset N$, where each $o \\in O$ has no outgoing edges and any number of incoming edges, and $I\\cap O = \\emptyset$. We define informativeness, which involves the connections via directed paths from the input nodes to the output nodes: A partially informative IOD Graph has at least one path from an input to an output, a very informative IOD Graph has a path from every input to some output, and a fully informative IOD Graph has a path from every input to every output.\n  A perceptron is an example of an IOD Graph. If it has non-zero weights and any number of layers, it is fully informative. As links are removed (assigned zero weight), the perceptron might become very, partially, or not informative.\n  We define a crossover operation on IOD Graphs in which we find subgraphs with matching sets of forward and backward directed links to ``swap.'' With this operation, IOD Graphs can be subject to evolutionary computation methods. We show that fully informative parents may yield a non-informative child. We also show that under conditions of contiguousness and the no dangling nodes condition, crossover compatible, partially informative parents yield partially informative children, and very informative input parents with partially informative output parents yield very informative children. However, even under these conditions, full informativeness may not be retained."}, "https://arxiv.org/abs/2406.10423": {"title": "A comprehensive generalization of the Friendship Paradox to weights and attributes", "link": "https://arxiv.org/abs/2406.10423", "description": "arXiv:2406.10423v1 Announce Type: new \nAbstract: The Friendship Paradox is a simple and powerful statement about node degrees in a graph (Feld 1991). However, it only applies to undirected graphs with no edge weights, and the only node characteristic it concerns is degree. Since many social networks are more complex than that, it is useful to generalize this phenomenon, if possible, and a number of papers have proposed different generalizations. Here, we unify these generalizations in a common framework, retaining the focus on undirected graphs and allowing for weighted edges and for numeric node attributes other than degree to be considered, since this extension allows for a clean characterization and links to the original concepts most naturally. While the original Friendship Paradox and the Weighted Friendship Paradox hold for all graphs, considering non-degree attributes actually makes the extensions fail around 50% of the time, given random attribute assignment. We provide simple correlation-based rules to see whether an attribute-based version of the paradox holds. In addition to theory, our simulation and data results show how all the concepts can be applied to synthetic and real networks. Where applicable, we draw connections to prior work to make this an accessible and comprehensive paper that lets one understand the math behind the Friendship Paradox and its basic extensions."}, "https://arxiv.org/abs/2406.10451": {"title": "Climate Change Task Force Report for the American Astronomical Society", "link": "https://arxiv.org/abs/2406.10451", "description": "arXiv:2406.10451v1 Announce Type: new \nAbstract: The AAS Strategic Plan for 2021-26 called for the creation of a task force to identify how the AAS can meet the goals of the Paris Agreement. The AAS and its membership recognize the danger climate change represents to humanity and our world, and to astronomy -- as a profession, a hobby, and a cultural good. Our profession in general -- and the AAS in particular -- should work to make it possible for all astronomers to have an equal opportunity to be successful without needing to incur high carbon emissions, and to preserve astronomy for future generations.\n  A study was completed of the carbon emissions associated with the AAS, finding that 84% of total AAS-related emissions are from in-person conferences. We also conducted a survey of AAS members to determine their attitudes about climate change. Respondents overwhelmingly (97%) think that the AAS should reduce its carbon footprint. Our task force created a list of fourteen recommendations, with two ranked as top priorities: The AAS should not schedule additional in-person meetings before 2030 and it should work to innovate the AAS conference model. Based upon our analysis it is clear that online interaction is the only way to increase participation while meaningfully decreasing emissions.\n  Our recommendations are aligned with the Astro2020 Decadal Survey as well as AAS values to disseminate our scientific understanding of the universe, and to do our work in an ethically responsible way. Because of their other benefits -- particularly in making our society more welcoming to those who traditionally have been excluded -- we feel that these are sound decisions, worthy of implementation even if the AAS wasn't trying to reduce its carbon footprint. They simply make sense as steps towards a professional society that better serves a broader membership, as our profession evolves to be greener, more inclusive, and more productive."}, "https://arxiv.org/abs/2406.10572": {"title": "Collaborative Framework with Shared Responsibility for Relief Management in Disaster Scenarios", "link": "https://arxiv.org/abs/2406.10572", "description": "arXiv:2406.10572v1 Announce Type: new \nAbstract: Disasters instances have been increasing both in frequency and intensity causing the tragic loss of life and making life harder for the survivors. Disaster relief management plays a crucial role in enhancing the lifestyle of disaster victims by managing the disaster impacts. Disaster relief management is a process with many collaborative sectors where different stakeholders should operate in all major phases of the disaster management progression. In the different phases of the disaster management process, many collaborative government organisations along with nongovernment organisations, leadership, community, and media at different levels need to share the responsibility with disaster victims to achieve effective disaster relief management. Shared responsibility enhances disaster relief management effectiveness and reduces the disaster's impact on the victims. Considering the diverse roles of different stakeholders, there has been a need for a framework that can bind different stakeholders together during disaster management. this paper shows a framework with major stakeholders of disaster relief management and how different stakeholders can take part in an effective disaster relief management process. The framework also highlights how each stakeholder can contribute to relief management at different phases after a disaster. The paper also explores some of the shared responsibility collaborative practices that have been implemented around the world in response to the disaster as a disaster relief management process. In addition, the paper highlights the knowledge obtained from those disaster instances and how this knowledge can be transferred and can be helpful in disaster mitigation and preparedness for future disaster scenarios."}, "https://arxiv.org/abs/2406.10589": {"title": "Resilience patterns in higher-order meta-population networks", "link": "https://arxiv.org/abs/2406.10589", "description": "arXiv:2406.10589v1 Announce Type: new \nAbstract: Meta-population networks are effective tools for capturing population movement across distinct regions, but the assumption of well-mixed regions fails to capture the reality of population higher-order interactions. As a multidimensional system capturing mobility characteristics, meta-population networks are inherently complex and difficult to interpret when subjected to resilience analysis based on N-dimensional equations. We propose a higher-order meta-population model that captures large-scale global cross-regional mobility and small-scale higher-order interactions within regions. Remarkably, we extend the dimension-reduction approach, simplifying the N-dimensional higher-order meta-population system into a one-dimensional equation by decomposing different network behaviours into a single universal resilience function, thereby allowing for convenient and accurate prediction of the system resilience. The network structure and human mobility parameters can clearly and simply express the epidemic threshold. Numerical experimental results on both real networks and star networks confirm the accuracy of the proposed dimension-reduction framework in predicting the evolution of epidemic dynamics on higher-order meta-population networks. Additionally, higher-order interactions among populations are shown to lead to explosive growth in the epidemic infection size potentially. Population mobility causes changes in the spatial distribution of infectious diseases across different regions."}, "https://arxiv.org/abs/2406.10717": {"title": "Economical representation of spatial networks", "link": "https://arxiv.org/abs/2406.10717", "description": "arXiv:2406.10717v1 Announce Type: new \nAbstract: Network visualization is essential for many scientific, societal, technological and artistic domains. The primary goal is to highlight patterns out of nodes interconnected by edges that are easy to understand, facilitate communication and support decision-making. This is typically achieved by rearranging the nodes to minimize the edge crossings responsible of unintelligible and often unaesthetic trends. But when the nodes cannot be moved, as in spatial and physical networks, this procedure is not viable. Here, we overcome this situation by turning the edge crossing problem into a graph filtering optimization. We demonstrate that the presence of longer connections prompt the optimal solution to yield sparser networks, thereby limiting the number of intersections and getting more readable layouts. This theoretical result matches human behavior and provides an ecologically-inspired criterion to visualize and model real-world interconnected systems."}, "https://arxiv.org/abs/2406.11405": {"title": "Network growth under opportunistic attachment", "link": "https://arxiv.org/abs/2406.11405", "description": "arXiv:2406.11405v1 Announce Type: new \nAbstract: Growing network models can potentially be a useful tool in the development of economic theory. This work introduces an \"opportunistic attachment\" mechanism where incoming nodes, in deciding where to join a network, consider features of the entry points available to them. For example, an entrepreneur looking to start a thriving business might consider the expected revenue of many hypothetical businesses. This mechanism is explored, in isolation, via a minimal model where PageRank serves to score the available opportunities. Despite its simplicity, this model gives rise to rich node dynamics, path-dependence, and an unexpected degenerate structure. We go on to argue that this model might be useful to theoretical development as a maximally stylised model of entrepreneurial growth. Central to the argument is an alternative set of microfoundations introduced in Leontief & Brody (1993) whereby the steady state of a random walk is a notion of economic equilibrium. To the extent this argument holds, our findings suggest that entrepreneurs face a shifting \"opportunity space\" where the number of potential business opportunities is effectively unbounded. Opportunistic attachment is thus a candidate mechanism for relating the structure of an economic system to its future growth."}, "https://arxiv.org/abs/2406.11423": {"title": "Dredge Word, Social Media, and Webgraph Networks for Unreliable Website Classification and Identification", "link": "https://arxiv.org/abs/2406.11423", "description": "arXiv:2406.11423v1 Announce Type: new \nAbstract: In an attempt to mimic the complex paths through which unreliable content spreads between search engines and social media, we explore the impact of incorporating both webgraph and large-scale social media contexts into website credibility classification and discovery systems. We further explore the usage of what we define as \\textit{dredge words} on social media -- terms or phrases for which unreliable domains rank highly. Through comprehensive graph neural network ablations, we demonstrate that curriculum-based heterogeneous graph models that leverage context from both webgraphs and social media data outperform homogeneous and single-mode approaches. We further demonstrate that the incorporation of dredge words into our model strongly associates unreliable websites with social media and online commerce platforms. Finally, we show our heterogeneous model greatly outperforms competing systems in the top-k identification of unlabeled unreliable websites. We demonstrate the strong unreliability signals present in the diverse paths that users follow to uncover unreliable content, and we release a novel dataset of dredge words."}, "https://arxiv.org/abs/2406.11450": {"title": "The Evolution of Language in Social Media Comments", "link": "https://arxiv.org/abs/2406.11450", "description": "arXiv:2406.11450v1 Announce Type: new \nAbstract: Understanding the impact of digital platforms on user behavior presents foundational challenges, including issues related to polarization, misinformation dynamics, and variation in news consumption. Comparative analyses across platforms and over different years can provide critical insights into these phenomena. This study investigates the linguistic characteristics of user comments over 34 years, focusing on their complexity and temporal shifts. Utilizing a dataset of approximately 300 million English comments from eight diverse platforms and topics, we examine the vocabulary size and linguistic richness of user communications and their evolution over time. Our findings reveal consistent patterns of complexity across social media platforms and topics, characterized by a nearly universal reduction in text length, diminished lexical richness, but decreased repetitiveness. Despite these trends, users consistently introduce new words into their comments at a nearly constant rate. This analysis underscores that platforms only partially influence the complexity of user comments. Instead, it reflects a broader, universal pattern of human behaviour, suggesting intrinsic linguistic tendencies of users when interacting online."}, "https://arxiv.org/abs/2406.11553": {"title": "The Susceptibility Paradox in Online Social Influence", "link": "https://arxiv.org/abs/2406.11553", "description": "arXiv:2406.11553v1 Announce Type: new \nAbstract: Understanding susceptibility to online influence is crucial for mitigating the spread of misinformation and protecting vulnerable audiences. This paper investigates susceptibility to influence within social networks, focusing on the differential effects of influence-driven versus spontaneous behaviors on user content adoption. Our analysis reveals that influence-driven adoption exhibits high homophily, indicating that individuals prone to influence often connect with similarly susceptible peers, thereby reinforcing peer influence dynamics. Conversely, spontaneous adoption shows significant but lower homophily. Additionally, we extend the Generalized Friendship Paradox to influence-driven behaviors, demonstrating that users' friends are generally more susceptible to influence than the users themselves, de facto establishing the notion of Susceptibility Paradox in online social influence. This pattern does not hold for spontaneous behaviors, where friends exhibit fewer spontaneous adoptions. We find that susceptibility to influence can be accurately predicted using friends' susceptibility alone, while predicting spontaneous adoption requires additional features, such as user metadata. These findings highlight the complex interplay between user engagement and preferences in spontaneous content adoption. Our results provide new insights into social influence mechanisms and offer implications for designing more effective moderation strategies to protect vulnerable audiences."}, "https://arxiv.org/abs/2406.10238": {"title": "Early Detection of Misinformation for Infodemic Management: A Domain Adaptation Approach", "link": "https://arxiv.org/abs/2406.10238", "description": "arXiv:2406.10238v1 Announce Type: cross \nAbstract: An infodemic refers to an enormous amount of true information and misinformation disseminated during a disease outbreak. Detecting misinformation at the early stage of an infodemic is key to manage it and reduce its harm to public health. An early stage infodemic is characterized by a large volume of unlabeled information concerning a disease. As a result, conventional misinformation detection methods are not suitable for this misinformation detection task because they rely on labeled information in the infodemic domain to train their models. To address the limitation of conventional methods, state-of-the-art methods learn their models using labeled information in other domains to detect misinformation in the infodemic domain. The efficacy of these methods depends on their ability to mitigate both covariate shift and concept shift between the infodemic domain and the domains from which they leverage labeled information. These methods focus on mitigating covariate shift but overlook concept shift, rendering them less effective for the task. In response, we theoretically show the necessity of tackling both covariate shift and concept shift as well as how to operationalize each of them. Built on the theoretical analysis, we develop a novel misinformation detection method that addresses both covariate shift and concept shift. Using two real-world datasets, we conduct extensive empirical evaluations to demonstrate the superior performance of our method over state-of-the-art misinformation detection methods as well as prevalent domain adaptation methods that can be tailored to solve the misinformation detection task."}, "https://arxiv.org/abs/2406.10266": {"title": "COVID-19 Twitter Sentiment Classification Using Hybrid Deep Learning Model Based on Grid Search Methodology", "link": "https://arxiv.org/abs/2406.10266", "description": "arXiv:2406.10266v1 Announce Type: cross \nAbstract: In the contemporary era, social media platforms amass an extensive volume of social data contributed by their users. In order to promptly grasp the opinions and emotional inclinations of individuals regarding a product or event, it becomes imperative to perform sentiment analysis on the user-generated content. Microblog comments often encompass both lengthy and concise text entries, presenting a complex scenario. This complexity is particularly pronounced in extensive textual content due to its rich content and intricate word interrelations compared to shorter text entries. Sentiment analysis of public opinion shared on social networking websites such as Facebook or Twitter has evolved and found diverse applications. However, several challenges remain to be tackled in this field. The hybrid methodologies have emerged as promising models for mitigating sentiment analysis errors, particularly when dealing with progressively intricate training data. In this article, to investigate the hesitancy of COVID-19 vaccination, we propose eight different hybrid deep learning models for sentiment classification with an aim of improving overall accuracy of the model. The sentiment prediction is achieved using embedding, deep learning model and grid search algorithm on Twitter COVID-19 dataset. According to the study, public sentiment towards COVID-19 immunization appears to be improving with time, as evidenced by the gradual decline in vaccine reluctance. Through extensive evaluation, proposed model reported an increased accuracy of 98.86%, outperforming other models. Specifically, the combination of BERT, CNN and GS yield the highest accuracy, while the combination of GloVe, BiLSTM, CNN and GS follows closely behind with an accuracy of 98.17%. In addition, increase in accuracy in the range of 2.11% to 14.46% is reported by the proposed model in comparisons with existing works."}, "https://arxiv.org/abs/2406.10380": {"title": "A Model for Economic Freedom on Mars", "link": "https://arxiv.org/abs/2406.10380", "description": "arXiv:2406.10380v1 Announce Type: cross \nAbstract: The momentum of human spaceflight initiatives continues to build toward Mars, and technological advances may eventually enable the potential for permanent space settlement. Aspirations for sustaining human life in space must be predicated on human factors, rather than technological constraints alone, and advances in models of governance and ethics are necessary as human civilization becomes a spacefaring species. This paper presents an idealistic but feasible model for economic freedom on Mars, which is situated within a framework in which Mars has been designated as a sovereign juridical peer to Earth. Under such conditions, Mars could maintain monetary stability through full reserve banking and a restriction on exchange with any fractional reserve Earth currencies, with a volume of circulating currency that changes based on the total population within fixed capacity infrastructure. Mars could maintain long-term political stability by diffusing the ownership of capital on Mars, which would allow all citizens of Mars to draw sufficient wealth from a combination of capital ownership and labor to live a good life. This model could also support limited tourism on Mars, in which real goods are exchanged for services but currency transactions between planets are prohibited. This model demonstrates the potential for a viable and sustainable economy on Mars that could conceivably be implemented, including on a sovereign Mars but also in other scenarios of space settlement. More broadly, this model illustrates that ideas such as diffuse capital ownership and limited government can enable freedom in space, and numerous models beyond a centralized world space agency should be explored to ensure the optimal governance of the emerging space economy."}, "https://arxiv.org/abs/2406.10498": {"title": "A Unified Graph Selective Prompt Learning for Graph Neural Networks", "link": "https://arxiv.org/abs/2406.10498", "description": "arXiv:2406.10498v1 Announce Type: cross \nAbstract: In recent years, graph prompt learning/tuning has garnered increasing attention in adapting pre-trained models for graph representation learning. As a kind of universal graph prompt learning method, Graph Prompt Feature (GPF) has achieved remarkable success in adapting pre-trained models for Graph Neural Networks (GNNs). By fixing the parameters of a pre-trained GNN model, the aim of GPF is to modify the input graph data by adding some (learnable) prompt vectors into graph node features to better align with the downstream tasks on the smaller dataset. However, existing GPFs generally suffer from two main limitations. First, GPFs generally focus on node prompt learning which ignore the prompting for graph edges. Second, existing GPFs generally conduct the prompt learning on all nodes equally which fails to capture the importances of different nodes and may perform sensitively w.r.t noisy nodes in aligning with the downstream tasks. To address these issues, in this paper, we propose a new unified Graph Selective Prompt Feature learning (GSPF) for GNN fine-tuning. The proposed GSPF integrates the prompt learning on both graph node and edge together, which thus provides a unified prompt model for the graph data. Moreover, it conducts prompt learning selectively on nodes and edges by concentrating on the important nodes and edges for prompting which thus make our model be more reliable and compact. Experimental results on many benchmark datasets demonstrate the effectiveness and advantages of the proposed GSPF method."}, "https://arxiv.org/abs/2406.10500": {"title": "Geodesic Distance Between Graphs: A Spectral Metric for Assessing the Stability of Graph Neural Networks", "link": "https://arxiv.org/abs/2406.10500", "description": "arXiv:2406.10500v1 Announce Type: cross \nAbstract: This paper presents a spectral framework for assessing the generalization and stability of Graph Neural Networks (GNNs) by introducing a Graph Geodesic Distance (GGD) metric. For two different graphs with the same number of nodes, our framework leverages a spectral graph matching procedure to find node correspondence so that the geodesic distance between them can be subsequently computed by solving a generalized eigenvalue problem associated with their Laplacian matrices. For graphs with different sizes, a resistance-based spectral graph coarsening scheme is introduced to reduce the size of the bigger graph while preserving the original spectral properties. We show that the proposed GGD metric can effectively quantify dissimilarities between two graphs by encapsulating their differences in key structural (spectral) properties, such as effective resistances between nodes, cuts, the mixing time of random walks, etc. Through extensive experiments comparing with the state-of-the-art metrics, such as the latest Tree-Mover's Distance (TMD) metric, the proposed GGD metric shows significantly improved performance for stability evaluation of GNNs especially when only partial node features are available."}, "https://arxiv.org/abs/2406.10608": {"title": "Scalable Temporal Motif Densest Subnetwork Discovery", "link": "https://arxiv.org/abs/2406.10608", "description": "arXiv:2406.10608v1 Announce Type: cross \nAbstract: Finding dense subnetworks, with density based on edges or more complex structures, such as subgraphs or $k$-cliques, is a fundamental algorithmic problem with many applications. While the problem has been studied extensively in static networks, much remains to be explored for temporal networks.\n  In this work we introduce the novel problem of identifying the temporal motif densest subnetwork, i.e., the densest subnetwork with respect to temporal motifs, which are high-order patterns characterizing temporal networks. This problem significantly differs from analogous formulations for dense temporal (or static) subnetworks as these do not account for temporal motifs. Identifying temporal motifs is an extremely challenging task, and thus, efficient methods are required. To this end, we design two novel randomized approximation algorithms with rigorous probabilistic guarantees that provide high-quality solutions. We perform extensive experiments showing that our methods outperform baselines. Furthermore, our algorithms scale on networks with up to billions of temporal edges, while baselines cannot handle such large networks. We use our techniques to analyze a financial network and show that our formulation reveals important network structures, such as bursty temporal events and communities of users with similar interests."}, "https://arxiv.org/abs/2406.10711": {"title": "Symmetry-driven embedding of networks in hyperbolic space", "link": "https://arxiv.org/abs/2406.10711", "description": "arXiv:2406.10711v1 Announce Type: cross \nAbstract: Hyperbolic models can reproduce the heavy-tailed degree distribution, high clustering, and hierarchical structure of empirical networks. Current algorithms for finding the hyperbolic coordinates of networks, however, do not quantify uncertainty in the inferred coordinates. We present BIGUE, a Markov chain Monte Carlo (MCMC) algorithm that samples the posterior distribution of a Bayesian hyperbolic random graph model. We show that combining random walk and random cluster transformations significantly improves mixing compared to the commonly used and state-of-the-art dynamic Hamiltonian Monte Carlo algorithm. Using this algorithm, we also provide evidence that the posterior distribution cannot be approximated by a multivariate normal distribution, thereby justifying the use of MCMC to quantify the uncertainty of the inferred parameters."}, "https://arxiv.org/abs/2406.10965": {"title": "DocNet: Semantic Structure in Inductive Bias Detection Models", "link": "https://arxiv.org/abs/2406.10965", "description": "arXiv:2406.10965v1 Announce Type: cross \nAbstract: News will have biases so long as people have opinions. However, as social media becomes the primary entry point for news and partisan gaps increase, it is increasingly important for informed citizens to be able to identify bias. People will be able to take action to avoid polarizing echo chambers if they know how the news they are consuming is biased. In this paper, we explore an often overlooked aspect of bias detection in documents: the semantic structure of news articles. We present DocNet, a novel, inductive, and low-resource document embedding and bias detection model that outperforms large language models. We also demonstrate that the semantic structure of news articles from opposing partisan sides, as represented in document-level graph embeddings, have significant similarities. These results can be used to advance bias detection in low-resource environments. Our code and data are made available at https://github.com/nlpresearchanon."}, "https://arxiv.org/abs/2406.10978": {"title": "Local wealth condensation for yard-sale models with wealth-dependent biases", "link": "https://arxiv.org/abs/2406.10978", "description": "arXiv:2406.10978v1 Announce Type: cross \nAbstract: In Chakraborti's yard-sale model of an economy, identical agents engage in pairwise trades, resulting in wealth exchanges that conserve each agent's expected wealth. Doob's martingale convergence theorem immediately implies almost sure wealth condensation, i.e., convergence to a state in which a single agent owns the entire economy. If some pairs of agents are not allowed to trade with each other, the martingale convergence theorem still implies local wealth condensation, i.e., convergence to a state in which some agents are wealthy, while all their trading partners are impoverished. In this note, we propose a new, more elementary proof of this result. Unlike the proof based on the martingale convergence theorem, our argument applies to models with a wealth-acquired advantage, and even to certain models with a poverty-acquired advantage."}, "https://arxiv.org/abs/2406.11046": {"title": "Impact of the Availability of ChatGPT on Software Development: A Synthetic Difference in Differences Estimation using GitHub Data", "link": "https://arxiv.org/abs/2406.11046", "description": "arXiv:2406.11046v1 Announce Type: cross \nAbstract: Advancements in Artificial Intelligence, particularly with ChatGPT, have significantly impacted software development. Utilizing novel data from GitHub Innovation Graph, we hypothesize that ChatGPT enhances software production efficiency. Utilizing natural experiments where some governments banned ChatGPT, we employ Difference-in-Differences (DID), Synthetic Control (SC), and Synthetic Difference-in-Differences (SDID) methods to estimate its effects. Our findings indicate a significant positive impact on the number of git pushes, repositories, and unique developers per 100,000 people, particularly for high-level, general purpose, and shell scripting languages. These results suggest that AI tools like ChatGPT can substantially boost developer productivity, though further analysis is needed to address potential downsides such as low quality code and privacy concerns."}, "https://arxiv.org/abs/2406.11504": {"title": "On the Feasibility of Fidelity$^-$ for Graph Pruning", "link": "https://arxiv.org/abs/2406.11504", "description": "arXiv:2406.11504v1 Announce Type: cross \nAbstract: As one of popular quantitative metrics to assess the quality of explanation of graph neural networks (GNNs), fidelity measures the output difference after removing unimportant parts of the input graph. Fidelity has been widely used due to its straightforward interpretation that the underlying model should produce similar predictions when features deemed unimportant from the explanation are removed. This raises a natural question: \"Does fidelity induce a global (soft) mask for graph pruning?\" To solve this, we aim to explore the potential of the fidelity measure to be used for graph pruning, eventually enhancing the GNN models for better efficiency. To this end, we propose Fidelity$^-$-inspired Pruning (FiP), an effective framework to construct global edge masks from local explanations. Our empirical observations using 7 edge attribution methods demonstrate that, surprisingly, general eXplainable AI methods outperform methods tailored to GNNs in terms of graph pruning performance."}, "https://arxiv.org/abs/2406.11685": {"title": "Edge Classification on Graphs: New Directions in Topological Imbalance", "link": "https://arxiv.org/abs/2406.11685", "description": "arXiv:2406.11685v1 Announce Type: cross \nAbstract: Recent years have witnessed the remarkable success of applying Graph machine learning (GML) to node/graph classification and link prediction. However, edge classification task that enjoys numerous real-world applications such as social network analysis and cybersecurity, has not seen significant advancement. To address this gap, our study pioneers a comprehensive approach to edge classification. We identify a novel `Topological Imbalance Issue', which arises from the skewed distribution of edges across different classes, affecting the local subgraph of each edge and harming the performance of edge classifications. Inspired by the recent studies in node classification that the performance discrepancy exists with varying local structural patterns, we aim to investigate if the performance discrepancy in topological imbalanced edge classification can also be mitigated by characterizing the local class distribution variance. To overcome this challenge, we introduce Topological Entropy (TE), a novel topological-based metric that measures the topological imbalance for each edge. Our empirical studies confirm that TE effectively measures local class distribution variance, and indicate that prioritizing edges with high TE values can help address the issue of topological imbalance. Based on this, we develop two strategies - Topological Reweighting and TE Wedge-based Mixup - to focus training on (synthetic) edges based on their TEs. While topological reweighting directly manipulates training edge weights according to TE, our wedge-based mixup interpolates synthetic edges between high TE wedges. Ultimately, we integrate these strategies into a novel topological imbalance strategy for edge classification: TopoEdge. Through extensive experiments, we demonstrate the efficacy of our proposed strategies on newly curated datasets and thus establish a new benchmark for (imbalanced) edge classification."}, "https://arxiv.org/abs/2406.11729": {"title": "Secure Cross-Chain Provenance for Digital Forensics Collaboration", "link": "https://arxiv.org/abs/2406.11729", "description": "arXiv:2406.11729v1 Announce Type: cross \nAbstract: In digital forensics and various sectors like medicine and supply chain, blockchains play a crucial role in providing a secure and tamper-resistant system that meticulously records every detail, ensuring accountability. However, collaboration among different agencies, each with its own blockchains, creates challenges due to diverse protocols and a lack of interoperability, hindering seamless information sharing. Cross-chain technology has been introduced to address these challenges. Current research about blockchains in digital forensics, tends to focus on individual agencies, lacking a comprehensive approach to collaboration and the essential aspect of cross-chain functionality. This emphasizes the necessity for a framework capable of effectively addressing challenges in securely sharing case information, implementing access controls, and capturing provenance data across interconnected blockchains. Our solution, ForensiCross, is the first cross-chain solution specifically designed for digital forensics and provenance. It includes BridgeChain and features a unique communication protocol for cross-chain and multi-chain solutions. ForensiCross offers meticulous provenance capture and extraction methods, mathematical analysis to ensure reliability, scalability considerations for a distributed intermediary in collaborative blockchain contexts, and robust security measures against potential vulnerabilities and attacks. Analysis and evaluation results indicate that ForensiCross is secure and, despite a slight increase in communication time, outperforms in node count efficiency and has secure provenance extraction. As an all-encompassing solution, ForensiCross aims to simplify collaborative investigations by ensuring data integrity and traceability."}, "https://arxiv.org/abs/2207.12123": {"title": "Entropy-based random models for hypergraphs", "link": "https://arxiv.org/abs/2207.12123", "description": "arXiv:2207.12123v2 Announce Type: replace \nAbstract: Network theory has primarily focused on pairwise relationships, disregarding many-body interactions: neglecting them, however, can lead to misleading representations of complex systems. Hypergraphs represent an increasingly popular alternative for describing polyadic interactions: our innovation lies in leveraging the representation of hypergraphs based on the incidence matrix for extending the entropy-based framework to higher-order structures. In analogy with the Exponential Random Graphs, we name the members of this novel class of models Exponential Random Hypergraphs. Here, we focus on two explicit examples, i.e. the generalisations of the Erd\\\"os-R\\'enyi Model and of the Configuration Model. After discussing their asymptotic properties, we employ them to analyse real-world configurations: more specifically, i) we extend the definition of several network quantities to hypergraphs, ii) compute their expected value under each null model and iii) compare it with the empirical one, in order to detect deviations from random behaviours. Differently from currently available techniques, ours is analytically tractable, scalable and effective in singling out the structural patterns of real-world hypergraphs differing significantly from those emerging as a consequence of simpler, structural constraints."}, "https://arxiv.org/abs/2211.12301": {"title": "Is this correct? Let's check!", "link": "https://arxiv.org/abs/2211.12301", "description": "arXiv:2211.12301v2 Announce Type: replace \nAbstract: Societal accumulation of knowledge is a complex process. The correctness of new units of knowledge depends not only on the correctness of new reasoning, but also on the correctness of old units that the new one builds on. The errors in such accumulation processes are often remedied by error correction and detection heuristics.\n  Motivating examples include the scientific process based on scientific publications, and software development based on libraries of code.\n  Natural processes that aim to keep errors under control, such as peer review in scientific publications, and testing and debugging in software development, would typically check existing pieces of knowledge -- both for the reasoning that generated them and the previous facts they rely on. In this work, we present a simple process that models such accumulation of knowledge and study the persistence (or lack thereof) of errors.\n  We consider a simple probabilistic model for the generation of new units of knowledge based on the preferential attachment growth model, which additionally allows for errors. Furthermore, the process includes checks aimed at catching these errors. We investigate when effects of errors persist forever in the system (with positive probability) and when they get rooted out completely by the checking process.\n  The two basic parameters associated with the checking process are the {\\em probability} of conducting a check and the depth of the check. We show that errors are rooted out if checks are sufficiently frequent and sufficiently deep. In contrast, shallow or infrequent checks are insufficient to root out errors."}, "https://arxiv.org/abs/2304.06970": {"title": "$\\text{H}^2\\text{TNE}$: Temporal Heterogeneous Information Network Embedding in Hyperbolic Spaces", "link": "https://arxiv.org/abs/2304.06970", "description": "arXiv:2304.06970v3 Announce Type: replace \nAbstract: Temporal heterogeneous information network (temporal HIN) embedding, aiming to represent various types of nodes of different timestamps into low dimensional spaces while preserving structural and semantic information, is of vital importance in diverse real-life tasks. Researchers have made great efforts on temporal HIN embedding in Euclidean spaces and got some considerable achievements. However, there is always a fundamental conflict that many real-world networks show hierarchical property and power-law distribution, and are not isometric of Euclidean spaces. Recently, representation learning in hyperbolic spaces has been proved to be valid for data with hierarchical and power-law structure. Inspired by this character, we propose a hyperbolic heterogeneous temporal network embedding ($\\text{H}^2\\text{TNE}$) model for temporal HINs. Specifically, we leverage a temporally and heterogeneously double-constrained random walk strategy to capture the structural and semantic information, and then calculate the embedding by exploiting hyperbolic distance in proximity measurement. Experimental results show that our method has superior performance on temporal link prediction and node classification compared with SOTA models."}, "https://arxiv.org/abs/2305.01552": {"title": "The Topology of a Family Tree Graph and Its Members' Satisfaction with One Another: A Machine Learning Approach", "link": "https://arxiv.org/abs/2305.01552", "description": "arXiv:2305.01552v2 Announce Type: replace \nAbstract: Family members' satisfaction with one another is central to creating healthy and supportive family environments. In this work, we propose and implement a novel computational technique aimed at exploring the possible relationship between the topology of a given family tree graph and its members' satisfaction with one another. Through an extensive empirical evaluation ($N=486$ families), we show that the proposed technique brings about highly accurate results in predicting family members' satisfaction with one another based solely on the family graph's topology. Furthermore, the results indicate that our technique favorably compares to baseline regression models which rely on established features associated with family members' satisfaction with one another in prior literature."}, "https://arxiv.org/abs/2309.01675": {"title": "Fundamental dynamics of popularity-similarity trajectories in real networks", "link": "https://arxiv.org/abs/2309.01675", "description": "arXiv:2309.01675v2 Announce Type: replace \nAbstract: Real networks are complex dynamical systems, evolving over time with the addition and deletion of nodes and links. Currently, there exists no principled mathematical theory for their dynamics -- a grand-challenge open problem. Here, we show that the popularity and similarity trajectories of nodes in hyperbolic embeddings of different real networks manifest universal self-similar properties with typical Hurst exponents $H \\ll 0.5$. This means that the trajectories are predictable, displaying anti-persistent or 'mean-reverting' behavior, and they can be adequately captured by a fractional Brownian motion process. The observed behavior can be qualitatively reproduced in synthetic networks that possess a latent geometric space, but not in networks that lack such space, suggesting that the observed subdiffusive dynamics are inherently linked to the hidden geometry of real networks. These results set the foundations for rigorous mathematical machinery for describing and predicting real network dynamics."}, "https://arxiv.org/abs/2310.10001": {"title": "Systematic discrepancies in the delivery of political ads on Facebook and Instagram", "link": "https://arxiv.org/abs/2310.10001", "description": "arXiv:2310.10001v2 Announce Type: replace \nAbstract: Political advertising on social media has become a central element in election campaigns. However, granular information about political advertising on social media was previously unavailable, thus raising concerns regarding fairness, accountability, and transparency in the electoral process. In this paper, we analyze targeted political advertising on social media via a unique, large-scale dataset of over 80000 political ads from Meta during the 2021 German federal election, with more than 1.1 billion impressions. For each political ad, our dataset records granular information about targeting strategies, spending, and actual impressions. We then study (i) the prevalence of targeted ads across the political spectrum; (ii) the discrepancies between targeted and actual audiences due to algorithmic ad delivery; and (iii) which targeting strategies on social media attain a wide reach at low cost. We find that targeted ads are prevalent across the entire political spectrum. Moreover, there are considerable discrepancies between targeted and actual audiences, and systematic differences in the reach of political ads (in impressions-per-EUR) among parties, where the algorithm favors ads from populists over others."}, "https://arxiv.org/abs/2402.05006": {"title": "Scalable Algorithm for Finding Balanced Subgraphs with Tolerance in Signed Networks", "link": "https://arxiv.org/abs/2402.05006", "description": "arXiv:2402.05006v2 Announce Type: replace \nAbstract: Signed networks, characterized by edges labeled as either positive or negative, offer nuanced insights into interaction dynamics beyond the capabilities of unsigned graphs. Central to this is the task of identifying the maximum balanced subgraph, crucial for applications like polarized community detection in social networks and portfolio analysis in finance. Traditional models, however, are limited by an assumption of perfect partitioning, which fails to mirror the complexities of real-world data. Addressing this gap, we introduce an innovative generalized balanced subgraph model that incorporates tolerance for irregularities. Our proposed region-based heuristic algorithm, tailored for this NP-hard problem, strikes a balance between low time complexity and high-quality outcomes. Comparative experiments validate its superior performance against leading solutions, delivering enhanced effectiveness (notably larger subgraph sizes) and efficiency (achieving up to 100x speedup) in both traditional and generalized contexts."}, "https://arxiv.org/abs/2312.08672": {"title": "CAT: A Causally Graph Attention Network for Trimming Heterophilic Graph", "link": "https://arxiv.org/abs/2312.08672", "description": "arXiv:2312.08672v3 Announce Type: replace-cross \nAbstract: Local Attention-guided Message Passing Mechanism (LAMP) adopted in Graph Attention Networks (GATs) is designed to adaptively learn the importance of neighboring nodes for better local aggregation on the graph, which can bring the representations of similar neighbors closer effectively, thus showing stronger discrimination ability. However, existing GATs suffer from a significant discrimination ability decline in heterophilic graphs because the high proportion of dissimilar neighbors can weaken the self-attention of the central node, jointly resulting in the deviation of the central node from similar nodes in the representation space. This kind of effect generated by neighboring nodes is called the Distraction Effect (DE) in this paper. To estimate and weaken the DE of neighboring nodes, we propose a Causally graph Attention network for Trimming heterophilic graph (CAT). To estimate the DE, since the DE are generated through two paths (grab the attention assigned to neighbors and reduce the self-attention of the central node), we use Total Effect to model DE, which is a kind of causal estimand and can be estimated from intervened data; To weaken the DE, we identify the neighbors with the highest DE (we call them Distraction Neighbors) and remove them. We adopt three representative GATs as the base model within the proposed CAT framework and conduct experiments on seven heterophilic datasets in three different sizes. Comparative experiments show that CAT can improve the node classification accuracy of all base GAT models. Ablation experiments and visualization further validate the enhancement of discrimination ability brought by CAT. The source code is available at https://github.com/GeoX-Lab/CAT."}, "https://arxiv.org/abs/2403.07183": {"title": "Monitoring AI-Modified Content at Scale: A Case Study on the Impact of ChatGPT on AI Conference Peer Reviews", "link": "https://arxiv.org/abs/2403.07183", "description": "arXiv:2403.07183v2 Announce Type: replace-cross \nAbstract: We present an approach for estimating the fraction of text in a large corpus which is likely to be substantially modified or produced by a large language model (LLM). Our maximum likelihood model leverages expert-written and AI-generated reference texts to accurately and efficiently examine real-world LLM-use at the corpus level. We apply this approach to a case study of scientific peer review in AI conferences that took place after the release of ChatGPT: ICLR 2024, NeurIPS 2023, CoRL 2023 and EMNLP 2023. Our results suggest that between 6.5% and 16.9% of text submitted as peer reviews to these conferences could have been substantially modified by LLMs, i.e. beyond spell-checking or minor writing updates. The circumstances in which generated text occurs offer insight into user behavior: the estimated fraction of LLM-generated text is higher in reviews which report lower confidence, were submitted close to the deadline, and from reviewers who are less likely to respond to author rebuttals. We also observe corpus-level trends in generated text which may be too subtle to detect at the individual level, and discuss the implications of such trends on peer review. We call for future interdisciplinary work to examine how LLM use is changing our information and knowledge practices."}, "https://arxiv.org/abs/2403.11456": {"title": "HateCOT: An Explanation-Enhanced Dataset for Generalizable Offensive Speech Detection via Large Language Models", "link": "https://arxiv.org/abs/2403.11456", "description": "arXiv:2403.11456v3 Announce Type: replace-cross \nAbstract: The widespread use of social media necessitates reliable and efficient detection of offensive content to mitigate harmful effects. Although sophisticated models perform well on individual datasets, they often fail to generalize due to varying definitions and labeling of \"offensive content.\" In this paper, we introduce HateCOT, an English dataset with over 52,000 samples from diverse sources, featuring explanations generated by GPT-3.5Turbo and curated by humans. We demonstrate that pretraining on HateCOT significantly enhances the performance of open-source Large Language Models on three benchmark datasets for offensive content detection in both zero-shot and few-shot settings, despite differences in domain and task. Additionally, HateCOT facilitates effective K-shot fine-tuning of LLMs with limited data and improves the quality of their explanations, as confirmed by our human evaluation."}, "https://arxiv.org/abs/2406.11884": {"title": "Hierarchical Compression of Text-Rich Graphs via Large Language Models", "link": "https://arxiv.org/abs/2406.11884", "description": "arXiv:2406.11884v1 Announce Type: new \nAbstract: Text-rich graphs, prevalent in data mining contexts like e-commerce and academic graphs, consist of nodes with textual features linked by various relations. Traditional graph machine learning models, such as Graph Neural Networks (GNNs), excel in encoding the graph structural information, but have limited capability in handling rich text on graph nodes. Large Language Models (LLMs), noted for their superior text understanding abilities, offer a solution for processing the text in graphs but face integration challenges due to their limitation for encoding graph structures and their computational complexities when dealing with extensive text in large neighborhoods of interconnected nodes. This paper introduces ``Hierarchical Compression'' (HiCom), a novel method to align the capabilities of LLMs with the structure of text-rich graphs. HiCom processes text in a node's neighborhood in a structured manner by organizing the extensive textual information into a more manageable hierarchy and compressing node text step by step. Therefore, HiCom not only preserves the contextual richness of the text but also addresses the computational challenges of LLMs, which presents an advancement in integrating the text processing power of LLMs with the structural complexities of text-rich graphs. Empirical results show that HiCom can outperform both GNNs and LLM backbones for node classification on e-commerce and citation graphs. HiCom is especially effective for nodes from a dense region in a graph, where it achieves a 3.48% average performance improvement on five datasets while being more efficient than LLM backbones."}, "https://arxiv.org/abs/2406.11887": {"title": "Understanding the Dynamics of the Stack Overflow Community through Social Network Analysis and Graph Algorithms", "link": "https://arxiv.org/abs/2406.11887", "description": "arXiv:2406.11887v1 Announce Type: new \nAbstract: This thesis conducts a focused literature review on online communities, centering on Stack Overflow, employing social network analysis and graph algorithms. It examines the evolving landscape of health information quality within the digital ecosystem, emphasizing the challenges posed and the multifaceted nature of quality. The significance of online communities, notably Stack Overflow, as hubs for social interaction and knowledge sharing is underscored. Proposing advanced approaches, the thesis introduces an ensemble deep learning model for traffic flow forecasting, an efficient multi-objective optimization method for influence maximization, and a graph convolutional neural network-based approach for link prediction."}, "https://arxiv.org/abs/2406.11891": {"title": "Towards Adaptive Neighborhood for Advancing Temporal Interaction Graph Modeling", "link": "https://arxiv.org/abs/2406.11891", "description": "arXiv:2406.11891v1 Announce Type: new \nAbstract: Temporal Graph Networks (TGNs) have demonstrated their remarkable performance in modeling temporal interaction graphs. These works can generate temporal node representations by encoding the surrounding neighborhoods for the target node. However, an inherent limitation of existing TGNs is their reliance on fixed, hand-crafted rules for neighborhood encoding, overlooking the necessity for an adaptive and learnable neighborhood that can accommodate both personalization and temporal evolution across different timestamps. In this paper, we aim to enhance existing TGNs by introducing an adaptive neighborhood encoding mechanism. We present SEAN, a flexible plug-and-play model that can be seamlessly integrated with existing TGNs, effectively boosting their performance. To achieve this, we decompose the adaptive neighborhood encoding process into two phases: (i) representative neighbor selection, and (ii) temporal-aware neighborhood information aggregation. Specifically, we propose the Representative Neighbor Selector component, which automatically pinpoints the most important neighbors for the target node. It offers a tailored understanding of each node's unique surrounding context, facilitating personalization. Subsequently, we propose a Temporal-aware Aggregator, which synthesizes neighborhood aggregation by selectively determining the utilization of aggregation routes and decaying the outdated information, allowing our model to adaptively leverage both the contextually significant and current information during aggregation. We conduct extensive experiments by integrating SEAN into three representative TGNs, evaluating their performance on four public datasets and one financial benchmark dataset introduced in this paper. The results demonstrate that SEAN consistently leads to performance improvements across all models, achieving SOTA performance and exceptional robustness."}, "https://arxiv.org/abs/2406.11901": {"title": "Model Evaluation and Anomaly Detection in Temporal Complex Networks using Deep Learning Methods", "link": "https://arxiv.org/abs/2406.11901", "description": "arXiv:2406.11901v1 Announce Type: new \nAbstract: Modeling complex networks allows us to analyze the characteristics and discover the basic mechanisms governing phenomena such as disease outbreaks, information diffusion, transportation efficiency, social influence, and even human brain function. Consequently, various network generative models (called temporal network models) have been presented to model how the network topologies evolve dynamically over time. Temporal network models face the challenge of results evaluation because common evaluation methods are appropriate only for static networks. This paper proposes an automatic approach based on deep learning to handle this issue. In addition to an evaluation method, the proposed method can also be used for anomaly detection in evolving networks. The proposed method has been evaluated on five different datasets, and the evaluations show that it outperforms the alternative methods based on the error rate measure in different datasets."}, "https://arxiv.org/abs/2406.11904": {"title": "Pay Attention to Weak Ties: A Heterogeneous Multiplex Representation Learning Framework for Link Prediction", "link": "https://arxiv.org/abs/2406.11904", "description": "arXiv:2406.11904v1 Announce Type: new \nAbstract: Graph neural networks (GNNs) can learn effective node representations that significantly improve link prediction accuracy. However, most GNN-based link prediction algorithms are incompetent to predict weak ties connecting different communities. Most link prediction algorithms are designed for networks with only one type of relation between nodes but neglect the fact that many complex systems, including transportation and social networks, consisting of multi-modalities of interactions that correspond to different nature of interactions and dynamics that can be modeled as multiplex network, where different types of relation are represented in different layers. This paper proposes a Multi-Relations-aware Graph Neural Network (MRGNN) framework to learn effective node representations for multiplex networks and make more accurate link predictions, especially for weak ties. Specifically, our model utilizes an intra-layer node-level feature propagation process and an inter-layer representation merge process, which applies a simple yet effective logistic or semantic attention voting mechanism to adaptively aggregate information from different layers. Extensive experiments on four diversified multiplex networks show that MRGNN outperforms the state-of-the-art multiplex link prediction algorithms on overall prediction accuracy, and works pretty well on forecasting weak ties"}, "https://arxiv.org/abs/2406.11907": {"title": "Mapping Literary Space: A Social Network from the Timeline of Cultural Events", "link": "https://arxiv.org/abs/2406.11907", "description": "arXiv:2406.11907v1 Announce Type: new \nAbstract: This paper applies social network analysis (SNA) to explore the literary networks of St. Petersburg from 1999 to 2019. By analyzing data from the \"SPbLitGuide\" newsletter, which documents literary events and their participants, we map the connections and collaborations within the literary community. Our approach uses text processing, knowledge extraction, and geographic data to construct a detailed network graph. Using SNA algorithms, we identify key communities and influential figures. The analysis reveals a robust small-world network with strong local clustering and widespread collaboration. These findings provide insights into the structure and dynamics of literary groups in St. Petersburg and provide a foundation for further research in the digital humanities."}, "https://arxiv.org/abs/2406.11924": {"title": "Explainable assessment of financial experts' credibility by classifying social media forecasts and checking the predictions with actual market data", "link": "https://arxiv.org/abs/2406.11924", "description": "arXiv:2406.11924v1 Announce Type: new \nAbstract: Social media include diverse interaction metrics related to user popularity, the most evident example being the number of user followers. The latter has raised concerns about the credibility of the posts by the most popular creators. However, most existing approaches to assess credibility in social media strictly consider this problem a binary classification, often based on a priori information, without checking if actual real-world facts back the users' comments. In addition, they do not provide automatic explanations of their predictions to foster their trustworthiness. In this work, we propose a credibility assessment solution for financial creators in social media that combines Natural Language Processing and Machine Learning. The reputation of the contributors is assessed by automatically classifying their forecasts on asset values by type and verifying these predictions with actual market data to approximate their probability of success. The outcome of this verification is a continuous credibility score instead of a binary result, an entirely novel contribution by this work. Moreover, social media metrics (i.e., user context) are exploited by calculating their correlation with the credibility rankings, providing insights on the interest of the end-users in financial posts and their forecasts (i.e., drop or rise). Finally, the system provides natural language explanations of its decisions based on a model-agnostic analysis of relevant features."}, "https://arxiv.org/abs/2406.12469": {"title": "Tracing the Unseen: Uncovering Human Trafficking Patterns in Job Listings", "link": "https://arxiv.org/abs/2406.12469", "description": "arXiv:2406.12469v1 Announce Type: new \nAbstract: In the shadow of the digital revolution, the insidious issue of human trafficking has found new breeding grounds within the realms of social media and online job boards. Previous research efforts have predominantly centered on identifying victims via the analysis of escort advertisements. However, our work shifts the focus towards enabling a proactive approach: pinpointing potential traffickers before they lure their preys through false job opportunities. In this study, we collect and analyze a vast dataset comprising over a quarter million job postings collected from eight relevant regions across the United States, spanning nearly two decades (2006-2024). The job boards we considered are specifically catered towards Chinese-speaking immigrants in the US. We classify the job posts into distinct groups based on the self-reported information of the posting user. Our investigation into the types of advertised opportunities, the modes of preferred contact, and the frequency of postings uncovers the patterns characterizing suspicious ads. Additionally, we highlight how external events such as health emergencies and conflicts appear to strongly correlate with increased volume of suspicious job posts: traffickers are more likely to prey upon vulnerable populations in times of crises. This research underscores the imperative for a deeper dive into how online job boards and communication platforms could be unwitting facilitators of human trafficking. More importantly, it calls for the urgent formulation of targeted strategies to dismantle these digital conduits of exploitation."}, "https://arxiv.org/abs/2406.12525": {"title": "Anatomy of Elite and Mass Polarization in Social Networks", "link": "https://arxiv.org/abs/2406.12525", "description": "arXiv:2406.12525v1 Announce Type: new \nAbstract: Existing methods for quantifying polarization in social networks typically report a single value describing the amount of polarization in a social system. While this approach can be used to confirm the observation that many societies have witnessed an increase in political polarization in recent years, it misses the complexities that could be used to understand the reasons behind this phenomenon. Notably, opposing groups can have unequal impact on polarization, and the elites are often understood to be more divided than the masses, making it critical to differentiate their roles in polarized systems. We propose a method to characterize these distinct hierarchies in polarized networks, enabling separate polarization measurements for these groups within a single social system. Applied to polarized topics in the Finnish Twittersphere surrounding the 2019 and 2023 parliamentary elections, our analysis reveals valuable insights: 1) The impact of opposing groups on observed polarization is rarely balanced, and 2) while the elite strongly contributes to structural polarization and consistently display greater alignment across various topics, the masses have also recently experienced a surge in issue alignment, a special form of polarization. Our findings suggest that the masses may not be as immune to an increasingly polarized environment as previously thought."}, "https://arxiv.org/abs/2406.12636": {"title": "UEFA Champions League entry is incentive incompatible again from the 2024/25 season", "link": "https://arxiv.org/abs/2406.12636", "description": "arXiv:2406.12636v1 Announce Type: new \nAbstract: A tournament is called incentive incompatible if it allows for a situation where a team could be strictly better off by losing. This paper uncovers that the entry rules of the UEFA Champions League, the most prestigious club football competition in Europe, suffer from this shortcoming again from the 2024/25 season. Consequently, a match with misaligned incentives has been barely avoided in the 2023/24 German Bundesliga. Two straightforward solutions are recommended. Fairness can be easily guaranteed by reversing the order of two paragraphs in the UEFA Champions League regulation."}, "https://arxiv.org/abs/2406.12647": {"title": "Evolution of cooperation with the diversity of cooperation tendencies", "link": "https://arxiv.org/abs/2406.12647", "description": "arXiv:2406.12647v1 Announce Type: new \nAbstract: The complete cooperation and the complete defection are two typical strategies considered in evolutionary games in many previous works. However, in real life, strategies of individuals are full of variety rather than only two complete ones. In this work, the diversity of strategies is introduced into the weak prisoners' dilemma game, which is measured by the diversity of the cooperation tendency. A higher diversity means more cooperation tendencies are provided. The complete cooperation strategy is the full cooperation tendency and the complete defection strategy is without any cooperation tendency. Agents with other cooperation tendencies behave as partial cooperators and as partial defectors simultaneously. The numerical simulation shows that increasing the diversity of the cooperation tendency promotes the cooperation level, not only the number of cooperators but also the average tendency over the whole population, until the diversity reaches its saturated value. Furthermore, our work points out maintaining cooperation is based on the cooperation efficiency approximating to the reward of cooperators and that the cooperation efficiency oscillates and quickly decreases to zero when cooperator clusters cannot resist the invasion of defectors. When the effect of the noise for the Femi update mechanism is considered, a higher diversity of strategies not only improves the cooperation level of the whole population but also supports the survival of more rational agents."}, "https://arxiv.org/abs/2406.11940": {"title": "Model-Based Inference and Experimental Design for Interference Using Partial Network Data", "link": "https://arxiv.org/abs/2406.11940", "description": "arXiv:2406.11940v1 Announce Type: cross \nAbstract: The stable unit treatment value assumption states that the outcome of an individual is not affected by the treatment statuses of others, however in many real world applications, treatments can have an effect on many others beyond the immediately treated. Interference can generically be thought of as mediated through some network structure. In many empirically relevant situations however, complete network data (required to adjust for these spillover effects) are too costly or logistically infeasible to collect. Partially or indirectly observed network data (e.g., subsamples, aggregated relational data (ARD), egocentric sampling, or respondent-driven sampling) reduce the logistical and financial burden of collecting network data, but the statistical properties of treatment effect adjustments from these design strategies are only beginning to be explored. In this paper, we present a framework for the estimation and inference of treatment effect adjustments using partial network data through the lens of structural causal models. We also illustrate procedures to assign treatments using only partial network data, with the goal of either minimizing estimator variance or optimally seeding. We derive single network asymptotic results applicable to a variety of choices for an underlying graph model. We validate our approach using simulated experiments on observed graphs with applications to information diffusion in India and Malawi."}, "https://arxiv.org/abs/2406.12002": {"title": "Modeling, Inference, and Prediction in Mobility-Based Compartmental Models for Epidemiology", "link": "https://arxiv.org/abs/2406.12002", "description": "arXiv:2406.12002v1 Announce Type: cross \nAbstract: Classical compartmental models in epidemiology often struggle to accurately capture real-world dynamics due to their inability to address the inherent heterogeneity of populations. In this paper, we introduce a novel approach that incorporates heterogeneity through a mobility variable, transforming the traditional ODE system into a system of integro-differential equations that describe the dynamics of population densities across different compartments. Our results show that, for the same basic reproduction number, our mobility-based model predicts a smaller final pandemic size compared to classic compartmental models, whose population densities are represented as Dirac delta functions in our density-based framework. This addresses the overestimation issue common in many classical models. Additionally, we demonstrate that the time series of the infected population is sufficient to uniquely identify the mobility distribution. We reconstruct this distribution using a machine-learning-based framework, providing both theoretical and algorithmic support to effectively constrain the mobility-based model with real-world data."}, "https://arxiv.org/abs/2406.12028": {"title": "Mixed-resolution hybrid modeling in an element-based framework", "link": "https://arxiv.org/abs/2406.12028", "description": "arXiv:2406.12028v1 Announce Type: cross \nAbstract: Computational modeling of a complex system is limited by the parts of the system with the least information. While detailed models and high-resolution data may be available for parts of a system, abstract relationships are often necessary to connect the parts and model the full system. For example, modeling food security necessitates the interaction of climate and socioeconomic factors, with models of system components existing at different levels of information in terms of granularity and resolution. Connecting these models is an ongoing challenge. In this work, we demonstrate methodology to quantize and integrate information from data and detailed component models alongside abstract relationships in a hybrid element-based modeling and simulation framework. In a case study of modeling food security, we apply quantization methods to generate (1) time-series model input from climate data and (2) a discrete representation of a component model (a statistical emulator of crop yield), which we then incorporate as an update rule in the hybrid element-based model, bridging differences in model granularity and resolution. Simulation of the hybrid element-based model recapitulated the trends of the original emulator, supporting the use of this methodology to integrate data and information from component models to simulate complex systems."}, "https://arxiv.org/abs/2406.12059": {"title": "A Scalable and Effective Alternative to Graph Transformers", "link": "https://arxiv.org/abs/2406.12059", "description": "arXiv:2406.12059v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) have shown impressive performance in graph representation learning, but they face challenges in capturing long-range dependencies due to their limited expressive power. To address this, Graph Transformers (GTs) were introduced, utilizing self-attention mechanism to effectively model pairwise node relationships. Despite their advantages, GTs suffer from quadratic complexity w.r.t. the number of nodes in the graph, hindering their applicability to large graphs. In this work, we present Graph-Enhanced Contextual Operator (GECO), a scalable and effective alternative to GTs that leverages neighborhood propagation and global convolutions to effectively capture local and global dependencies in quasilinear time. Our study on synthetic datasets reveals that GECO reaches 169x speedup on a graph with 2M nodes w.r.t. optimized attention. Further evaluations on diverse range of benchmarks showcase that GECO scales to large graphs where traditional GTs often face memory and time limitations. Notably, GECO consistently achieves comparable or superior quality compared to baselines, improving the SOTA up to 4.5%, and offering a scalable and effective solution for large-scale graph learning."}, "https://arxiv.org/abs/2406.12098": {"title": "Circular transformation of the European steel industry renders scrap metal a strategic resource", "link": "https://arxiv.org/abs/2406.12098", "description": "arXiv:2406.12098v1 Announce Type: cross \nAbstract: The steel industry is a major contributor to CO2 emissions, accounting for 7% of global emissions. The European steel industry is seeking to reduce its emissions by increasing the use of electric arc furnaces (EAFs), which can produce steel from scrap, marking a major shift towards a circular steel economy. Here, we show by combining trade with business intelligence data that this shift requires a deep restructuring of the global and European scrap trade, as well as a substantial scaling of the underlying business ecosystem. We find that the scrap imports of European countries with major EAF installations have steadily decreased since 2007 while globally scrap trade started to increase recently. Our statistical modelling shows that every 1,000 tonnes of EAF capacity installed is associated with an increase in annual imports of 550 tonnes and a decrease in annual exports of 1,000 tonnes of scrap, suggesting increased competition for scrap metal as countries ramp up their EAF capacity. Furthermore, each scrap company enables an increase of around 79,000 tonnes of EAF-based steel production per year in the EU. Taking these relations as causal and extrapolating to the currently planned EAF capacity, we find that an additional 730 (SD 140) companies might be required, employing about 35,000 people (IQR 29,000-50,000) and generating an additional estimated turnover of USD 35 billion (IQR 27-48). Our results thus suggest that scrap metal is likely to become a strategic resource. They highlight the need for a massive restructuring of the industry's supply networks and identify the resulting growth opportunities for companies."}, "https://arxiv.org/abs/2406.12119": {"title": "Deploying scalable traffic prediction models for efficient management in real-world large transportation networks during hurricane evacuations", "link": "https://arxiv.org/abs/2406.12119", "description": "arXiv:2406.12119v1 Announce Type: cross \nAbstract: Accurate traffic prediction is vital for effective traffic management during hurricane evacuation. This paper proposes a predictive modeling system that integrates Multilayer Perceptron (MLP) and Long-Short Term Memory (LSTM) models to capture both long-term congestion patterns and short-term speed patterns. Leveraging various input variables, including archived traffic data, spatial-temporal road network information, and hurricane forecast data, the framework is designed to address challenges posed by heterogeneous human behaviors, limited evacuation data, and hurricane event uncertainties. Deployed in a real-world traffic prediction system in Louisiana, the model achieved an 82% accuracy in predicting long-term congestion states over a 6-hour period during a 7-day hurricane-impacted duration. The short-term speed prediction model exhibited Mean Absolute Percentage Errors (MAPEs) ranging from 7% to 13% across evacuation horizons from 1 to 6 hours. Evaluation results underscore the model's potential to enhance traffic management during hurricane evacuations, and real-world deployment highlights its adaptability and scalability in diverse hurricane scenarios within extensive transportation networks."}, "https://arxiv.org/abs/2406.12161": {"title": "Understanding Help-Seeking and Help-Giving on Social Media for Image-Based Sexual Abuse", "link": "https://arxiv.org/abs/2406.12161", "description": "arXiv:2406.12161v1 Announce Type: cross \nAbstract: Image-based sexual abuse (IBSA), like other forms of technology-facilitated abuse, is a growing threat to people's digital safety. Attacks include unwanted solicitations for sexually explicit images, extorting people under threat of leaking their images, or purposefully leaking images to enact revenge or exert control. In this paper, we explore how people seek and receive help for IBSA on social media. Specifically, we identify over 100,000 Reddit posts that engage relationship and advice communities for help related to IBSA. We draw on a stratified sample of 261 posts to qualitatively examine how various types of IBSA unfold, including the mapping of gender, relationship dynamics, and technology involvement to different types of IBSA. We also explore the support needs of victim-survivors experiencing IBSA and how communities help victim-survivors navigate their abuse through technical, emotional, and relationship advice. Finally, we highlight sociotechnical gaps in connecting victim-survivors with important care, regardless of whom they turn to for help."}, "https://arxiv.org/abs/2406.12167": {"title": "Bounds and Bugs: The Limits of Symmetry Metrics to Detect Partisan Gerrymandering", "link": "https://arxiv.org/abs/2406.12167", "description": "arXiv:2406.12167v1 Announce Type: cross \nAbstract: We provide both a theoretical and empirical analysis of the Mean-Median Difference (MM) and Partisan Bias (PB), which are both symmetry metrics intended to detect gerrymandering. We consider vote-share, seat-share pairs $(V, S)$ for which one can construct election data having vote share $V$ and seat share $S$, and turnout is equal in each district. We calculate the range of values that MM and PB can achieve on that constructed election data. In the process, we find the range of vote-share, seat share pairs $(V, S)$ for which there is constructed election data with vote share $V$, seat share $S$, and $MM=0$, and see that the corresponding range for PB is the same set of $(V,S)$ pairs. We show how the set of such $(V,S)$ pairs allowing for $MM=0$ (and $PB=0$) changes when turnout in each district is allowed to be different.\n  Although the set of $(V,S)$ pairs for which there is election data with $MM=0$ is the same as the set of $(V,S)$ pairs for which there is election data with $PB=0$, the range of possible values for MM and PB on a fixed $(V, S)$ is different. Additionally, for a fixed constructed election outcome, the values of the Mean-Median Difference and Partisan Bias can theoretically be as large as 0.5. We show empirically that these two metric values can differ by as much as 0.33 in US congressional map data. We use both neutral ensemble analysis and the short-burst method to show that neither the Mean-Median Difference nor the Partisan Bias can reliably detect when a districting map has an extreme number of districts won by a particular party. Finally, we give additional empirical and logical arguments in an attempt to explain why other metrics are better at detecting when a districting map has an extreme number of districts won by a particular party."}, "https://arxiv.org/abs/2406.12374": {"title": "Problem-Solving in Language Model Networks", "link": "https://arxiv.org/abs/2406.12374", "description": "arXiv:2406.12374v1 Announce Type: cross \nAbstract: To improve the reasoning and question-answering capabilities of Large Language Models (LLMs), several multi-agent approaches have been introduced. While these methods enhance performance, the application of collective intelligence-based approaches to complex network structures and the dynamics of agent interactions remain underexplored. This work extends the concept of multi-agent debate to more general network topologies, measuring the question-answering accuracy, influence, consensus, and the effects of bias on the collective. The results show that random networks perform similarly to fully connected networks despite using significantly fewer tokens. Furthermore, a strong consensus among agents in correlates with correct answers, whereas divided responses typically indicate incorrect answers. Analysing the influence of the agents reveals a balance between self-reflection and interconnectedness; self-reflection aids when local interactions are incorrect, and local interactions aid when the agent itself is incorrect. Additionally, bias plays a strong role in system performance with correctly biased hub nodes boosting performance. These insights suggest that using random networks or scale-free networks with knowledgeable agents placed in central positions can enhance the overall performance of multi-agent systems."}, "https://arxiv.org/abs/2406.12412": {"title": "A Novel Algorithm for Community Detection in Networks using Rough Sets and Consensus Clustering", "link": "https://arxiv.org/abs/2406.12412", "description": "arXiv:2406.12412v1 Announce Type: cross \nAbstract: Complex networks, such as those in social, biological, and technological systems, often present challenges to the task of community detection. Our research introduces a novel rough clustering based consensus community framework (RC-CCD) for effective structure identification of network communities. The RC-CCD method employs rough set theory to handle uncertainties within data and utilizes a consensus clustering approach to aggregate multiple clustering results, enhancing the reliability and accuracy of community detection. This integration allows the RC-CCD to effectively manage overlapping communities, which are often present in complex networks.\n  This approach excels at detecting overlapping communities, offering a detailed and accurate representation of network structures. Comprehensive testing on benchmark networks generated by the Lancichinetti-Fortunato-Radicchi method showcased the strength and adaptability of the new proposal to varying node degrees and community sizes. Cross-comparisons of RC-CCD versus other well known detection algorithms outcomes highlighted its stability and adaptability."}, "https://arxiv.org/abs/2406.12444": {"title": "Who Checks the Checkers? Exploring Source Credibility in Twitter's Community Notes", "link": "https://arxiv.org/abs/2406.12444", "description": "arXiv:2406.12444v1 Announce Type: cross \nAbstract: In recent years, the proliferation of misinformation on social media platforms has become a significant concern. Initially designed for sharing information and fostering social connections, platforms like Twitter (now rebranded as X) have also unfortunately become conduits for spreading misinformation. To mitigate this, these platforms have implemented various mechanisms, including the recent suggestion to use crowd-sourced non-expert fact-checkers to enhance the scalability and efficiency of content vetting. An example of this is the introduction of Community Notes on Twitter.\n  While previous research has extensively explored various aspects of Twitter tweets, such as information diffusion, sentiment analytics and opinion summarization, there has been a limited focus on the specific feature of Twitter Community Notes, despite its potential role in crowd-sourced fact-checking. Prior research on Twitter Community Notes has involved empirical analysis of the feature's dataset and comparative studies that also include other methods like expert fact-checking. Distinguishing itself from prior works, our study covers a multi-faceted analysis of sources and audience perception within Community Notes. We find that the majority of cited sources are news outlets that are left-leaning and are of high factuality, pointing to a potential bias in the platform's community fact-checking. Left biased and low factuality sources validate tweets more, while Center sources are used more often to refute tweet content. Additionally, source factuality significantly influences public agreement and helpfulness of the notes, highlighting the effectiveness of the Community Notes Ranking algorithm. These findings showcase the impact and biases inherent in community-based fact-checking initiatives."}, "https://arxiv.org/abs/2406.12818": {"title": "Optimal Bailouts in Diversified Financial Networks", "link": "https://arxiv.org/abs/2406.12818", "description": "arXiv:2406.12818v1 Announce Type: cross \nAbstract: Widespread default involves substantial deadweight costs which could be countered by injecting capital into failing firms. Injections have positive spillovers that can trigger a repayment cascade. But which firms should a regulator bailout so as to minimize the total injection of capital while ensuring solvency of all firms? While the problem is, in general, NP-hard, for a wide range of networks that arise from a stochastic block model, we show that the optimal bailout can be implemented by a simple policy that targets firms based on their characteristics and position in the network. Specific examples of the setting include core-periphery networks."}, "https://arxiv.org/abs/2406.12835": {"title": "Influence Maximization via Graph Neural Bandits", "link": "https://arxiv.org/abs/2406.12835", "description": "arXiv:2406.12835v1 Announce Type: cross \nAbstract: We consider a ubiquitous scenario in the study of Influence Maximization (IM), in which there is limited knowledge about the topology of the diffusion network. We set the IM problem in a multi-round diffusion campaign, aiming to maximize the number of distinct users that are influenced. Leveraging the capability of bandit algorithms to effectively balance the objectives of exploration and exploitation, as well as the expressivity of neural networks, our study explores the application of neural bandit algorithms to the IM problem. We propose the framework IM-GNB (Influence Maximization with Graph Neural Bandits), where we provide an estimate of the users' probabilities of being influenced by influencers (also known as diffusion seeds). This initial estimate forms the basis for constructing both an exploitation graph and an exploration one. Subsequently, IM-GNB handles the exploration-exploitation tradeoff, by selecting seed nodes in real-time using Graph Convolutional Networks (GCN), in which the pre-estimated graphs are employed to refine the influencers' estimated rewards in each contextual setting. Through extensive experiments on two large real-world datasets, we demonstrate the effectiveness of IM-GNB compared with other baseline methods, significantly improving the spread outcome of such diffusion campaigns, when the underlying network is unknown."}, "https://arxiv.org/abs/2406.12841": {"title": "Demystifying Higher-Order Graph Neural Networks", "link": "https://arxiv.org/abs/2406.12841", "description": "arXiv:2406.12841v1 Announce Type: cross \nAbstract: Higher-order graph neural networks (HOGNNs) are an important class of GNN models that harness polyadic relations between vertices beyond plain edges. They have been used to eliminate issues such as over-smoothing or over-squashing, to significantly enhance the accuracy of GNN predictions, to improve the expressiveness of GNN architectures, and for numerous other goals. A plethora of HOGNN models have been introduced, and they come with diverse neural architectures, and even with different notions of what the \"higher-order\" means. This richness makes it very challenging to appropriately analyze and compare HOGNN models, and to decide in what scenario to use specific ones. To alleviate this, we first design an in-depth taxonomy and a blueprint for HOGNNs. This facilitates designing models that maximize performance. Then, we use our taxonomy to analyze and compare the available HOGNN models. The outcomes of our analysis are synthesized in a set of insights that help to select the most beneficial GNN model in a given scenario, and a comprehensive list of challenges and opportunities for further research into more powerful HOGNNs."}, "https://arxiv.org/abs/2309.15070": {"title": "Timeliness criticality in complex systems", "link": "https://arxiv.org/abs/2309.15070", "description": "arXiv:2309.15070v3 Announce Type: replace \nAbstract: In complex systems, external parameters often determine the phase in which the system operates, i.e., its macroscopic behavior. For nearly a century, statistical physics has extensively studied systems' transitions across phases, (universal) critical exponents, and related dynamical properties. Here we consider the functionality of systems, notably operations in socio-technical ones, production in economic ones and, more generally, any schedule-based system, where timing is of crucial importance. We introduce a stylized model of delay propagation on temporal networks, where the magnitude of delay-mitigating buffer acts as a control parameter. The model exhibits {\\it timeliness criticality}, a novel form of critical behavior. We characterize fluctuations near criticality, commonly referred to as ``avalanches'', and identify the corresponding critical exponents. The model exhibits timeliness criticality also when run on real-world temporal systems such as production networks. Additionally, we explore potential connections with the Mode-Coupling Theory of glasses, the depinning transition and the directed polymer problem."}, "https://arxiv.org/abs/2402.14177": {"title": "Investigating Human Values in Online Communities", "link": "https://arxiv.org/abs/2402.14177", "description": "arXiv:2402.14177v2 Announce Type: replace \nAbstract: Human values play a vital role as an analytical tool in social sciences, enabling the study of diverse dimensions within society as a whole and among individual communities. This paper addresses the limitations of traditional survey-based studies of human values by proposing a computational application of Schwartz's values framework to Reddit, a platform organized into distinct online communities. After ensuring the reliability of automated value extraction tools for Reddit content, we automatically annotate six million posts across 10,000 subreddits with Schwartz values. Our analysis unveils both previously recorded and novel insights into the values prevalent within various online communities. For instance, when examining subreddits with differing opinions on controversial topics, we discover higher universalism values in the Vegan subreddit compared to Carnivores. Additionally, our study of geographically specific subreddits highlights the correlation between traditional values and conservative U.S. states."}, "https://arxiv.org/abs/2402.11114": {"title": "Whose Emotions and Moral Sentiments Do Language Models Reflect?", "link": "https://arxiv.org/abs/2402.11114", "description": "arXiv:2402.11114v2 Announce Type: replace-cross \nAbstract: Language models (LMs) are known to represent the perspectives of some social groups better than others, which may impact their performance, especially on subjective tasks such as content moderation and hate speech detection. To explore how LMs represent different perspectives, existing research focused on positional alignment, i.e., how closely the models mimic the opinions and stances of different groups, e.g., liberals or conservatives. However, human communication also encompasses emotional and moral dimensions. We define the problem of affective alignment, which measures how LMs' emotional and moral tone represents those of different groups. By comparing the affect of responses generated by 36 LMs to the affect of Twitter messages, we observe significant misalignment of LMs with both ideological groups. This misalignment is larger than the partisan divide in the U.S. Even after steering the LMs towards specific ideological perspectives, the misalignment and liberal tendencies of the model persist, suggesting a systemic bias within LMs."}, "https://arxiv.org/abs/2406.12926": {"title": "Diffusion on assortative networks: from mean-field to agent-based, via Newman rewiring", "link": "https://arxiv.org/abs/2406.12926", "description": "arXiv:2406.12926v1 Announce Type: new \nAbstract: In mathematical models of epidemic diffusion on networks based upon systems of differential equations, it is convenient to use the Heterogeneous Mean Field approximation (HMF) because it allows to write one single equation for all nodes of a certain degree $k$, each one virtually present with a probability given by the degree distribution $P(k)$. The two-point correlations between nodes are defined by the matrix $P(h|k)$, which can typically be uncorrelated, assortative or disassortative. After a brief review of this approach and of the results obtained within this approximation for the Bass diffusion model, in this work we look at the transition from the HMF approximation to the description of diffusion through the dynamics of single nodes, first still with differential equations, and then with agent-based models. For this purpose, one needs a method for the explicit construction of ensembles of random networks or scale-free networks having a pre-defined degree distribution (Configuration Model) and a method for rewiring these networks towards some desired or \"target\" degree correlations (Newman Rewiring). We describe Python-NetworkX codes implemented for the two methods in our recent work and compare some of the results obtained in the HMF approximation with the new results obtained with statistical ensembles of real networks, including the case of signed networks."}, "https://arxiv.org/abs/2406.12951": {"title": "Reviewing climate change attribution in UK natural hazards and their impacts", "link": "https://arxiv.org/abs/2406.12951", "description": "arXiv:2406.12951v1 Announce Type: new \nAbstract: The field of Detection and Attribution is rapidly moving beyond weather and climate, and towards incorporating hazards and their impacts on natural and human systems. Here, we review the comprehensive literature base relevant for the UK ahead of the next Climate Change Risk Assessment. The current literature highlights a detectable and non-trivial influence of climate change in many UK impact sectors already - notably health, agriculture, and infrastructure. We found that heatwaves were the most studied hazard overall, with a unanimous consensus on a strong attributable signal of human-induced climate change in their increased frequency and intensity over the last century. The most notable gap identified overall was in attributing climate-related impacts to human influence, with a few impact studies for only a handful of the hazards assessed. Furthermore, just under half of the 29 hazards were not found to have any UK-relevant attribution studies, with most of the remainder having three or fewer. This review highlights requirements for and opportunities to develop attribution scicnce to meet the needs of the UK. Diversifying hazards and impacts studied, in conjunction with the techniques and approaches used, will undoubtedly benefit the community."}, "https://arxiv.org/abs/2406.13016": {"title": "Verhulst Equation and the Universal Pattern for the Global Population Growth", "link": "https://arxiv.org/abs/2406.13016", "description": "arXiv:2406.13016v1 Announce Type: new \nAbstract: The global population growth from 10,000 BC to 2023 is discussed within the Verhulst scaling equation and its extensions framework. The analysis focuses on per the capita global population rate coefficient Gp(P)=[dP(t)/P(t)]/dt=dlnP(t)/d, which reveals two linear domains: from 700CE till 1966 and from 1966 till 2023. Such a pattern can be considered a universal reference for reliable scaling relations describing P(t) changes. It is also the distortions-sensitive test indicating domains of their applicability and yielding optimal values of parameters. For models recalling the Verhulst equation, a single pair of growth rate and system capacity coefficients (r,s) should describe global population rise in the mentioned periods. However, the Verhulst equation with such effective parameters does not describe P(t) changes. Notable is the new way of data preparation, based on collecting data from various sources and their numerical filtering to obtain a smooth set of optimal values enabling the derivative-based analysis. The analysis reveals links between P(t) changes and some historical and pre-historical references influencing the global scale."}, "https://arxiv.org/abs/2406.13075": {"title": "Exact Community Recovery (under Side Information): Optimality of Spectral Algorithms", "link": "https://arxiv.org/abs/2406.13075", "description": "arXiv:2406.13075v1 Announce Type: new \nAbstract: In this paper, we study the problem of exact community recovery in general, two-community block models considering both Bernoulli and Gaussian matrix models, capturing the Stochastic Block Model, submatrix localization, and $\\mathbb{Z}_2$-synchronization as special cases. We also study the settings where $side$ $information$ about community assignment labels is available, modeled as passing the true labels through a noisy channel: either the binary erasure channel (where some community labels are known while others are erased) or the binary symmetric channel (where some labels are flipped). We provide a unified analysis of the effect of side information on the information-theoretic limits of exact recovery, generalizing prior works and extending to new settings. Additionally, we design a simple but optimal spectral algorithm that incorporates side information (when present) along with the eigenvectors of the matrix observation. Using the powerful tool of entrywise eigenvector analysis [Abbe, Fan, Wang, Zhong 2020], we show that our spectral algorithm can mimic the so called $genie$-$aided$ $estimators$, where the $i^{\\mathrm{th}}$ genie-aided estimator optimally computes the estimate of the $i^{\\mathrm{th}}$ label, when all remaining labels are revealed by a genie. This perspective provides a unified understanding of the optimality of spectral algorithms for various exact recovery problems in a recent line of work."}, "https://arxiv.org/abs/2406.13299": {"title": "Empirical Evaluation of Integrated Trust Mechanism to Improve Trust in E-commerce Services", "link": "https://arxiv.org/abs/2406.13299", "description": "arXiv:2406.13299v1 Announce Type: new \nAbstract: There are mostly two approaches to tackle trust management worldwide Strong and crisp and Soft and Social. We analyze the impact of integrated trust mechanism in three different e-commerce services. The trust aspect is a dormant element between potential users and being developed expert or internet systems. We support our integration by preside over an experiment in controlled laboratory environment. The model selected for the experiment is a composite of policy and reputation based trust mechanisms and widely acknowledged in e-commerce industry. The integration between policy and trust mechanism was accomplished through mapping process, weakness of one brought to a close with the strength of other. Furthermore, experiment has been supervised to validate the effectiveness of implementation by segregating both integrated and traditional trust mechanisms in learning system"}, "https://arxiv.org/abs/2406.13499": {"title": "GraphMU: Repairing Robustness of Graph Neural Networks via Machine Unlearning", "link": "https://arxiv.org/abs/2406.13499", "description": "arXiv:2406.13499v1 Announce Type: new \nAbstract: Graph Neural Networks (GNNs) have demonstrated significant application potential in various fields. However, GNNs are still vulnerable to adversarial attacks. Numerous adversarial defense methods on GNNs are proposed to address the problem of adversarial attacks. However, these methods can only serve as a defense before poisoning, but cannot repair poisoned GNN. Therefore, there is an urgent need for a method to repair poisoned GNN. In this paper, we address this gap by introducing the novel concept of model repair for GNNs. We propose a repair framework, Repairing Robustness of Graph Neural Networks via Machine Unlearning (GraphMU), which aims to fine-tune poisoned GNN to forget adversarial samples without the need for complete retraining. We also introduce a unlearning validation method to ensure that our approach effectively forget specified poisoned data. To evaluate the effectiveness of GraphMU, we explore three fine-tuned subgraph construction scenarios based on the available perturbation information: (i) Known Perturbation Ratios, (ii) Known Complete Knowledge of Perturbations, and (iii) Unknown any Knowledge of Perturbations. Our extensive experiments, conducted across four citation datasets and four adversarial attack scenarios, demonstrate that GraphMU can effectively restore the performance of poisoned GNN."}, "https://arxiv.org/abs/2406.13734": {"title": "A Unified Core Structure in Multiplex Networks: From Finding the Densest Subgraph to Modeling User Engagement", "link": "https://arxiv.org/abs/2406.13734", "description": "arXiv:2406.13734v1 Announce Type: new \nAbstract: In many complex systems, the interactions between objects span multiple aspects. Multiplex networks are accurate paradigms to model such systems, where each edge is associated with a type. A key graph mining primitive is extracting dense subgraphs, and this has led to interesting notions such as K-cores, known as building blocks of complex networks. Despite recent attempts to extend the notion of core to multiplex networks, existing studies suffer from a subset of the following limitations: They 1) force all nodes to exhibit their high degree in the same set of relation types while in multiplex networks some connection types can be noisy for some nodes, 2) either require high computational cost or miss the complex information of multiplex networks, and 3) assume the same importance for all relation types. We introduce S-core, a novel and unifying family of dense structures in multiplex networks that uses a function S(.) to summarize the degree vector of each node. We then discuss how one can choose a proper S(.) from the data. To demonstrate the usefulness of S-cores, we focus on finding the densest subgraph as well as modeling user engagement in multiplex networks. We present a new density measure in multiplex networks and discuss its advantages over existing density measures. We show that the problem of finding the densest subgraph in multiplex networks is NP-hard and design an efficient approximation algorithm based on S-cores. Finally, we present a new mathematical model of user engagement in the presence of different relation types. Our experiments shows the efficiency and effectiveness of our algorithms and supports the proposed mathematical model of user engagement."}, "https://arxiv.org/abs/2406.13789": {"title": "Death, Taxes, and Inequality", "link": "https://arxiv.org/abs/2406.13789", "description": "arXiv:2406.13789v1 Announce Type: new \nAbstract: Income inequalities and redistribution policies are modeled with a minimal, endogenous model of a simple foraging economy. The model is scaled to match human lifespans and overall death rates. Stochastic income distributions from the model are compared to empirical data from actual economies. Empirical data are fit to implied distributions providing necessary resolution for comparison. The impacts of redistribution policies on total wealth, income distributions, and inequality are shown to be similar for the empirical data and the model. These comparisons enable detailed determinations of population welfare beyond what is possible with total wealth and inequality metrics. Estate taxes in the model appear quite effective in reducing inequality without reducing total wealth. Significant income inequality emerges for the model for a population of equally capable individuals presented with equal opportunities. Stochastic population instability at both the high and low ends of infertility are considered."}, "https://arxiv.org/abs/2406.13816": {"title": "The Dangerous Allure of Low Fertility", "link": "https://arxiv.org/abs/2406.13816", "description": "arXiv:2406.13816v1 Announce Type: new \nAbstract: Stochastic population and wealth trajectories for societies as functions of fertility are modeled with a minimal, endogenous model of a simple foraging economy. The model is scaled to match human lifespans and overall death rates. Stochastic population instability at both the high and low ends of fertility are considered. Lower population levels, caused by low fertility, generate concerns on economic growth, military security, and international political power; while also seen by some as reducing ecological and environmental damage. The model shows that increasingly low fertility leads to both higher wealth and lower population levels. As society is encouraged by increasing per capita wealth to continue to decrease fertility, dangerous population regimes are reached where stochastic extinction becomes more and more likely."}, "https://arxiv.org/abs/2406.14460": {"title": "Podcast Outcasts: Understanding Rumble's Podcast Dynamics", "link": "https://arxiv.org/abs/2406.14460", "description": "arXiv:2406.14460v1 Announce Type: new \nAbstract: Podcasting on Rumble, an alternative video-sharing platform, attracts controversial figures known for spreading divisive and often misleading content, which sharply contrasts with YouTube's more regulated environment. Motivated by the growing impact of podcasts on political discourse, as seen with figures like Joe Rogan and Andrew Tate, this paper explores the political biases and content strategies used by these platforms. In this paper, we conduct a comprehensive analysis of over 13K podcast videos from both YouTube and Rumble, focusing on their political content and the dynamics of their audiences. Using advanced speech-to-text transcription, topic modeling, and contrastive learning techniques, we explore three critical aspects: the presence of political bias in podcast channels, the nature of content that drives podcast views, and the usage of visual elements in these podcasts. Our findings reveal a distinct right-wing orientation in Rumble's podcasts, contrasting with YouTube's more diverse and apolitical content."}, "https://arxiv.org/abs/2406.14522": {"title": "Learning thresholds lead to stable language coexistence", "link": "https://arxiv.org/abs/2406.14522", "description": "arXiv:2406.14522v1 Announce Type: new \nAbstract: We introduce a language competition model that incorporates the effects of memory and learning on the language shift dynamics, using the Abrams-Strogatz model as a starting point. On a coarse grained time scale, the effects of memory and learning can be expressed as thresholds on the speakers fractions. In its simplest form, the resulting model is exactly solvable. Besides the consensus on one of the two languages, the model describes additional equilibrium states that are not present in the Abrams-Strogatz model: a stable coexistence of the two languages, if both thresholds are low enough, so that the language shift processes in the two opposite directions compensate each other, and a frozen state coinciding with the initial state, when both thresholds are too high for any language shift to take place. We show numerically that these results are preserved for threshold functions of a more general shape."}, "https://arxiv.org/abs/2406.12892": {"title": "Synthesis and Characterization of NiCoMn MOFs for Wastewater Treatment", "link": "https://arxiv.org/abs/2406.12892", "description": "arXiv:2406.12892v1 Announce Type: cross \nAbstract: Water pollution has become a global problem. Sources of wastewater majorly include industrial and commercial sectors. To cater to the exponential increase in clean water, efficient technologies are needed to treat wastewater. Several techniques such as redox reactions, membrane filtrations, mechanical processes, chemical treatment and adsorption techniques have been employed. However, their cost and effectiveness is still a major problem. In this study, we employed an effective wastewater treatment technique by synthesizing NiCoMn MOFs using a simple hydrothermal technique and characterized the properties using XRD and SEM for their possible characteristics. XRD analysis confirmed the successful synthesis of NiCoMn MOFs. Sufficient information regarding the surface morphology and topology was given by the SEM analysis which proved a nanoporous structure with high surface area effective for adsorption and oxidative catalysis of contaminants in wastewater. Moreover, a high electrostatic attraction between the MOFs was observed which could attract oppositely charged contaminants. The results showed a high potential for the synthesized NiCoMn MOFs for wastewater treatment applications."}, "https://arxiv.org/abs/2406.13201": {"title": "Toward Structure Fairness in Dynamic Graph Embedding: A Trend-aware Dual Debiasing Approach", "link": "https://arxiv.org/abs/2406.13201", "description": "arXiv:2406.13201v1 Announce Type: cross \nAbstract: Recent studies successfully learned static graph embeddings that are structurally fair by preventing the effectiveness disparity of high- and low-degree vertex groups in downstream graph mining tasks. However, achieving structure fairness in dynamic graph embedding remains an open problem. Neglecting degree changes in dynamic graphs will significantly impair embedding effectiveness without notably improving structure fairness. This is because the embedding performance of high-degree and low-to-high-degree vertices will significantly drop close to the generally poorer embedding performance of most slightly changed vertices in the long-tail part of the power-law distribution. We first identify biased structural evolutions in a dynamic graph based on the evolving trend of vertex degree and then propose FairDGE, the first structurally Fair Dynamic Graph Embedding algorithm. FairDGE learns biased structural evolutions by jointly embedding the connection changes among vertices and the long-short-term evolutionary trend of vertex degrees. Furthermore, a novel dual debiasing approach is devised to encode fair embeddings contrastively, customizing debiasing strategies for different biased structural evolutions. This innovative debiasing strategy breaks the effectiveness bottleneck of embeddings without notable fairness loss. Extensive experiments demonstrate that FairDGE achieves simultaneous improvement in the effectiveness and fairness of embeddings."}, "https://arxiv.org/abs/2406.13303": {"title": "Integration of Policy and Reputation based Trust Mechanisms in e-Commerce Industry", "link": "https://arxiv.org/abs/2406.13303", "description": "arXiv:2406.13303v1 Announce Type: cross \nAbstract: The e-commerce systems are being tackled from commerce behavior and internet technologies. Therefore, trust aspect between buyer-seller transactions is a potential element which needs to be addressed in competitive e-commerce industry. The e-commerce industry is currently handling two different trust approaches. First approach consists on centralized mechanism where digital credentials/set of rules assembled, called Policy based trust mechanisms . Second approach consists on decentralized trust mechanisms where reputation, points assembled and shared, called Reputation based trust mechanisms. The difference between reputation and policy based trust mechanism will be analyzed and recommendations would be proposed to increase trust between buyer and seller in e-commerce industry. The integration of trust mechanism is proposed through mapping process, strength of one mechanism with the weakness of other. The proposed model for integrated mechanism will be presented and illustrated how the proposed model will be used in real world e-commerce industry."}, "https://arxiv.org/abs/2406.13369": {"title": "Effective Edge-wise Representation Learning in Edge-Attributed Bipartite Graphs", "link": "https://arxiv.org/abs/2406.13369", "description": "arXiv:2406.13369v1 Announce Type: cross \nAbstract: Graph representation learning (GRL) is to encode graph elements into informative vector representations, which can be used in downstream tasks for analyzing graph-structured data and has seen extensive applications in various domains. However, the majority of extant studies on GRL are geared towards generating node representations, which cannot be readily employed to perform edge-based analytics tasks in edge-attributed bipartite graphs (EABGs) that pervade the real world, e.g., spam review detection in customer-product reviews and identifying fraudulent transactions in user-merchant networks. Compared to node-wise GRL, learning edge representations (ERL) on such graphs is challenging due to the need to incorporate the structure and attribute semantics from the perspective of edges while considering the separate influence of two heterogeneous node sets U and V in bipartite graphs. To our knowledge, despite its importance, limited research has been devoted to this frontier, and existing workarounds all suffer from sub-par results.\n  Motivated by this, this paper designs EAGLE, an effective ERL method for EABGs. Building on an in-depth and rigorous theoretical analysis, we propose the factorized feature propagation (FFP) scheme for edge representations with adequate incorporation of long-range dependencies of edges/features without incurring tremendous computation overheads. We further ameliorate FFP as a dual-view FFP by taking into account the influences from nodes in U and V severally in ERL. Extensive experiments on 5 real datasets showcase the effectiveness of the proposed EAGLE models in semi-supervised edge classification tasks. In particular, EAGLE can attain a considerable gain of at most 38.11% in AP and 1.86% in AUC when compared to the best baselines."}, "https://arxiv.org/abs/2406.13452": {"title": "Quantum Networks: from Multipartite Entanglement to Hypergraph Immersion", "link": "https://arxiv.org/abs/2406.13452", "description": "arXiv:2406.13452v1 Announce Type: cross \nAbstract: Multipartite entanglement, a higher-order interaction unique to quantum information, offers various advantages over bipartite entanglement in quantum network (QN) applications. Establishing multipartite entanglement across remote parties in QN requires entanglement routing, which irreversibly transforms the QN topology at the cost of existing entanglement links. Here, we address the question of whether a QN can be topologically transformed into another via entanglement routing. Our key result is an exact mapping from multipartite entanglement routing to Nash-Williams's graph immersion problem, extended to hypergraphs. This generalized hypergraph immersion problem introduces a partial order between QN topologies, permitting certain topological transformations while precluding others, offering discerning insights into the design and manipulation of higher-order network topologies in QNs."}, "https://arxiv.org/abs/2406.13605": {"title": "Nicer Than Humans: How do Large Language Models Behave in the Prisoner's Dilemma?", "link": "https://arxiv.org/abs/2406.13605", "description": "arXiv:2406.13605v1 Announce Type: cross \nAbstract: The behavior of Large Language Models (LLMs) as artificial social agents is largely unexplored, and we still lack extensive evidence of how these agents react to simple social stimuli. Testing the behavior of AI agents in classic Game Theory experiments provides a promising theoretical framework for evaluating the norms and values of these agents in archetypal social situations. In this work, we investigate the cooperative behavior of Llama2 when playing the Iterated Prisoner's Dilemma against random adversaries displaying various levels of hostility. We introduce a systematic methodology to evaluate an LLM's comprehension of the game's rules and its capability to parse historical gameplay logs for decision-making. We conducted simulations of games lasting for 100 rounds, and analyzed the LLM's decisions in terms of dimensions defined in behavioral economics literature. We find that Llama2 tends not to initiate defection but it adopts a cautious approach towards cooperation, sharply shifting towards a behavior that is both forgiving and non-retaliatory only when the opponent reduces its rate of defection below 30%. In comparison to prior research on human participants, Llama2 exhibits a greater inclination towards cooperative behavior. Our systematic approach to the study of LLMs in game theoretical scenarios is a step towards using these simulations to inform practices of LLM auditing and alignment."}, "https://arxiv.org/abs/2406.13920": {"title": "Explainable AI Security: Exploring Robustness of Graph Neural Networks to Adversarial Attacks", "link": "https://arxiv.org/abs/2406.13920", "description": "arXiv:2406.13920v1 Announce Type: cross \nAbstract: Graph neural networks (GNNs) have achieved tremendous success, but recent studies have shown that GNNs are vulnerable to adversarial attacks, which significantly hinders their use in safety-critical scenarios. Therefore, the design of robust GNNs has attracted increasing attention. However, existing research has mainly been conducted via experimental trial and error, and thus far, there remains a lack of a comprehensive understanding of the vulnerability of GNNs. To address this limitation, we systematically investigate the adversarial robustness of GNNs by considering graph data patterns, model-specific factors, and the transferability of adversarial examples. Through extensive experiments, a set of principled guidelines is obtained for improving the adversarial robustness of GNNs, for example: (i) rather than highly regular graphs, the training graph data with diverse structural patterns is crucial for model robustness, which is consistent with the concept of adversarial training; (ii) the large model capacity of GNNs with sufficient training data has a positive effect on model robustness, and only a small percentage of neurons in GNNs are affected by adversarial attacks; (iii) adversarial transfer is not symmetric and the adversarial examples produced by the small-capacity model have stronger adversarial transferability. This work illuminates the vulnerabilities of GNNs and opens many promising avenues for designing robust GNNs."}, "https://arxiv.org/abs/2406.14290": {"title": "Examining the Implications of Deepfakes for Election Integrity", "link": "https://arxiv.org/abs/2406.14290", "description": "arXiv:2406.14290v1 Announce Type: cross \nAbstract: It is becoming cheaper to launch disinformation operations at scale using AI-generated content, in particular 'deepfake' technology. We have observed instances of deepfakes in political campaigns, where generated content is employed to both bolster the credibility of certain narratives (reinforcing outcomes) and manipulate public perception to the detriment of targeted candidates or causes (adversarial outcomes). We discuss the threats from deepfakes in politics, highlight model specifications underlying different types of deepfake generation methods, and contribute an accessible evaluation of the efficacy of existing detection methods. We provide this as a summary for lawmakers and civil society actors to understand how the technology may be applied in light of existing policies regulating its use. We highlight the limitations of existing detection mechanisms and discuss the areas where policies and regulations are required to address the challenges of deepfakes."}, "https://arxiv.org/abs/2303.01934": {"title": "CONTAIN: A Community-based Algorithm for Network Immunization", "link": "https://arxiv.org/abs/2303.01934", "description": "arXiv:2303.01934v2 Announce Type: replace \nAbstract: Network immunization is an automated task in the field of network analysis that involves protecting a network (modeled as a graph) from being infected by an undesired arbitrary diffusion. In this article, we consider the spread of harmful content in social networks, and we propose CONTAIN, a novel COmmuNiTy-based Algorithm for network ImmuNization. Our solution uses the network information to (1) detect harmful content spreaders, and (2) generate partitions and rank them for immunization using the subgraphs induced by each spreader, i.e., employing CONTAIN. The experimental results obtained on real-world datasets show that CONTAIN outperforms state-of-the-art solutions, i.e., NetShield and SparseShield, by immunizing the network in fewer iterations, thus, converging significantly faster than the state-of-the-art algorithms. We also compared our solution in terms of scalability with the state-of-the-art tree-based mitigation algorithm MCWDST, as well as with NetShield and SparseShield. We can conclude that our solution outperforms MCWDST and NetShield."}, "https://arxiv.org/abs/2307.13520": {"title": "Using power system modelling outputs to identify weather-induced extreme events in highly renewable systems", "link": "https://arxiv.org/abs/2307.13520", "description": "arXiv:2307.13520v2 Announce Type: replace \nAbstract: In highly renewable power systems the increased weather dependence can result in new resilience challenges, such as renewable energy droughts, or a lack of sufficient renewable generation at times of high demand. The weather conditions responsible for these challenges have been well-studied in the literature. However, in reality multi-day resilience challenges are triggered by complex interactions between high demand, low renewable availability, electricity transmission constraints and storage dynamics. We show these challenges cannot be rigorously understood from an exclusively power systems, or meteorological, perspective. We propose a new method that uses electricity shadow prices - obtained by a European power system model based on 40 years of reanalysis data - to identify the most difficult periods driving system investments. Such difficult periods are driven by large-scale weather conditions such as low wind and cold temperature periods of various lengths associated with stationary high pressure over Europe. However, purely meteorological approaches fail to identify which events lead to the largest system stress over the multi-decadal study period due to the influence of subtle transmission bottlenecks and storage issues across multiple regions. These extreme events also do not relate strongly to traditional weather patterns (such as Euro-Atlantic weather regimes or the North Atlantic Oscillation index). We therefore compile a new set of weather patterns to define energy system stress events which include the impacts of electricity storage and large-scale interconnection. Without interdisciplinary studies combining state-of-the-art energy meteorology and modelling, further strive for adequate renewable power systems will be hampered."}, "https://arxiv.org/abs/2311.06436": {"title": "Augmented Degree Correction for Bipartite Networks with Applications to Recommender Systems", "link": "https://arxiv.org/abs/2311.06436", "description": "arXiv:2311.06436v2 Announce Type: replace \nAbstract: In recommender systems, users rate items, and are subsequently served other product recommendations based on these ratings. Even though users usually rate a tiny percentage of the available items, the system tries to estimate unobserved preferences by finding similarities across users and across items. In this work, we treat the observed ratings data as partially observed, dense, weighted, bipartite networks. For a class of systems without outside information, we adapt an approach developed for dense, weighted networks to account for unobserved edges and the bipartite nature of the problem. This approach allows for community structure, and for local estimation of flexible patterns of ratings across different pairs of communities. We compare the performance of our proposed approach to existing methods on a simulated data set, as well as on a data set of joke ratings, examining model performance in both cases at differing levels of sparsity."}, "https://arxiv.org/abs/2403.10277": {"title": "Delayed interactions in the noisy voter model through the periodic polling mechanism", "link": "https://arxiv.org/abs/2403.10277", "description": "arXiv:2403.10277v3 Announce Type: replace \nAbstract: We investigate the effects of delayed interactions on the stationary distribution of the noisy voter model. We assume that the delayed interactions occur through the periodic polling mechanism and replace the original instantaneous two-agent interactions. In our analysis, we require that the polling period aligns with the delay in announcing poll outcomes. As expected, when the polling period is relatively short, the model with delayed interactions is almost equivalent to the original model. As the polling period increases, oscillatory behavior emerges, but the model with delayed interactions still converges to stationary distribution. The stationary distribution resembles a Beta-binomial distribution, with its shape parameters scaling with the polling period. The observed scaling behavior is non-monotonic. Namely, the shape parameters peak at some intermediate polling period."}, "https://arxiv.org/abs/2311.09086": {"title": "The Uli Dataset: An Exercise in Experience Led Annotation of oGBV", "link": "https://arxiv.org/abs/2311.09086", "description": "arXiv:2311.09086v2 Announce Type: replace-cross \nAbstract: Online gender based violence has grown concomitantly with adoption of the internet and social media. Its effects are worse in the Global majority where many users use social media in languages other than English. The scale and volume of conversations on the internet has necessitated the need for automated detection of hate speech, and more specifically gendered abuse. There is, however, a lack of language specific and contextual data to build such automated tools. In this paper we present a dataset on gendered abuse in three languages- Hindi, Tamil and Indian English. The dataset comprises of tweets annotated along three questions pertaining to the experience of gender abuse, by experts who identify as women or a member of the LGBTQIA community in South Asia. Through this dataset we demonstrate a participatory approach to creating datasets that drive AI systems."}, "https://arxiv.org/abs/2406.14681": {"title": "Intercity Connectivity and Innovation", "link": "https://arxiv.org/abs/2406.14681", "description": "arXiv:2406.14681v1 Announce Type: new \nAbstract: Urban outputs, from economy to innovation, are known to grow as a power of a city's population. But, since large cities tend to be central in transportation and communication networks, the effects attributed to city size may be confounded with those of intercity connectivity. Here, we map intercity networks for the world's two largest economies (the United States and China) to explore whether a city's position in the networks of communication, human mobility, and scientific collaboration explains variance in a city's patenting activity that is unaccounted for by its population. We find evidence that models incorporating intercity connectivity outperform population-based models and exhibit stronger predictive power for patenting activity, particularly for technologies of more recent vintage (which we expect to be more complex or sophisticated). The effects of intercity connectivity are more robust in China, even after controlling for population, GDP, and education, but not in the United States once adjusted for GDP and education. This divergence suggests distinct urban network dynamics driving innovation in these regions. In China, models with social media and mobility networks explain more heterogeneity in the scaling of innovation, whereas in the United States, scientific collaboration plays a more significant role. These findings support the significance of a city's position within the intercity network in shaping its success in innovative activities."}, "https://arxiv.org/abs/2406.14692": {"title": "A Review of Spatial Network Insights and Methods in the Context of Planning: Applications, Challenges, and Opportunities", "link": "https://arxiv.org/abs/2406.14692", "description": "arXiv:2406.14692v1 Announce Type: new \nAbstract: With the rise of geospatial big data, new narratives of cities based on spatial networks and flows have replaced the traditional focus on locations. While plenty of research have empirically analyzed network structures, there lacks a state-of-the-art synthesis of applicable insights and methods of spatial networks in the planning context. In this chapter, we reviewed the theories, concepts, methods, and applications of spatial network analysis in cities and their insights for planners from four areas of concern: spatial structures, urban infrastructure optimizations, indications of economic wealth, social capital, and residential mobility, and public health control (especially COVID-19). We also outlined four challenges that planners face when taking the planning knowledge from spatial networks to actions: data openness and privacy, linkage to direct policy implications, lack of civic engagement, and the difficulty to visualize and integrate with GIS. Finally, we envisioned how spatial networks can be integrated into a collaborative planning framework."}, "https://arxiv.org/abs/2406.14698": {"title": "Generating geographically and economically realistic large-scale synthetic contact networks: A general method using publicly available data", "link": "https://arxiv.org/abs/2406.14698", "description": "arXiv:2406.14698v1 Announce Type: new \nAbstract: Synthetic contact networks are useful for modeling epidemic spread and social transmission, but data to infer realistic contact patterns that take account of assortative connections at the geographic and economic levels is limited. We developed a method to generate synthetic contact networks for any region of the United States based on publicly available data. First, we generate a synthetic population of individuals within households from US census data using combinatorial optimization. Then, individuals are assigned to workplaces and schools using commute data, employment statistics, and school enrollment data. The resulting population is then connected into a realistic contact network using graph generation algorithms. We test the method on two census regions and show that the synthetic populations accurately reflect the source data. We further show that the contact networks have distinct properties compared to networks generated without a synthetic population, and that those differences affect the rate of disease transmission in an epidemiological simulation. We provide open-source software to generate a synthetic population and contact network for any area within the US."}, "https://arxiv.org/abs/2406.14751": {"title": "Complex network community discovery using fast local move iterated greedy algorithm", "link": "https://arxiv.org/abs/2406.14751", "description": "arXiv:2406.14751v1 Announce Type: new \nAbstract: Examining the community structures within intricate networks is crucial for comprehending their intrinsic dynamics and functionality. The paper presents the Fast Local Move Iterated Greedy (FLMIG) algorithm, a novel method designed to effectively identify community structures in intricate networks. The FLMIG algorithm improves the modularity optimization process by including a rapid local move heuristic and an iterated greedy mechanism that switches between destructive and constructive phases to strengthen the community partitions. The main innovation is the integration of random neighbor moves with an enhanced Prune Louvain algorithm, which guarantees fast convergence while maintaining the connection of the identified communities. The results of our comprehensive studies, conducted on both synthetic and and real-world networks, clearly show that FLMIG surpasses existing cutting-edge techniques in terms of both accuracy and computing efficiency. This algorithm not only provides a strong tool for identifying communities, but also makes a valuable contribution to the broader field of network analysis by offering a method that can effectively handle large-scale and dynamically evolving networks."}, "https://arxiv.org/abs/2406.14913": {"title": "Cooperative bots exhibit nuanced effects on cooperation across strategic frameworks", "link": "https://arxiv.org/abs/2406.14913", "description": "arXiv:2406.14913v1 Announce Type: new \nAbstract: The positive impact of cooperative bots on cooperation within evolutionary game theory is well documented; however, existing studies have predominantly used discrete strategic frameworks, focusing on deterministic actions with a fixed probability of one. This paper extends the investigation to continuous and mixed strategic approaches. Continuous strategies employ intermediate probabilities to convey varying degrees of cooperation and focus on expected payoffs. In contrast, mixed strategies calculate immediate payoffs from actions chosen at a given moment within these probabilities. Using the prisoner's dilemma game, this study examines the effects of cooperative bots on human cooperation within hybrid populations of human players and simple bots, across both well-mixed and structured populations. Our findings reveal that cooperative bots significantly enhance cooperation in both population types across these strategic approaches under weak imitation scenarios, where players are less concerned with material gains. However, under strong imitation scenarios, while cooperative bots do not alter the defective equilibrium in well-mixed populations, they have varied impacts in structured populations across these strategic approaches. Specifically, they disrupt cooperation under discrete and continuous strategies but facilitate it under mixed strategies. These results highlight the nuanced effects of cooperative bots within different strategic frameworks and underscore the need for careful deployment, as their effectiveness is highly sensitive to how humans update their actions and their chosen strategic approach."}, "https://arxiv.org/abs/2406.14922": {"title": "Social learning with complex contagion", "link": "https://arxiv.org/abs/2406.14922", "description": "arXiv:2406.14922v1 Announce Type: new \nAbstract: We introduce a mathematical model that combines the concepts of complex contagion with payoff-biased imitation, to describe how social behaviors spread through a population. Traditional models of social learning by imitation are based on simple contagion -- where an individual may imitate a more successful neighbor following a single interaction. Our framework generalizes this process to incorporate complex contagion, which requires multiple exposures before an individual considers adopting a different behavior. We formulate this as a discrete time and state stochastic process in a finite population, and we derive its continuum limit as an ordinary differential equation that generalizes the replicator equation, the most widely used dynamical model in evolutionary game theory. When applied to linear frequency-dependent games, our social learning with complex contagion produces qualitatively different outcomes than traditional imitation dynamics: it can shift the Prisoner's Dilemma from a unique all-defector equilibrium to either a stable mixture of cooperators and defectors in the population, or a bistable system; it changes the Snowdrift game from a single to a bistable equilibrium; and it can alter the Coordination game from bistability at the boundaries to two internal equilibria. The long-term outcome depends on the balance between the complexity of the contagion process and the strength of selection that biases imitation towards more successful types. Our analysis intercalates the fields of evolutionary game theory with complex contagions, and it provides a synthetic framework that describes more realistic forms of behavioral change in social systems."}, "https://arxiv.org/abs/2406.15185": {"title": "Percolation transition of k-frequent destinations network for urban mobility", "link": "https://arxiv.org/abs/2406.15185", "description": "arXiv:2406.15185v1 Announce Type: new \nAbstract: Urban spatial interactions are a complex aggregation of routine visits and random explorations by individuals. The inherent uncertainty of these random visitations poses significant challenges to understanding urban structures and socioeconomic developments. To capture the core dynamics of urban interaction networks, we analyze the percolation structure of the $k$-most frequented destinations of intracity place-to-place flows from mobile phone data of eight major U.S. cities at a Census Block Group (CBG) level. Our study reveals a consistent percolation transition at $k^* = 130$, a critical threshold for the number of frequently visited destinations necessary to maintain a cohesive urban network. This percolation threshold proves remarkably consistent across diverse urban configurations, sizes, and geographical settings over a 48-month study period, and can largely be interpreted as the joint effect of the emergence of hubness and the level of mixing of residents. Furthermore, we examine the socioeconomic profiles of residents from different origin areas categorized by the fulfillment level of $k^*=130$ principal destinations, revealing a pronounced distinction in the origins' socioeconomic advantages. These insights offer a nuanced understanding of how urban spaces are interconnected and the determinants of travel behavior. Our findings contribute to a deeper comprehension of the structural dynamics that govern urban spatial interactions."}, "https://arxiv.org/abs/2406.14772": {"title": "Consistent community detection in multi-layer networks with heterogeneous differential privacy", "link": "https://arxiv.org/abs/2406.14772", "description": "arXiv:2406.14772v1 Announce Type: cross \nAbstract: As network data has become increasingly prevalent, a substantial amount of attention has been paid to the privacy issue in publishing network data. One of the critical challenges for data publishers is to preserve the topological structures of the original network while protecting sensitive information. In this paper, we propose a personalized edge flipping mechanism that allows data publishers to protect edge information based on each node's privacy preference. It can achieve differential privacy while preserving the community structure under the multi-layer degree-corrected stochastic block model after appropriately debiasing, and thus consistent community detection in the privatized multi-layer networks is achievable. Theoretically, we establish the consistency of community detection in the privatized multi-layer network and show that better privacy protection of edges can be obtained for a proportion of nodes while allowing other nodes to give up their privacy. Furthermore, the advantage of the proposed personalized edge-flipping mechanism is also supported by its numerical performance on various synthetic networks and a real-life multi-layer network."}, "https://arxiv.org/abs/2406.14894": {"title": "Talking the Talk Does Not Entail Walking the Walk: On the Limits of Large Language Models in Lexical Entailment Recognition", "link": "https://arxiv.org/abs/2406.14894", "description": "arXiv:2406.14894v1 Announce Type: cross \nAbstract: Verbs form the backbone of language, providing the structure and meaning to sentences. Yet, their intricate semantic nuances pose a longstanding challenge. Understanding verb relations through the concept of lexical entailment is crucial for comprehending sentence meanings and grasping verb dynamics. This work investigates the capabilities of eight Large Language Models in recognizing lexical entailment relations among verbs through differently devised prompting strategies and zero-/few-shot settings over verb pairs from two lexical databases, namely WordNet and HyperLex. Our findings unveil that the models can tackle the lexical entailment recognition task with moderately good performance, although at varying degree of effectiveness and under different conditions. Also, utilizing few-shot prompting can enhance the models' performance. However, perfectly solving the task arises as an unmet challenge for all examined LLMs, which raises an emergence for further research developments on this topic."}, "https://arxiv.org/abs/2406.14928": {"title": "Autonomous Agents for Collaborative Task under Information Asymmetry", "link": "https://arxiv.org/abs/2406.14928", "description": "arXiv:2406.14928v1 Announce Type: cross \nAbstract: Large Language Model Multi-Agent Systems (LLM-MAS) have achieved great progress in solving complex tasks. It performs communication among agents within the system to collaboratively solve tasks, under the premise of shared information. However, when agents' communication is leveraged to enhance human cooperation, a new challenge arises due to information asymmetry, since each agent can only access the information of its human user. Previous MAS struggle to complete tasks under this condition. To address this, we propose a new MAS paradigm termed iAgents, which denotes Informative Multi-Agent Systems. In iAgents, the human social network is mirrored in the agent network, where agents proactively exchange human information necessary for task resolution, thereby overcoming information asymmetry. iAgents employs a novel agent reasoning mechanism, InfoNav, to navigate agents' communication towards effective information exchange. Together with InfoNav, iAgents organizes human information in a mixed memory to provide agents with accurate and comprehensive information for exchange. Additionally, we introduce InformativeBench, the first benchmark tailored for evaluating LLM agents' task-solving ability under information asymmetry. Experimental results show that iAgents can collaborate within a social network of 140 individuals and 588 relationships, autonomously communicate over 30 turns, and retrieve information from nearly 70,000 messages to complete tasks within 3 minutes."}, "https://arxiv.org/abs/2406.15038": {"title": "Online detection and infographic explanation of spam reviews with data drift adaptation", "link": "https://arxiv.org/abs/2406.15038", "description": "arXiv:2406.15038v1 Announce Type: cross \nAbstract: Spam reviews are a pervasive problem on online platforms due to its significant impact on reputation. However, research into spam detection in data streams is scarce. Another concern lies in their need for transparency. Consequently, this paper addresses those problems by proposing an online solution for identifying and explaining spam reviews, incorporating data drift adaptation. It integrates (i) incremental profiling, (ii) data drift detection & adaptation, and (iii) identification of spam reviews employing Machine Learning. The explainable mechanism displays a visual and textual prediction explanation in a dashboard. The best results obtained reached up to 87 % spam F-measure."}, "https://arxiv.org/abs/2406.15216": {"title": "A Highly Granular Temporary Migration Dataset Derived From Mobile Phone Data in Senegal", "link": "https://arxiv.org/abs/2406.15216", "description": "arXiv:2406.15216v1 Announce Type: cross \nAbstract: Understanding temporary migration is crucial for addressing various socio-economic and environmental challenges in developing countries. However, traditional surveys often fail to capture such movements effectively, leading to a scarcity of reliable data, particularly in sub-Saharan Africa. This article introduces a detailed and open-access dataset that leverages mobile phone data to capture temporary migration in Senegal with unprecedented spatio-temporal detail. The dataset provides measures of migration flows and stock across 151 locations across the country and for each half-month period from 2013 to 2015, with a specific focus on movements lasting between 20 and 180 days. The article presents a suite of methodological tools that not only include algorithmic methods for the detection of temporary migration events in digital traces, but also addresses key challenges in aggregating individual trajectories into coherent migration statistics. These methodological advancements are not only pivotal for the intrinsic value of the dataset but also adaptable for generating systematic migration statistics from other digital trace datasets in other contexts."}, "https://arxiv.org/abs/2406.15311": {"title": "The disruption index suffers from citation inflation and is confounded by shifts in scholarly citation practice", "link": "https://arxiv.org/abs/2406.15311", "description": "arXiv:2406.15311v1 Announce Type: cross \nAbstract: Measuring the rate of innovation in academia and industry is fundamental to monitoring the efficiency and competitiveness of the knowledge economy. To this end, a disruption index (CD) was recently developed and applied to publication and patent citation networks (Wu et al., Nature 2019; Park et al., Nature 2023). Here we show that CD systematically decreases over time due to secular growth in research and patent production, following two distinct mechanisms unrelated to innovation -- one behavioral and the other structural. Whereas the behavioral explanation reflects shifts associated with techno-social factors (e.g. self-citation practices), the structural explanation follows from `citation inflation' (CI), an inextricable feature of real citation networks attributable to increasing reference list lengths, which causes CD to systematically decrease. We demonstrate this causal link by way of mathematical deduction, computational simulation, multi-variate regression, and quasi-experimental comparison of the disruptiveness of PNAS versus PNAS Plus articles, which differ only in their lengths. Accordingly, we analyze CD data available in the SciSciNet database and find that disruptiveness incrementally increased from 2005-2015, and that the negative relationship between disruption and team-size is remarkably small in overall magnitude effect size, and shifts from negative to positive for team size $\\geq$ 8 coauthors."}, "https://arxiv.org/abs/2405.00053": {"title": "A new understanding on the history of developing MRI for cancer detection", "link": "https://arxiv.org/abs/2405.00053", "description": "arXiv:2405.00053v2 Announce Type: replace \nAbstract: Science is about facts and truth. Yet sometimes the truth and facts are not obvious. For example, in the field of MRI (Magnetic Resonance Imaging), there has been a long-lasting debate about who were the major contributors in its development. Particularly, there was a strong dispute between the followers of two scientists, R. Damadian and P. Lauterbur. In this review, we carefully trace the major developments in applying NMR for cancer detection starting almost 50 years ago. The research records show that the truth was beyond the claims of either research camps. The development of NMR for cancer detection involved multiple research groups, who made critical contributions at different junctures."}, "https://arxiv.org/abs/2405.03701": {"title": "QxEAI: Quantum-like evolutionary algorithm for automated probabilistic forecasting", "link": "https://arxiv.org/abs/2405.03701", "description": "arXiv:2405.03701v2 Announce Type: replace \nAbstract: Forecasting, to estimate future events, is crucial for business and decision-making. This paper proposes QxEAI, a methodology that produces a probabilistic forecast that utilizes a quantum-like evolutionary algorithm based on training a quantum-like logic decision tree and a classical value tree on a small number of related time series. We demonstrate how the application of our quantum-like evolutionary algorithm to forecasting can overcome the challenges faced by classical and other machine learning approaches. By using three real-world datasets (Dow Jones Index, retail sales, gas consumption), we show how our methodology produces accurate forecasts while requiring little to none manual work."}, "https://arxiv.org/abs/2307.13206": {"title": "Transferability of Graph Neural Networks using Graphon and Sampling Theories", "link": "https://arxiv.org/abs/2307.13206", "description": "arXiv:2307.13206v2 Announce Type: replace-cross \nAbstract: Graph neural networks (GNNs) have become powerful tools for processing graph-based information in various domains. A desirable property of GNNs is transferability, where a trained network can swap in information from a different graph without retraining and retain its accuracy. A recent method of capturing transferability of GNNs is through the use of graphons, which are symmetric, measurable functions representing the limit of large dense graphs. In this work, we contribute to the application of graphons to GNNs by presenting an explicit two-layer graphon neural network (WNN) architecture. We prove its ability to approximate bandlimited graphon signals within a specified error tolerance using a minimal number of network weights. We then leverage this result, to establish the transferability of an explicit two-layer GNN over all sufficiently large graphs in a convergent sequence. Our work addresses transferability between both deterministic weighted graphs and simple random graphs and overcomes issues related to the curse of dimensionality that arise in other GNN results. The proposed WNN and GNN architectures offer practical solutions for handling graph data of varying sizes while maintaining performance guarantees without extensive retraining."}, "https://arxiv.org/abs/2406.15428": {"title": "Assortativity in networks", "link": "https://arxiv.org/abs/2406.15428", "description": "arXiv:2406.15428v1 Announce Type: new \nAbstract: The degree-degree correlation is crucial in understanding the structural properties of and dynamics occurring upon network, and is often measured by the assortativity coefficient $r$. In this paper, we first study this measure in detail and conclude that $r$ belongs to an asymmetric range $[-1,1)$ rather than the widely-cited $[-1,1]$. Among which, we verify that star is the unique tree network that achieves the lower bound of index $r$. Next, we obtain that all the resultant networks based on several widely-used kinds of edge-based iterative operations are disassortative if seed model has negative $r$, and also generate a family of growing neutral networks. Then, we propose an edge-based iterative operation to construct growing assortative network when seed is assortative, and further extend it to work well in general setting. Lastly, we establish a sufficient condition for existence of neutral tree network, accordingly, not only find out a representative of any order neutral tree network for the first time, but also are the first to create growing neutral tree networks as well. Also, we obtain $8n/9$ neutral non-tree graphs of distinct order as $n\\rightarrow\\infty$."}, "https://arxiv.org/abs/2406.15439": {"title": "Heterogeneous peer effects of college roommates on academic performance", "link": "https://arxiv.org/abs/2406.15439", "description": "arXiv:2406.15439v1 Announce Type: new \nAbstract: Understanding how student peers influence learning outcomes is crucial for effective education management in complex social systems. The complexities of peer selection and evolving peer relationships, however, pose challenges for identifying peer effects using static observational data. Here we use both null-model and regression approaches to examine peer effects using longitudinal data from 5,272 undergraduates, where roommate assignments are plausibly random upon enrollment and roommate relationships persist until graduation. Specifically, we construct a roommate null model by randomly shuffling students among dorm rooms and introduce an assimilation metric to quantify similarities in roommate academic performance. We find significantly larger assimilation in actual data than in the roommate null model, suggesting roommate peer effects, whereby roommates have more similar performance than expected by chance alone. Moreover, assimilation exhibits an overall increasing trend over time, suggesting that peer effects become stronger the longer roommates live together. Our regression analysis further reveals the moderating role of peer heterogeneity. In particular, when roommates perform similarly, the positive relationship between a student's future performance and their roommates' average prior performance is more pronounced, and their ordinal rank in the dorm room has an independent effect. Our findings contribute to understanding the role of college roommates in influencing student academic performance."}, "https://arxiv.org/abs/2406.15449": {"title": "Rate of epidemic spreading on complex networks", "link": "https://arxiv.org/abs/2406.15449", "description": "arXiv:2406.15449v1 Announce Type: new \nAbstract: The initial phase of an epidemic is often characterised by an exponential increase in the number of infected individuals. In well-mixed populations, this exponential increase is controlled by the basic reproduction number R0 and the distribution of times between consecutive infection along an infection chain. However, we are still lacking a general understanding of how epidemics spread when individual interactions form a complex network. Here, we derive an expression for the rate of exponential spread of an epidemic on a complex network. We find that this rate is affected by the degree distribution, the network assortativity, and the level of clustering. Our result holds for a broad range of networks, aside from networks with very broad degree distribution, where no clear exponential regime is present. The theory presented in this paper bridges the gap between classic epidemiology and the theory of complex network, with broad implications for model inference and policy making."}, "https://arxiv.org/abs/2406.15452": {"title": "A-TEAM: Advanced Traffic Event Analysis and Management Platform for Transportation Data-Driven Problem Solving", "link": "https://arxiv.org/abs/2406.15452", "description": "arXiv:2406.15452v1 Announce Type: new \nAbstract: The rapid growth in terms of the availability of transportation data provides great potential for the introduction of emerging data-driven methodologies into transportation-related research and development efforts. However, advanced data-driven models, such as artificial-intelligence based approaches, usually contain complicated modeling structures and require strict data formats along with a very complex execution environment. It is thus often challenging to deploy and implement such data-driven models in a real-world environment. Moreover, a full-fledged application requires not only well developed and calibrated models, but also efficient connections with back end infrastructure such as large databases and front end utilities, such as a user-interface. This paper introduces a novel platform which provides an integrated architecture for deploying multi-purpose real-time traffic management applications. Inspired by the concept of modular design in software system development, this paper proposes a modular platform allowing users to customize their mission specific needs and preferences. The developed platform is capable of incorporating flexible user-provided models and/or data with the ultimate goal of deploying them as a complete application ready for real-world use. To illustrate this novel modular software system concept, this paper presents a work zone management and coordination application that is built upon the developed implementation platform to provide useful decision support to traffic engineers."}, "https://arxiv.org/abs/2406.15453": {"title": "Revisiting Monetarism: influence of Entropic Models", "link": "https://arxiv.org/abs/2406.15453", "description": "arXiv:2406.15453v1 Announce Type: new \nAbstract: This paper introduces an approach to gas-like models, from the concept of entropy, using the money stock data of two economic agents, in this case of two countries, which carry out market actions (trading) in two theoretical scenarios: in the absence of debt and with debt. The exercise deals exclusively with a no debt scenario and the data and results show that the bounded model generates low $P_{(m)}$, values that the results of the regressions between the two countries show an advantageous position of the stock country $m_i$ over the stock country $m_j$. About the rationale, it is found that these models can provide meaningful information regarding the behavior of monetary variables, -- taking into account the different conceptual positions proposed in the manuscript -- using analogies derived from other fields of study ranging from molecules in rarefied gases or particles collisions, bringing the data to the interaction of economic actors."}, "https://arxiv.org/abs/2406.15455": {"title": "Determination of the mean center of a region: A physics-based approach", "link": "https://arxiv.org/abs/2406.15455", "description": "arXiv:2406.15455v1 Announce Type: new \nAbstract: The mean center of a geographical region, including continents and countries, has been mostly determined to study the trend of population migration, the shift of economic hubs, and the spatial change of extreme climate events. However, the determination of the mean center is a formidable task as it deals with the curvature of the earth's surface. Here, we report a physics-based model to determine the mean center of a region. Our method provides the analytical expression for the location of the mean center for both flat and curved spaces, such as straight lines, circles, planes, three-dimensional space, cylinders, and spheres. Some of these expressions are often used to compute the center of mass of the physical system. Therefore, the implication of our model in the physical system extends the general validity of the model. Furthermore, we have computed various mean centers of India, such as the geographical, population, and crime centers. We have also assessed the year-wise movement of the crime center and found a spatial trend towards the north."}, "https://arxiv.org/abs/2406.15463": {"title": "Emergent Complexity in the Decision-Making Process of Chess Players", "link": "https://arxiv.org/abs/2406.15463", "description": "arXiv:2406.15463v1 Announce Type: new \nAbstract: In this article, we study the decision-making process of chess players by using a chess engine to evaluate the moves across different pools of games. We quantify the decisiveness of each move during the games using a metric called $\\Delta$, which is derived from the engine's evaluation of the positions. We then performed a comparative analysis across players of varying competitive levels. Firstly, we observed that players face a wide spectrum of $\\Delta$ values, evidencing the complexity of the process. By examining groups of winning and losing players, we found evidence where a decrease in complexity may be associated with a drop in player performance levels. Secondly, we observed that players' accuracy increases in positions with high $\\Delta$ values regardless of competitive level. Complementing this information with a null model where players make completely random legal moves allowed us to characterize the decision-making process under the simple strategy of making moves that minimize $\\Delta$ values. Finally, based on this idea, we proposed a simple model that approximately replicates the global emergent properties of the system."}, "https://arxiv.org/abs/2406.15464": {"title": "How Does Culture Evolve?", "link": "https://arxiv.org/abs/2406.15464", "description": "arXiv:2406.15464v1 Announce Type: new \nAbstract: This chapter synthesizes evidence from cognitive science, evolutionary theory, anthropology, psychological studies, and computational models for a complex systems inspired theory of creativity, and its role in cultural evolution. Creativity is guided by the global shape of one's integrated network of memories, concepts, and beliefs: one's worldview. This integrated structure and its dynamical change over time are described using autocatalytic networks. Autocatalytic networks can interact with each other, and they can grow and evolve; through interactions between their components, they generate novel components. Thus, they are used to describe cultural change both within and between individuals, as well as across cultural lineages. The chapter outlines autocatalytic network models of the origin of culture, the cognitive developmental process by which each child becomes a participant in cultural evolution, and the role of imitation, leadership, and social media on cultural evolution, as well as the trade-off between creativity and continuity."}, "https://arxiv.org/abs/2406.15492": {"title": "On the Principles behind Opinion Dynamics in Multi-Agent Systems of Large Language Models", "link": "https://arxiv.org/abs/2406.15492", "description": "arXiv:2406.15492v1 Announce Type: new \nAbstract: We study the evolution of opinions inside a population of interacting large language models (LLMs). Every LLM needs to decide how much funding to allocate to an item with three initial possibilities: full, partial, or no funding. We identify biases that drive the exchange of opinions based on the LLM's tendency to (i) find consensus with the other LLM's opinion, (ii) display caution when specifying funding, and (iii) consider ethical concerns in its opinion. We find these biases are affected by the perceived absence of compelling reasons for opinion change, the perceived willingness to engage in discussion, and the distribution of allocation values. Moreover, tensions among biases can lead to the survival of funding for items with negative connotations. We also find that the final distribution of full, partial, and no funding opinions is more diverse when an LLM freely forms its opinion after an interaction than when its opinion is a multiple-choice selection among the three allocation options. In the latter case, consensus or polarization is generally attained. When agents are aware of past opinions, they seek to maintain consistency with them, and more diverse updating rules emerge. Our study is performed using a Llama 3 LLM."}, "https://arxiv.org/abs/2406.15493": {"title": "Exploring Study Abroad with Traditionally Underrepresented Populations: Impacts of Institutional Types", "link": "https://arxiv.org/abs/2406.15493", "description": "arXiv:2406.15493v1 Announce Type: new \nAbstract: The study investigated roles of institutional types and ethnic/racial background on academic credit among the traditionally underrepresented population of the U.S. study abroad program. Using archival data, the study sampled the students' enrollment and academic credit information spanning a period of 20 years (2003 - 2022). Data analysis Using One-Way Analysis of Variance (ANOVA) indicates significant main influence of institutional type (p<.001) and significant main influence of ethnic/racial identity (p<.001) on students' academic credit. The result was discussed in terms of its relevance in educational policy re-evaluations, improvement of the study conditions of the underrepresented students, and enhancement of the enrollment opportunities of these minority population across all U.S. institutions of learning"}, "https://arxiv.org/abs/2406.15511": {"title": "On the number of freeway lanes and its positive or negative effect on safety", "link": "https://arxiv.org/abs/2406.15511", "description": "arXiv:2406.15511v1 Announce Type: new \nAbstract: We address the 80-year-old question of whether a freeway with more lanes results in fewer or more accidents. For finding the optimally safe number of lanes, in particular, we look at three types of accidents that are prevalent on urban freeways, namely \"following too closely\", \"driver inattention\", and \"unsafe change of lanes\". To do so we extend the intelligent driver model (IDM) to create a microscopic traffic flow model which is capable of producing accidents. We study the rate of accidents relative to a baseline 2-lane unidirectional freeway via Monte Carlo simulation. For each simulation instance we create a starting configuration involving only a few cars over a short segment of the freeway and simulate the dynamics thereafter. Furthermore, we look at the number of shoulders present, and show that the presence of shoulders can positively or negatively affect the accident rate depending on the type of accident."}, "https://arxiv.org/abs/2406.15514": {"title": "How big does a population need to be before demographers can ignore individual-level randomness in demographic events?", "link": "https://arxiv.org/abs/2406.15514", "description": "arXiv:2406.15514v1 Announce Type: new \nAbstract: When studying a national-level population, demographers can safely ignore the effect of individual-level randomness on age-sex structure. When studying a single community, or group of communities, however, the potential importance of individual-level randomness is less clear. We seek to measure the effect of individual-level randomness in births and deaths on standard summary indicators of age-sex structure, for populations of different sizes, focusing on on demographic conditions typical of historical populations. We conduct a microsimulation experiment where we simulate events and age-sex structure under a range of settings for demographic rates and population size. The experiment results suggest that individual-level randomness strongly affects age-sex structure for populations of about 100, but has a much smaller effect on populations of 1,000, and a negligible effect on populations of 10,000. Our conclusion is that analyses of age-sex structure in historical populations with sizes on the order 100 must account for individual-level randomness in demographic events. Analyses of populations with sizes on the order of 1,000 may need to make some allowance for individual-level variation, but other issues, such as measurement error, probably deserve more attention. Analyses of populations of 10,000 can safely ignore individual-level variation."}, "https://arxiv.org/abs/2406.15517": {"title": "Multidimensional representation of semantic relations between physical theories, fundamental constants and units of measurement with formal concept analysis", "link": "https://arxiv.org/abs/2406.15517", "description": "arXiv:2406.15517v1 Announce Type: new \nAbstract: We propose several hierarchical graphs that represent the semantic relations between physical theories, their fundamental constants and units of measurement. We begin with an alternative representation of Zelmanov's cube of fundamental constants as a concept lattice. We then propose the inclusion of a new fundamental constant: Milgrom's critical acceleration and discuss the implications of such analysis. We then look for the same fundamental constants in a graph that relates magnitudes and units of measurement in the International System of Units. This exercise shows the potential of visualizing hierarchical networks as a tool to better comprehend the interrelations and dependencies of physical magnitudes, units and theories. New regimes of application may be deduced, as well as an interesting reflection on our ontologies and corresponding theoretical objects."}, "https://arxiv.org/abs/2406.15533": {"title": "Food Pairing Unveiled: Exploring Recipe Creation Dynamics through Recommender Systems", "link": "https://arxiv.org/abs/2406.15533", "description": "arXiv:2406.15533v1 Announce Type: new \nAbstract: In the early 2000s, renowned chef Heston Blumenthal formulated his \"food pairing\" hypothesis, positing that if foods share many flavor compounds, then they tend to taste good when eaten together. In 2011, Ahn et al. conducted a study using a dataset of recipes, ingredients, and flavor compounds, finding that, in Western cuisine, ingredients in recipes often share more flavor compounds than expected by chance, indicating a natural tendency towards food pairing. Building upon Ahn's research, our work applies state-of-the-art collaborative filtering techniques to the dataset, providing a tool that can recommend new foods to add in recipes, retrieve missing ingredients and advise against certain combinations. We create our recommender in two ways, by taking into account ingredients appearances in recipes or shared flavor compounds between foods. While our analysis confirms the existence of food pairing, the recipe-based recommender performs significantly better than the flavor-based one, leading to the conclusion that food pairing is just one of the principles to take into account when creating recipes. Furthermore, and more interestingly, we find that food pairing in data is mostly due to trivial couplings of very similar ingredients, leading to a reconsideration of its current role in recipes, from being an already existing feature to a key to open up new scenarios in gastronomy. Our flavor-based recommender can thus leverage this novel concept and provide a new tool to lead culinary innovation."}, "https://arxiv.org/abs/2406.15595": {"title": "The impact of fear and behaviour response to established and novel diseases", "link": "https://arxiv.org/abs/2406.15595", "description": "arXiv:2406.15595v1 Announce Type: new \nAbstract: We analyze a disease transmission model that allows individuals to acquire fear and change their behaviour to reduce transmission. Fear is acquired through contact with infected individuals and through the influence of fearful individuals. We analyze the model in two limits: First, an Established Disease Limit (EDL), where the spread of the disease is much faster than the spread of fear, and second, a Novel Disease Limit (NDL), where the spread of the disease is comparable to that of fear. For the EDL, we show that the relative rate of fear acquisition to disease transmission controls the size of the fearful population at the end of a disease outbreak, and that the fear-induced contact reduction behaviour has very little impact on disease burden. Conversely, we show that in the NDL, disease burden can be controlled by fear-induced behaviour depending on the rate of fear loss. Specifically, fear-induced behaviour introduces a contact parameter $p$, which if too large prevents the contact reduction from effectively managing the epidemic. We analytically identify a critical prophylactic behaviour parameter $p=p_c$ where this happens leading to a discontinuity in epidemic prevalence. We show that this change in disease burden introduces multiple epidemic waves."}, "https://arxiv.org/abs/2406.15636": {"title": "Simple Games on Complex Networks", "link": "https://arxiv.org/abs/2406.15636", "description": "arXiv:2406.15636v1 Announce Type: new \nAbstract: The relationship between topology and dynamics of complex systems has motivated continuing interest from the scientific community. In the present work, we address this interesting topic from the perspective of simple games, involving two teams playing according to a small set of simple rules, taking place on four types of complex networks. Starting from a minimalist game, characterized by full symmetry always leading to ties, four other games are described in progressive order of complexity, taking into account the presence of neighbors as well as strategies. Each of these five games, as well as their specific changes when implemented in four types of networks, are studied in terms of statistics of the total duration of the game as well as the number of victories and ties, with several interesting results that substantiate, in some cases, the importance of the network topology on the respective dynamics. As a subsidiary result, the visualization of relationships between the data elements in terms of coincidence similarity networks allowed a more complete and direct interpretation of the obtained results."}, "https://arxiv.org/abs/2406.15679": {"title": "Iterative Service-Learning: A Computing-Based Case-study Applied to Small Rural Organizations", "link": "https://arxiv.org/abs/2406.15679", "description": "arXiv:2406.15679v1 Announce Type: new \nAbstract: This paper describes the iterative use of service learning to develop, review, and improve computing-based artifacts. It is well-known that computing students benefit from service-learning experiences as do the community partners. It is also well-known that computing artifacts rarely function well long-term without versioning and updates. Service-learning projects are often one-time engagements, completed by single teams of students over the course of a semester course. This limits the benefit for community partners that do not have the expertise or resources to review and update a project on their own.\n  Over several years, teams of undergraduate students in a capstone course created tailored social media plans for numerous small rural organizations. The projects were required to meet client specific needs, with identified audiences, measurable goals, and strategies and tactics to reach the identified goals. This paper builds on previously results for 60 projects conducted over several years. Nine clients were selected to participate in the iterative follow-up process, where new student teams conducted client interviews, reviewed the initial plans, and analyzed metrics from the current strategies and tactics to provide updated, improved artifacts. Using ABET learning objectives as a basis, clients reviewed the student teams and artifacts. This longitudinal study discusses the impact of this intervention to increase implementation and sustained use rates of computing artifacts developed through service learning. Both students and clients reported high satisfaction levels, and clients were particularly satisfied with the iterative improvement process. This research demonstrates an innovative practice for creating and maintaining computing artifacts through iterative service learning, while addressing the resource constraints of small organizations."}, "https://arxiv.org/abs/2406.15780": {"title": "Triple Helix synergy and patent dynamics", "link": "https://arxiv.org/abs/2406.15780", "description": "arXiv:2406.15780v1 Announce Type: new \nAbstract: We use a computationally efficient technique of Logistic Continuous Wavelet transform (CWT) to analyze patent data for Switzerland, Germany, USA, and Brszil for the period 1980-2000. We found that patent growth dynamics follows the dynamics of innovation system synergy in the framework of Triple Helix model of innovations where observed non-linear actors' interactions are provided by biased information exchange between heterogenious actors. Suggested approach reveals the latent trend structure in patent and innovation dynamics and may help policymakers identify the potential drivers of patent and innovation activity and form informed policy for boosting innovation development. The paper also privides a foundation for future research in differnt fields studying complex systems of interacting heterogenious agents."}, "https://arxiv.org/abs/2406.15814": {"title": "Simulation-Optimization Approaches for the Network Immunization Problem with Quarantining", "link": "https://arxiv.org/abs/2406.15814", "description": "arXiv:2406.15814v1 Announce Type: new \nAbstract: Vaccination has played an important role in preventing the spread of infectious diseases. However, the limited availability of vaccines and personnel at the roll-out of a new vaccine, as well as the costs of vaccination campaigns, might limit how many people can be vaccinated. Network immunization thus focuses on selecting a fixed-size subset of individuals to vaccinate so as to minimize the disease spread. In this paper, we consider simulation-optimization approaches for this selection problem. Here, the simulation of disease spread in an activity-based contact graph allows us to consider the effect of contact tracing and a limited willingness to test and quarantine. First, we develop a stochastic programming algorithm based on sampling infection forests from the simulation. Second, we propose a genetic algorithm that is tailored to the immunization problem and combines simulation runs of different sizes to balance the time needed to find promising solutions with the uncertainty resulting from simulation. Both approaches are tested on data from a major university in Denmark and disease characteristics representing those of COVID-19. Our results show that the proposed methods are competitive with a large number of centrality-based measures over a range of disease parameters and that the proposed methods are able to outperform them for a considerable number of these instances. Finally, we compare network immunization against our previously proposed approach of limiting distinct contacts. Although, independently, network immunization has a larger impact in reducing disease spread, we show that the combination of both methods reduces the disease spread even further."}, "https://arxiv.org/abs/2406.15894": {"title": "Persuasion, Betrayal and Regret in Election Campaigns", "link": "https://arxiv.org/abs/2406.15894", "description": "arXiv:2406.15894v1 Announce Type: new \nAbstract: Elections play a fundamental role in democratic societies, however they are often characterized by unexpected results. Here we discuss an election campaign model inspired by the compartmental epidemiology, and we show that the model captures the main characteristics of an election campaign: persuasion, betrayal and regret. All of these three factors can be used together or independently to influence the campaign, and to determine the winner. We include results for both the deterministic and the stochastic versions of the model, and we show that the decision to not vote significantly increases the fluctuations in the model, amplifying the chance of controversial results, in agreement with the well known \"paradox of not voting\"."}, "https://arxiv.org/abs/2406.16051": {"title": "Entropy-driven decision-making dynamics sheds light on the emergence of the \"paradox of choice\"", "link": "https://arxiv.org/abs/2406.16051", "description": "arXiv:2406.16051v1 Announce Type: new \nAbstract: Decision making is the cognitive process of selecting a course of action among multiple alternatives. As the decision maker belongs to a complex microenvironment (which contains multiple decision makers), has to make a decision where multiple options are present which often leads to a phenomenon known as the \"paradox of choices\". The latter refers to the case where too many options can lead to negative outcomes, such as increased uncertainty, decision paralysis, and frustration. Here, we employ an entropy driven mechanism within a statistical physics framework to explain the premises of the paradox. In turn, we focus on the emergence of a collective \"paradox of choice\", in the case of interacting decision-making agents, quantified as the decision synchronization time. Our findings reveal a trade-off between synchronization time and the sensing radius, indicating the optimal conditions for information transfer among group members, which significantly depends the individual sensitivity parameters. Interestingly, when agents sense their microenvironment in a biased way or their decisions are influenced by their past choices, then the collective \"paradox of choice\" does not occur. In a nutshell, our theory offers a low-dimensional and unified statistical explanation of the \"paradox of choice\" at the individual and at the collective level."}, "https://arxiv.org/abs/2406.16092": {"title": "Quantitative Global Carbon Inequality Network", "link": "https://arxiv.org/abs/2406.16092", "description": "arXiv:2406.16092v1 Announce Type: new \nAbstract: International trading networks significantly influence global economic conditions and environmental outcomes. A notable imbalance between economic gains and emissions transfers persists, manifesting as carbon inequality. This study introduces a novel metric, the Ecological Economic Equality Index, integrated with complex network dynamics analysis, to quantitatively evaluate the evolving roles within the global trading network and to pinpoint inequities in trade relationships from 1995 to 2022. Utilising high spatiotemporal resolution data from the Environmentally Extended Multi-regional Input-output model, our findings reveal a widening disparity in carbon inequality and dynamic patterns. This analysis emphasises the gap in regional carbon inequality and identifies unequal trade. The study underscores that carbon inequality is a critical challenge affecting both developing and developed regions, demanding widespread attention and action."}, "https://arxiv.org/abs/2406.16175": {"title": "The Persistence of Contrarianism on Twitter: Mapping users' sharing habits for the Ukraine war, COVID-19 vaccination, and the 2020 Midterm Elections", "link": "https://arxiv.org/abs/2406.16175", "description": "arXiv:2406.16175v1 Announce Type: new \nAbstract: Empirical studies of online disinformation emphasize matters of public concern such as the COVID-19 pandemic, foreign election interference, and the Russo-Ukraine war, largely in studies that treat the topics separately. Comparatively fewer studies attempt to relate such disparate topics and address the extent to which they share behaviors. In this study, we compare three samples of Twitter data on COVID-19 vaccination, the Ukraine war and the 2020 midterm elections, to ascertain how distinct ideological stances of users across the three samples might be related. Our results indicate the emergence of a broad contrarian stance that is defined by its opposition to public health narratives/policies along with the Biden administration's foreign policy stances. Sharing activity within the contrarian position falls on a spectrum with outright conspiratorial content on one end. We confirm the existence of ideologically coherent cross-subject stances among Twitter users, but in a manner not squarely aligned with right-left political orientations."}, "https://arxiv.org/abs/2406.16186": {"title": "Philosophical views of justice and their implications in energy systems modelling", "link": "https://arxiv.org/abs/2406.16186", "description": "arXiv:2406.16186v1 Announce Type: new \nAbstract: What constitutes socially just or unjust energy systems or transitions can be derived from the philosophy and theories of justice. Assessments of justice and utilising them in modelling lead to great differences based on which justice principles are applied. We find that comparisons between the two principles of utilitarianism and egalitarianism dominate in assessments of distributive justice, with the latter most often considered representing a \"just energy system\". The lack of recognition of alternative and equally valid principles of justice, resting on e.g. capabilities, responsibilities and/or opportunities, leads to a narrow understanding of justice that fails to align with the views of different individuals, stakeholders and societies. More importantly, it can lead to the unjust design of future energy systems and energy systems analysis. In this work, we contribute to the growing amount of research on justice in energy systems modelling by assessing the implications of different philosophical views on justice on modelling results. Through a modelling exercise with a power system model for Europe, we explore different designs of a future net-zero European energy system, and its distributional implications based on the application of different justice principles. In addition to the utilitarian and egalitarian approach, we include, among others, principles of \"polluters pay\" and \"ability-to-pay\", which take historical contributions of GHG and the socio-economic conditions of a region into account. We find that socially just energy systems look significantly different depending on the justice principles applied. The results may stimulate a greater discussion among researchers and policymakers on the implications of different constructions of justice in modelling, expansion of approaches, and demonstrate the importance of transparency and assumptions when communicating such results"}, "https://arxiv.org/abs/2406.16560": {"title": "GNNTAL:A Novel Model for Identifying Critical Nodes in Complex Networks", "link": "https://arxiv.org/abs/2406.16560", "description": "arXiv:2406.16560v1 Announce Type: new \nAbstract: Identification of critical nodes is a prominent topic in the study of complex networks. Numerous methods have been proposed, yet most exhibit inherent limitations. Traditional approaches primarily analyze specific structural features of the network; however, node influence is typically the result of a combination of multiple factors. Machine learning-based methods struggle to effectively represent the complex characteristics of network structures through suitable embedding techniques and require substantial data for training, rendering them prohibitively costly for large-scale networks. To address these challenges, this paper presents an active learning model based on GraphSAGE and Transformer, named GNNTAL. This model is initially pre-trained on random or synthetic networks and subsequently fine-tuned on real-world networks by selecting a few representative nodes using K-Means clustering and uncertainty sampling. This approach offers two main advantages: (1) it significantly reduces training costs; (2) it simultaneously incorporates both local and global features. A series of comparative experiments conducted on twelve real-world networks demonstrate that GNNTAL achieves superior performance. Additionally, this paper proposes an influence maximization method based on the predictions of the GNNTAL model, which achieves optimal performance without the need for complex computations. Finally, the paper analyses certain limitations of the GNNTAL model and suggests potential solutions."}, "https://arxiv.org/abs/2406.16676": {"title": "Unveiling Cognitive Constraints in Language Production: Extracting and Validating the Active Ego Network of Words", "link": "https://arxiv.org/abs/2406.16676", "description": "arXiv:2406.16676v1 Announce Type: new \nAbstract: The \"ego network of words\" model captures structural properties in language production associated with cognitive constraints. While previous research focused on the layer-based structure and its semantic properties, this paper argues that an essential element, the concept of an active network, is missing. The active part of the ego network of words only includes words that are regularly used by individuals, akin to the ego networks in the social domain, where the active part includes relationships regularly nurtured by individuals and hence demanding cognitive effort. In this work, we define a methodology for extracting the active part of the ego network of words and validate it using interview transcripts and tweets. The robustness of our method to varying input data sizes and temporal stability is demonstrated. We also demonstrate that without the active network concept (and a tool for properly extracting the active network from data), the \"ego network of words\" model is not able to properly estimate the cognitive effort involved and it becomes vulnerable to the amount of data considered (leading to the disappearance of the layered structure in large datasets). Our results are well-aligned with prior analyses of the ego network of words, where the limitation of the data collected led automatically (and implicitly) to approximately consider the active part of the network only. Moreover, the validation on the transcripts dataset (MediaSum) highlights the generalizability of the model across diverse domains and the ingrained cognitive constraints in language usage."}, "https://arxiv.org/abs/2406.16762": {"title": "Adaptive Payoff-driven Interaction in Networked Snowdrift Games", "link": "https://arxiv.org/abs/2406.16762", "description": "arXiv:2406.16762v1 Announce Type: new \nAbstract: In social dilemmas, most interactions are transient and susceptible to restructuring, leading to continuous changes in social networks over time. Typically, agents assess the rewards of their current interactions and adjust their connections to optimize outcomes. In this paper, we introduce an adaptive network model in the snowdrift game to examine dynamic levels of cooperation and network topology, involving the potential for both the termination of existing connections and the establishment of new ones. In particular, we define the agent's asymmetric disassociation tendency toward their neighbors, which fundamentally determines the probability of edge dismantlement. The mechanism allows agents to selectively sever and rewire their connections to alternative individuals to refine partnerships. Our findings reveal that adaptive networks are particularly effective in promoting a robust evolution toward states of either pure cooperation or complete defection, especially under conditions of extreme cost-benefit ratios, as compared to static network models. Moreover, the dynamic restructuring of connections and the distribution of network degrees among agents are closely linked to the levels of cooperation in stationary states. Specifically, cooperators tend to seek broader neighborhoods when confronted with the invasion of multiple defectors."}, "https://arxiv.org/abs/2406.16787": {"title": "Parrondo's paradox in susceptible-infectious-susceptible dynamics over periodic temporal networks", "link": "https://arxiv.org/abs/2406.16787", "description": "arXiv:2406.16787v1 Announce Type: new \nAbstract: Many social and biological networks periodically change over time with daily, weekly, and other cycles. Thus motivated, we formulate and analyze susceptible-infectious-susceptible (SIS) epidemic models over temporal networks with periodic schedules. More specifically, we assume that the temporal network consists of a cycle of alternately used static networks, each with a given duration. We show Parrondo's paradox behavior in this model, with which the periodic alternation of two static networks that are supra-threshold (i.e., above the epidemic threshold of the SIS model) yields a sub-threshold dynamics (i.e., with the number of infectious nodes exponentially decaying over time) in many cases. We find community structure to play an important role in shaping this phenomenon, and we study its dependence on the connectivity between and number of communities. Our findings associate such paradoxical behavior with anti-phase oscillatory behavior of the number of infectious nodes in different communities of the network."}, "https://arxiv.org/abs/2406.15470": {"title": "Mental Disorder Classification via Temporal Representation of Text", "link": "https://arxiv.org/abs/2406.15470", "description": "arXiv:2406.15470v1 Announce Type: cross \nAbstract: Mental disorders pose a global challenge, aggravated by the shortage of qualified mental health professionals. Mental disorder prediction from social media posts by current LLMs is challenging due to the complexities of sequential text data and the limited context length of language models. Current language model-based approaches split a single data instance into multiple chunks to compensate for limited context size. The predictive model is then applied to each chunk individually, and the most voted output is selected as the final prediction. This results in the loss of inter-post dependencies and important time variant information, leading to poor performance. We propose a novel framework which first compresses the large sequence of chronologically ordered social media posts into a series of numbers. We then use this time variant representation for mental disorder classification. We demonstrate the generalization capabilities of our framework by outperforming the current SOTA in three different mental conditions: depression, self-harm, and anorexia, with an absolute improvement of 5% in the F1 score. We investigate the situation where current data instances fall within the context length of language models and present empirical results highlighting the importance of temporal properties of textual data. Furthermore, we utilize the proposed framework for a cross-domain study, exploring commonalities across disorders and the possibility of inter-domain data usage."}, "https://arxiv.org/abs/2406.15498": {"title": "An Integration of policy and reputation based trust mechanisms", "link": "https://arxiv.org/abs/2406.15498", "description": "arXiv:2406.15498v1 Announce Type: cross \nAbstract: Due to popularization of internet and e-commerce, more and more people getting involved in online shopping market. A large number of companies have been transferred to the internet where online customers have been increased due to easy access. The online business facilitates people to communicate without knowing each other. The e-commerce systems are the combination of commerce behavior and internet technologies. Therefore, trust aspects are positive elements in buyer-seller transactions and a potential source of competitive e-commerce industry. There are two different approaches to handle the trust. The first approach has a solid authentication set of rules where decisions are made on some digital or logical rules called policy based trust mechanism. The second approach is a decentralized trust approach where reputation assembled and shared in distributed environment called reputation based trust mechanism. Objectives: In this thesis, the strengths and weaknesses of policy and reputation based trust mechanisms have been identified through systematic literature review and industrial interviews. Furthermore, the process of integrated trust mechanism has been proposed. The integrated trust mechanism is proposed through mapping process, weakness of one mechanism with the strength of other. The proposed integrated trust mechanism was validated by conducting experiment with buyer/seller scenario in auction system. The analysis of collected results indicated that proposed integrated trust mechanism improved the trust of buyer against eBay and Tradera. At the end, we have discussed some key points that may affect trust relationship between seller and buyer. Furthermore, there is a need for further validation of proposed trust mechanism in auction system/e-commerce industry."}, "https://arxiv.org/abs/2406.15957": {"title": "Weak recovery, hypothesis testing, and mutual information in stochastic block models and planted factor graphs", "link": "https://arxiv.org/abs/2406.15957", "description": "arXiv:2406.15957v1 Announce Type: cross \nAbstract: The stochastic block model is a canonical model of communities in random graphs. It was introduced in the social sciences and statistics as a model of communities, and in theoretical computer science as an average case model for graph partitioning problems under the name of the ``planted partition model.'' Given a sparse stochastic block model, the two standard inference tasks are: (i) Weak recovery: can we estimate the communities with non trivial overlap with the true communities? (ii) Detection/Hypothesis testing: can we distinguish if the sample was drawn from the block model or from a random graph with no community structure with probability tending to $1$ as the graph size tends to infinity?\n  In this work, we show that for sparse stochastic block models, the two inference tasks are equivalent except at a critical point. That is, weak recovery is information theoretically possible if and only if detection is possible. We thus find a strong connection between these two notions of inference for the model. We further prove that when detection is impossible, an explicit hypothesis test based on low degree polynomials in the adjacency matrix of the observed graph achieves the optimal statistical power. This low degree test is efficient as opposed to the likelihood ratio test, which is not known to be efficient. Moreover, we prove that the asymptotic mutual information between the observed network and the community structure exhibits a phase transition at the weak recovery threshold.\n  Our results are proven in much broader settings including the hypergraph stochastic block models and general planted factor graphs. In these settings we prove that the impossibility of weak recovery implies contiguity and provide a condition which guarantees the equivalence of weak recovery and detection."}, "https://arxiv.org/abs/2406.16357": {"title": "Towards Lightweight Graph Neural Network Search with Curriculum Graph Sparsification", "link": "https://arxiv.org/abs/2406.16357", "description": "arXiv:2406.16357v1 Announce Type: cross \nAbstract: Graph Neural Architecture Search (GNAS) has achieved superior performance on various graph-structured tasks. However, existing GNAS studies overlook the applications of GNAS in resource-constraint scenarios. This paper proposes to design a joint graph data and architecture mechanism, which identifies important sub-architectures via the valuable graph data. To search for optimal lightweight Graph Neural Networks (GNNs), we propose a Lightweight Graph Neural Architecture Search with Graph SparsIfication and Network Pruning (GASSIP) method. In particular, GASSIP comprises an operation-pruned architecture search module to enable efficient lightweight GNN search. Meanwhile, we design a novel curriculum graph data sparsification module with an architecture-aware edge-removing difficulty measurement to help select optimal sub-architectures. With the aid of two differentiable masks, we iteratively optimize these two modules to efficiently search for the optimal lightweight architecture. Extensive experiments on five benchmarks demonstrate the effectiveness of GASSIP. Particularly, our method achieves on-par or even higher node classification performance with half or fewer model parameters of searched GNNs and a sparser graph."}, "https://arxiv.org/abs/2406.16552": {"title": "Inference of Sequential Patterns for Neural Message Passing in Temporal Graphs", "link": "https://arxiv.org/abs/2406.16552", "description": "arXiv:2406.16552v1 Announce Type: cross \nAbstract: The modelling of temporal patterns in dynamic graphs is an important current research issue in the development of time-aware GNNs. Whether or not a specific sequence of events in a temporal graph constitutes a temporal pattern not only depends on the frequency of its occurrence. We consider whether it deviates from what is expected in a temporal graph where timestamps are randomly shuffled. While accounting for such a random baseline is important to model temporal patterns, it has mostly been ignored by current temporal graph neural networks. To address this issue we propose HYPA-DBGNN, a novel two-step approach that combines (i) the inference of anomalous sequential patterns in time series data on graphs based on a statistically principled null model, with (ii) a neural message passing approach that utilizes a higher-order De Bruijn graph whose edges capture overrepresented sequential patterns. Our method leverages hypergeometric graph ensembles to identify anomalous edges within both first- and higher-order De Bruijn graphs, which encode the temporal ordering of events. The model introduces an inductive bias that enhances model interpretability. We evaluate our approach for static node classification using benchmark datasets and a synthetic dataset that showcases its ability to incorporate the observed inductive bias regarding over- and under-represented temporal edges. We demonstrate the framework's effectiveness in detecting similar patterns within empirical datasets, resulting in superior performance compared to baseline methods in node classification tasks. To the best of our knowledge, our work is the first to introduce statistically informed GNNs that leverage temporal and causal sequence anomalies. HYPA-DBGNN represents a path for bridging the gap between statistical graph inference and neural graph representation learning, with potential applications to static GNNs."}, "https://arxiv.org/abs/2406.16816": {"title": "On the Impact of Sample Size in Reconstructing Noisy Graph Signals: A Theoretical Characterisation", "link": "https://arxiv.org/abs/2406.16816", "description": "arXiv:2406.16816v1 Announce Type: cross \nAbstract: Reconstructing a signal on a graph from noisy observations of a subset of the vertices is a fundamental problem in the field of graph signal processing. This paper investigates how sample size affects reconstruction error in the presence of noise via an in-depth theoretical analysis of the two most common reconstruction methods in the literature, least-squares reconstruction (LS) and graph-Laplacian regularised reconstruction (GLR). Our theorems show that at sufficiently low signal-to-noise ratios (SNRs), under these reconstruction methods we may simultaneously decrease sample size and decrease average reconstruction error. We further show that at sufficiently low SNRs, for LS reconstruction we have a $\\Lambda$-shaped error curve and for GLR reconstruction, a sample size of $ \\mathcal{O}(\\sqrt{N})$, where $N$ is the total number of vertices, results in lower reconstruction error than near full observation. We present thresholds on the SNRs, $\\tau$ and $\\tau_{GLR}$, below which the error is non-monotonic, and illustrate these theoretical results with experiments across multiple random graph models, sampling schemes and SNRs. These results demonstrate that any decision in sample-size choice has to be made in light of the noise levels in the data."}, "https://arxiv.org/abs/2211.00880": {"title": "DeepTrace: Learning to Optimize Contact Tracing in Epidemic Networks with Graph Neural Networks", "link": "https://arxiv.org/abs/2211.00880", "description": "arXiv:2211.00880v3 Announce Type: replace \nAbstract: Digital contact tracing aims to curb epidemics by identifying and mitigating public health emergencies through technology. Backward contact tracing, which tracks the sources of infection, proved crucial in places like Japan for identifying COVID-19 infections from superspreading events. This paper presents a novel perspective of digital contact tracing as online graph exploration and addresses the forward and backward contact tracing problem as a maximum-likelihood (ML) estimation problem using iterative epidemic network data sampling. The challenge lies in the combinatorial complexity and rapid spread of infections. We introduce DeepTrace, an algorithm based on a Graph Neural Network (GNN) that iteratively updates its estimations as new contact tracing data is collected, learning to optimize the maximum likelihood estimation by utilizing topological features to accelerate learning and improve convergence. The contact tracing process combines either BFS or DFS to expand the network and trace the infection source, ensuring comprehensive and efficient exploration. Additionally, the GNN model is fine-tuned through a two-phase approach: pre-training with synthetic networks to approximate likelihood probabilities and fine-tuning with high-quality data to refine the model. Using COVID-19 variant data, we illustrate that DeepTrace surpasses current methods in identifying superspreaders, providing a robust basis for a scalable digital contact tracing strategy."}, "https://arxiv.org/abs/2307.01915": {"title": "Using mathematics to study how people influence each other's opinions", "link": "https://arxiv.org/abs/2307.01915", "description": "arXiv:2307.01915v3 Announce Type: replace \nAbstract: People sometimes change their opinions when they discuss things with other people. Researchers study mathematical models of opinions to explore how people influence each other through their social interactions. In today's digital world, these models can help us learn how to promote accurate information and reduce unwanted influence. In this article, we discuss a simple mathematical model that looks at opinion changes from social interactions. We briefly describe what opinion models can tell us and how researchers try to make them more realistic."}, "https://arxiv.org/abs/2308.05247": {"title": "TUBERAIDER: Attributing Coordinated Hate Attacks on YouTube Videos to their Source Communities", "link": "https://arxiv.org/abs/2308.05247", "description": "arXiv:2308.05247v2 Announce Type: replace \nAbstract: Alas, coordinated hate attacks, or raids, are becoming increasingly common online. In a nutshell, these are perpetrated by a group of aggressors who organize and coordinate operations on a platform (e.g., 4chan) to target victims on another community (e.g., YouTube). In this paper, we focus on attributing raids to their source community, paving the way for moderation approaches that take the context (and potentially the motivation) of an attack into consideration. We present TUBERAIDER, an attribution system achieving over 75% accuracy in detecting and attributing coordinated hate attacks on YouTube videos. We instantiate it using links to YouTube videos shared on 4chan's /pol/ board, r/The_Donald, and 16 Incels-related subreddits. We use a peak detector to identify a rise in the comment activity of a YouTube video, which signals that an attack may be occurring. We then train a machine learning classifier based on the community language (i.e., TF-IDF scores of relevant keywords) to perform the attribution. We test TUBERAIDER in the wild and present a few case studies of actual aggression attacks identified by it to showcase its effectiveness."}, "https://arxiv.org/abs/2401.17890": {"title": "Followers do not dictate the virality of news outlets on social media", "link": "https://arxiv.org/abs/2401.17890", "description": "arXiv:2401.17890v2 Announce Type: replace \nAbstract: Initially conceived for entertainment, social media platforms have profoundly transformed the dissemination of information and consequently reshaped the dynamics of agenda-setting. In this scenario, understanding the factors that capture audience attention and drive viral content is crucial. Employing Gibrat's Law, which posits that an entity's growth rate is unrelated to its size, we examine the engagement growth dynamics of news outlets on social media. Our analysis encloses the Facebook historical data of over a thousand news outlets, encompassing approximately 57 million posts in four European languages from 2008 to the end of 2022. We discover universal growth dynamics according to which news virality is independent of the traditional size or engagement with the outlet. Moreover, our analysis reveals a significant long-term impact of news source reliability on engagement growth, with engagement induced by unreliable sources decreasing over time. We conclude the paper by presenting a statistical model replicating the observed growth dynamics."}, "https://arxiv.org/abs/2402.01940": {"title": "Generalized Naming Game and Bayesian Naming Game as Dynamical Systems", "link": "https://arxiv.org/abs/2402.01940", "description": "arXiv:2402.01940v3 Announce Type: replace \nAbstract: We study the $\\beta$-model ($\\beta$-NG) and the Bayesian Naming Game (BNG) as dynamical systems. By applying linear stability analysis to the dynamical system associated with the $\\beta$-model, we demonstrate the existence of a non-generic bifurcation with a bifurcation point $\\beta_c = 1/3$. As $\\beta$ passes through $\\beta_c$, the stability of isolated fixed points changes, giving rise to a one-dimensional manifold of fixed points. Notably, this attracting invariant manifold forms an arc of an ellipse. In the context of the BNG, we propose modeling the Bayesian learning probabilities $p_A$ and $p_B$ as logistic functions. This modeling approach allows us to establish the existence of fixed points without relying on the overly strong assumption that $p_A = p_B = p$, where $p$ is a constant."}, "https://arxiv.org/abs/2401.07115": {"title": "Open Models, Closed Minds? On Agents Capabilities in Mimicking Human Personalities through Open Large Language Models", "link": "https://arxiv.org/abs/2401.07115", "description": "arXiv:2401.07115v2 Announce Type: replace-cross \nAbstract: The emergence of unveiling human-like behaviors in Large Language Models (LLMs) has led to a closer connection between NLP and human psychology. Scholars have been studying the inherent personalities exhibited by LLMs and attempting to incorporate human traits and behaviors into them. However, these efforts have primarily focused on commercially-licensed LLMs, neglecting the widespread use and notable advancements seen in Open LLMs. This work aims to address this gap by employing a set of 12 LLM Agents based on the most representative Open models and subject them to a series of assessments concerning the Myers-Briggs Type Indicator (MBTI) test and the Big Five Inventory (BFI) test. Our approach involves evaluating the intrinsic personality traits of Open LLM agents and determining the extent to which these agents can mimic human personalities when conditioned by specific personalities and roles. Our findings unveil that $(i)$ each Open LLM agent showcases distinct human personalities; $(ii)$ personality-conditioned prompting produces varying effects on the agents, with only few successfully mirroring the imposed personality, while most of them being ``closed-minded'' (i.e., they retain their intrinsic traits); and $(iii)$ combining role and personality conditioning can enhance the agents' ability to mimic human personalities. Our work represents a step up in understanding the dense relationship between NLP and human psychology through the lens of Open LLMs."}, "https://arxiv.org/abs/2404.11869": {"title": "Node-like as a Whole: Structure-aware Searching and Coarsening for Graph Classification", "link": "https://arxiv.org/abs/2404.11869", "description": "arXiv:2404.11869v2 Announce Type: replace-cross \nAbstract: Graph Transformers (GTs) have made remarkable achievements in graph-level tasks. However, most existing works regard graph structures as a form of guidance or bias for enhancing node representations, which focuses on node-central perspectives and lacks explicit representations of edges and structures. One natural question is, can we treat graph structures node-like as a whole to learn high-level features? Through experimental analysis, we explore the feasibility of this assumption. Based on our findings, we propose a novel multi-view graph representation learning model via structure-aware searching and coarsening (GRLsc) on GT architecture for graph classification. Specifically, we build three unique views, original, coarsening, and conversion, to learn a thorough structural representation. We compress loops and cliques via hierarchical heuristic graph coarsening and restrict them with well-designed constraints, which builds the coarsening view to learn high-level interactions between structures. We also introduce line graphs for edge embeddings and switch to edge-central perspective to construct the conversion view. Experiments on eight real-world datasets demonstrate the improvements of GRLsc over 28 baselines from various architectures."}, "https://arxiv.org/abs/2404.16066": {"title": "Social Media Use is Predictable from App Sequences: Using LSTM and Transformer Neural Networks to Model Habitual Behavior", "link": "https://arxiv.org/abs/2404.16066", "description": "arXiv:2404.16066v2 Announce Type: replace-cross \nAbstract: The present paper introduces a novel approach to studying social media habits through predictive modeling of sequential smartphone user behaviors. While much of the literature on media and technology habits has relied on self-report questionnaires and simple behavioral frequency measures, we examine an important yet understudied aspect of media and technology habits: their embeddedness in repetitive behavioral sequences. Leveraging Long Short-Term Memory (LSTM) and transformer neural networks, we show that (i) social media use is predictable at the within and between-person level and that (ii) there are robust individual differences in the predictability of social media use. We examine the performance of several modeling approaches, including (i) global models trained on the pooled data from all participants, (ii) idiographic person-specific models, and (iii) global models fine-tuned on person-specific data. Neither person-specific modeling nor fine-tuning on person-specific data substantially outperformed the global models, indicating that the global models were able to represent a variety of idiosyncratic behavioral patterns. Additionally, our analyses reveal that the person-level predictability of social media use is not substantially related to the frequency of smartphone use in general or the frequency of social media use, indicating that our approach captures an aspect of habits that is distinct from behavioral frequency. Implications for habit modeling and theoretical development are discussed."}, "https://arxiv.org/abs/2406.17043": {"title": "The hidden architecture of connections: How do multidimensional identities shape our social networks?", "link": "https://arxiv.org/abs/2406.17043", "description": "arXiv:2406.17043v1 Announce Type: new \nAbstract: Our multidimensional identities determine how we interact with each other, shaping social networks through group-based connection preferences. While interactions along single dimensions have been extensively studied, the dynamics driving multidimensional connection preferences remain largely unexplored. In this work, we develop a network model of multidimensional social interactions to tackle two crucial questions: What is the structure of our latent connection preferences, and how do we integrate information from our multidimensional identities to connect with others? To answer these questions, we systematically model different latent preference structures and preference aggregation mechanisms. Then, we compare them using Bayesian model selection by fitting empirical data from high school friendship networks. We find that a simple latent preference model consistently outperforms more complex alternatives. The calibrated model provides robust measures of latent connection preferences in real-world networks, bringing insights into how one- and multidimensional groups interact. Finally, we develop natural operationalizations of dimension salience, revealing which aspects of identity are most relevant for individuals when forming connections."}, "https://arxiv.org/abs/2406.17135": {"title": "Testing network clustering algorithms with Natural Language Processing", "link": "https://arxiv.org/abs/2406.17135", "description": "arXiv:2406.17135v1 Announce Type: new \nAbstract: The advent of online social networks has led to the development of an abundant literature on the study of online social groups and their relationship to individuals' personalities as revealed by their textual productions. Social structures are inferred from a wide range of social interactions. Those interactions form complex -- sometimes multi-layered -- networks, on which community detection algorithms are applied to extract higher order structures. The choice of the community detection algorithm is however hardily questioned in relation with the cultural production of the individual they classify. In this work, we assume the entangled nature of social networks and their cultural production to propose a definition of cultural based online social groups as sets of individuals whose online production can be categorized as social group-related. We take advantage of this apparently self-referential description of online social groups with a hybrid methodology that combines a community detection algorithm and a natural language processing classification algorithm. A key result of this analysis is the possibility to score community detection algorithms using their agreement with the natural language processing classification. A second result is that we can assign the opinion of a random user at >85% accuracy."}, "https://arxiv.org/abs/2406.17435": {"title": "Echo chamber effects in signed networks", "link": "https://arxiv.org/abs/2406.17435", "description": "arXiv:2406.17435v1 Announce Type: new \nAbstract: Echo chamber effects in social networks are generally attributed to the prevalence of interactions among like-minded peers. However, recent evidence has emphasized the role of hostile interactions between opposite-minded groups. Here, we model information propagation between such groups by generalizing popular contagion models to signed networks. We show that echo chambers spontaneously emerge in balanced networks, and in antibalanced ones for specific parameters. The robustness of our results is confirmed through simulations on various network topologies, including a real-world dataset."}, "https://arxiv.org/abs/2406.17552": {"title": "A Weighted-Median Model of Opinion Dynamics on Networks", "link": "https://arxiv.org/abs/2406.17552", "description": "arXiv:2406.17552v1 Announce Type: new \nAbstract: Social interactions influence people's opinions. In some situations, these interactions result in a consensus opinion; in others, they result in opinion fragmentation and the formation of different opinion groups in the form of \"echo chambers\". Consider a social network of individuals, who hold continuous-valued scalar opinions and change their opinions when they interact with each other. In such an opinion model, it is common for an opinion-update rule to depend on the mean opinion of interacting individuals. However, we consider an alternative update rule - which may be more realistic in some situations - that instead depends on a weighted median opinion of interacting individuals. Through numerical simulations of our opinion model, we investigate how the limit opinion distribution depends on network structure. For configuration-model networks, we also derive a mean-field approximation for the asymptotic dynamics of the opinion distribution when there are infinitely many individuals in a network."}, "https://arxiv.org/abs/2406.17556": {"title": "Modularity Based Community Detection in Hypergraphs", "link": "https://arxiv.org/abs/2406.17556", "description": "arXiv:2406.17556v1 Announce Type: new \nAbstract: In this paper, we propose a scalable community detection algorithm using hypergraph modularity function, h-Louvain. It is an adaptation of the classical Louvain algorithm in the context of hypergraphs. We observe that a direct application of the Louvain algorithm to optimize the hypergraph modularity function often fails to find meaningful communities. We propose a solution to this issue by adjusting the initial stage of the algorithm via carefully and dynamically tuned linear combination of the graph modularity function of the corresponding two-section graph and the desired hypergraph modularity function. The process is guided by Bayesian optimization of the hyper-parameters of the proposed procedure. Various experiments on synthetic as well as real-world networks are performed showing that this process yields improved results in various regimes."}, "https://arxiv.org/abs/2406.17724": {"title": "Spatiotemporal statistical features of velocity responses to traffic congestions in a local motorway network", "link": "https://arxiv.org/abs/2406.17724", "description": "arXiv:2406.17724v1 Announce Type: new \nAbstract: The causal connection between congestions and velocity changes at different locations induces various statistical features, which we identify and measure in detail. We carry out an empirical analysis of large-scale traffic data on a local motorway network around the Breitscheid intersection in the North Rhine-Westphalia, Germany. We put forward a response function which measures the velocity change at a certain location versus time conditioned on a congestion at another location. We use a novel definition of the corresponding congestion indicator to ensure causality. We find that the response of velocities to the congestion exhibits phase changes in time. A negative response at smaller time lags transforms into positive one at larger time lags, implying a certain traffic mechanism. The response decays as a power law with the distance. We also identify a scaling property leading to a collapse of the response functions on one curve."}, "https://arxiv.org/abs/2406.17736": {"title": "Fairness in Social Influence Maximization via Optimal Transport", "link": "https://arxiv.org/abs/2406.17736", "description": "arXiv:2406.17736v1 Announce Type: new \nAbstract: We study fairness in social influence maximization, whereby one seeks to select seeds that spread a given information throughout a network, ensuring balanced outreach among different communities (e.g. demographic groups). In the literature, fairness is often quantified in terms of the expected outreach within individual communities. In this paper, we demonstrate that such fairness metrics can be misleading since they ignore the stochastic nature of information diffusion processes. When information diffusion occurs in a probabilistic manner, multiple outreach scenarios can occur. As such, outcomes such as \"in 50% of the cases, no one of group 1 receives the information and everyone in group 2 receives it and in other 50%, the opposite happens\", which always results in largely unfair outcomes, are classified as fair by a variety of fairness metrics in the literature. We tackle this problem by designing a new fairness metric, mutual fairness, that captures variability in outreach through optimal transport theory. We propose a new seed selection algorithm that optimizes both outreach and mutual fairness, and we show its efficacy on several real datasets. We find that our algorithm increases fairness with only a minor decrease (and at times, even an increase) in efficiency."}, "https://arxiv.org/abs/2406.17752": {"title": "Connectivity and Community Structure of Online and Register-based Social Networks", "link": "https://arxiv.org/abs/2406.17752", "description": "arXiv:2406.17752v1 Announce Type: new \nAbstract: The dominance of online social media data as a source of population-scale social network studies has recently been challenged by networks constructed from government-curated register data. In this paper, we investigate how the two compare, focusing on aggregations of the Dutch online social network (OSN) Hyves and a register-based social network (RSN) of the Netherlands. First and foremost, we find that the connectivity of the two population-scale networks is strikingly similar, especially between closeby municipalities, with more long-distance ties captured by the OSN. This result holds when correcting for population density and geographical distance, notwithstanding that these two patterns appear to be the main drivers of connectivity. Second, we show that the community structure of neither network follows strict administrative geographical delineations (e.g., provinces). Instead, communities appear to either center around large metropolitan areas or, outside of the country's most urbanized area, are comprised of large blocks of interdependent municipalities. Interestingly, beyond population and distance-related patterns, communities also highlight the persistence of deeply rooted historical and sociocultural communities based on religion. The results of this study suggest that both online social networks and register-based social networks are valuable resources for insights into the social network structure of an entire population."}, "https://arxiv.org/abs/2406.16963": {"title": "Large Language Models for Link Stealing Attacks Against Graph Neural Networks", "link": "https://arxiv.org/abs/2406.16963", "description": "arXiv:2406.16963v1 Announce Type: cross \nAbstract: Graph data contains rich node features and unique edge information, which have been applied across various domains, such as citation networks or recommendation systems. Graph Neural Networks (GNNs) are specialized for handling such data and have shown impressive performance in many applications. However, GNNs may contain of sensitive information and susceptible to privacy attacks. For example, link stealing is a type of attack in which attackers infer whether two nodes are linked or not. Previous link stealing attacks primarily relied on posterior probabilities from the target GNN model, neglecting the significance of node features. Additionally, variations in node classes across different datasets lead to different dimensions of posterior probabilities. The handling of these varying data dimensions posed a challenge in using a single model to effectively conduct link stealing attacks on different datasets. To address these challenges, we introduce Large Language Models (LLMs) to perform link stealing attacks on GNNs. LLMs can effectively integrate textual features and exhibit strong generalizability, enabling attacks to handle diverse data dimensions across various datasets. We design two distinct LLM prompts to effectively combine textual features and posterior probabilities of graph nodes. Through these designed prompts, we fine-tune the LLM to adapt to the link stealing attack task. Furthermore, we fine-tune the LLM using multiple datasets and enable the LLM to learn features from different datasets simultaneously. Experimental results show that our approach significantly enhances the performance of existing link stealing attack tasks in both white-box and black-box scenarios. Our method can execute link stealing attacks across different datasets using only a single model, making link stealing attacks more applicable to real-world scenarios."}, "https://arxiv.org/abs/2406.17144": {"title": "An information-geometric approach for network decomposition using the q-state Potts model", "link": "https://arxiv.org/abs/2406.17144", "description": "arXiv:2406.17144v1 Announce Type: cross \nAbstract: Complex networks are critical in many scientific, technological, and societal contexts due to their ability to represent and analyze intricate systems with interdependent components. Often, after labeling the nodes of a network with a community detection algorithm, its modular organization emerges, allowing a better understanding of the underlying structure by uncovering hidden relationships. In this paper, we introduce a novel information-geometric framework for the filtering and decomposition of networks whose nodes have been labeled. Our approach considers the labeled network as the outcome of a Markov random field modeled by a q-state Potts model. According to information geometry, the first and second order Fisher information matrices are related to the metric and curvature tensor of the parametric space of a statistical model. By computing an approximation to the local shape operator, the proposed methodology is able to identify low and high information nodes, allowing the decomposition of the labeled network in two complementary subgraphs. Hence, we call this method as the LO-HI decomposition. Experimental results with several kinds of networks show that the high information subgraph is often related to edges and boundaries, while the low information subgraph is a smoother version of the network, in the sense that the modular structure is improved."}, "https://arxiv.org/abs/2406.17518": {"title": "Enhancing Explainability of Knowledge Learning Paths: Causal Knowledge Networks", "link": "https://arxiv.org/abs/2406.17518", "description": "arXiv:2406.17518v1 Announce Type: cross \nAbstract: A reliable knowledge structure is a prerequisite for building effective adaptive learning systems and intelligent tutoring systems. Pursuing an explainable and trustworthy knowledge structure, we propose a method for constructing causal knowledge networks. This approach leverages Bayesian networks as a foundation and incorporates causal relationship analysis to derive a causal network. Additionally, we introduce a dependable knowledge-learning path recommendationHuman-Centric eXplainable AI in Education technique built upon this framework, improving teaching and learning quality while maintaining transparency in the decision-making process."}, "https://arxiv.org/abs/2406.17572": {"title": "Ranking nodes in bipartite systems with a non-linear iterative map", "link": "https://arxiv.org/abs/2406.17572", "description": "arXiv:2406.17572v1 Announce Type: cross \nAbstract: This paper introduces a method based on a non-linear iterative map to evaluate node relevance in bipartite networks. By tuning a single parameter gamma, the method captures different concepts of node importance, including established measures like degree centrality, eigenvector centrality and the fitness-complexity ranking used in economics. The algorithm's flexibility allows for efficient ranking optimization tailored to specific tasks. As an illustrative example, we apply this method to ecological mutualistic networks, where ranking quality can be assessed by the extinction area - the rate at which the system collapses when species are removed in a certain order. The map with the optimal gamma value, which is dataset-specific, surpasses existing ranking methods on this task. Additionally, our method excels in evaluating nestedness, another crucial structural property of ecological systems, requiring specific node rankings. The final part of the paper explores the theoretical aspects of the map, revealing a phase transition at a critical $\\gamma$ value dependent on the data structure that can be characterized analytically for random networks. Near the critical point, the map exhibits unique features and a distinctive triangular packing pattern of the adjacency matrix."}, "https://arxiv.org/abs/2207.01830": {"title": "Optimal Verification of Rumors in Networks", "link": "https://arxiv.org/abs/2207.01830", "description": "arXiv:2207.01830v2 Announce Type: replace-cross \nAbstract: We study the diffusion of a true and a false message when agents are biased and able to verify messages. As a recipient of a rumor who verifies it becomes informed of the truth, a higher rumor prevalence can increase the prevalence of the truth. We uncover conditions such that this happens and discuss policy implications. Specifically, a planner aiming to maximize the prevalence of the truth should allow rumors to circulate if: verification overcomes ignorance of messages, transmission of information is relatively low, and the planner's budget to induce verification is neither too low nor too high."}, "https://arxiv.org/abs/2210.04359": {"title": "Fine-Grained Detection of Solidarity for Women and Migrants in 155 Years of German Parliamentary Debates", "link": "https://arxiv.org/abs/2210.04359", "description": "arXiv:2210.04359v2 Announce Type: replace-cross \nAbstract: Solidarity is a crucial concept to understand social relations in societies. In this paper, we explore fine-grained solidarity frames to study solidarity towards women and migrants in German parliamentary debates between 1867 and 2022. Using 2,864 manually annotated text snippets (with a cost exceeding 18k Euro), we evaluate large language models (LLMs) like Llama 3, GPT-3.5, and GPT-4. We find that GPT-4 outperforms other LLMs, approaching human annotation quality. Using GPT-4, we automatically annotate more than 18k further instances (with a cost of around 500 Euro) across 155 years and find that solidarity with migrants outweighs anti-solidarity but that frequencies and solidarity types shift over time. Most importantly, group-based notions of (anti-)solidarity fade in favor of compassionate solidarity, focusing on the vulnerability of migrant groups, and exchange-based anti-solidarity, focusing on the lack of (economic) contribution. Our study highlights the interplay of historical events, socio-economic needs, and political ideologies in shaping migration discourse and social cohesion. We also show that powerful LLMs, if carefully prompted, can be cost-effective alternatives to human annotation for hard social scientific tasks."}, "https://arxiv.org/abs/2401.11116": {"title": "Effects of Research Paper Promotion via ArXiv and X", "link": "https://arxiv.org/abs/2401.11116", "description": "arXiv:2401.11116v2 Announce Type: replace-cross \nAbstract: In the evolving landscape of scientific publishing, it is important to understand the drivers of high-impact research, to equip scientists with actionable strategies to enhance the reach of their work, and to understand trends in the use of modern scientific publishing tools to inform their further development. Here, we study trends in the use of early preprint publications and revisions on ArXiv and the use of X (formerly Twitter) for promotion of such papers in computer science and physics. We find that early submissions to ArXiv and promotion on X have soared in recent years. Estimating the effect that the use of each of these modern affordances has on the number of citations of scientific publications, we find that peer-reviewed conference papers in computer science that are submitted early to ArXiv gain on average $21.1 \\pm 17.4$ more citations, revised on ArXiv gain $18.4 \\pm 17.6$ more citations, and promoted on X gain $44.4 \\pm 8$ more citations in the first 5 years from an initial publication. In contrast, journal articles in physics experience comparatively lower boosts in citation counts, with increases of $3.9 \\pm 1.1$, $4.3 \\pm 0.9$, and $6.9 \\pm 3.5$ citations respectively for the same interventions. Our results show that promoting one's work on ArXiv or X has a large impact on the number of citations, as well as the number of influential citations computed by Semantic Scholar, and thereby on the career of researchers. These effects are present also for publications in physics, but they are relatively smaller. The larger relative effect sizes, effects of promotion accumulating over time, and elevated unpredictability of the number of citations in computer science than in physics suggest a greater role of world-of-mouth spreading in computer science than in physics."}, "https://arxiv.org/abs/2403.14431": {"title": "Breaking Consensus in Kinetic Opinion Formation Models on Graphons", "link": "https://arxiv.org/abs/2403.14431", "description": "arXiv:2403.14431v2 Announce Type: replace-cross \nAbstract: In this work we propose and investigate a strategy to prevent consensus in kinetic models for opinion formation. We consider a large interacting agent system, and assume that agent interactions are driven by compromise as well as self-thinking dynamics and also modulated by an underlying static social network. This network structure is included using so-called graphons, which modulate the interaction frequency in the corresponding kinetic formulation. We then derive the corresponding limiting Fokker Planck equation, and analyze its large time behavior. This microscopic setting serves as a starting point for the proposed control strategy, which steers agents away from mean opinion and is characterised by a suitable penalization depending on the properties of the graphon. We show that this minimalist approach is very effective by analyzing the quasi-stationary solutions mean-field model in a plurality of graphon structures. Several numerical experiments are also provided to show the effectiveness of the approach in preventing the formation of consensus steering the system towards a declustered state."}, "https://arxiv.org/abs/2406.17904": {"title": "Application of Liquid Rank Reputation System for Twitter Trend Analysis on Bitcoin", "link": "https://arxiv.org/abs/2406.17904", "description": "arXiv:2406.17904v1 Announce Type: new \nAbstract: Analyzing social media trends can create a win-win situation for both creators and consumers. Creators can receive fair compensation, while consumers gain access to engaging, relevant, and personalized content. This paper proposes a new model for analyzing Bitcoin trends on Twitter by incorporating a 'liquid democracy' approach based on user reputation. This system aims to identify the most impactful trends and their influence on Bitcoin prices and trading volume. It uses a Twitter sentiment analysis model based on a reputation rating system to determine the impact on Bitcoin price change and traded volume. In addition, the reputation model considers the users' higher-order friends on the social network (the initial Twitter input channels in our case study) to improve the accuracy and diversity of the reputation results. We analyze Bitcoin-related news on Twitter to understand how trends and user sentiment, measured through our Liquid Rank Reputation System, affect Bitcoin price fluctuations and trading activity within the studied time frame. This reputation model can also be used as an additional layer in other trend and sentiment analysis models. The paper proposes the implementation, challenges, and future scope of the liquid rank reputation model."}, "https://arxiv.org/abs/2406.17993": {"title": "Anatomizing Societal Recovery at the Microscale: Heterogeneity in Household Lifestyle Activities Rebounding after Disasters", "link": "https://arxiv.org/abs/2406.17993", "description": "arXiv:2406.17993v1 Announce Type: new \nAbstract: This study presents a granular analysis of societal recovery from disasters at the individual level, focusing on the aftermath of Hurricane Harvey and Hurricane Ida. Societal recovery is defined as the restoration of the societal functioning of the affected community to its normal/steady-state level. It evaluates the recovery of impacted residents based on fluctuations in their lifestyle patterns in visits to points of interest. The analysis focuses on: (1) the extent of heterogeneity in lifestyle recovery of residents in the same spatial area; and (2) the extent to which variations in lifestyle recovery and its heterogeneity among users can be explained based on hazard impact extent and social vulnerability. As lifestyle recovery progresses, heterogeneity diminishes, indicating that lower lifestyle recovery rates correlate with higher heterogeneity within a spatial area. This relationship between lifestyle recovery and heterogeneity can lead to the misestimation of recovery timelines, potentially resulting in the inefficient allocation of resources and disproportionate attention to already recovering communities. Key contributions of the study are fourfold: First, it characterizes societal recovery at the finest scale by examining fluctuations in individual lifestyles, revealing heterogeneity even among neighbors. Second, it proposes using individual lifestyle as an indicator of societal functioning to measure, more human centrically, disaster impacts and recovery speeds. Third, it introduces a method for quantifying lifestyle recovery that enables near-real-time monitoring, departing from traditional survey-based methods. Fourth, it provides empirical insights into the relationship between disaster impacts and societal recovery, showing that the severity of disaster impacts and resident income levels and percentage of minority populations influence recovery durations."}, "https://arxiv.org/abs/2406.18168": {"title": "Emergence of social hierarchies in a society with two competitive classes", "link": "https://arxiv.org/abs/2406.18168", "description": "arXiv:2406.18168v1 Announce Type: new \nAbstract: Agent-based models describing social interactions among individuals can help to better understand emerging macroscopic patterns in societies. One of the topics which is worth tackling is the formation of different kinds of hierarchies that emerge in social spaces such as cities. Here we propose a Bonabeau-like model by adding a second class of agents. The fundamental particularity of our model is that only a pairwise interaction between agents of the opposite class is allowed. Agent fitness can thus only change by competition among the two classes, while the total fitness in the society remains constant. The main result is that for a broad range of values of the model parameters, the fitness of the agents of each class show a decay in time except for one or very few agents which capture almost all the fitness in the society. Numerical simulations also reveal a singular shift from egalitarian to hierarchical society for each class. This behaviour depends on the control parameter $\\eta$, playing the role of the inverse of the temperature of the system. Results are invariant with regard to the system size, contingent solely on the quantity of agents within each class. Finally, a couple of scaling laws are provided thus showing a data collapse from different model parameters and they follow a shape which can be related to the presence of a phase transition in the model."}, "https://arxiv.org/abs/2406.18503": {"title": "From Tweet to Theft: Tracing the Flow of Stolen Cryptocurrency", "link": "https://arxiv.org/abs/2406.18503", "description": "arXiv:2406.18503v1 Announce Type: new \nAbstract: This paper presents a case study of a cryptocurrency scam that utilized coordinated and inauthentic behavior on Twitter. In 2020, 143 accounts sold by an underground merchant were used to orchestrate a fake giveaway. Tweets pointing to a fake blog post lured victims into sending Uniswap tokens (UNI) to designated addresses on the Ethereum blockchain, with the false promise of receiving more tokens in return. Using one of the scammer's addresses and leveraging the transparency and immutability of the Ethereum blockchain, we traced the flow of stolen funds through various addresses, revealing the tactics adopted to obfuscate traceability. The final destination of the funds involved two deposit addresses. The first, managed by a well-known cryptocurrency exchange, was likely associated with the scammer's own account on that platform and saw deposits exceeding $3.5 million. The second address was linked to a popular cryptocurrency swap service. These findings highlight the critical need for more stringent measures to verify the source of funds and prevent illicit activities."}, "https://arxiv.org/abs/2406.17836": {"title": "A Moonshot for AI Oracles in the Sciences", "link": "https://arxiv.org/abs/2406.17836", "description": "arXiv:2406.17836v1 Announce Type: cross \nAbstract: Nobel laureate Philip Anderson and Elihu Abrahams once stated that, \"even if machines did contribute to normal science, we see no mechanism by which they could create a Kuhnian revolution and thereby establish a new physical law.\" In this Perspective, we draw upon insights from the philosophies of science and artificial intelligence (AI) to propose necessary conditions of precisely such a mechanism for generating revolutionary mathematical theories. Recent advancements in AI suggest that satisfying the proposed necessary conditions by machines may be plausible; thus, our proposed necessary conditions also define a moonshot challenge. We also propose a heuristic definition of the intelligibility of mathematical theories to accelerate the development of machine theorists."}, "https://arxiv.org/abs/2406.17918": {"title": "GraphSnapShot: Graph Machine Learning Acceleration with Fast Storage and Retrieval", "link": "https://arxiv.org/abs/2406.17918", "description": "arXiv:2406.17918v1 Announce Type: cross \nAbstract: In our recent research, we have developed a framework called GraphSnapShot, which has been proven an useful tool for graph learning acceleration. GraphSnapShot is a framework for fast cache, storage, retrieval and computation for graph learning. It can quickly store and update the local topology of graph structure and allows us to track patterns in the structure of graph networks, just like take snapshots of the graphs. In experiments, GraphSnapShot shows efficiency, it can achieve up to 30% training acceleration and 73% memory reduction for lossless graph ML training compared to current baselines such as dgl.This technique is particular useful for large dynamic graph learning tasks such as social media analysis and recommendation systems to process complex relationships between entities."}, "https://arxiv.org/abs/2406.17963": {"title": "Empowering Interdisciplinary Insights with Dynamic Graph Embedding Trajectories", "link": "https://arxiv.org/abs/2406.17963", "description": "arXiv:2406.17963v1 Announce Type: cross \nAbstract: We developed DyGETViz, a novel framework for effectively visualizing dynamic graphs (DGs) that are ubiquitous across diverse real-world systems. This framework leverages recent advancements in discrete-time dynamic graph (DTDG) models to adeptly handle the temporal dynamics inherent in dynamic graphs. DyGETViz effectively captures both micro- and macro-level structural shifts within these graphs, offering a robust method for representing complex and massive dynamic graphs. The application of DyGETViz extends to a diverse array of domains, including ethology, epidemiology, finance, genetics, linguistics, communication studies, social studies, and international relations. Through its implementation, DyGETViz has revealed or confirmed various critical insights. These include the diversity of content sharing patterns and the degree of specialization within online communities, the chronological evolution of lexicons across decades, and the distinct trajectories exhibited by aging-related and non-related genes. Importantly, DyGETViz enhances the accessibility of scientific findings to non-domain experts by simplifying the complexities of dynamic graphs. Our framework is released as an open-source Python package for use across diverse disciplines. Our work not only addresses the ongoing challenges in visualizing and analyzing DTDG models but also establishes a foundational framework for future investigations into dynamic graph representation and analysis across various disciplines."}, "https://arxiv.org/abs/2403.06641": {"title": "Socio-spatial segregation and human mobility: A review of empirical evidence", "link": "https://arxiv.org/abs/2403.06641", "description": "arXiv:2403.06641v3 Announce Type: replace \nAbstract: Social segregation, the spatial and social separation between individuals from different backgrounds, can affect sustainable urban development and social cohesion. The literature has traditionally focused on residential segregation, examining how individuals' residential locations are distributed differently across neighborhoods based on income, ethnicity, and education. However, this approach overlooks the complexity of spatial segregation because daily activities often extend far beyond residential areas. Since the 2010s, emerging mobility data sources have enabled a new understanding of socio-spatial segregation by considering daily activities such as work, school, shopping, and leisure visits. From traditional surveys to GPS trajectories, diverse data sources reveal that day-to-day mobility can impact segregation by reducing or amplifying segregation levels obtained when considering residential aspects alone. This literature review focuses on three critical questions: (a) How do human mobility patterns relate to individuals' segregation experiences? (b) What key factors explain the relationship between one's mobility patterns and segregation experiences? and (c) What are the strengths and limitations of segregation research that incorporates extensive mobility data? Our literature review enhances the understanding of socio-spatial segregation at the individual level and clarifies core concepts and methodological challenges in the field. By incorporating studies from computational social science, urban science, and transportation, our review aims to provide actionable insights for reducing segregation and addressing research gaps in this increasingly interdisciplinary area."}, "https://arxiv.org/abs/2302.08829": {"title": "Great year, bad Sharpe? A note on the joint distribution of performance and risk-adjusted return", "link": "https://arxiv.org/abs/2302.08829", "description": "arXiv:2302.08829v2 Announce Type: replace-cross \nAbstract: Returns distributions are heavy-tailed across asset classes. In this note, I examine the implications of this well-known stylized fact for the joint statistics of performance (absolute return) and Sharpe ratio (risk-adjusted return). Using both synthetic and real data, I show that, all other things being equal, the investments with the best in-sample performance are never associated with the best in-sample Sharpe ratios (and vice versa). This counter-intuitive effect is unrelated to the risk-return tradeoff familiar from portfolio theory: it is, rather, a consequence of asymptotic correlations between the sample mean and sample standard deviation of heavy-tailed variables. In addition to its large sample noise, this non-monotonic association of the Sharpe ratio with performance puts into question its status as the gold standard metric of investment quality."}, "https://arxiv.org/abs/2311.00721": {"title": "Empathy Detection from Text, Audiovisual, Audio or Physiological Signals: Task Formulations and Machine Learning Methods", "link": "https://arxiv.org/abs/2311.00721", "description": "arXiv:2311.00721v2 Announce Type: replace-cross \nAbstract: Empathy indicates an individual's ability to understand others. Over the past few years, empathy has drawn attention from various disciplines, including but not limited to Affective Computing, Cognitive Science and Psychology. Detecting empathy has potential applications in society, healthcare and education. Despite being a broad and overlapping topic, the avenue of empathy detection leveraging Machine Learning remains underexplored from a systematic literature review perspective. We collected 828 papers from 10 well-known databases, systematically screened them and analysed the final 61 papers. Our analyses reveal several prominent task formulations $-$ including empathy on localised utterances or overall expressions, unidirectional or parallel empathy, and emotional contagion $-$ in monadic, dyadic and group interactions. Empathy detection methods are summarised based on four input modalities $-$ text, audiovisual, audio and physiological signals $-$ thereby presenting modality-specific network architecture design protocols. We discuss challenges, research gaps and potential applications in the Affective Computing-based empathy domain, which can facilitate new avenues of exploration. We further enlist the public availability of datasets and codes. We believe that our work is a stepping stone to developing a robust empathy detection system that can be deployed in practice to enhance the overall well-being of human life."}, "https://arxiv.org/abs/2406.18617": {"title": "Similarities among top one day batters: physics-based quantification", "link": "https://arxiv.org/abs/2406.18617", "description": "arXiv:2406.18617v1 Announce Type: new \nAbstract: Assessment of the performance of a player in any sport is very much needed to determine the ranking of players and make a solid team with the best players. Besides these, fans, journalists, sports persons, and sports councils often analyse the performances of current and retired players to identify the best players of all time. Here, we study the performance of all-time top batters in one-day cricket using physics-based statistical methods. The batters are selected in this study who possess either higher total runs or a high number of centuries. It is found that the total runs increases linearly with the innings number at the later stage of the batter carrier, and the runs rate estimated from the linear regression analysis also increases linearly with the average runs. The probability of non-scoring innings is found to be a negligibly small number (i.e., $\\leq 0.1$ ) for each batter. Furthermore, based on innings-wise runs, we have computed the six-dimensional probability distribution vector for each player. Two components of the probability distribution vector vary linearly with average runs. The component representing the probability of scoring runs less than 50 linearly decreases with the average runs. In contrast, the probability of scoring runs greater than or equal to 100 and less than 150 linearly increases with the average runs. We have also estimated the entropy to assess the diversity of a player. Interestingly, the entropy varies linearly with the average runs, giving rise to two clusters corresponding to the old and recent players. Furthermore, the angle between two probability vectors is calculated for each pair of players to measure the similarities among the players. It is found that some of the players are almost identical to each other."}, "https://arxiv.org/abs/2406.18761": {"title": "Why Teach Quantum In Your Own Time: The Values of Grassroots Organizations Involved in Quantum Technologies Education and Outreach", "link": "https://arxiv.org/abs/2406.18761", "description": "arXiv:2406.18761v1 Announce Type: new \nAbstract: This paper examines the intersection of goals and values within grassroots organizations operating in the realm of quantum technologies (QT) education. It delineates a fundamental distinction between the objective to provide education and the drive to democratize learning through principles of inclusivity, accessibility, and diversity. The analysis reveals how these organizations navigate their nascent stages, grappling with the dual challenge of adhering to their foundational values while aspiring for sustainable growth and development in the highly specialized field of QT. The study uncovers the strategic approaches adopted by these entities, including efforts to create educational ecosystems and foster community engagement. The research underscores the potential vulnerabilities of these grassroots organizations, particularly in relation to the longevity and evolution of their initiatives as members transition into professional roles within the quantum sector. Through this investigation, the paper contributes to a nuanced understanding of how emerging educational organizations in the QT field balance their ideological commitments with practical growth considerations, highlighting the critical factors that influence their trajectory and impact."}, "https://arxiv.org/abs/2406.18780": {"title": "Investigation on centrality measures and opinion dynamics in two-layer networks with replica nodes", "link": "https://arxiv.org/abs/2406.18780", "description": "arXiv:2406.18780v1 Announce Type: new \nAbstract: We examine two-layer networks and centrality measures defined on them. The propose two fast and accurate algorithms to approximate the game-theoretic centrality measures and examine connection between centrality measures and characteristics of opinion dynamic processes on such networks. As an example, we consider a Zachary's karate club social network and extend it by adding the second (internal) layer of communication. Internal layer represents the idea that individuals can share their real opinions with their close friends. The structures of the external and internal layers may be different. As characteristics of of opinion dynamic processes we mean consensus time and winning rate of a particular opinion. We find significantly strong positive correlation between internal graph density and consensus time, and significantly strong negative correlation between centrality of authoritative nodes and consensus time."}, "https://arxiv.org/abs/2406.18792": {"title": "A data-driven assessment of biomedical terminology evolution using information theoretical and network analysis approaches", "link": "https://arxiv.org/abs/2406.18792", "description": "arXiv:2406.18792v1 Announce Type: new \nAbstract: The Medical Subject Headings (MeSH), one of the main knowledge organization systems in the biomedical domain, is constantly evolving following the latest scientific discoveries in health and life sciences. Previous research focused on quantifying information in MeSH using its hierarchical structure. In this work, we propose a data-driven approach based on information theory and network analyses to quantify the knowledge evolution in MeSH and the relevance of its individual concepts. Our approach leverages article annotations and their citation networks to compute the level of informativeness, usefulness, disruptiveness, and influence of MeSH concepts over time. The citation network includes the instances of MeSH concepts or MeSH headings, and the concept relevance is calculated individually. Then, this computation is propagated to the hierarchy to establish the relevance of a concept. We quantitatively evaluated our approach using changes in the MeSH terminology and showed that it effectively captures the evolution of the terminology. Moreover, we validated the ability of our framework to characterize retracted articles and show that concepts used to annotate retracted articles differ substantially from those used to annotate non-retracted. The proposed framework provides an effective method to rank concept relevance and can be useful in maintaining evolving knowledge organization systems."}, "https://arxiv.org/abs/2406.19079": {"title": "Oligopoly Game Stabilisation Through Multilayer Congestion Dynamics", "link": "https://arxiv.org/abs/2406.19079", "description": "arXiv:2406.19079v1 Announce Type: new \nAbstract: International trade and logistics are subject to factors including geopolitical instability, climate change, and black swan events such as the unforeseen closure of the Suez Canal. The problem of predicting local price change under modification of an underlying transport network or change in supply characteristics unites elements of game theory, network theory and transport. The Cournot Oligopoly models economic actors as rational players attempting to maximise profit by optimising supply quantities with analytical results now consolidated about equilibrium characteristics where transport conditions are fixed. Similarly, where supply and demand are fixed, the routing of goods in a transport network can be analytically solved through a traffic assignment problem. Hence we can solve the coupled Cournot-congestion problem by means of a 2-layer network. Where the layers are linked, inter-layer feedback wherein players attempt to maximise their utility occurs. In this respect we find players benefit from taking advantage of non-simultaneous responses to the market rather than moving to a new equilibrium. We draw conclusions about the nature of equilibria, finding that the concave utility curve property results in unique and stable equilibrium for each uncoupled layer, while linked layers have a non-unique stable equilibria for which general solutions are stated."}, "https://arxiv.org/abs/2406.19149": {"title": "\"A network of mutualities of being\": socio-material archaeological networks and biological ties at \\c{C}atalh\\\"oy\\\"uk", "link": "https://arxiv.org/abs/2406.19149", "description": "arXiv:2406.19149v1 Announce Type: new \nAbstract: Recent advances in archaeogenomics have granted access to previously unavailable biological information with the potential to further our understanding of past social dynamics at a range of scales. However, to properly integrate these data within archaeological narratives, new methodological and theoretical tools are required. Effort must be put into finding new methods for weaving together different datasets where material culture and archaeogenomic data are both constitutive elements. This is true on a small scale, when we study relationships at the individual level, and at a larger scale when we deal with social and population dynamics. Specifically, in the study of kinship systems it is essential to contextualize and make sense of biological relatedness through social relations, which, in archaeology, is achieved by using material culture as a proxy. In this paper we propose a Network Science framework to integrate archaeogenomic data and material culture at an intrasite scale to study biological relatedness and social organization at the Neolithic site of \\c{C}atalh\\\"oy\\\"uk. Methodologically, we propose the use of network variance to investigate the concentration of biological relatedness and material culture within networks of houses. This approach allowed us to observe how material culture similarity between buildings gives valuable information on potential biological relationships between individuals and how biogenetic ties concentrate at specific localities on site."}, "https://arxiv.org/abs/2406.19204": {"title": "CoDiNG -- Naming Game with Continuous Latent State of Agents", "link": "https://arxiv.org/abs/2406.19204", "description": "arXiv:2406.19204v1 Announce Type: new \nAbstract: Understanding the mechanisms behind opinion formation is crucial for gaining insight into the processes that shape political beliefs, cultural attitudes, consumer choices, and social movements. This work aims to explore a nuanced model that captures the intricacies of real-world opinion dynamics by synthesizing principles from cognitive science and employing social network analysis. The proposed model is a hybrid continuous-discrete extension of the well-known Naming Game opinion model. The added latent continuous layer of opinion strength follows cognitive processes in the human brain, akin to memory imprints. The discrete layer allows for the conversion of intrinsic continuous opinion into discrete form, which often occurs when we publicly verbalize our opinions. We evaluated our model using real data as ground truth and demonstrated that the proposed mechanism outperforms the classic Naming Game model in many cases, reflecting that our model is closer to the real process of opinion formation."}, "https://arxiv.org/abs/2406.19277": {"title": "The Emergence of Threads: The Birth of a New Social Network", "link": "https://arxiv.org/abs/2406.19277", "description": "arXiv:2406.19277v1 Announce Type: new \nAbstract: Threads, a new microblogging platform from Meta, was launched in July 2023. In contrast to prior new platforms, Threads was borne out of an existing parent platform, Instagram, for which all users must already possess an account. This offers a unique opportunity to study platform evolution, to understand how one existing platform can support the \"birth\" of another. With this in mind, this paper provides an initial exploration of Threads, contrasting it with its parent, Instagram. We compare user behaviour within and across the two social media platforms, focusing on posting frequency, content preferences, and engagement patterns. Utilising a temporal analysis framework, we identify consistent daily posting trends on the parent platform and uncover contrasting behaviours when comparing intra-platform and cross-platform activities. Our findings reveal that Threads engages more with political and AI-related topics, compared to Instagram which focuses more on lifestyle and fashion topics. Our analysis also shows that user activities align more closely on weekends across both platforms. Engagement analysis suggests that users prefer to post about topics that garner more likes and that topic consistency is maintained when users transition from Instagram to Threads. Our research provides insights into user behaviour and offers a basis for future studies on Threads."}, "https://arxiv.org/abs/2406.18596": {"title": "Uniform Stability of Dynamic SICA HIV Transmission Models on Time Scales", "link": "https://arxiv.org/abs/2406.18596", "description": "arXiv:2406.18596v1 Announce Type: cross \nAbstract: We consider a SICA model for HIV transmission on time scales. We prove permanence of solutions and we derive sufficient conditions for the existence and uniform asymptotic stability of a unique positive almost periodic solution of the system in terms of a Lyapunov function."}, "https://arxiv.org/abs/2406.18854": {"title": "What Is Missing In Homophily? Disentangling Graph Homophily For Graph Neural Networks", "link": "https://arxiv.org/abs/2406.18854", "description": "arXiv:2406.18854v1 Announce Type: cross \nAbstract: Graph homophily refers to the phenomenon that connected nodes tend to share similar characteristics. Understanding this concept and its related metrics is crucial for designing effective Graph Neural Networks (GNNs). The most widely used homophily metrics, such as edge or node homophily, quantify such \"similarity\" as label consistency across the graph topology. These metrics are believed to be able to reflect the performance of GNNs, especially on node-level tasks. However, many recent studies have empirically demonstrated that the performance of GNNs does not always align with homophily metrics, and how homophily influences GNNs still remains unclear and controversial. Then, a crucial question arises: What is missing in our current understanding of homophily? To figure out the missing part, in this paper, we disentangle the graph homophily into $3$ aspects: label, structural, and feature homophily, providing a more comprehensive understanding of GNN performance. To investigate their synergy, we propose a Contextual Stochastic Block Model with $3$ types of Homophily (CSBM-3H), where the topology and feature generation are controlled by the $3$ metrics. Based on the theoretical analysis of CSBM-3H, we derive a new composite metric, named Tri-Hom, that considers all $3$ aspects and overcomes the limitations of conventional homophily metrics. The theoretical conclusions and the effectiveness of Tri-Hom have been verified through synthetic experiments on CSBM-3H. In addition, we conduct experiments on $31$ real-world benchmark datasets and calculate the correlations between homophily metrics and model performance. Tri-Hom has significantly higher correlation values than $17$ existing metrics that only focus on a single homophily aspect, demonstrating its superiority and the importance of homophily synergy. Our code is available at \\url{https://github.com/zylMozart/Disentangle_GraphHom}."}, "https://arxiv.org/abs/2406.19222": {"title": "The myth of declining competitive balance in the UEFA Champions League group stage", "link": "https://arxiv.org/abs/2406.19222", "description": "arXiv:2406.19222v1 Announce Type: cross \nAbstract: According to previous studies, competitive balance has significantly declined in the UEFA Champions League group stage over the recent decades. Our paper introduces six alternative indices for measuring ex ante and ex post competitive balance in order to explore the robustness of these results. The ex ante measures are based on Elo ratings, while the ex post measures compare the group ranking to reasonable benchmarks. We find no evidence of any trend in the competitive balance of the UEFA Champions League group stage between the 2003/04 and 2023/24 seasons."}, "https://arxiv.org/abs/2307.08564": {"title": "Shaping New Norms for AI", "link": "https://arxiv.org/abs/2307.08564", "description": "arXiv:2307.08564v2 Announce Type: replace \nAbstract: As Artificial Intelligence (AI) becomes increasingly integrated into our lives, the need for new norms is urgent. However, AI evolves at a much faster pace than the characteristic time of norm formation, posing an unprecedented challenge to our societies. This paper examines possible criticalities of the processes of norm formation surrounding AI. Thus, it focuses on how new norms can be established, rather than on what these norms should be. It distinguishes different scenarios based on the centralisation or decentralisation of the norm formation process, analysing the cases where new norms are shaped by formal authorities, informal institutions, or emerge spontaneously in a bottom-up fashion. On the latter point, the paper reports a conversation with ChatGPT in which the LLM discusses some of the emerging norms it has observed. Far from seeking exhaustiveness, this article aims to offer readers interpretive tools to understand society's response to the growing pervasiveness of AI. An outlook on how AI could influence the formation of future social norms emphasises the importance for open societies to anchor their formal deliberation process in an open, inclusive, and transparent public discourse."}, "https://arxiv.org/abs/2311.16360": {"title": "Geometrics of the Adjacent Possible: Harvesting Values at the Curvature", "link": "https://arxiv.org/abs/2311.16360", "description": "arXiv:2311.16360v2 Announce Type: replace \nAbstract: Novelty alone is not sufficient for innovation. For new ideas and products to thrive, they must find their place within the existing societal fabric, such as institutions, conventions, and infrastructures that have been built over time. Past successes create inertia, favoring conservative advances. Here, we develop a quantitative framework to map the contours of the adjacent possible in the presence of the power of typicality. Typical assemblies, frequently combined building blocks in past innovations, compress and curve the space of possibilities toward what is imaginable, accessible, and implementable, much like gravitational forces on new ideas and actions. We demonstrate that these curvatures in the space of possibilities are not just abstract constructs but empirically measurable through two complementary studies. We first show that Edison's inventions are primarily located in areas of high curvature, aligning with his strategy of building upon institutionalized domains. In contrast, Tesla's inventions are mainly found in low-curvature areas, indicating his propensity for exploring new territories and pushing innovation boundaries. Further analysis of the entire U.S. patent database reveals that innovations in high-curvature areas are more likely to yield monetary value. High-curvature areas indicate windows of opportunity through the interplay between innovation and convention, explaining why commercially successful ideas often emerge at the fringes of institutionalized domains."}, "https://arxiv.org/abs/2302.03228": {"title": "Heterophily-Aware Graph Attention Network", "link": "https://arxiv.org/abs/2302.03228", "description": "arXiv:2302.03228v2 Announce Type: replace-cross \nAbstract: Graph Neural Networks (GNNs) have shown remarkable success in graph representation learning. Unfortunately, current weight assignment schemes in standard GNNs, such as the calculation based on node degrees or pair-wise representations, can hardly be effective in processing the networks with heterophily, in which the connected nodes usually possess different labels or features. Existing heterophilic GNNs tend to ignore the modeling of heterophily of each edge, which is also a vital part in tackling the heterophily problem. In this paper, we firstly propose a heterophily-aware attention scheme and reveal the benefits of modeling the edge heterophily, i.e., if a GNN assigns different weights to edges according to different heterophilic types, it can learn effective local attention patterns, which enable nodes to acquire appropriate information from distinct neighbors. Then, we propose a novel Heterophily-Aware Graph Attention Network (HA-GAT) by fully exploring and utilizing the local distribution as the underlying heterophily, to handle the networks with different homophily ratios. To demonstrate the effectiveness of the proposed HA-GAT, we analyze the proposed heterophily-aware attention scheme and local distribution exploration, by seeking for an interpretation from their mechanism. Extensive results demonstrate that our HA-GAT achieves state-of-the-art performances on eight datasets with different homophily ratios in both the supervised and semi-supervised node classification tasks."}, "https://arxiv.org/abs/2310.17171": {"title": "Estimating True Beliefs in Opinion Dynamics with Social Pressure", "link": "https://arxiv.org/abs/2310.17171", "description": "arXiv:2310.17171v2 Announce Type: replace-cross \nAbstract: Social networks often exert social pressure, causing individuals to adapt their expressed opinions to conform to their peers. An agent in such systems can be modeled as having a (true and unchanging) inherent belief while broadcasting a declared opinion at each time step based on her inherent belief and the past declared opinions of her neighbors. An important question in this setting is parameter estimation: how to disentangle the effects of social pressure to estimate inherent beliefs from declared opinions. This is useful for forecasting when agents' declared opinions are influenced by social pressure while real-world behavior only depends on their inherent beliefs. To address this, Jadbabaie et al. formulated the Interacting P\\'olya Urn model of opinion dynamics under social pressure and studied it on complete-graph social networks using an aggregate estimator, and found that their estimator converges to the inherent beliefs unless majority pressure pushes the network to consensus.\n  In this work, we studythis model on arbitrary networks, providing an estimator which converges to the inherent beliefs even in consensus situations. Finally, we bound the convergence rate of our estimator in both consensus and non-consensus scenarios; to get the bound for consensus scenarios (which converge slower than non-consensus) we additionally found how quickly the system converges to consensus."}, "https://arxiv.org/abs/2406.19554": {"title": "A Network-Based Measure of Cosponsorship Influence on Bill Passing in the United States House of Representatives", "link": "https://arxiv.org/abs/2406.19554", "description": "arXiv:2406.19554v1 Announce Type: new \nAbstract: Each year, the United States Congress considers {thousands of legislative proposals to select bills} to present to the US President to sign into law. Naturally, the decision processes of members of Congress are subject to peer influence. In this paper, we examine the effect on bill passage of accrued influence between US Congress members in the US House of Representatives. We explore how the influence of a bill's cosponsors affects the bill's outcome (specifically, whether or not it passes in the House). We define a notion of influence by analyzing the structure of a network that we construct {using} cosponsorship dynamics. We award `influence' between a pair of Congress members when they cosponsor a bill that achieves some amount of legislative success. We find that properties of the bill cosponsorship network can be a useful signal to examine influence in Congress; they help explain why some bills pass and others fail. We compare our measure of influence to off-the-shelf centrality measures and conclude that our influence measure is more indicative of bill passage."}, "https://arxiv.org/abs/2406.19571": {"title": "Reranking Social Media Feeds: A Practical Guide for Field Experiments", "link": "https://arxiv.org/abs/2406.19571", "description": "arXiv:2406.19571v1 Announce Type: new \nAbstract: Social media plays a central role in shaping public opinion and behavior, yet performing experiments on these platforms and, in particular, on feed algorithms is becoming increasingly challenging. This article offers practical recommendations to researchers developing and deploying field experiments focused on real-time re-ranking of social media feeds. This article is organized around two contributions. First, we overview an experimental method using web browser extensions that intercepts and re-ranks content in real-time, enabling naturalistic re-ranking field experiments. We then describe feed interventions and measurements that this paradigm enables on participants' actual feeds, without requiring the involvement of social media platforms. Second, we offer concrete technical recommendations for intercepting and re-ranking social media feeds with minimal user-facing delay, and provide an open-source implementation. This document aims to summarize lessons learned, provide concrete implementation details, and foster the ecosystem of independent social media research."}, "https://arxiv.org/abs/2406.19692": {"title": "Steering cooperation: Adversarial attacks on prisoner's dilemma in complex networks", "link": "https://arxiv.org/abs/2406.19692", "description": "arXiv:2406.19692v1 Announce Type: new \nAbstract: This study examines the application of adversarial attack concepts to control the evolution of cooperation in the prisoner's dilemma game in complex networks. Specifically, it proposes a simple adversarial attack method that drives players' strategies towards a target state by adding small perturbations to social networks. The proposed method is evaluated on both model and real-world networks. Numerical simulations demonstrate that the proposed method can effectively promote cooperation with significantly smaller perturbations compared to other techniques. Additionally, this study shows that adversarial attacks can also be useful in inhibiting cooperation (promoting defection). The findings reveal that adversarial attacks on social networks can be potent tools for both promoting and inhibiting cooperation, opening new possibilities for controlling cooperative behavior in social systems while also highlighting potential risks."}, "https://arxiv.org/abs/2406.19867": {"title": "Sampled Datasets Risk Substantial Bias in the Identification of Political Polarization on Social Media", "link": "https://arxiv.org/abs/2406.19867", "description": "arXiv:2406.19867v1 Announce Type: new \nAbstract: Following recent policy changes by X (Twitter) and other social media platforms, user interaction data has become increasingly difficult to access. These restrictions are impeding robust research pertaining to social and political phenomena online, which is critical due to the profound impact social media platforms may have on our societies. Here, we investigate the reliability of polarization measures obtained from different samples of social media data by studying the structural polarization of the Polish political debate on Twitter over a 24-hour period. First, we show that the political discussion on Twitter is only a small subset of the wider Twitter discussion. Second, we find that large samples can be representative of the whole political discussion on a platform, but small samples consistently fail to accurately reflect the true structure of polarization online. Finally, we demonstrate that keyword-based samples can be representative if keywords are selected with great care, but that poorly selected keywords can result in substantial political bias in the sampled data. Our findings demonstrate that it is not possible to measure polarization in a reliable way with small, sampled datasets, highlighting why the current lack of research data is so problematic, and providing insight into the practical implementation of the European Union's Digital Service Act which aims to improve researchers' access to social media data."}, "https://arxiv.org/abs/2406.19878": {"title": "A political radicalization framework based on Moral Foundations Theory", "link": "https://arxiv.org/abs/2406.19878", "description": "arXiv:2406.19878v1 Announce Type: new \nAbstract: Moral Foundations Theory proposes that individuals with conflicting political views base their behavior on different principles chosen from a small group of universal moral foundations. This study proposes using a set of widely accepted moral foundations (Fairness, Ingroup loyalty, Authority, and Purity) as proxies to determine the degree of radicalization of online communities. The fifth principle, Care, is generally surpassed by others, which are higher in the radicalized groups' moral hierarchy. Moreover, the presented data-driven methodological framework proposes an alternative way to measure whether a community complies with some moral principle or foundation: not evaluating its speech, but its behavior through interactions of its individuals, establishing a bridge between structural features of the interaction network and the intensity of communities' radicalization regarding the considered moral foundations. Two foundations may be assessed using the network's structural characteristics: Ingroup loyalty measured by group-level modularity, and Authority evaluated using group domination for detecting potential hierarchical substructures within the network. By analyzing the set of Pareto-optimal groups regarding a multidimensional moral relevance scale, the most radicalized communities are identified among those considered extreme in some of their attitudes or views. The application of the proposed framework is illustrated using real-world datasets. The radicalized communities' behavior exhibits increasing isolation, and its authorities and leaders show growing domination over their audience. There were also detected differences between users' behavior and speech, showing that individuals tend to share more 'extreme' ingroup content than that they publish: extreme views get more likes on social media."}, "https://arxiv.org/abs/2406.19953": {"title": "Uncovering the hidden core-periphery structure in hyperbolic networks", "link": "https://arxiv.org/abs/2406.19953", "description": "arXiv:2406.19953v1 Announce Type: new \nAbstract: The hyperbolic network models exhibit very fundamental and essential features, like small-worldness, scale-freeness, high-clustering coefficient, and community structure. In this paper, we comprehensively explore the presence of an important feature, the core-periphery structure, in the hyperbolic network models, which is often exhibited by real-world networks. We focused on well-known hyperbolic models such as popularity-similarity optimization model (PSO) and S1/H2 models and studied core-periphery structures using a well-established method that is based on standard random walk Markov chain model. The observed core-periphery centralization values indicate that the core-periphery structure can be very pronounced under certain conditions. We also validate our findings by statistically testing for the significance of the observed core-periphery structure in the network geometry. This study extends network science and reveals core-periphery insights applicable to various domains, enhancing network performance and resiliency in transportation and information systems."}, "https://arxiv.org/abs/2406.19543": {"title": "Demarked: A Strategy for Enhanced Abusive Speech Moderation through Counterspeech, Detoxification, and Message Management", "link": "https://arxiv.org/abs/2406.19543", "description": "arXiv:2406.19543v1 Announce Type: cross \nAbstract: Despite regulations imposed by nations and social media platforms, such as recent EU regulations targeting digital violence, abusive content persists as a significant challenge. Existing approaches primarily rely on binary solutions, such as outright blocking or banning, yet fail to address the complex nature of abusive speech. In this work, we propose a more comprehensive approach called Demarcation scoring abusive speech based on four aspect -- (i) severity scale; (ii) presence of a target; (iii) context scale; (iv) legal scale -- and suggesting more options of actions like detoxification, counter speech generation, blocking, or, as a final measure, human intervention. Through a thorough analysis of abusive speech regulations across diverse jurisdictions, platforms, and research papers we highlight the gap in preventing measures and advocate for tailored proactive steps to combat its multifaceted manifestations. Our work aims to inform future strategies for effectively addressing abusive speech online."}, "https://arxiv.org/abs/2406.19679": {"title": "Statistical Analysis on Scale and Regional Distribution of Undergraduate Physics Programs in Korean Universities", "link": "https://arxiv.org/abs/2406.19679", "description": "arXiv:2406.19679v1 Announce Type: cross \nAbstract: We report on the temporal changes in undergraduate-level physics programs at Korean universities from 1915 to 2023 by analyzing data on physics-related departments and their students using basic statistics and the scaling theory of statistical physics. Our analysis reveals that the number of departments peaked around the turn of the 21st century, and it has been steadily decreasing ever since, with particularly severe declines in private universities located outside the capital region. Besides the change in the overall numbers, we also show the change in the self-identity of physics-related departments reflected in department names, which reveals a recent trend of emphasizing more application-side such as semiconductors and data. As a sophisticated measure to quantify regional imbalances relative to the population eligible for higher education, we present scaling exponents from the scaling theory, which shows a shift from sublinear to linear for departments and a shift from linear to superlinear for students. The result indicates the exacerbation of the regional imbalance of university-level physics education in Korea."}, "https://arxiv.org/abs/2304.12559": {"title": "Attraction by pairwise coherence explains the emergence of ideological sorting", "link": "https://arxiv.org/abs/2304.12559", "description": "arXiv:2304.12559v4 Announce Type: replace \nAbstract: Political polarization has become a growing concern in democratic societies, as it drives tribal alignments and erodes civic deliberation among citizens. Given its prevalence across different countries, previous research has sought to understand under which conditions people tend to endorse extreme opinions. However, in polarized contexts, citizens not only adopt more extreme views but also become correlated across issues that are, a priori, seemingly unrelated. This phenomenon, known as \"ideological sorting\", has been receiving greater attention in recent years but the micro-level mechanisms underlying its emergence remain poorly understood. Here, we study the conditions under which a social dynamic system is expected to become ideologically sorted as a function of the mechanisms of interaction between its individuals. To this end, we developed and analyzed a multidimensional agent-based model that incorporates two mechanisms: homophily (where people tend to interact with those holding similar opinions) and pairwise-coherence favoritism (where people tend to interact with ingroups holding politically coherent opinions). We numerically integrated the model's master equations that perfectly describe the system's dynamics and found that ideological sorting only emerges in models that include pairwise-coherence favoritism. We then compared the model's outcomes with empirical data from 24,035 opinions across 67 topics and found that pairwise-coherence favoritism is significantly present in datasets that measure political attitudes but absent across topics not considered related to politics. Overall, this work combines theoretical approaches from system dynamics with model-based analyses of empirical data to uncover a potential mechanism underlying the pervasiveness of ideological sorting."}, "https://arxiv.org/abs/2403.00195": {"title": "The evolution of pluralistic ignorance", "link": "https://arxiv.org/abs/2403.00195", "description": "arXiv:2403.00195v2 Announce Type: replace \nAbstract: Pluralistic ignorance is a social-psychological phenomenon that occurs when individuals privately hold beliefs that differ from perceived group norms. Traditional models, based on opinion dynamics with private and public states, fail to account for a key aspect: when nonexpression aligns with normative behavior, initial social pressure can induce pluralistic ignorance. We show that pluralistic ignorance persists under infrequent imitation and strong initial minority influence. Although individuals can overcome this ignorance by the end of interactions, it reemerges in subsequent meetings. However, excessive imitation erases pluralistic ignorance, leading to a uniform state in which internal and external states align. Furthermore, incorporating memory into the internalization process shows that pluralistic ignorance peaks at moderate imitation levels."}, "https://arxiv.org/abs/2303.17001": {"title": "The G-invariant graph Laplacian", "link": "https://arxiv.org/abs/2303.17001", "description": "arXiv:2303.17001v4 Announce Type: replace-cross \nAbstract: Graph Laplacian based algorithms for data lying on a manifold have been proven effective for tasks such as dimensionality reduction, clustering, and denoising. In this work, we consider data sets whose data points lie on a manifold that is closed under the action of a known unitary matrix Lie group G. We propose to construct the graph Laplacian by incorporating the distances between all the pairs of points generated by the action of G on the data set. We deem the latter construction the ``G-invariant Graph Laplacian'' (G-GL). We show that the G-GL converges to the Laplace-Beltrami operator on the data manifold, while enjoying a significantly improved convergence rate compared to the standard graph Laplacian which only utilizes the distances between the points in the given data set. Furthermore, we show that the G-GL admits a set of eigenfunctions that have the form of certain products between the group elements and eigenvectors of certain matrices, which can be estimated from the data efficiently using FFT-type algorithms. We demonstrate our construction and its advantages on the problem of filtering data on a noisy manifold closed under the action of the special unitary group SU(2)."}, "https://arxiv.org/abs/2305.05833": {"title": "A Statistical Model of Bipartite Networks: Application to Cosponsorship in the United States Senate", "link": "https://arxiv.org/abs/2305.05833", "description": "arXiv:2305.05833v2 Announce Type: replace-cross \nAbstract: Many networks in political and social research are bipartite, with edges connecting exclusively across two distinct types of nodes. A common example includes cosponsorship networks, in which legislators are connected indirectly through the bills they support. Yet most existing network models are designed for unipartite networks, where edges can arise between any pair of nodes. However, using a unipartite network model to analyze bipartite networks, as often done in practice, can result in aggregation bias and artificially high-clustering -- a particularly insidious problem when studying the role groups play in network formation. To address these methodological problems, we develop a statistical model of bipartite networks theorized to be generated through group interactions by extending the popular mixed-membership stochastic blockmodel. Our model allows researchers to identify the groups of nodes, within each node type in the bipartite structure, that share common patterns of edge formation. The model also incorporates both node and dyad-level covariates as the predictors of group membership and of observed dyadic relations. We develop an efficient computational algorithm for fitting the model, and apply it to cosponsorship data from the United States Senate. We show that legislators in a Senate that was perfectly split along party lines were able to remain productive and pass major legislation by forming non-partisan, power-brokering coalitions that found common ground through their collaboration on low-stakes bills. We also find evidence for norms of reciprocity, and uncover the substantial role played by policy expertise in the formation of cosponsorships between senators and legislation. We make an open-source software package available that makes it possible for other researchers to uncover similar insights from bipartite networks."}, "https://arxiv.org/abs/2306.02766": {"title": "Networked Communication for Decentralised Agents in Mean-Field Games", "link": "https://arxiv.org/abs/2306.02766", "description": "arXiv:2306.02766v3 Announce Type: replace-cross \nAbstract: We introduce networked communication to the mean-field game framework, in particular to oracle-free settings where $N$ decentralised agents learn along a single, non-episodic run of the empirical system. We prove that our architecture, with only a few reasonable assumptions about network structure, has sample guarantees bounded between those of the centralised- and independent-learning cases. We discuss how the sample guarantees of the three theoretical algorithms do not actually result in practical convergence. We therefore show that in practical settings where the theoretical parameters are not observed (leading to poor estimation of the Q-function), our communication scheme significantly accelerates convergence over the independent case (and often even the centralised case), without relying on the assumption of a centralised learner. We contribute further practical enhancements to all three theoretical algorithms, allowing us to present their first empirical demonstrations. Our experiments confirm that we can remove several of the theoretical assumptions of the algorithms, and display the empirical convergence benefits brought by our new networked communication. We additionally show that the networked approach has significant advantages, over both the centralised and independent alternatives, in terms of robustness to unexpected learning failures and to changes in population size."}, "https://arxiv.org/abs/2307.14270": {"title": "Socioeconomic agents as active matter in nonequilibrium Sakoda-Schelling models", "link": "https://arxiv.org/abs/2307.14270", "description": "arXiv:2307.14270v2 Announce Type: replace-cross \nAbstract: How robust are socioeconomic agent-based models with respect to the details of the agents' decision rule? We tackle this question by considering an occupation model in the spirit of the Sakoda-Schelling model, historically introduced to shed light on segregation dynamics among human groups. For a large class of utility functions and decision rules, we pinpoint the nonequilibrium nature of the agent dynamics, while recovering the equilibrium-like phase separation phenomenology. Within the mean field approximation we show how the model can be mapped, to some extent, onto an active matter field description. Finally, we consider non-reciprocal interactions between two populations, and show how they can lead to non-steady macroscopic behavior. We believe our approach provides a unifying framework to further study geography-dependent agent-based models, notably paving the way for joint consideration of population and price dynamics within a field theoretic approach."}, "https://arxiv.org/abs/2407.00145": {"title": "Co-evolving networks for opinion and social dynamics in agent-based models", "link": "https://arxiv.org/abs/2407.00145", "description": "arXiv:2407.00145v1 Announce Type: new \nAbstract: The rise of digital social media has strengthened the coevolution of public opinions and social interactions, that shape social structures and collective outcomes in increasingly complex ways. Existing literature often explores this interplay as a one-directional influence, focusing on how opinions determine social ties within adaptive networks. However, this perspective overlooks the intrinsic dynamics driving social interactions, which can significantly influence how opinions form and evolve. In this work, we address this gap, by introducing the co-evolving opinion and social dynamics using stochastic agent-based models. Agents' mobility in a social space is governed by both their social and opinion similarity with others. Similarly, the dynamics of opinion formation is driven by the opinions of agents in their social vicinity. We analyze the underlying social and opinion interaction networks and explore the mechanisms influencing the appearance of emerging phenomena, like echo chambers and opinion consensus. To illustrate the model's potential for real-world analysis, we apply it to General Social Survey data on political identity and public opinion regarding governmental issues. Our findings highlight the model's strength in capturing the coevolution of social connections and individual opinions over time."}, "https://arxiv.org/abs/2407.00213": {"title": "Targeting influence in a harmonic opinion model", "link": "https://arxiv.org/abs/2407.00213", "description": "arXiv:2407.00213v1 Announce Type: new \nAbstract: Influence propagation in social networks is a central problem in modern social network analysis, with important societal applications in politics and advertising. A large body of work has focused on cascading models, viral marketing, and finite-horizon diffusion. There is, however, a need for more developed, mathematically principled \\emph{adversarial models}, in which multiple, opposed actors strategically select nodes whose influence will maximally sway the crowd to their point of view.\n  In the present work, we develop and analyze such a model based on harmonic functions and linear diffusion. We prove that our general problem is NP-hard and that the objective function is monotone and submodular; consequently, we can greedily approximate the solution within a constant factor. Introducing and analyzing a convex relaxation, we show that the problem can be approximately solved using smooth optimization methods. We illustrate the effectiveness of our approach on a variety of example networks."}, "https://arxiv.org/abs/2407.00254": {"title": "An Exhaustive Study of Two-Node McCulloch-Pitts Networks", "link": "https://arxiv.org/abs/2407.00254", "description": "arXiv:2407.00254v1 Announce Type: new \nAbstract: Boolean networks are widely used in computational biology, evolutionary studies, and social sciences. However, the set of all Boolean-function-defined networks are harder to study as a whole. On the other hand, McCulloch-Pitts gates are sparsely parameterized using only a few number of link strengths, making it possible to study and compare different networks models. We treat two-node McCulloch-Pitts systems as a minimal complex system. When the link strengths are discretized, $3^4=81$ network models or rules are organized in the rule space The limiting dynamics of each rule may depend on the choice of binary state value ([-1,1] or [0,1]), and on the treatment at the threshold point, leading to at least six variants. One variant with [-1,1] as the binary state value (V1 model) tends to have a more diverse dynamical behaviors with a mixture of multiple cycles and fixed points at the limiting state, whereas other variants tend to fall only to fixed-point limiting dynamics. We use V1 models to study the organization of rules with different dynamics in the rule space and robustness of limiting dynamics with respect to a mutation in the rule table, as well as the related phenomena of phase transition and edge-of-chaos. We use another variant (V4 models) with only the fixed-point limiting dynamics to study the robustness of limiting state with respect to perturbation of initial states. The two types of robustness do not seem to be associated with each other. Other aspects of fully discretized two-node MaCulloch-Pitts networks are also studied, including: the proposal of a seventh variant based on a difference equation; relation to Rene Thomas' two types of feedback loops; spectrum properties of state space transition matrix; and asynchronous updating. Our works also expand the concept of network motifs by allowing more finer details."}, "https://arxiv.org/abs/2407.00258": {"title": "Graph Simplification Solutions to the Street Intersection Miscount Problem", "link": "https://arxiv.org/abs/2407.00258", "description": "arXiv:2407.00258v1 Announce Type: new \nAbstract: Street intersection counts and densities are ubiquitous measures in transport geography and planning. However, typical street network data and typical street network analysis tools can substantially overcount them. This paper explains why this happens and introduces solutions to this problem. It presents the OSMnx package's algorithms to automatically simplify graph models of urban street networks -- via edge simplification and node consolidation -- resulting in faster, parsimonious models and more accurate network measures like intersection counts/densities, street segment lengths, and node degrees. Then it validates these algorithms and conducts a worldwide empirical assessment of count bias to quantify the motivating problem's prevalence. A full accounting of this bias and better methods to attenuate misrepresentations of intersections are necessary for data-driven, evidence-informed transport planning."}, "https://arxiv.org/abs/2407.00340": {"title": "The Echoes of the 'I': Tracing Identity with Demographically Enhanced Word Embeddings", "link": "https://arxiv.org/abs/2407.00340", "description": "arXiv:2407.00340v1 Announce Type: new \nAbstract: Identity is one of the most commonly studied constructs in social science. However, despite extensive theoretical work on identity, there remains a need for additional empirical data to validate and refine existing theories. This paper introduces a novel approach to studying identity by enhancing word embeddings with socio-demographic information. As a proof of concept, we demonstrate that our approach successfully reproduces and extends established findings regarding gendered self-views. Our methodology can be applied in a wide variety of settings, allowing researchers to tap into a vast pool of naturally occurring data, such as social media posts. Unlike similar methods already introduced in computer science, our approach allows for the study of differences between social groups. This could be particularly appealing to social scientists and may encourage the faster adoption of computational methods in the field."}, "https://arxiv.org/abs/2407.00355": {"title": "Global decomposition of networks into multiple cores formed by local hubs", "link": "https://arxiv.org/abs/2407.00355", "description": "arXiv:2407.00355v1 Announce Type: new \nAbstract: Networks are ubiquitous in various fields, representing systems where nodes and their interconnections constitute their intricate structures. We introduce a network decomposition scheme to reveal multiscale core-periphery structures lurking inside, using the concept of locally defined nodal hub centrality and edge-pruning techniques built upon it. We demonstrate that the hub-centrality-based edge pruning reveals a series of breaking points in network decomposition, which effectively separates a network into its backbone and shell structures. Our local-edge decomposition method iteratively identifies and removes locally least important nodes, and uncovers an onion-like hierarchical structure as a result. Compared with the conventional $k$-core decomposition method, our method based on relative information residing in local structures exhibits a clear advantage in terms of discovering locally crucial substructures. Furthermore, we introduce the core-periphery score to properly separate the core and periphery with our decomposition scheme. By extending the method combined with the network community structure, we successfully detect multiple core-periphery structures by decomposition inside each community. Moreover, the application of our decomposition to supernode networks defined from the communities reveals the intricate relation between the two representative mesoscale structures."}, "https://arxiv.org/abs/2407.00404": {"title": "The Uneven Impact of Mobility on the Segregation of Native and Foreign-born Individuals", "link": "https://arxiv.org/abs/2407.00404", "description": "arXiv:2407.00404v1 Announce Type: new \nAbstract: Segregation is a key challenge in promoting more diverse and inclusive cities. Research based on smartphone data has revealed that segregation can extend beyond residential areas into everyday activities like visiting shops and restaurants. The impact of these activities on segregation, however, is unclear. Some studies suggest that they promote mixing, while others indicate they reinforce segregation. Here, we elucidate how day-to-day mobility shapes overall segregation levels, looking at the distinctive segregation experienced by native and foreign-born individuals. Our study is based on ~320,000 smartphone trajectories collected in Sweden, where immigration creates profound divides. We find that while mobility levels generally promote mixing for native-born individuals, foreign-born individuals remain segregated in their out-of-home activities. Using counterfactual simulations, we show that this heterogeneous effect of mobility on experienced segregation results mainly from two mechanisms: homophily and limited travel, i.e., foreign-born individuals (i) prefer destinations visited by similar individuals, and (ii) have limited mobility ranges. We show that homophily plays a minor role, while limited mobility, associated with reduced transport access, limits opportunities for foreign-born to diversify their encounters. Our findings reconcile conflicting literature and suggest that enhancing transport accessibility in foreign-born areas could reduce social segregation."}, "https://arxiv.org/abs/2407.01106": {"title": "Indirect social influence and diffusion of innovations: An experimental approach", "link": "https://arxiv.org/abs/2407.01106", "description": "arXiv:2407.01106v1 Announce Type: new \nAbstract: A fundamental feature for understanding the diffusion of innovations through a social group is the manner in which we are influenced by our own social interactions. It is usually assumed that only direct interactions, those that form our social network, determine the dynamics of adopting innovations. Here, we put this assumption to the test by experimentally and theoretically studying the role of direct and indirect influences in the adoption of innovations. We perform experiments specifically designed to capture the influence that an individual receives from their direct social ties as well as from those socially close to them, as a function of the separation they have in their social network. The results of 21 experimental sessions with more than 590 participants show that the rate of adoption of an innovation is significantly influenced not only by our nearest neighbors but also by the second and third levels of influences an adopter has. Using a mathematical model that accounts for both direct and indirect interactions in a network, we fit the experimental results and determine the way in which influences decay with social distance. The results indicate that the strength of peer pressure on an adopter coming from its second and third circles of influence is approximately 2/3 and 1/3, respectively, relative to their closest neighbors. Our results strongly suggest that innovation adoption is a complex process in which an individual feels significant pressure not only from their direct ties but also by those socially close to them."}, "https://arxiv.org/abs/2407.01213": {"title": "EMIF: Evidence-aware Multi-source Information Fusion Network for Explainable Fake News Detection", "link": "https://arxiv.org/abs/2407.01213", "description": "arXiv:2407.01213v1 Announce Type: new \nAbstract: Extensive research on automatic fake news detection has been conducted due to the significant detrimental effects of fake news proliferation. Most existing approaches rely on a single source of evidence, such as comments or relevant news, to derive explanatory evidence for decision-making, demonstrating exceptional performance. However, their single evidence source suffers from two critical drawbacks: (i) noise abundance, and (ii) resilience deficiency. Inspired by the natural process of fake news identification, we propose an Evidence-aware Multi-source Information Fusion (EMIF) network that jointly leverages user comments and relevant news to make precise decision and excavate reliable evidence. To accomplish this, we initially construct a co-attention network to capture general semantic conflicts between comments and original news. Meanwhile, a divergence selection module is employed to identify the top-K relevant news articles with content that deviates the most from the original news, which ensures the acquisition of multiple evidence with higher objectivity. Finally, we utilize an inconsistency loss function within the evidence fusion layer to strengthen the consistency of two types of evidence, both negating the authenticity of the same news. Extensive experiments and ablation studies on real-world dataset FibVID show the effectiveness of our proposed model. Notably, EMIF shows remarkable robustness even in scenarios where a particular source of information is inadequate."}, "https://arxiv.org/abs/2407.01279": {"title": "Finding Hidden Swing Voters in the 2022 Italian Elections Twitter Discourse", "link": "https://arxiv.org/abs/2407.01279", "description": "arXiv:2407.01279v1 Announce Type: new \nAbstract: The global proliferation of social media platforms has transformed political communication, making the study of online interactions between politicians and voters crucial for understanding contemporary political discourse. In this work, we examine the dynamics of political messaging and voter behavior on Twitter during the 2022 Italian general elections. Specifically, we focus on voters who changed their political preferences over time (swing voters), identifying significant patterns of migration and susceptibility to propaganda messages. Our analysis reveals that during election periods, the popularity of politicians increases, and there is a notable variation in the use of persuasive language techniques, including doubt, loaded language, appeals to values, and slogans. Swing voters are more vulnerable to these propaganda techniques compared to non-swing voters, with differences in vulnerability patterns across various types of political shifts. These findings highlight the nuanced impact of social media on political opinion in Italy."}, "https://arxiv.org/abs/2407.01293": {"title": "Applying the Ego Network Model to Cross-Target Stance Detection", "link": "https://arxiv.org/abs/2407.01293", "description": "arXiv:2407.01293v1 Announce Type: new \nAbstract: Understanding human interactions and social structures is an incredibly important task, especially in such an interconnected world. One task that facilitates this is Stance Detection, which predicts the opinion or attitude of a text towards a target entity. Traditionally, this has often been done mainly via the use of text-based approaches, however, recent work has produced a model (CT-TN) that leverages information about a user's social network to help predict their stance, outperforming certain cross-target text-based approaches. Unfortunately, the data required for such graph-based approaches is not always available. This paper proposes two novel tools for Stance Detection: the Ego Network Model (ENM) and the Signed Ego Network Model (SENM). These models are founded in anthropological and psychological studies and have been used within the context of social network analysis and related tasks (e.g., link prediction). Stance Detection predictions obtained using these features achieve a level of accuracy similar to the graph-based features used by CT-TN while requiring less and more easily obtainable data. In addition to this, the performances of the inner and outer circles of the ENM, representing stronger and weaker social ties, respectively are compared. Surprisingly, the outer circles, which contain more numerous but less intimate connections, are more useful for predicting stance."}, "https://arxiv.org/abs/2407.01405": {"title": "Social Isolation, Digital Connection: COVID-19's Impact on Twitter Ego Networks", "link": "https://arxiv.org/abs/2407.01405", "description": "arXiv:2407.01405v1 Announce Type: new \nAbstract: One of the most impactful measures to fight the COVID-19 pandemic in its early first years was the lockdown, implemented by governments to reduce physical contact among people and minimize opportunities for the virus to spread. As people were compelled to limit their physical interactions and stay at home, they turned to online social platforms to alleviate feelings of loneliness. Ego networks represent how people organize their relationships due to human cognitive constraints that impose limits on meaningful interactions among people. Physical contacts were disrupted during the lockdown, causing socialization to shift entirely online, leading to a shift in socialization into online platforms. Our research aimed to investigate the impact of lockdown measures on online ego network structures potentially caused by the increase of cognitive expenses in online social networks. In particular, we examined a large Twitter dataset of users, covering 7 years of their activities. We found that during the lockdown, there was an increase in network sizes and a richer structure in social circles, with relationships becoming more intimate. Moreover, we observe that, after the lockdown measures were relaxed, these features returned to their pre-lockdown values."}, "https://arxiv.org/abs/2407.01460": {"title": "How Clustering Affects the Convergence of Decentralized Optimization over Networks: A Monte-Carlo-based Approach", "link": "https://arxiv.org/abs/2407.01460", "description": "arXiv:2407.01460v1 Announce Type: new \nAbstract: Decentralized algorithms have gained substantial interest owing to advancements in cloud computing, Internet of Things (IoT), intelligent transportation networks, and parallel processing over sensor networks. The convergence of such algorithms is directly related to specific properties of the underlying network topology. Specifically, the clustering coefficient is known to affect, for example, the controllability/observability and the epidemic growth over networks. In this work, we study the effects of the clustering coefficient on the convergence rate of networked optimization approaches. In this regard, we model the structure of large-scale distributed systems by random scale-free (SF) and clustered scale-free (CSF) networks and compare the convergence rate by tuning the network clustering coefficient. This is done by keeping other relevant network properties (such as power-law degree distribution, number of links, and average degree) unchanged. Monte-Carlo-based simulations are used to compare the convergence rate over many trials of SF graph topologies. Furthermore, to study the convergence rate over real case studies, we compare the clustering coefficient of some real-world networks with the eigenspectrum of the underlying network (as a measure of convergence rate). The results interestingly show higher convergence rate over low-clustered networks. This is significant as one can improve the learning rate of many existing decentralized machine-learning scenarios by tuning the network clustering."}, "https://arxiv.org/abs/2407.01471": {"title": "Tracking the 2024 US Presidential Election Chatter on Tiktok: A Public Multimodal Dataset", "link": "https://arxiv.org/abs/2407.01471", "description": "arXiv:2407.01471v1 Announce Type: new \nAbstract: This paper documents our release of a large-scale data collection of TikTok posts related to the upcoming 2024 U.S. Presidential Election. Our current data comprises 1.8 million videos published between November 1, 2023, and May 26, 2024. Its exploratory analysis identifies the most common keywords, hashtags, and bigrams in both Spanish and English posts, focusing on the election and the two main Presidential candidates, President Joe Biden and Donald Trump.\n  We utilized the TikTok Research API, incorporating various election-related keywords and hashtags, to capture the full scope of relevant content. To address the limitations of the TikTok Research API, we also employed third-party scrapers to expand our dataset. The dataset is publicly available at https://github.com/gabbypinto/US2024PresElectionTikToks"}, "https://arxiv.org/abs/2407.00042": {"title": "Module control of network analysis in psychopathology", "link": "https://arxiv.org/abs/2407.00042", "description": "arXiv:2407.00042v1 Announce Type: cross \nAbstract: The network approach to characterizing psychopathology departs from traditional latent categorical and dimensional approaches. Causal interplay among symptoms contributed to dynamic psychopathology system. Therefore, analyzing the symptom clusters is critical for understanding mental disorders. Furthermore, despite extensive research studying the topological features of symptom networks, the control relationships between symptoms remain largely unclear. Here, we present a novel systematizing concept, module control, to analyze the control principle of the symptom network at a module level. We introduce Module Control Network (MCN) to identify key modules that regulate the network's behavior. By applying our approach to a multivariate psychological dataset, we discover that non-emotional modules, such as sleep-related and stress-related modules, are the primary controlling modules in the symptom network. Our findings indicate that module control can expose central symptom cluster governing psychopathology network, offering novel insights into the underlying mechanisms of mental disorders and individualized approach to psychological interventions."}, "https://arxiv.org/abs/2407.00167": {"title": "Can GPT-4 Help Detect Quit Vaping Intentions? An Exploration of Automatic Data Annotation Approach", "link": "https://arxiv.org/abs/2407.00167", "description": "arXiv:2407.00167v1 Announce Type: cross \nAbstract: In recent years, the United States has witnessed a significant surge in the popularity of vaping or e-cigarette use, leading to a notable rise in cases of e-cigarette and vaping use-associated lung injury (EVALI) that caused hospitalizations and fatalities during the EVALI outbreak in 2019, highlighting the urgency to comprehend vaping behaviors and develop effective strategies for cessation. Due to the ubiquity of social media platforms, over 4.7 billion users worldwide use them for connectivity, communications, news, and entertainment with a significant portion of the discourse related to health, thereby establishing social media data as an invaluable organic data resource for public health research. In this study, we extracted a sample dataset from one vaping sub-community on Reddit to analyze users' quit-vaping intentions. Leveraging OpenAI's latest large language model GPT-4 for sentence-level quit vaping intention detection, this study compares the outcomes of this model against layman and clinical expert annotations. Using different prompting strategies such as zero-shot, one-shot, few-shot and chain-of-thought prompting, we developed 8 prompts with varying levels of detail to explain the task to GPT-4 and also evaluated the performance of the strategies against each other. These preliminary findings emphasize the potential of GPT-4 in social media data analysis, especially in identifying users' subtle intentions that may elude human detection."}, "https://arxiv.org/abs/2407.00347": {"title": "Resource Allocation and Secure Wireless Communication in the Large Model-based Mobile Edge Computing System", "link": "https://arxiv.org/abs/2407.00347", "description": "arXiv:2407.00347v1 Announce Type: cross \nAbstract: With the rapid advancement of large models and mobile edge computing, transfer learning, particularly through fine-tuning, has become crucial for adapting models to downstream tasks. Traditionally, this requires users to share their data with model owners for fine-tuning, which is not only costly but also raises significant privacy concerns. Furthermore, fine-tuning large-scale models is computationally intensive and often impractical for many users. To tackle these challenges, we introduce a system that combines offsite-tuning with physical-layer security, which provides local data owners with a lightweight adapter and a compressed emulator. Data owners then fine-tune the adapter locally and securely send it back to the model owners through a confidential channel for integration, ensuring privacy and resource conservation. Our paper focuses on optimizing computational resource allocation among data owners and the large model owner deployed on edge, and on the compression ratio of adapters. We incorporate a secrecy uplink channel to maximize the utility that we defined while minimizing system costs like energy consumption and delay. The optimization uses the Dinkelbach algorithm, fractional programming, successive convex approximation and alternating optimization. Experiments demonstrate our algorithm's superiority over existing methods."}, "https://arxiv.org/abs/2407.00940": {"title": "Unifying thermophotovoltaic performance metrics with technoeconomics", "link": "https://arxiv.org/abs/2407.00940", "description": "arXiv:2407.00940v1 Announce Type: cross \nAbstract: Thermophotovoltaics (TPV) are becoming a promising new heat engine with rapid recent gains in performance. Their performance is characterized by two metrics: efficiency and power density. As we bridge the gap between lab-scale and system-scale devices, we need to understand how each of these metrics impacts the technoeconomics of a TPV system. In this work, we develop a technoeconomic metric based on the levelized cost of electricity (LCOE) to understand how the metrics should be weighted relative to each other in terms of importance. We find that systems with high infrastructure and fuel costs should prioritize TPV efficiency, while systems where the TPV cell cost dominates should prioritize power density. We then evaluate how concrete cell improvements could improve the technoeconomics of five example systems, identifying the most impactful specific properties. Namely, improving spectral control with sub-bandgap reflectance is the most effective at reducing LCOE in systems with high infrastructure cost, while increasing view factor and reducing series resistance are most critical in systems with high TPV cell cost. Improving just 1-2 of these properties can reduce the LCOE by 30-50%. This study therefore helps researchers understand which performance metric is more important for their application and how to achieve high values of this performance metric."}, "https://arxiv.org/abs/2307.10279": {"title": "A conjecture on demographic mortality at high ages", "link": "https://arxiv.org/abs/2307.10279", "description": "arXiv:2307.10279v4 Announce Type: replace \nAbstract: The possibility of modeling and therefore predicting the trend of demographic mortality is of great scientific and social interest. The article presents and discusses the hypothesis that the demographic distribution of mortality in advanced ages converges asymptotically to an S-system distribution as lifespan increases. The statistical distribution of the S-system was introduced by the author in a 2022 paper and was derived by applying the methods of Fermi statistics to a cellular automaton acting as an \"arbitrary oscillator\". This distribution is here recalled and formalized analytically and its characteristics are described. The conjecture is based on two case studies: mortality in the United States from 1900 to 2017 and mortality in Italy from 1974 to 2019. The conjecture, applied to both case studies, appears reasonable. Tables and comparison figures are provided to support this. Finally, an attempt to predict demographic mortality behavior and limitations for the years to come is provided."}, "https://arxiv.org/abs/2401.08832": {"title": "From News Sharers to Post Viewers: How Topic Diversity and Conspiracy Theories Shape Engagement With Misinformation During a Health Crisis?", "link": "https://arxiv.org/abs/2401.08832", "description": "arXiv:2401.08832v2 Announce Type: replace \nAbstract: Engagement with misinformation on social media poses unprecedented threats to societal well-being, particularly during health crises when susceptibility to misinformation is heightened in a multi-topic context. This paper focuses on the COVID-19 pandemic and addresses a critical gap in understanding online engagement with multi-topic misinformation at two user levels: news sharers who share source news items on social media and post viewers who engage with online news posts. To this end, we conduct a comprehensive analysis of 7273 fact-checked source news claims related to COVID-19 and their associated posts on X, through the lens of topic diversity and conspiracy theories. We find that false news, particularly when accompanied by conspiracy theories, exhibits higher topic diversity than true news. At the news sharer level, false news has a longer lifetime and receives more posts on X than true news. Additionally, the integration of conspiracy theories is significantly associated with a longer lifetime for COVID-19 misinformation. However, topic diversity has no significant association with news sharer engagement in terms of news lifetime and the number of posts. At the post viewer level, contrary to the news sharer level, news posts characterized by heightened topic diversity receive more reposts, likes, and replies. Notably, post viewers tend to engage more with misinformation containing conspiracy narratives: false news posts that contain conspiracy theories, on average, receive 40.8% more reposts, 45.2% more likes, and 44.1% more replies compared to false news posts without conspiracy theories. Our findings suggest that news sharers and post viewers exhibit different engagement patterns on social media regarding topic diversity and conspiracy theories, offering valuable insights into designing targeted misinformation intervention strategies at both user levels."}, "https://arxiv.org/abs/2401.13054": {"title": "Frustrated Random Walks: A Fast Method to Compute Node Distances on Hypergraphs", "link": "https://arxiv.org/abs/2401.13054", "description": "arXiv:2401.13054v2 Announce Type: replace \nAbstract: A hypergraph is a generalization of a graph that arises naturally when attribute-sharing among entities is considered. Compared to graphs, hypergraphs have the distinct advantage that they contain explicit communities and are more convenient to manipulate. An open problem in hypergraph research is how to accurately and efficiently calculate node distances on hypergraphs. Estimating node distances enables us to find a node's nearest neighbors, which has important applications in such areas as recommender system, targeted ads, etc. In this paper, we propose using expected hitting times of random walks to compute hypergraph node distances. We note that simple random walks (SRW) cannot accurately compute node distances on highly complex real-world hypergraphs, which motivates us to introduce frustrated random walks (FRW) for this task. We further benchmark our method against DeepWalk, and show that while the latter can achieve comparable results, FRW has a distinct computational advantage in cases where the number of targets is fairly small. For such cases, we show that FRW runs in significantly shorter time than DeepWalk. Finally, we analyze the time complexity of our method, and show that for large and sparse hypergraphs, the complexity is approximately linear, rendering it superior to the DeepWalk alternative."}, "https://arxiv.org/abs/2402.03358": {"title": "A Comprehensive Survey on Graph Reduction: Sparsification, Coarsening, and Condensation", "link": "https://arxiv.org/abs/2402.03358", "description": "arXiv:2402.03358v4 Announce Type: replace \nAbstract: Many real-world datasets can be naturally represented as graphs, spanning a wide range of domains. However, the increasing complexity and size of graph datasets present significant challenges for analysis and computation. In response, graph reduction, or graph summarization, has gained prominence for simplifying large graphs while preserving essential properties. In this survey, we aim to provide a comprehensive understanding of graph reduction methods, including graph sparsification, graph coarsening, and graph condensation. Specifically, we establish a unified definition for these methods and introduce a hierarchical taxonomy to categorize the challenges they address. Our survey then systematically reviews the technical details of these methods and emphasizes their practical applications across diverse scenarios. Furthermore, we outline critical research directions to ensure the continued effectiveness of graph reduction techniques, as well as provide a comprehensive paper list at \\url{https://github.com/Emory-Melody/awesome-graph-reduction}. We hope this survey will bridge literature gaps and propel the advancement of this promising field."}, "https://arxiv.org/abs/2403.13450": {"title": "Complex Networks characterization of Indian Water Dam Systems and its topographic response", "link": "https://arxiv.org/abs/2403.13450", "description": "arXiv:2403.13450v2 Announce Type: replace \nAbstract: In this paper a Complex Network approach is taken to understand the salient features of Indian Water Dam Networks. Detailed analysis of 15 river basin networks have been carried out. The data has been taken from \"River Basin Atlas of India\" compiled by the Indian Space Research Organisation (ISRO) and Central Water Commission (CWC), Ministry of Water Resources, Government of India. The paper also investigates the correlation between various structural properties of the networks like total number of nodes, Link Density, Clustering Coefficient amongst each other and also with the Irrigation Potential and topographical features like the Elevation gradient of the region measured in meters. A mathematical model has also been proposed to understand the relation between irrigation potential measured in thousand hectares unit with the number of nodes, i.e. dams and barrages, to get a more quantitative understanding of the system. The paper also tries to observe the response of the network properties to actual topographical features of the region. This lays down a basic foundational work in understanding these water dam networks through a complex network approach over which further work can be done to make the predictions more efficient."}, "https://arxiv.org/abs/2404.02205": {"title": "A Holistic Indicator of Polarization to Measure Online Sexism", "link": "https://arxiv.org/abs/2404.02205", "description": "arXiv:2404.02205v2 Announce Type: replace \nAbstract: The online trend of the manosphere and feminist discourse on social networks requires a holistic measure of the level of sexism in an online community. This indicator is important for policymakers and moderators of online communities (e.g., subreddits) and computational social scientists, either to revise moderation strategies based on the degree of sexism or to match and compare the temporal sexism across different platforms and communities with real-time events and infer social scientific insights.\n  In this paper, we build a model that can provide a comparable holistic indicator of toxicity targeted toward male and female identity and male and female individuals. Despite previous supervised NLP methods that require annotation of toxic comments at the target level (e.g. annotating comments that are specifically toxic toward women) to detect targeted toxic comments, our indicator uses supervised NLP to detect the presence of toxicity and unsupervised word embedding association test to detect the target automatically.\n  We apply our model to gender discourse communities (e.g., r/TheRedPill, r/MGTOW, r/FemaleDatingStrategy) to detect the level of toxicity toward genders (i.e., sexism). Our results show that our framework accurately and consistently (93% correlation) measures the level of sexism in a community. We finally discuss how our framework can be generalized in the future to measure qualities other than toxicity (e.g. sentiment, humor) toward general-purpose targets and turn into an indicator of different sorts of polarizations."}, "https://arxiv.org/abs/2304.07203": {"title": "On the convergence of nonlinear averaging dynamics with three-body interactions on hypergraphs", "link": "https://arxiv.org/abs/2304.07203", "description": "arXiv:2304.07203v2 Announce Type: replace-cross \nAbstract: Complex networked systems in fields such as physics, biology, and social sciences often involve interactions that extend beyond simple pairwise ones. Hypergraphs serve as powerful modeling tools for describing and analyzing the intricate behaviors of systems with multi-body interactions. Herein, we investigate a discrete-time nonlinear averaging dynamics with three-body interactions: an underlying hypergraph, comprising triples as hyperedges, delineates the structure of these interactions, while the vertices update their states through a weighted, state-dependent average of neighboring pairs' states. This dynamics captures reinforcing group effects, such as peer pressure, and exhibits higher-order dynamical effects resulting from a complex interplay between initial states, hypergraph topology, and nonlinearity of the update. Differently from linear averaging dynamics on graphs with two-body interactions, this model does not converge to the average of the initial states but rather induces a shift. By assuming random initial states and by making some regularity and density assumptions on the hypergraph, we prove that the dynamics converges to a multiplicatively-shifted average of the initial states, with high probability. We further characterize the shift as a function of two parameters describing the initial state and interaction strength, as well as the convergence time as a function of the hypergraph structure."}, "https://arxiv.org/abs/2308.09790": {"title": "A Two-Part Machine Learning Approach to Characterizing Network Interference in A/B Testing", "link": "https://arxiv.org/abs/2308.09790", "description": "arXiv:2308.09790v2 Announce Type: replace-cross \nAbstract: The reliability of controlled experiments, commonly referred to as \"A/B tests,\" is often compromised by network interference, where the outcomes of individual units are influenced by interactions with others. Significant challenges in this domain include the lack of accounting for complex social network structures and the difficulty in suitably characterizing network interference. To address these challenges, we propose a machine learning-based method. We introduce \"causal network motifs\" and utilize transparent machine learning models to characterize network interference patterns underlying an A/B test on networks. Our method's performance has been demonstrated through simulations on both a synthetic experiment and a large-scale test on Instagram. Our experiments show that our approach outperforms conventional methods such as design-based cluster randomization and conventional analysis-based neighborhood exposure mapping. Our approach provides a comprehensive and automated solution to address network interference for A/B testing practitioners. This aids in informing strategic business decisions in areas such as marketing effectiveness and product customization."}, "https://arxiv.org/abs/2310.05070": {"title": "CO-ASnet :A Smart Contract Architecture Design based on Blockchain Technology with Active Sensor Networks", "link": "https://arxiv.org/abs/2310.05070", "description": "arXiv:2310.05070v2 Announce Type: replace-cross \nAbstract: The influence of opinion leaders impacts different aspects of social finance. How to analyse the utility of opinion leaders' influence in realizing assets on the blockchain and adopt a compliant regulatory scheme is worth exploring and pondering. Taking Musk's call on social media to buy Dogecoin as an example, this paper uses an event study to empirically investigate the phenomenon in which opinion leaders use ICOs (initial coin offerings) to exert influence. The results show that opinion leaders can use ICOs to influence the price of token assets with money and data traffic in their social network. They can obtain excess returns and reduce the cost of realization so that the closed loop of influence realization will be accelerated. Based on this phenomenon and the results of its impact, we use the ChainLink Oracle with Active Sensor Networks(CO-ASnet) to design a safe and applicable decentralized regulatory scheme that can constructively provide risk assessment strategies and early warning measures for token issuance. The influence realization of opinion leaders in blockchain issuance is bound to receive widespread attention, and this paper will provide an exemplary reference for regulators and enterprises to explore the boundaries of blockchain financial product development and governance."}, "https://arxiv.org/abs/2404.01216": {"title": "Novel Node Category Detection Under Subpopulation Shift", "link": "https://arxiv.org/abs/2404.01216", "description": "arXiv:2404.01216v2 Announce Type: replace-cross \nAbstract: In real-world graph data, distribution shifts can manifest in various ways, such as the emergence of new categories and changes in the relative proportions of existing categories. It is often important to detect nodes of novel categories under such distribution shifts for safety or insight discovery purposes. We introduce a new approach, Recall-Constrained Optimization with Selective Link Prediction (RECO-SLIP), to detect nodes belonging to novel categories in attributed graphs under subpopulation shifts. By integrating a recall-constrained learning framework with a sample-efficient link prediction mechanism, RECO-SLIP addresses the dual challenges of resilience against subpopulation shifts and the effective exploitation of graph structure. Our extensive empirical evaluation across multiple graph datasets demonstrates the superior performance of RECO-SLIP over existing methods. The experimental code is available at https://github.com/hsinghuan/novel-node-category-detection."}, "https://arxiv.org/abs/2407.01799": {"title": "Disentangling individual-level from location-based income uncovers socioeconomic preferential mobility and impacts segregation estimates", "link": "https://arxiv.org/abs/2407.01799", "description": "arXiv:2407.01799v1 Announce Type: new \nAbstract: Segregation encodes information about society, such as social cohesion, mixing, and inequality. However, most past and current studies tackled socioeconomic (SE) segregation by analyzing static aggregated mobility networks, often without considering further individual features beyond income and, most importantly, without distinguishing individual-level from location-based income. Accessing individual-level income may help mapping macroscopic behavior into more granular mobility patterns, hence impacting segregation estimates. Here we combine a mobile phone dataset of daily mobility flows across Spanish districts stratified and adjusted by age, gender and income with census data of districts median income. We build mobility-based SE assortativity matrices for multiple demographics and observe mobility patterns of three income groups with respect to location-based SE classes. We find that SE assortativity differs when isolating the mobility of specific income groups: we observe that groups prefer to visit areas with higher average income than their own, which we call preferential mobility. Our analysis suggests substantial differences between weekdays and weekends SE assortativity by age class, with weekends characterized by higher SE assortativity. Our modeling approach shows that the radiation model, which typically performs best at reproducing inter-municipal population mobility, best fits middle income and middle-aged flows, while performing worse on young and low income groups. Our double-sided approach, focusing on assortativity patterns and mobility modeling, suggests that state of the art mobility models fail at capturing preferential mobility behavior. Overall, our work indicates that mobility models considering the interplay of SE preferential behavior, age and gender gaps may sensibly improve the state of the art models performance."}, "https://arxiv.org/abs/2407.01820": {"title": "Exploring the Role of Randomization on Belief Rigidity in Online Social Networks", "link": "https://arxiv.org/abs/2407.01820", "description": "arXiv:2407.01820v1 Announce Type: new \nAbstract: People often stick to their existing beliefs, ignoring contradicting evidence or only interacting with those who reinforce their views. Social media platforms often facilitate such tendencies of homophily and echo-chambers as they promote highly personalized content to maximize user engagement. However, increased belief rigidity can negatively affect real-world policy decisions such as leading to climate change inaction and increased vaccine hesitancy. To understand and effectively tackle belief rigidity on online social networks, designing and evaluating various intervention strategies is crucial, and increasing randomization in the network can be considered one such intervention. In this paper, we empirically quantify the effects of a randomized social network structure on belief rigidity, specifically examining the potential benefits of introducing randomness into the network. We show that individuals' beliefs are positively influenced by peer opinions, regardless of whether those opinions are similar to or differ from their own by passively sensing belief rigidity through our experimental framework. Moreover, people incorporate a slightly higher variety of different peers (based on their opinions) into their networks when the recommendation algorithm provides them with diverse content, compared to when it provides them with similar content. Our results indicate that in some cases, there might be benefits to randomization, providing empirical evidence that a more randomized network could be a feasible way of helping people get out of their echo-chambers. Our findings have broader implications in computing and platform design of social media, and can help combat overly rigid beliefs in online social networks."}, "https://arxiv.org/abs/2407.02074": {"title": "CGAP: Urban Region Representation Learning with Coarsened Graph Attention Pooling", "link": "https://arxiv.org/abs/2407.02074", "description": "arXiv:2407.02074v1 Announce Type: new \nAbstract: The explosion of massive urban data recently has provided us with a valuable opportunity to gain deeper insights into urban regions and the daily lives of residents. Urban region representation learning emerges as a crucial realm for fulfilling this task. Among deep learning approaches, graph neural networks (GNNs) have shown promise, given that city elements can be naturally represented as nodes with various connections between them as edges. However, many existing GNN approaches encounter challenges such as over-smoothing and limitations in capturing information from nodes in other regions, resulting in the loss of crucial urban information and a decline in region representation performance. To address these challenges, we leverage urban graph structure information and introduce a hierarchical graph pooling process called Coarsened Graph Attention Pooling (CGAP). CGAP features local attention units to create coarsened intermediate graphs and global features. Additionally, by incorporating urban region graphs and global features into a global attention layer, we harness relational information to enhance representation effectiveness. Furthermore, CGAP integrates region attributes such as Points of Interest (POIs) and inter-regional contexts like human mobility, enabling the exploitation of multi-modal urban data for more comprehensive representation learning. Experiments on three downstream tasks related to the UN Sustainable Development Goals validate the effectiveness of region representations learned by our approach. Experimental results and analyses demonstrate that CGAP excels in various socioeconomic prediction tasks compared to competitive baselines."}, "https://arxiv.org/abs/2407.02290": {"title": "A systematic comparison of measures for k-anonymity in networks", "link": "https://arxiv.org/abs/2407.02290", "description": "arXiv:2407.02290v1 Announce Type: new \nAbstract: Privacy-aware sharing of network data is a difficult task due to the interconnectedness of individuals in networks. An important part of this problem is the inherently difficult question of how in a particular situation the privacy of an individual node should be measured. To that end, in this paper we propose a set of aspects that one should consider when choosing a measure for privacy. These aspects include the type of desired privacy and attacker scenario against which the measure protects, utility of the data, the type of desired output, and the computational complexity of the chosen measure. Based on these aspects, we provide a systematic overview of existing approaches in the literature. We then focus on a set of measures that ultimately enables our objective: sharing the anonymized full network dataset with limited disclosure risk. The considered measures, each based on the concept of k-anonymity, account for the structure of the surroundings of a certain node and differ in completeness and reach of the structural information taken into account. We present a comprehensive theoretical characterization as well as comparative empirical experiments on a wide range of real-world network datasets with up to millions of edges. We find that the choice of the measure has an enormous effect on aforementioned aspects. Most interestingly, we find that the most effective measures consider a greater node vicinity, yet utilize minimal structural information and thus use minimal computational resources. This finding has important implications for researchers and practitioners, who may, based on the recommendations given in this paper, make an informed choice on how to safely share large-scale network data in a privacy-aware manner."}, "https://arxiv.org/abs/2407.01788": {"title": "Impact of the Network Size and Frequency of Information Receipt on Polarization in Social Networks", "link": "https://arxiv.org/abs/2407.01788", "description": "arXiv:2407.01788v1 Announce Type: cross \nAbstract: Opinion Dynamics is an interdisciplinary area of research. Psychology and Sociology have proposed models of how individuals form opinions and how social interactions influence this process. Socio-Physicists have interpreted patterns in opinion formation as arising from non-linearity in the underlying process, shaping the models. Agent-based modeling has offered a platform to study the Opinion Dynamics of large groups. This paper recasts recent models in opinion formation into a proper dynamical system, injecting the idea of clock time into evolving opinions. The time interval between successive receipts of new information (frequency of information receipts) becomes a factor to study. Social media has shrunk time intervals between information receipts, increasing their frequency. The recast models show that shorter intervals and larger networks increase an individual's propensity for polarization, defined as an inability to hold a neutral opinion. A Polarization number based on sociological parameters is proposed, with critical values beyond which individuals are prone to polarization, depending on psychological parameters. Reduced time intervals and larger interacting groups can push the Polarization number to critical values, contributing to polarization. The Extent of Polarization is defined as the width of the region around neutral within which an individual cannot hold an opinion. Results are reported for model parameters found in the literature. The findings offer an opportunity to adjust model parameters to align with empirical evidence, aiding the study of Opinion Dynamics in large social networks using Agent-Based Modeling."}, "https://arxiv.org/abs/2407.01852": {"title": "Early-Career Researchers' Perspective on Future Colliders", "link": "https://arxiv.org/abs/2407.01852", "description": "arXiv:2407.01852v1 Announce Type: cross \nAbstract: Since its inception, the Large Hadron Collider (LHC) has significantly advanced particle physics and will continue to do so in the context of the High Luminosity LHC (HL-LHC) program to collect $3000$ fb$^{-1}$ by the end of 2041. The particle physics community worldwide is discussing which future collider could follow in the footsteps of the LHC and uncover yet inaccessible phenomena.\n  To foster the discussion on this important topic among the young particle physicist community, the Early-Career Researchers (ECR) panel of the European Committee for Future Colliders (ECFA) has organized the Future Colliders for Early-Career Researchers workshop at CERN in September 2023. This document aims to summarise this event and present the ECR perspective, outline the key questions that came up during the discussions, and explore how ECRs can influence the decision process of future colliders community and beyond."}, "https://arxiv.org/abs/2407.02018": {"title": "A Proposal for a FAIR Management of 3D Data in Cultural Heritage: The Aldrovandi Digital Twin Case", "link": "https://arxiv.org/abs/2407.02018", "description": "arXiv:2407.02018v1 Announce Type: cross \nAbstract: In this article we analyse 3D models of cultural heritage with the aim of answering three main questions: what processes can be put in place to create a FAIR-by-design digital twin of a temporary exhibition? What are the main challenges in applying FAIR principles to 3D data in cultural heritage studies and how are they different from other types of data (e.g. images) from a data management perspective? We begin with a comprehensive literature review touching on: FAIR principles applied to cultural heritage data; representation models; both Object Provenance Information (OPI) and Metadata Record Provenance Information (MRPI), respectively meant as, on the one hand, the detailed history and origin of an object, and - on the other hand - the detailed history and origin of the metadata itself, which describes the primary object (whether physical or digital); 3D models as cultural heritage research data and their creation, selection, publication, archival and preservation. We then describe the process of creating the Aldrovandi Digital Twin, by collecting, storing and modelling data about cultural heritage objects and processes. We detail the many steps from the acquisition of the Digital Cultural Heritage Objects (DCHO), through to the upload of the optimised DCHO onto a web-based framework (ATON), with a focus on open technologies and standards for interoperability and preservation. Using the FAIR Principles for Heritage Library, Archive and Museum Collections as a framework, we look in detail at how the Digital Twin implements FAIR principles at the object and metadata level. We then describe the main challenges we encountered and we summarise what seem to be the peculiarities of 3D cultural heritage data and the possible directions for further research in this field."}, "https://arxiv.org/abs/2407.02057": {"title": "HC-GLAD: Dual Hyperbolic Contrastive Learning for Unsupervised Graph-Level Anomaly Detection", "link": "https://arxiv.org/abs/2407.02057", "description": "arXiv:2407.02057v1 Announce Type: cross \nAbstract: Unsupervised graph-level anomaly detection (UGAD) has garnered increasing attention in recent years due to its significance. However, most existing methods only rely on traditional graph neural networks to explore pairwise relationships but such kind of pairwise edges are not enough to describe multifaceted relationships involving anomaly. There is an emergency need to exploit node group information which plays a crucial role in UGAD. In addition, most previous works ignore the global underlying properties (e.g., hierarchy and power-law structure) which are common in real-world graph datasets and therefore are indispensable factors on UGAD task. In this paper, we propose a novel Dual Hyperbolic Contrastive Learning for Unsupervised Graph-Level Anomaly Detection (HC-GLAD in short). To exploit node group connections, we construct hypergraphs based on gold motifs and subsequently perform hypergraph convolution. Furthermore, to preserve the hierarchy of real-world graphs, we introduce hyperbolic geometry into this field and conduct both graph and hypergraph embedding learning in hyperbolic space with hyperboloid model. To the best of our knowledge, this is the first work to simultaneously apply hypergraph with node group connections and hyperbolic geometry into this field. Extensive experiments on several real world datasets of different fields demonstrate the superiority of HC-GLAD on UGAD task. The code is available at https://github.com/Yali-F/HC-GLAD."}, "https://arxiv.org/abs/2407.02143": {"title": "Counterfactual Data Augmentation with Denoising Diffusion for Graph Anomaly Detection", "link": "https://arxiv.org/abs/2407.02143", "description": "arXiv:2407.02143v1 Announce Type: cross \nAbstract: A critical aspect of Graph Neural Networks (GNNs) is to enhance the node representations by aggregating node neighborhood information. However, when detecting anomalies, the representations of abnormal nodes are prone to be averaged by normal neighbors, making the learned anomaly representations less distinguishable. To tackle this issue, we propose CAGAD -- an unsupervised Counterfactual data Augmentation method for Graph Anomaly Detection -- which introduces a graph pointer neural network as the heterophilic node detector to identify potential anomalies whose neighborhoods are normal-node-dominant. For each identified potential anomaly, we design a graph-specific diffusion model to translate a part of its neighbors, which are probably normal, into anomalous ones. At last, we involve these translated neighbors in GNN neighborhood aggregation to produce counterfactual representations of anomalies. Through aggregating the translated anomalous neighbors, counterfactual representations become more distinguishable and further advocate detection performance. The experimental results on four datasets demonstrate that CAGAD significantly outperforms strong baselines, with an average improvement of 2.35% on F1, 2.53% on AUC-ROC, and 2.79% on AUC-PR."}, "https://arxiv.org/abs/2407.02396": {"title": "A refractory density approach to a multi-scale SEIRS epidemic model", "link": "https://arxiv.org/abs/2407.02396", "description": "arXiv:2407.02396v1 Announce Type: cross \nAbstract: We propose a novel multi-scale modeling framework for infectious disease spreading, borrowing ideas and modeling tools from the so-called Refractory Density (RD) approach. We introduce a microscopic model that describes the probability of infection for a single individual and the evolution of the disease within their body. From the individual-level description, we then present the corresponding population-level model of epidemic spreading on the mesoscopic and macroscopic scale. We conclude with numerical illustrations taking into account either a white Gaussian noise or an escape noise to showcase the potential of our approach in producing both transient and asymptotic complex dynamics as well as finite-size fluctuations consistently across multiple scales. A comparison with the epidemiology of coronaviruses is also given to corroborate the qualitative relevance of our new approach."}, "https://arxiv.org/abs/2303.08424": {"title": "Emergence of economic and social disparities through competitive gift-giving", "link": "https://arxiv.org/abs/2303.08424", "description": "arXiv:2303.08424v2 Announce Type: replace \nAbstract: Several tiers of social organization with varying economic and social disparities have been observed. However, a quantitative characterization of the types and the causal mechanisms for the transitions have hardly been explained. While anthropologists have emphasized that gift exchange, rather than market exchange, prevails in traditional societies and shapes social relations, few mathematical studies have explored its consequences for social organizations. In this study, we present a simple model of competitive gift-giving that describes how gifts bring goods to the recipient and honor to the donor, and simulate social change. Numerical simulations and an analysis of the corresponding mean-field theory demonstrate the transitions between the following four phases with different distribution shapes of wealth and social reputation: the band, without economic or social disparities; the tribe, with economic but without social disparities; the chiefdom, with both; and the kingdom, with economic disparity and weak social disparity except for an outlier, namely, the ``monarch''. The emergence of strong disparities is characterized by power law distributions and is attributed to the ``rich get richer'' process. In contrast, the absence of such a process leads to exponential distributions due to random fluctuations. The phases depend on the parameters characterizing the frequency and scale of gift interactions. Our findings provide quantitative criteria for classifying social organizations based on economic and social disparities, consistent with anthropological theory and empirical observations. Thus, we propose empirically measurable explanatory variables and characteristics for the evolution of social organizations. The constructive model, guided by social scientific theory, can provide the basic mechanistic explanation of social evolution and integrate theories of the social sciences."}, "https://arxiv.org/abs/2309.15176": {"title": "Robust Stance Detection: Understanding Public Perceptions in Social Media", "link": "https://arxiv.org/abs/2309.15176", "description": "arXiv:2309.15176v2 Announce Type: replace-cross \nAbstract: The abundance of social media data has presented opportunities for accurately determining public and group-specific stances around policy proposals or controversial topics. In contrast with sentiment analysis which focuses on identifying prevailing emotions, stance detection identifies precise positions (i.e., supportive, opposing, neutral) relative to a well-defined topic, such as perceptions toward specific global health interventions during the COVID-19 pandemic. Traditional stance detection models, while effective within their specific domain (e.g., attitudes towards masking protocols during COVID-19), often lag in performance when applied to new domains and topics due to changes in data distribution. This limitation is compounded by the scarcity of domain-specific, labeled datasets, which are expensive and labor-intensive to create. A solution we present in this paper combines counterfactual data augmentation with contrastive learning to enhance the robustness of stance detection across domains and topics of interest. We evaluate the performance of current state-of-the-art stance detection models, including a prompt-optimized large language model, relative to our proposed framework succinctly called STANCE-C3 (domain-adaptive Cross-target STANCE detection via Contrastive learning and Counterfactual generation). Empirical evaluations demonstrate STANCE-C3's consistent improvements over the baseline models with respect to accuracy across domains and varying focal topics. Despite the increasing prevalence of general-purpose models such as generative AI, specialized models such as STANCE-C3 provide utility in safety-critical domains wherein precision is highly valued, especially when a nuanced understanding of the concerns of different population segments could result in crafting more impactful public policies."}, "https://arxiv.org/abs/2310.05212": {"title": "Semiotics Networks Representing Perceptual Inference", "link": "https://arxiv.org/abs/2310.05212", "description": "arXiv:2310.05212v4 Announce Type: replace-cross \nAbstract: Every day, humans perceive objects and communicate these perceptions through various channels. In this paper, we present a computational model designed to track and simulate the perception of objects, as well as their representations as conveyed in communication.\n  We delineate two fundamental components of our internal representation, termed \"observed\" and \"seen\", which we correlate with established concepts in computer vision, namely encoding and decoding. These components are integrated into semiotic networks, which simulate perceptual inference of object perception and human communication.\n  Our model of object perception by a person allows us to define object perception by {\\em a network}. We demonstrate this with an example of an image baseline classifier by constructing a new network that includes the baseline classifier and an additional layer. This layer produces the images \"perceived\" by the entire network, transforming it into a perceptualized image classifier. This facilitates visualization of the acquired network.\n  Within our network, the image representations become more efficient for classification tasks when they are assembled and randomized. In our experiments, the perceptualized network outperformed the baseline classifier on MNIST training databases consisting of a restricted number of images.\n  Our model is not limited to persons and can be applied to any system featuring a loop involving the processing from \"internal\" to \"external\" representations."}, "https://arxiv.org/abs/2407.02548": {"title": "Speed-accuracy tradeoff and its effect in the game of cricket: predictive modeling from statistical mechanics perspective", "link": "https://arxiv.org/abs/2407.02548", "description": "arXiv:2407.02548v1 Announce Type: new \nAbstract: The speed-accuracy tradeoffs are prevalent in a wide range of physical systems. In this paper, we demonstrate speed-accuracy tradeoffs in the game of cricket, where 'batters' score runs on the balls bowled by the 'bowlers'. It is shown that the run scoring rate by a batter and the probability of dismissal follow a power-law relation. Due to availability of extensive data, game of cricket is an excellent model for the study of the effect of speed-accuracy tradeoff on the overall performance of the system. It is shown that the exponent of the power-law governs the nature of the adaptability of the player in different conditions and can be used for their assessment. Further, it is demonstrated that the players with extreme values of the power-law exponent are better suited for different playing conditions as compared to the ones with moderate values. These findings can be utilized to identify the potential of the cricket players for different game formats and can further help team management in devising strategies for the best outcomes with a given set of players."}, "https://arxiv.org/abs/2407.02603": {"title": "Heider balance on Archimedean lattices", "link": "https://arxiv.org/abs/2407.02603", "description": "arXiv:2407.02603v1 Announce Type: new \nAbstract: The phenomenon of Heider (structural) balance is known for a long time (P. Bonacich and P. Lu, Introduction to Mathematical Sociology, Princeton UP, 2012). Yet it attracts attention of numerous computational scholars, as it is an example of a macroscopic ordering which emerges as a consequence of local interactions. In this paper, we investigate the thermal evolution (driven by thermal noise level $T$) of the work function $U(T)$ for Heider balance on several Archimedean lattices that contain separated triangles, pairs of triangles, chains of triangles and complex structures of triangles. To that end, the heat-bath algorithm is applied. Two schemes of link values updating are considered: synchronous and asynchronous. In the latter case, the analytical formula $U(T)=-\\tanh(1/T)$ based on the partition function is provided. The Archimedean lattices are encoded with adjacency matrices, and Fortran procedures for their construction are provided. Finally, we present the mathematical proof that for any two-dimensional lattice, perfect structural (Heider) balance is unreachable at $T>0$."}, "https://arxiv.org/abs/2407.02612": {"title": "Women for Quantum -- Manifesto of Values", "link": "https://arxiv.org/abs/2407.02612", "description": "arXiv:2407.02612v1 Announce Type: new \nAbstract: Data show that the presence of women in quantum science is affected by a number of detriments and their percentage decreases even further for higher positions. Beyond data, from our shared personal experiences as female tenured quantum physics professors, we believe that the current model of scientific leadership, funding, and authority fails to represent many of us. It is time for a real change that calls for a different kind of force and for the participation of everyone. Women for quantum calls for a joint effort and aims with this initiative to contribute to such a transformation."}, "https://arxiv.org/abs/2407.02662": {"title": "Supporters and Skeptics: LLM-based Analysis of Engagement with Mental Health (Mis)Information Content on Video-sharing Platforms", "link": "https://arxiv.org/abs/2407.02662", "description": "arXiv:2407.02662v1 Announce Type: new \nAbstract: Over one in five adults in the US lives with a mental illness. In the face of a shortage of mental health professionals and offline resources, online short-form video content has grown to serve as a crucial conduit for disseminating mental health help and resources. However, the ease of content creation and access also contributes to the spread of misinformation, posing risks to accurate diagnosis and treatment. Detecting and understanding engagement with such content is crucial to mitigating their harmful effects on public health. We perform the first quantitative study of the phenomenon using YouTube Shorts and Bitchute as the sites of study. We contribute MentalMisinfo, a novel labeled mental health misinformation (MHMisinfo) dataset of 739 videos (639 from Youtube and 100 from Bitchute) and 135372 comments in total, using an expert-driven annotation schema. We first found that few-shot in-context learning with large language models (LLMs) are effective in detecting MHMisinfo videos. Next, we discover distinct and potentially alarming linguistic patterns in how audiences engage with MHMisinfo videos through commentary on both video-sharing platforms. Across the two platforms, comments could exacerbate prevailing stigma with some groups showing heightened susceptibility to and alignment with MHMisinfo. We discuss technical and public health-driven adaptive solutions to tackling the \"epidemic\" of mental health misinformation online."}, "https://arxiv.org/abs/2407.02807": {"title": "Regional and Temporal Patterns of Partisan Polarization during the COVID-19 Pandemic in the United States and Canada", "link": "https://arxiv.org/abs/2407.02807", "description": "arXiv:2407.02807v1 Announce Type: new \nAbstract: Public health measures were among the most polarizing topics debated online during the COVID-19 pandemic. Much of the discussion surrounded specific events, such as when and which particular interventions came into practise. In this work, we develop and apply an approach to measure subnational and event-driven variation of partisan polarization and explore how these dynamics varied both across and within countries. We apply our measure to a dataset of over 50 million tweets posted during late 2020, a salient period of polarizing discourse in the early phase of the pandemic. In particular, we examine regional variations in both the United States and Canada, focusing on three specific health interventions: lockdowns, masks, and vaccines. We find that more politically conservative regions had higher levels of partisan polarization in both countries, especially in the US where a strong negative correlation exists between regional vaccination rates and degree of polarization in vaccine related discussions. We then analyze the timing, context, and profile of spikes in polarization, linking them to specific events discussed on social media across different regions in both countries. These typically last only a few days in duration, suggesting that online discussions reflect and could even drive changes in public opinion, which in the context of pandemic response impacts public health outcomes across different regions and over time."}, "https://arxiv.org/abs/2407.02980": {"title": "Modelling the mitigation of anti-vaccine opinion propagation to suppress epidemic spread: A computational approach", "link": "https://arxiv.org/abs/2407.02980", "description": "arXiv:2407.02980v1 Announce Type: new \nAbstract: Information regarding vaccines from sources such as health services, media, and social networks can significantly shape vaccination decisions. In particular, the dissemination of negative information can contribute to vaccine hesitancy, thereby exacerbating infectious disease outbreaks. This study investigates strategies to mitigate anti-vaccine social contagion through effective counter-campaigns that disseminate positive vaccine information and encourage vaccine uptake, aiming to reduce the size of epidemics. In a coupled agent-based model that consists of opinion and disease diffusion processes, we explore and compare different heuristics to design positive campaigns based on the network structure and local presence of negative vaccine attitudes. We examine two campaigning regimes: a static regime with a fixed set of targets, and a dynamic regime in which targets can be updated over time. We demonstrate that strategic targeting and engagement with the dynamics of anti-vaccine influence diffusion in the network can effectively mitigate the spread of anti-vaccine sentiment, thereby reducing the epidemic size. However, the effectiveness of the campaigns differs across different targeting strategies and is impacted by a range of factors. We find that the primary advantage of static campaigns lies in their capacity to act as an obstacle, preventing the clustering of emerging anti-vaccine communities, thereby resulting in smaller and unconnected anti-vaccine groups. On the other hand, dynamic campaigns reach a broader segment of the population and adapt to the evolution of anti-vaccine diffusion, not only protecting susceptible agents from negative influence but also fostering positive propagation within negative regions."}, "https://arxiv.org/abs/2407.03074": {"title": "Dynamics of An Information Theoretic Analog of Two Masses on a Spring", "link": "https://arxiv.org/abs/2407.03074", "description": "arXiv:2407.03074v1 Announce Type: new \nAbstract: In this letter we investigate an information theoretic analogue of the classic two masses on spring system, arising from a physical interpretation of Friston's free energy principle in the theory of learning in a system of agents. Using methods from classical mechanics on manifolds, we define a kinetic energy term using the Fisher metric on distributions and a potential energy function defined in terms of stress on the agents' beliefs. The resulting Lagrangian (Hamiltonian) produces a variation of the classic DeGroot dynamics. In the two agent case, the potential function is defined using the Jeffrey's divergence and the resulting dynamics are characterized by a non-linear spring. These dynamics produce trajectories that resemble flows on tori but are shown numerically to produce chaos near the boundary of the space. We then investigate persuasion as an information theoretic control problem where analysis indicates that manipulating peer pressure with a fixed target is a more stable approach to altering an agent's belief than providing a slowly changing belief state that approaches the target."}, "https://arxiv.org/abs/2407.03117": {"title": "A 72h exploration of the co-evolution of food insecurity and international migration", "link": "https://arxiv.org/abs/2407.03117", "description": "arXiv:2407.03117v1 Announce Type: new \nAbstract: Food insecurity, defined as the lack of physical or economic access to safe, nutritious and sufficient food, remains one of the main challenges of the 2030 Agenda for Sustainable Development. Food insecurity is a complex phenomenon, resulting from the interplay of environmental, socio-demographic, and political events. Previous work has investigated the nexus between climate change, conflict, migration and food security at the household level, however these relations are still largely unexplored at national scales. In this context, during the Complexity72h workshop, held at the Universidad Carlos III de Madrid in June 2024, we explored the co-evolution of international migration flows and food insecurity at the national scale, accounting for remittances, as well as for changes in the economic, conflict, and climate situation. To this aim, we gathered data from several publicly available sources (Food and Agriculture Organization, World Bank, and UN Department of Economic and Social Affairs) and analyzed the association between food insecurity and migration, migration and remittances, and remittances and food insecurity. We then propose a framework linking together these associations to model the co-evolution of food insecurity and international migrations."}, "https://arxiv.org/abs/2407.03159": {"title": "Protection Degree and Migration in the Stochastic SIRS Model: A Queueing System Perspective", "link": "https://arxiv.org/abs/2407.03159", "description": "arXiv:2407.03159v1 Announce Type: new \nAbstract: With the prevalence of COVID-19, the modeling of epidemic propagation and its analyses have played a significant role in controlling epidemics. However, individual behaviors, in particular the self-protection and migration, which have a strong influence on epidemic propagation, were always neglected in previous studies. In this paper, we mainly propose two models from the individual and population perspectives. In the first individual model, we introduce the individual protection degree that effectively suppresses the epidemic level as a stochastic variable to the SIRS model. In the alternative population model, an open Markov queueing network is constructed to investigate the individual number of each epidemic state, and we present an evolving population network via the migration of people. Besides, stochastic methods are applied to analyze both models. In various simulations, the infected probability, the number of individuals in each state and its limited distribution are demonstrated."}, "https://arxiv.org/abs/2407.03255": {"title": "How Similar Are Elected Politicians and Their Constituents? Quantitative Evidence From Online Social Network", "link": "https://arxiv.org/abs/2407.03255", "description": "arXiv:2407.03255v1 Announce Type: new \nAbstract: How similar are politicians to those who vote for them? This is a critical question at the heart of democratic representation and particularly relevant at times when political dissatisfaction and populism are on the rise. To answer this question we compare the online discourse of elected politicians and their constituents. We collect a two and a half years (September 2020 - February 2023) constituency-level dataset for USA and UK that includes: (i) the Twitter timelines (5.6 Million tweets) of elected political representatives (595 UK Members of Parliament and 433 USA Representatives), (ii) the Nextdoor posts (21.8 Million posts) of the constituency (98.4% USA and 91.5% UK constituencies). We find that elected politicians tend to be equally similar to their constituents in terms of content and style regardless of whether a constituency elects a right or left-wing politician. The size of the electoral victory and the level of income of a constituency shows a nuanced picture. The narrower the electoral victory, the more similar the style and the more dissimilar the content is. The lower the income of a constituency, the more similar the content is. In terms of style, poorer constituencies tend to have a more similar sentiment and more dissimilar psychological text traits (i.e. measured with LIWC categories)."}, "https://arxiv.org/abs/2407.02624": {"title": "Optimizing Information Access in Networks via Edge Augmentation", "link": "https://arxiv.org/abs/2407.02624", "description": "arXiv:2407.02624v1 Announce Type: cross \nAbstract: Given a graph $G = (V, E)$ and a model of information flow on that network, a fundamental question is to understand if all the nodes have sufficient access to information generated at other nodes in the graph. If not, we can ask if a small set of edge additions improve information access. Formally, the broadcast value of a network is defined to be the minimum over pairs $u,v \\in V$ of the probability that an information cascade starting at $u$ reaches $v$. Recent work in the algorithmic fairness literature has focused on heuristics for adding a few edges to a graph to improve its broadcast. Our goal is to formally study the approximability of the Broadcast Improvement problem: given $G$ and a parameter $k$, find the best set of $k$ edges to add to $G$ in order to maximize the broadcast value of the resulting graph.\n  We develop efficient bicriteria approximation algorithms. If the optimal solution adds $k$ edges and achieves a broadcast of $\\beta^*$, we develop algorithms that can (a) add $2k-1$ edges and achieve a broadcast value roughly $(\\beta^*)^4$, or (b) add $O(k\\log n)$ edges and achieve a broadcast roughly $\\beta^*$. We also provide other trade-offs, that can be better depending on $k$ and the parameter associated with propagation in the cascade model. We complement our results by proving that unless P = NP, any algorithm that adds $O(k)$ edges must lose significantly in the approximation of $\\beta^*$, resolving an open question.\n  Our techniques are inspired by connections between Broadcast Improvement and problems such as Metric $k$-Center and Diameter Reduction. However, since the objective involves information cascades, we need to develop novel probabilistic tools to reason about the existence of paths in edge-sampled graphs. Finally, we show that our techniques extend to a single-source variant, for which we show both bicriteria algorithms and inapproximability results."}, "https://arxiv.org/abs/2407.02710": {"title": "WARNING This Contains Misinformation: The Effect of Cognitive Factors, Beliefs, and Personality on Misinformation Warning Tag Attitudes", "link": "https://arxiv.org/abs/2407.02710", "description": "arXiv:2407.02710v1 Announce Type: cross \nAbstract: Social media platforms enhance the propagation of online misinformation by providing large user bases with a quick means to share content. One way to disrupt the rapid dissemination of misinformation at scale is through warning tags, which label content as potentially false or misleading. Past warning tag mitigation studies yield mixed results for diverse audiences, however. We hypothesize that personalizing warning tags to the individual characteristics of their diverse users may enhance mitigation effectiveness. To reach the goal of personalization, we need to understand how people differ and how those differences predict a person's attitudes and self-described behaviors toward tags and tagged content. In this study, we leverage Amazon Mechanical Turk (n = 132) and undergraduate students (n = 112) to provide this foundational understanding. Specifically, we find attitudes towards warning tags and self-described behaviors are positively influenced by factors such as Personality Openness and Agreeableness, Need for Cognitive Closure (NFCC), Cognitive Reflection Test (CRT) score, and Trust in Medical Scientists. Conversely, Trust in Religious Leaders, Conscientiousness, and political conservatism were negatively correlated with these attitudes and behaviors. We synthesize our results into design insights and a future research agenda for more effective and personalized misinformation warning tags and misinformation mitigation strategies more generally."}, "https://arxiv.org/abs/2407.02758": {"title": "Differential Encoding for Improved Representation Learning over Graphs", "link": "https://arxiv.org/abs/2407.02758", "description": "arXiv:2407.02758v1 Announce Type: cross \nAbstract: Combining the message-passing paradigm with the global attention mechanism has emerged as an effective framework for learning over graphs. The message-passing paradigm and the global attention mechanism fundamentally generate node embeddings based on information aggregated from a node's local neighborhood or from the whole graph. The most basic and commonly used aggregation approach is to take the sum of information from a node's local neighbourhood or from the whole graph. However, it is unknown if the dominant information is from a node itself or from the node's neighbours (or the rest of the graph nodes). Therefore, there exists information lost at each layer of embedding generation, and this information lost could be accumulated and become more serious when more layers are used in the model. In this paper, we present a differential encoding method to address the issue of information lost. The idea of our method is to encode the differential representation between the information from a node's neighbours (or the rest of the graph nodes) and that from the node itself. The obtained differential encoding is then combined with the original aggregated local or global representation to generate the updated node embedding. By integrating differential encodings, the representational ability of generated node embeddings is improved. The differential encoding method is empirically evaluated on different graph tasks on seven benchmark datasets. The results show that it is a general method that improves the message-passing update and the global attention update, advancing the state-of-the-art performance for graph representation learning on these datasets."}, "https://arxiv.org/abs/2407.02885": {"title": "CogErgLLM: Exploring Large Language Model Systems Design Perspective Using Cognitive Ergonomics", "link": "https://arxiv.org/abs/2407.02885", "description": "arXiv:2407.02885v1 Announce Type: cross \nAbstract: Integrating cognitive ergonomics with LLMs is essential for enhancing safety, reliability, and user satisfaction in human-AI interactions. Current LLM design often lacks this integration, leading to systems that may not fully align with human cognitive capabilities and limitations. Insufficient focus on incorporating cognitive science methods exacerbates biases in LLM outputs, while inconsistent application of user-centered design principles results in sub-optimal user experiences. To address these challenges, our position paper explores the critical integration of cognitive ergonomics principles into LLM design, aiming to provide a comprehensive framework and practical guidelines for ethical LLM development. Through our contributions, we seek to advance understanding and practice in integrating cognitive ergonomics into LLM systems, fostering safer, more reliable, and ethically sound human-AI interactions."}, "https://arxiv.org/abs/2407.02992": {"title": "Scientific Text Analysis with Robots applied to observatory proposals", "link": "https://arxiv.org/abs/2407.02992", "description": "arXiv:2407.02992v1 Announce Type: cross \nAbstract: To test the potential disruptive effect of Artificial Intelligence (AI) transformers (e.g., ChatGPT) and their associated Large Language Models on the time allocation process, both in proposal reviewing and grading, an experiment has been set-up at ESO for the P112 Call for Proposals. The experiment aims at raising awareness in the ESO community and build valuable knowledge by identifying what future steps ESO and other observatories might need to take to stay up to date with current technologies. We present here the results of the experiment, which may further be used to inform decision-makers regarding the use of AI in the proposal review process. We find that the ChatGPT-adjusted proposals tend to receive lower grades compared to the original proposals. Moreover, ChatGPT 3.5 can generally not be trusted in providing correct scientific references, while the most recent version makes a better, but far from perfect, job. We also studied how ChatGPT deals with assessing proposals. It does an apparent remarkable job at providing a summary of ESO proposals, although it doesn't do so good to identify weaknesses. When looking at how it evaluates proposals, however, it appears that ChatGPT systematically gives a higher mark than humans, and tends to prefer proposals written by itself."}, "https://arxiv.org/abs/2407.03126": {"title": "Game-Theoretic Protection Adoption Against Networked SIS Epidemics", "link": "https://arxiv.org/abs/2407.03126", "description": "arXiv:2407.03126v1 Announce Type: cross \nAbstract: In this paper, we investigate game-theoretic strategies for containing spreading processes on large-scale networks. Specifically, we consider the class of networked susceptible-infected-susceptible (SIS) epidemics where a large population of agents strategically choose whether to adopt partially effective protection. We define the utilities of the agents which depends on the degree of the agent, its individual infection status and action, as well as the the overall prevalence of the epidemic and strategy profile of the entire population. We further present the coupled dynamics of epidemic evolution as well as strategy update which is assumed to follow the replicator dynamics. By relying on timescale separation arguments, we first derive the optimal strategy of protection adoption by the agents for a given epidemic state, and then present the reduced epidemic dynamics. The existence and uniqueness of endemic equilibrium is rigorously characterized and forms the main result of this paper. Finally, we present extensive numerical results to highlight the impacts of heterogeneous node degrees, infection rates, cost of protection adoption, and effectiveness of protection on the epidemic prevalence at the equilibrium."}, "https://arxiv.org/abs/2407.03190": {"title": "Cutting through the noise to motivate people: A comprehensive analysis of COVID-19 social media posts de/motivating vaccination", "link": "https://arxiv.org/abs/2407.03190", "description": "arXiv:2407.03190v1 Announce Type: cross \nAbstract: The COVID-19 pandemic exposed significant weaknesses in the healthcare information system. The overwhelming volume of misinformation on social media and other socioeconomic factors created extraordinary challenges to motivate people to take proper precautions and get vaccinated. In this context, our work explored a novel direction by analyzing an extensive dataset collected over two years, identifying the topics de/motivating the public about COVID-19 vaccination. We analyzed these topics based on time, geographic location, and political orientation. We noticed that while the motivating topics remain the same over time and geographic location, the demotivating topics rapidly. We also identified that intrinsic motivation, rather than external mandate, is more advantageous to inspire the public. This study addresses scientific communication and public motivation in social media. It can help public health officials, policymakers, and social media platforms develop more effective messaging strategies to cut through the noise of misinformation and educate the public about scientific findings."}, "https://arxiv.org/abs/2303.09590": {"title": "Visual Analytics of Multivariate Networks with Representation Learning and Composite Variable Construction", "link": "https://arxiv.org/abs/2303.09590", "description": "arXiv:2303.09590v3 Announce Type: replace \nAbstract: Multivariate networks are commonly found in real-world data-driven applications. Uncovering and understanding the relations of interest in multivariate networks is not a trivial task. This paper presents a visual analytics workflow for studying multivariate networks to extract associations between different structural and semantic characteristics of the networks (e.g., what are the combinations of attributes largely relating to the density of a social network?). The workflow consists of a neural-network-based learning phase to classify the data based on the chosen input and output attributes, a dimensionality reduction and optimization phase to produce a simplified set of results for examination, and finally an interpreting phase conducted by the user through an interactive visualization interface. A key part of our design is a composite variable construction step that remodels nonlinear features obtained by neural networks into linear features that are intuitive to interpret. We demonstrate the capabilities of this workflow with multiple case studies on networks derived from social media usage and also evaluate the workflow with qualitative feedback from experts."}, "https://arxiv.org/abs/2308.02755": {"title": "Multi-topic belief formation through bifurcations over signed social networks", "link": "https://arxiv.org/abs/2308.02755", "description": "arXiv:2308.02755v2 Announce Type: replace \nAbstract: We propose and analyze a nonlinear dynamic model of continuous-time multi-dimensional belief formation over signed social networks. Our model accounts for the effects of a structured belief system, self-appraisal, internal biases, and various sources of cognitive dissonance posited by recent theories in social psychology. We prove that agents become opinionated as a consequence of a bifurcation. We analyze how the balance of social network effects in the model controls the nature of the bifurcation and, therefore, the belief-forming limit-set solutions. Our analysis provides constructive conditions on how multi-stable network belief equilibria and belief oscillations emerging at a belief-forming bifurcation depend on the communication network graph and belief system network graph. Our model and analysis provide new theoretical insights on the dynamics of social systems and a new principled framework for designing decentralized decision-making on engineered networks in the presence of structured relationships among alternatives."}, "https://arxiv.org/abs/2001.05452": {"title": "The Gossiping Insert-Eliminate Algorithm for Multi-Agent Bandits", "link": "https://arxiv.org/abs/2001.05452", "description": "arXiv:2001.05452v4 Announce Type: replace-cross \nAbstract: We consider a decentralized multi-agent Multi Armed Bandit (MAB) setup consisting of $N$ agents, solving the same MAB instance to minimize individual cumulative regret. In our model, agents collaborate by exchanging messages through pairwise gossip style communications on an arbitrary connected graph. We develop two novel algorithms, where each agent only plays from a subset of all the arms. Agents use the communication medium to recommend only arm-IDs (not samples), and thus update the set of arms from which they play. We establish that, if agents communicate $\\Omega(\\log(T))$ times through any connected pairwise gossip mechanism, then every agent's regret is a factor of order $N$ smaller compared to the case of no collaborations. Furthermore, we show that the communication constraints only have a second order effect on the regret of our algorithm. We then analyze this second order term of the regret to derive bounds on the regret-communication tradeoffs. Finally, we empirically evaluate our algorithm and conclude that the insights are fundamental and not artifacts of our bounds. We also show a lower bound which gives that the regret scaling obtained by our algorithm cannot be improved even in the absence of any communication constraints. Our results thus demonstrate that even a minimal level of collaboration among agents greatly reduces regret for all agents."}, "https://arxiv.org/abs/2301.10844": {"title": "Diameter of Compact Riemann Surfaces", "link": "https://arxiv.org/abs/2301.10844", "description": "arXiv:2301.10844v4 Announce Type: replace-cross \nAbstract: Diameter is one of the most basic properties of a geometric object, while Riemann surfaces are one of the most basic geometric objects. Surprisingly, the diameter of compact Riemann surfaces is known exactly only for the sphere and the torus. For higher genuses, only very general but loose upper and lower bounds are available. The problem of calculating the diameter exactly has been intractable since there is no simple expression for the distance between a pair of points on a high-genus surface. Here we prove that the diameters of a class of simple Riemann surfaces known as generalized Bolza surfaces of any genus greater than $1$ are equal to the radii of their fundamental polygons. This is the first exact result for the diameter of a compact hyperbolic manifold."}, "https://arxiv.org/abs/2305.18784": {"title": "Collaborative Multi-Agent Heterogeneous Multi-Armed Bandits", "link": "https://arxiv.org/abs/2305.18784", "description": "arXiv:2305.18784v2 Announce Type: replace-cross \nAbstract: The study of collaborative multi-agent bandits has attracted significant attention recently. In light of this, we initiate the study of a new collaborative setting, consisting of $N$ agents such that each agent is learning one of $M$ stochastic multi-armed bandits to minimize their group cumulative regret. We develop decentralized algorithms which facilitate collaboration between the agents under two scenarios. We characterize the performance of these algorithms by deriving the per agent cumulative regret and group regret upper bounds. We also prove lower bounds for the group regret in this setting, which demonstrates the near-optimal behavior of the proposed algorithms."}, "https://arxiv.org/abs/2311.12702": {"title": "\"There Has To Be a Lot That We're Missing\": Moderating AI-Generated Content on Reddit", "link": "https://arxiv.org/abs/2311.12702", "description": "arXiv:2311.12702v4 Announce Type: replace-cross \nAbstract: Generative AI has begun to alter how we work, learn, communicate, and participate in online communities. How might our online communities be changed by generative AI? To start addressing this question, we focused on online community moderators' experiences with AI-generated content (AIGC). We performed fifteen in-depth, semi-structured interviews with community moderators on the social sharing site Reddit to understand their attitudes towards AIGC and how their communities are responding. Our study finds communities are choosing to enact rules restricting use of AIGC for both ideological and practical reasons. We find that, despite the absence of foolproof tools for detecting AIGC, moderators were able to somewhat limit the disruption caused by this new phenomenon by working with their communities to clarify norms about AIGC use. However, moderators found enforcing AIGC restrictions challenging, and had to rely on time-intensive and inaccurate detection heuristics in their efforts. Our results highlight the importance of supporting community autonomy and self-determination in the face of this sudden technological change, and suggest potential design solutions that may help."}, "https://arxiv.org/abs/2401.15090": {"title": "Maximum entropy in dynamic complex networks", "link": "https://arxiv.org/abs/2401.15090", "description": "arXiv:2401.15090v2 Announce Type: replace-cross \nAbstract: The field of complex networks studies a wide variety of interacting systems by representing them as networks. To understand their properties and mutual relations, the randomisation of network connections is a commonly used tool. However, information theoretic-based randomisation methods with well-established foundations mostly provide a stationary description of these systems, while stochastic randomisation methods that account for their dynamic nature lack such general foundations and require extensive repetition of the stochastic process to measure statistical properties. In this work, we extend the applicability of information-theoretic methods beyond stationary network models. By using the information-theoretic principle of maximum caliber we construct dynamic network ensemble distributions based on constraints representing statistical properties with known values throughout the evolution. We focus on the particular cases of dynamics constrained by the average number of connections of the whole network and each node, comparing each evolution to simulations of stochastic randomisation that obey the same constraints. We find that ensemble distributions estimated from simulations match those calculated with maximum caliber and that the equilibrium distributions to which they converge agree with known results of maximum entropy given the same constraints. Finally, we discuss further the connections to other maximum entropy approaches to network dynamics and conclude by proposing some possible avenues of future research."}, "https://arxiv.org/abs/2407.03375": {"title": "Asymptotic and stability analysis of kinetic models for opinion formation on networks: an Allen-Cahn approach", "link": "https://arxiv.org/abs/2407.03375", "description": "arXiv:2407.03375v1 Announce Type: new \nAbstract: We present the analysis of the stationary equilibria and their stability in case of an opinion formation process in presence of binary opposite opinions evolving according to majority-like rules on social networks. The starting point is a kinetic Boltzmann-type model derived from microscopic interactions rules for the opinion exchange among individuals holding a certain degree of connectivity. The key idea is to derive from the kinetic model an Allen-Cahn type equation for the fraction of individuals holding one of the two opinions. The latter can be studied by means of a linear stability analysis and by exploiting integral operator analysis. While this is true for ternary interactions, for binary interactions the derived equation of interest is a linear scattering equation, that can be studied by means of General Relative Entropy tools and integral operators."}, "https://arxiv.org/abs/2407.03376": {"title": "The Complex Interplay Between Risk Tolerance and the Spread of Infectious Diseases", "link": "https://arxiv.org/abs/2407.03376", "description": "arXiv:2407.03376v1 Announce Type: new \nAbstract: Risk-driven behavior provides a feedback mechanism through which individuals both shape and are collectively affected by an epidemic. We introduce a general and flexible compartmental model to study the effect of heterogeneity in the population with regards to risk tolerance. The interplay between behavior and epidemiology leads to a rich set of possible epidemic dynamics. Depending on the behavioral composition of the population, we find that increasing heterogeneity in risk tolerance can either increase or decrease the epidemic size. We find that multiple waves of infection can arise due to the interplay between transmission and behavior, even without the replenishment of susceptibles. We find that increasing protective mechanisms such as the effectiveness of interventions, the number of risk-averse people in the population, and the duration of intervention usage reduces the epidemic overshoot. When the protection is pushed past a critical threshold, the epidemic dynamics enter an underdamped regime where the epidemic size exactly equals the herd immunity threshold. Lastly, we can find regimes where epidemic size does not monotonically decrease with a population that becomes increasingly risk-averse."}, "https://arxiv.org/abs/2407.03388": {"title": "Passenger Route and Departure Time Guidance under Disruptions in Oversaturated Urban Rail Transit Networks", "link": "https://arxiv.org/abs/2407.03388", "description": "arXiv:2407.03388v1 Announce Type: new \nAbstract: The urban rail transit (URT) system attracts many commuters with its punctuality and convenience. However, it is vulnerable to disruptions caused by factors like extreme weather and temporary equipment failures, which greatly impact passengers' journeys and diminish the system's service quality. In this study, we propose targeted travel guidance for passengers at different space-time locations by devising passenger rescheduling strategies during disruptions. This guidance not only offers insights into route changes but also provides practical recommendations for delaying departure times when required. We present a novel three-feature four-group passenger classification principle, integrating temporal, spatial, and spatio-temporal features to classify passengers in disrupted URT networks. This approach results in the creation of four distinct solution spaces based on passenger groups. A mixed integer programming model is built based on individual level considering the First-in-First-out (FIFO) rule in oversaturated networks. Additionally, we present a two-stage solution approach for handling the complex issues in large-scale networks. Experimental results from both small-scale artificial networks and the real-world Beijing URT network validate the efficacy of our proposed passenger rescheduling strategies in mitigating disruptions. Specifically, when compared to scenarios with no travel guidance during disruptions, our strategies achieve a substantial reduction in total passenger travel time by 29.7% and 50.9% respectively, underscoring the effectiveness in managing unexpected disruptions."}, "https://arxiv.org/abs/2407.03484": {"title": "Visualizing the Evolution of Twitter (X", "link": "https://arxiv.org/abs/2407.03484", "description": "arXiv:2407.03484v1 Announce Type: new \nAbstract: With the rise of social media platforms, especially X.com (formerly Twitter), there is a growing interest in understanding digital social networks and human digital interactions. This paper presents a comprehensive methodology for extracting, processing, and visually analyzing data from X.com, using a combination of Python and R packages, enhanced by our publicly accessible, customizable code. Our approach compiles a dynamic dataset that captures various interactions: replies, retweets, and mentions. To explore deeper insights, the data is subjected to sentiment analysis and keyword coding, indicating shifts in discourse over time. Our method is structured in three primary phases. Initially, R is employed for pulling data and the formation of social network datasets. Following this, the combination of Python and R is utilized for sentiment analysis and keyword coding, aiming to uncover the underlying emotional shifts and language transitions within topics of discussion. The final phase employs R to visualize the dynamic shifts within these social networks. These visualization tools highlight changes in user interactions and patterns of influence. For a practical demonstration, we analyzed conversations on X.com regarding the controversial proposal to halt AI development, focusing specifically on discussions about ChatGPT. By using keyword searches, leading voices in the debate were identified. Our analysis of sentiment and keywords revealed patterns in emotions and language, while visual tools illustrated the development of network connections and their influence. This study emphasizes the vital role of visual tools in understanding online social dynamics in the digital age."}, "https://arxiv.org/abs/2407.03551": {"title": "Feelings about Bodies: Emotions on Diet and Fitness Forums Reveal Gendered Stereotypes and Body Image Concerns", "link": "https://arxiv.org/abs/2407.03551", "description": "arXiv:2407.03551v1 Announce Type: new \nAbstract: The gendered expectations about ideal body types can lead to body image concerns, dissatisfaction, and in extreme cases, disordered eating and other psychopathologies across the gender spectrum. While research has focused on pro-anorexia online communities that glorify the 'thin ideal', less attention has been given to the broader spectrum of body image concerns or how emerging disorders like muscle dysmorphia ('bigorexia') present in online discussions. To address these gaps, we analyze 46 Reddit discussion forums related to diet, fitness, and associated mental health challenges. Using membership structure analysis and transformer-based language models, we project these communities along gender and body ideal axes, revealing complex interactions between gender, body ideals, and emotional expression. Our findings show that feminine-oriented communities generally express more negative emotions, particularly in thinness-promoting forums. Conversely, communities focused on the muscular ideal exhibit less negativity, regardless of gender orientation. We also uncover a gendered pattern in emotional indicators of mental health challenges, with communities discussing serious issues aligning more closely with thinness-oriented, predominantly feminine-leaning communities. By revealing the gendered emotional dynamics of online communities, our findings can inform the development of more effective content moderation approaches that facilitate supportive interactions, while minimizing exposure to potentially harmful content."}, "https://arxiv.org/abs/2407.03568": {"title": "When LLM Meets Hypergraph: A Sociological Analysis on Personality via Online Social Networks", "link": "https://arxiv.org/abs/2407.03568", "description": "arXiv:2407.03568v1 Announce Type: new \nAbstract: Individual personalities significantly influence our perceptions, decisions, and social interactions, which is particularly crucial for gaining insights into human behavior patterns in online social network analysis. Many psychological studies have observed that personalities are strongly reflected in their social behaviors and social environments. In light of these problems, this paper proposes a sociological analysis framework for one's personality in an environment-based view instead of individual-level data mining. Specifically, to comprehensively understand an individual's behavior from low-quality records, we leverage the powerful associative ability of LLMs by designing an effective prompt. In this way, LLMs can integrate various scattered information with their external knowledge to generate higher-quality profiles, which can significantly improve the personality analysis performance. To explore the interactive mechanism behind the users and their online environments, we design an effective hypergraph neural network where the hypergraph nodes are users and the hyperedges in the hypergraph are social environments. We offer a useful dataset with user profile data, personality traits, and several detected environments from the real-world social platform. To the best of our knowledge, this is the first network-based dataset containing both hypergraph structure and social information, which could push forward future research in this area further. By employing the framework on this dataset, we can effectively capture the nuances of individual personalities and their online behaviors, leading to a deeper understanding of human interactions in the digital world."}, "https://arxiv.org/abs/2407.03773": {"title": "Decoding Political Polarization in Social Media Interactions", "link": "https://arxiv.org/abs/2407.03773", "description": "arXiv:2407.03773v1 Announce Type: new \nAbstract: Social media platforms significantly influence ideological divisions by enabling users to select information that aligns with their beliefs and avoid opposing viewpoints. Analyzing approximately 47 million Facebook posts, this study investigates the interactions of around 170 million users with news pages, revealing distinct patterns based on political orientations. While users generally prefer content that reflects their political biases, the extent of engagement varies even among individuals with similar ideological leanings. Specifically, political biases heavily influence commenting behaviors, particularly among users leaning towards the center-left and the right. Conversely, the 'likes' from center-left and centrist users are more indicative of their political affiliations. This research illuminates the complex relationship between social media behavior and political polarization, offering new insights into the manifestation of ideological divisions online."}, "https://arxiv.org/abs/2407.03904": {"title": "Asymmetric Iterated Prisoner's Dilemma on BA Scale-Free Network", "link": "https://arxiv.org/abs/2407.03904", "description": "arXiv:2407.03904v1 Announce Type: new \nAbstract: In real-world scenarios, individuals often cooperate for mutual benefit. However, differences in wealth can lead to varying outcomes for similar actions. In complex social networks, individuals' choices are also influenced by their neighbors. To explore the evolution of strategies in realistic settings, we conducted repeated asymmetric prisoners dilemma experiments on a weighted BA scale-free network. Our analysis highlighted how the four components of memory-one strategies affect win rates, found two special strategies in the evolutionary process, and increased the cooperation levels among individuals. These findings offer practical insights for addressing real-world problems."}, "https://arxiv.org/abs/2407.03968": {"title": "Academic Freedom and International Research Collaboration: A Longitudinal Analysis of Global Network Evolution", "link": "https://arxiv.org/abs/2407.03968", "description": "arXiv:2407.03968v1 Announce Type: new \nAbstract: The topic of academic freedom has come to the fore as nations around the world experience a wave of democratic backsliding. Institutions of higher education are often targets of autocrats who seek to suppress intellectual sources of social and political resistance. At the same time, international collaboration in scientific research has reached an all-time high, and the network of global science grows larger and denser every year. This research analyzes the effects of academic freedom on international research collaboration (IRC) among a sample of 166 countries. Global international collaboration data are drawn from articles in Web of Science across a 33-year time frame (1993-2022) and used to construct three separate IRC networks in science and technology (S&amp;T), social sciences (SocSci), and arts and humanities (A&amp;H). The Academic Freedom Index, covering the same time frame, is drawn from the Varieties of Democracy Project. Stochastic actor-oriented models (SAOM) are used to analyze the networks, implemented using the R package RSiena. Since IRC networks are naturally weighted by frequency of international co-authorship instances for each year, the R package backbone is used to binarize and trim the ties. Numerous endogenous network control variables are included in the model, as are exogenous country level factors, including geographic distance, number of authors, and GDP. The results show positive significant estimates for direct effects, non-linear direct effects, and homophily effects of academic freedom on tie creation and maintenance over time. These estimates increase in strength moving from the S&amp;T network, to the SocSci network, and is strongest in the A\\&amp;H network. This research provides support for the theory that academic research flourishes within environments of intellectual openness and freedom."}, "https://arxiv.org/abs/2407.04503": {"title": "When LLMs Play the Telephone Game: Cumulative Changes and Attractors in Iterated Cultural Transmissions", "link": "https://arxiv.org/abs/2407.04503", "description": "arXiv:2407.04503v1 Announce Type: new \nAbstract: As large language models (LLMs) start interacting with each other and generating an increasing amount of text online, it becomes crucial to better understand how information is transformed as it passes from one LLM to the next. While significant research has examined individual LLM behaviors, existing studies have largely overlooked the collective behaviors and information distortions arising from iterated LLM interactions. Small biases, negligible at the single output level, risk being amplified in iterated interactions, potentially leading the content to evolve towards attractor states. In a series of telephone game experiments, we apply a transmission chain design borrowed from the human cultural evolution literature: LLM agents iteratively receive, produce, and transmit texts from the previous to the next agent in the chain. By tracking the evolution of text toxicity, positivity, difficulty, and length across transmission chains, we uncover the existence of biases and attractors, and study their dependence on the initial text, the instructions, language model, and model size. For instance, we find that more open-ended instructions lead to stronger attraction effects compared to more constrained tasks. We also find that different text properties display different sensitivity to attraction effects, with toxicity leading to stronger attractors than length. These findings highlight the importance of accounting for multi-step transmission dynamics and represent a first step towards a more comprehensive understanding of LLM cultural dynamics."}, "https://arxiv.org/abs/2407.03446": {"title": "Towards Asimov's Psychohistory: Harnessing Topological Data Analysis, Artificial Intelligence and Social Media data to Forecast Societal Trends", "link": "https://arxiv.org/abs/2407.03446", "description": "arXiv:2407.03446v1 Announce Type: cross \nAbstract: In the age of big data and advanced computational methods, the prediction of large-scale social behaviors, reminiscent of Isaac Asimov's fictional science of Psychohistory, is becoming increasingly feasible. This paper consists of a theoretical exploration of the integration of computational power and mathematical frameworks, particularly through Topological Data Analysis (TDA) (Carlsson, Vejdemo-Johansson, 2022) and Artificial Intelligence (AI), to forecast societal trends through social media data analysis. By examining social media as a reflective surface of collective human behavior through the systematic behaviorist approach (Glenn, et al., 2016), I argue that these tools provide unprecedented clarity into the dynamics of large communities. This study dialogues with Asimov's work, drawing parallels between his visionary concepts and contemporary methodologies, illustrating how modern computational techniques can uncover patterns and predict shifts in social behavior, contributing to the emerging field of digital sociology -- or even, Psychohistory itself."}, "https://arxiv.org/abs/2407.03665": {"title": "Heterogeneous Hypergraph Embedding for Recommendation Systems", "link": "https://arxiv.org/abs/2407.03665", "description": "arXiv:2407.03665v1 Announce Type: cross \nAbstract: Recent advancements in recommender systems have focused on integrating knowledge graphs (KGs) to leverage their auxiliary information. The core idea of KG-enhanced recommenders is to incorporate rich semantic information for more accurate recommendations. However, two main challenges persist: i) Neglecting complex higher-order interactions in the KG-based user-item network, potentially leading to sub-optimal recommendations, and ii) Dealing with the heterogeneous modalities of input sources, such as user-item bipartite graphs and KGs, which may introduce noise and inaccuracies. To address these issues, we present a novel Knowledge-enhanced Heterogeneous Hypergraph Recommender System (KHGRec). KHGRec captures group-wise characteristics of both the interaction network and the KG, modeling complex connections in the KG. Using a collaborative knowledge heterogeneous hypergraph (CKHG), it employs two hypergraph encoders to model group-wise interdependencies and ensure explainability. Additionally, it fuses signals from the input graphs with cross-view self-supervised learning and attention mechanisms. Extensive experiments on four real-world datasets show our model's superiority over various state-of-the-art baselines, with an average 5.18\\% relative improvement. Additional tests on noise resilience, missing data, and cold-start problems demonstrate the robustness of our KHGRec framework. Our model and evaluation datasets are publicly available at \\url{https://github.com/viethungvu1998/KHGRec}."}, "https://arxiv.org/abs/2407.03953": {"title": "Generalizing Graph Transformers Across Diverse Graphs and Tasks via Pre-Training on Industrial-Scale Data", "link": "https://arxiv.org/abs/2407.03953", "description": "arXiv:2407.03953v1 Announce Type: cross \nAbstract: Graph pre-training has been concentrated on graph-level on small graphs (e.g., molecular graphs) or learning node representations on a fixed graph. Extending graph pre-trained models to web-scale graphs with billions of nodes in industrial scenarios, while avoiding negative transfer across graphs or tasks, remains a challenge. We aim to develop a general graph pre-trained model with inductive ability that can make predictions for unseen new nodes and even new graphs. In this work, we introduce a scalable transformer-based graph pre-training framework called PGT (Pre-trained Graph Transformer). Specifically, we design a flexible and scalable graph transformer as the backbone network. Meanwhile, based on the masked autoencoder architecture, we design two pre-training tasks: one for reconstructing node features and the other one for reconstructing local structures. Unlike the original autoencoder architecture where the pre-trained decoder is discarded, we propose a novel strategy that utilizes the decoder for feature augmentation. We have deployed our framework on Tencent's online game data. Extensive experiments have demonstrated that our framework can perform pre-training on real-world web-scale graphs with over 540 million nodes and 12 billion edges and generalizes effectively to unseen new graphs with different downstream tasks. We further conduct experiments on the publicly available ogbn-papers100M dataset, which consists of 111 million nodes and 1.6 billion edges. Our framework achieves state-of-the-art performance on both industrial datasets and public datasets, while also enjoying scalability and efficiency."}, "https://arxiv.org/abs/2407.04366": {"title": "Nash epidemics", "link": "https://arxiv.org/abs/2407.04366", "description": "arXiv:2407.04366v1 Announce Type: cross \nAbstract: Faced with a dangerous epidemic humans will spontaneously social distance to reduce their risk of infection at a socio-economic cost. Compartmentalised epidemic models have been extended to include this endogenous decision making: Individuals choose their behaviour to optimise a utility function, self-consistently giving rise to population behaviour. Here we study the properties of the resulting Nash equilibria, in which no member of the population can gain an advantage by unilaterally adopting different behaviour. We leverage a new analytic solution to obtain, (1) a simple relationship between rational social distancing behaviour and the current number of infections; (2) new scaling results for how the infection peak and number of total cases depend on the cost of contracting the disease; (3) characteristic infection costs that divide regimes of strong and weak behavioural response and depend only on the basic reproduction number of the disease; (4) a closed form expression for the value of the utility. We discuss how these analytic results provide a deep and intuitive understanding into the disease dynamics, useful for both individuals and policymakers. In particular the relationship between social distancing and infections represents a heuristic that could be communicated to the population to encourage, or \"bootstrap\", rational behaviour."}, "https://arxiv.org/abs/2407.04465": {"title": "Learning Patterns from Biological Networks: A Compounded Burr Probability Model", "link": "https://arxiv.org/abs/2407.04465", "description": "arXiv:2407.04465v1 Announce Type: cross \nAbstract: Complex biological networks, comprising metabolic reactions, gene interactions, and protein interactions, often exhibit scale-free characteristics with power-law degree distributions. However, empirical studies have revealed discrepancies between observed biological network data and ideal power-law fits, highlighting the need for improved modeling approaches. To address this challenge, we propose a novel family of distributions, building upon the baseline Burr distribution. Specifically, we introduce the compounded Burr (CBurr) distribution, derived from a continuous probability distribution family, enabling flexible and efficient modeling of node degree distributions in biological networks. This study comprehensively investigates the general properties of the CBurr distribution, focusing on parameter estimation using the maximum likelihood method. Subsequently, we apply the CBurr distribution model to large-scale biological network data, aiming to evaluate its efficacy in fitting the entire range of node degree distributions, surpassing conventional power-law distributions and other benchmarks. Through extensive data analysis and graphical illustrations, we demonstrate that the CBurr distribution exhibits superior modeling capabilities compared to traditional power-law distributions. This novel distribution model holds great promise for accurately capturing the complex nature of biological networks and advancing our understanding of their underlying mechanisms."}, "https://arxiv.org/abs/2307.04700": {"title": "Strength and weakness of disease-induced herd immunity in networks", "link": "https://arxiv.org/abs/2307.04700", "description": "arXiv:2307.04700v2 Announce Type: replace \nAbstract: When a fraction of a population becomes immune to an infectious disease, the population-wide infection risk decreases nonlinearly due to collective protection known as herd immunity. Studies based on mean-field models suggest that natural infection in a heterogeneous population may induce herd immunity more efficiently than homogeneous immunization. Here, we use network epidemic models to show that the opposite can also be the case. We identify two competing mechanisms driving disease-induced herd immunity in networks: the high density of immunity among socially active individuals enhances the herd immunity effect, while the topological localization of immune individuals weakens it. The effect of localization is stronger in networks embedded in low-dimensional space, which can make disease-induced immunity less effective than random immunization. Our results highlight the role of networks in shaping herd immunity and call for careful examination of model predictions that inform public health policies."}, "https://arxiv.org/abs/2310.06461": {"title": "Phosphorus recycling from human excreta in French agroecosystems and potential for food self-sufficiency", "link": "https://arxiv.org/abs/2310.06461", "description": "arXiv:2310.06461v2 Announce Type: replace \nAbstract: Phosphorus (P) is an essential constituent of life but large P losses from agroecosystems and sanitation systems are a major source of eutrophication in water bodies.These losses are doubly detrimental as P in human excretions can be used for crop fertilization.Through a unique dataset of 20,000 French WasteWater Treatment Plants (WWTPs) operational measurements over two decades and a P mass balance, we assess the fate of human excretions and their agricultural potential.Despite 75% of French WWTPs sludge being spread on crops, only 50% of the excreted P makes it back to agroecosystems. This is among the highest rate in Western countries where assessments have been made.Meanwhile, another 35% of the excreted P ends up in surface waters or the environment through WWTP discharge, individual autonomous systems diffuse losses, and sewers leaks.The remaining 15% is incinerated or sent to landfills.Moreover, while WWTP removal efficiency increased in the 2000s, reaching an 80% national average, it has been followed by a decade of stagnation in every French basin.The final removal efficiency for each basin, from 65% to 85%, closely matches whether the area was defined as P-sensitive in the European directive.Our results suggest that recycling all P in excretions could help supply 7 to 34% of French food supply without changing the current food system.Reshaping agricultural systems (shifting to more plant-based diets, decreasing P losses and food waste) would enable to go even further on the road to food sufficiency."}, "https://arxiv.org/abs/2401.02121": {"title": "Characterizing pedestrian contact interaction trajectories to understand spreading risk in human crowds", "link": "https://arxiv.org/abs/2401.02121", "description": "arXiv:2401.02121v2 Announce Type: replace \nAbstract: A spreading process can be observed when particular information, substances, or diseases spread through a population over time in social and biological systems. It is widely believed that contact interactions among individual entities play an essential role in the spreading process. Although contact interactions are often influenced by geometrical conditions, little attention has been paid to understand their effects, especially on contact duration among pedestrians. To examine how the pedestrian flow setups affect contact duration distribution, we have analyzed trajectories of pedestrians in contact interactions collected from pedestrian flow experiments of uni-, bi- and multi-directional setups. Based on turning angle entropy and efficiency, we have classified the type of motion observed in the contact interactions. We have found that the majority of contact interactions in the unidirectional flow setup can be categorized as confined motion, hinting at the possibility of long-lived contact duration. However, ballistic motion is more frequently observed in the other flow conditions, yielding frequent, brief contact interactions. Our results demonstrate that observing more confined motions is likely associated with the increase of parallel contact interactions regardless of pedestrian flow setups. This study highlights that the confined motions tend to yield longer contact duration, suggesting that the infectious disease transmission risk would be considerable even for low transmissibility. These results have important implications for crowd management in the context of minimizing spreading risk. This work is an extended version of Kwak et al. (2023) presented at the 2023 International Conference on Computational Science (ICCS)."}, "https://arxiv.org/abs/2404.10837": {"title": "The CHEPA model: assessing the impact of HEPA filter units in classrooms using a fast-running coupled indoor air quality and dynamic thermal model", "link": "https://arxiv.org/abs/2404.10837", "description": "arXiv:2404.10837v2 Announce Type: replace \nAbstract: The quality of the classroom environment, including ventilation, air quality and thermal conditions, has an important impact on children's health and academic achievements. The use of portable HEPA filter air cleaners is widely suggested as a strategy to mitigate exposure to particulate matter and airborne viruses. However, there is a need to quantify the relative benefits of such devices including the impacts on energy use. We present a simple coupled dynamic thermal and air quality model and apply it to naturally ventilated classrooms, representative of modern and Victorian era construction. We consider the addition of HEPA filters with, and without, reduced opening of windows, and explore concentrations of carbon dioxide (\\co), \\PM, airborne viral RNA, classroom temperature and energy use. Results indicate the addition of HEPA filters was predicted to reduce \\PM~ by 40--60\\% and viral RNA by 30--50\\% depending on the classroom design and window opening behaviour. The energy cost of running HEPA filters is likely to be only 1\\%--2\\% of the classroom heating costs. In scenarios when HEPA filters were on and window opening was reduced (to account for the additional clean air delivery rate of the filters), the heating cost was predicted to be reduced by as much as -13\\%, and these maximum reductions grew to -46\\% in wintertime simulations. In these scenarios the HEPA filters result in a notable reduction in \\PM~and viral RNA, but the \\co\\ concentration is significantly higher. The model provides a mechanism for exploring the relative impact of ventilation and air cleaning strategies on both exposures and energy costs, enabling an understanding of where trade-offs lie."}, "https://arxiv.org/abs/2404.16862": {"title": "Edge Importance in Complex Networks", "link": "https://arxiv.org/abs/2404.16862", "description": "arXiv:2404.16862v2 Announce Type: replace \nAbstract: Complex networks are made up of vertices and edges. The latter connect the vertices. There are several ways to measure the importance of the vertices, e.g., by counting the number of edges that start or end at each vertex, or by using the subgraph centrality of the vertices. It is more difficult to assess the importance of the edges. One approach is to consider the line graph associated with the given network and determine the importance of the vertices of the line graph, but this is fairly complicated except for small networks. This paper compares two approaches to estimate the importance of edges of medium-sized to large networks. One approach computes partial derivatives of the total communicability of the weights of the edges, where a partial derivative of large magnitude indicates that the corresponding edge may be important. Our second approach computes the Perron sensitivity of the edges. A high sensitivity signals that the edge may be important. The performance of these methods and some computational aspects are discussed. Applications of interest include to determine whether a network can be replaced by a network with fewer edges with about the same communicability."}, "https://arxiv.org/abs/2401.02627": {"title": "Characteristics and prevalence of fake social media profiles with AI-generated faces", "link": "https://arxiv.org/abs/2401.02627", "description": "arXiv:2401.02627v2 Announce Type: replace-cross \nAbstract: Recent advancements in generative artificial intelligence (AI) have raised concerns about their potential to create convincing fake social media accounts, but empirical evidence is lacking. In this paper, we present a systematic analysis of Twitter (X) accounts using human faces generated by Generative Adversarial Networks (GANs) for their profile pictures. We present a dataset of 1,420 such accounts and show that they are used to spread scams, spam, and amplify coordinated messages, among other inauthentic activities. Leveraging a feature of GAN-generated faces -- consistent eye placement -- and supplementing it with human annotation, we devise an effective method for identifying GAN-generated profiles in the wild. Applying this method to a random sample of active Twitter users, we estimate a lower bound for the prevalence of profiles using GAN-generated faces between 0.021% and 0.044% -- around 10K daily active accounts. These findings underscore the emerging threats posed by multimodal generative AI. We release the source code of our detection method and the data we collect to facilitate further investigation. Additionally, we provide practical heuristics to assist social media users in recognizing such accounts."}, "https://arxiv.org/abs/2403.06559": {"title": "Waiting times for sea level variations in the Port of Trieste: a computational data-driven study", "link": "https://arxiv.org/abs/2403.06559", "description": "arXiv:2403.06559v2 Announce Type: replace-cross \nAbstract: We report here a series of detailed statistical analyses on the sea level variations in the Port of Trieste using one of the largest existing catalogues that covers more than a century of measurements. We show that the distribution of waiting times, which are defined here akin to econophysics, namely the series of shortest time spans between a given sea level L and the next sea level of at least L + {\\delta} in the catalogue, exhibits a distinct scale-free character for small values of {\\delta}, while for larger values of {\\delta} the distribution is very similar to the exponential distribution. The distribution of waiting times for small values of {\\delta} is typical for complex systems exhibiting criticality and is reported abundantly in the literature, while the exponential-like distribution observed for large values of {\\delta} has been observed in contexts as diverse as magnetic systems and light sleep duration."}, "https://arxiv.org/abs/2407.05083": {"title": "Exploring agent interaction patterns in the comment sections of fake and real news", "link": "https://arxiv.org/abs/2407.05083", "description": "arXiv:2407.05083v1 Announce Type: new \nAbstract: User comments on social media have been recognized as a crucial factor in distinguishing between fake and real news, with many studies focusing on the textual content of user reactions. However, the interactions among agents in the comment sections for fake and real news have not been fully explored. In this study, we analyze a dataset comprising both fake and real news from Reddit to investigate agent interaction patterns, considering both the network structure and the sentiment of the nodes. Our findings reveal that (i) comments on fake news are more likely to form groups, (ii) compared to fake news, where users generate more negative sentiment, real news tend to elicit more neutral and positive sentiments. Additionally, nodes with similar sentiments cluster together more tightly than anticipated. From a dynamic perspective, we found that the sentiment distribution among nodes stabilizes early and remains stable over time. These findings have both theoretical and practical implications, particularly for the early detection of real and fake news within social networks."}, "https://arxiv.org/abs/2407.05161": {"title": "A Survey of Datasets for Information Diffusion Tasks", "link": "https://arxiv.org/abs/2407.05161", "description": "arXiv:2407.05161v1 Announce Type: new \nAbstract: Information diffusion across various new media platforms gradually influences perceptions, decisions, and social behaviors of individual users. In communication studies, the famous Five W's of Communication model (5W Model) has displayed the process of information diffusion clearly. At present, although plenty of studies and corresponding datasets about information diffusion have emerged, a systematic categorization of tasks and an integration of datasets are still lacking. To address this gap, we survey a systematic taxonomy of information diffusion tasks and datasets based on the \"5W Model\" framework. We first categorize the information diffusion tasks into ten subtasks with definitions and datasets analysis, from three main tasks of information diffusion prediction, social bot detection, and misinformation detection. We also collect the publicly available dataset repository of information diffusion tasks with the available links and compare them based on six attributes affiliated to users and content: user information, social network, bot label, propagation content, propagation network, and veracity label. In addition, we discuss the limitations and future directions of current datasets and research topics to advance the future development of information diffusion. The dataset repository can be accessed at our website https://github.com/fuxiaG/Information-Diffusion-Datasets."}, "https://arxiv.org/abs/2407.05198": {"title": "Medfluencer: A Network Representation of Medical Influencers' Identities and Discourse on Social Media", "link": "https://arxiv.org/abs/2407.05198", "description": "arXiv:2407.05198v1 Announce Type: new \nAbstract: In our study, we first constructed a dataset from the tweets of the top 100 medical influencers with the highest Influencer Score during the COVID-19 pandemic. This dataset was then used to construct a socio-semantic network, mapping both their identities and key topics, which are crucial for understanding their impact on public health discourse. To achieve this, we developed a few-shot multi-label classifier to identify influencers and their network actors' identities, employed BERTopic for extracting thematic content, and integrated these components into a network model to analyze their impact on health discourse."}, "https://arxiv.org/abs/2407.05669": {"title": "Fractional Budget Allocation for Influence Maximization under General Marketing Strategies", "link": "https://arxiv.org/abs/2407.05669", "description": "arXiv:2407.05669v1 Announce Type: new \nAbstract: We consider the fractional influence maximization problem, i.e., identifying users on a social network to be incentivized with potentially partial discounts to maximize the influence on the network. The larger the discount given to a user, the higher the likelihood of its activation (adopting a new product or innovation), who then attempts to activate its neighboring users, causing a cascade effect of influence through the network. Our goal is to devise efficient algorithms that assign initial discounts to the network's users to maximize the total number of activated users at the end of the cascade, subject to a constraint on the total sum of discounts given. In general, the activation likelihood could be any non-decreasing function of the discount, whereas, our focus lies on the case when the activation likelihood is an affine function of the discount, potentially varying across different users. As this problem is shown to be NP-hard, we propose and analyze an efficient (1-1/e)-approximation algorithm. Furthermore, we run experiments on real-world social networks to show the performance and scalability of our method."}, "https://arxiv.org/abs/2407.05929": {"title": "Multiplexity is temporal: effects of social times on network structure", "link": "https://arxiv.org/abs/2407.05929", "description": "arXiv:2407.05929v1 Announce Type: new \nAbstract: Large-scale social networks constructed using contact metadata have been invaluable tools for understanding and testing social theories of society-wide social structures. However, multiplex relationships explaining different social contexts have been out of reach of this methodology, limiting our ability to understand this crucial aspect of social systems. We propose a method that infers latent social times from the weekly activity of large-scale contact metadata, and reconstruct multilayer networks where layers correspond to social times. We then analyze the temporal multiplexity of ties in a society-wide communication network of millions of individuals. This allows us to test the propositions of Feld's social focus theory across a society-wide network: We show that ties favour their own social times regardless of contact intensity, suggesting they reflect underlying social foci. We present a result on strength of monoplex ties, which indicates that monoplex ties are bridging and even more important for global network connectivity than the weak, low-contact ties. Finally, we show that social times are transitive, so that when egos use a social time for a small subset of alters, the alters use the social time among themselves as well. Our framework opens up a way to analyse large-scale communication as multiplex networks and uncovers society-level patterns of multiplex connectivity."}, "https://arxiv.org/abs/2407.05956": {"title": "Untangling the Furball: A Practice Mapping Approach to the Analysis of Multimodal Interactions in Social Networks", "link": "https://arxiv.org/abs/2407.05956", "description": "arXiv:2407.05956v1 Announce Type: new \nAbstract: This article introduces the analytical approach of practice mapping, using vector embeddings of network actions and interactions to map commonalities and disjunctures in the practices of social media users, as a framework for methodological advancement beyond the limitations of conventional network analysis and visualisation. In particular, the methodological framework we outline here has the potential to incorporate multiple distinct modes of interaction into a single practice map, can be further enriched with account-level attributes such as information gleaned from textual analysis, profile information, available demographic details, and other features, and can be applied even to a cross-platform analysis of communicative patterns and practices.\n  The article presents practice mapping as an analytical framework and outlines its key methodological considerations. Given its prominence in past social media research, we draw on examples and data from the platform formerly known as Twitter in order to enable experienced scholars to translate their approaches to a practice mapping paradigm more easily, but point out how data from other platforms may be used in equivalent ways in practice mapping studies. We illustrate the utility of the approach by applying it to a dataset where the application of conventional network analysis and visualisation approaches has produced few meaningful insights."}, "https://arxiv.org/abs/2407.05988": {"title": "Minimum-regret hydrogen supply chain strategies to foster the energy transition of European hard-to-abate industries", "link": "https://arxiv.org/abs/2407.05988", "description": "arXiv:2407.05988v1 Announce Type: new \nAbstract: Low-carbon hydrogen (H2) is envisioned to play a central role in decarbonizing European hard-to-abate industries, such as refineries, ammonia, methanol, steel, and cement. To enable its widespread use, H2 supply chain (HSC) infrastructure is required. Mature and economically viable low-carbon H2 production pathways include steam methane reforming (SMR) of natural gas coupled with carbon dioxide capture and storage (CCS), water-electrolysis from renewable electricity, biomethane reforming, and biomass gasification. However, uncertainties surrounding demand and feedstock availabilities hamper their proliferation. Here, we investigate the impact of uncertainty in H2 demand and biomass availability on the optimal HSC design. The HSC is modeled as a network of H2 production and consumption sites that are interconnected with H2 and biomass transport technologies. A CCS supply chain is modeled alongside the HSC. The cost-optimal HSC design is determined based on a linear optimization problem that considers a regional resolution and a multi-year time horizon (2022-2050). We adopt a scenario-based uncertainty quantification approach and define discrete H2 demand and biomass availability scenarios. Applying a minimum-regret strategy, we show that sufficiently large low-carbon H2 production capacities (about 9.6 Mt/a by 2030) are essential to flexibly scale up HSCs and accommodate H2 demands of up to 35 Mt/a by 2050. While biomass-based H2 production emerges as the most cost-efficient low-carbon H2 production pathway, investments are not recommended unless the availability of biomass feedstocks is guaranteed. Instead, investments in SMR-CCS and electrolysis often offer greater flexibility. In addition, we highlight the importance of CCS infrastructure, which is required across scenarios."}, "https://arxiv.org/abs/2407.06149": {"title": "WIBACong: An Argument-centric Framework for Understanding US Congressional Hearings", "link": "https://arxiv.org/abs/2407.06149", "description": "arXiv:2407.06149v1 Announce Type: new \nAbstract: How can we utilize state-of-the-art NLP tools to better understand legislative deliberation? Committee hearings are a core feature of any legislature, and they create an institutional setting to promote the exchange of arguments and reasoning that directly impact and shape legislation. We develop WIBACong, which is an application of the WIBA NLP framework for quantifying and qualifying the deliberation dynamics that we previously developed, applied to US Congressional Hearings. WIBA is a pipeline for extracting and analyzing argumentation communicated within text corpora, enabling a focused attention on the dynamics of debates occurring in democratic settings. With our framework, we are able to uncover the nuances of how deliberative discourse actually is. In WIBACong, we propose a variety of summary statistics and useful visualizations to the WIBA output in order to analyze argumentation in U.S. committee hearing testimony, and in so doing we reveal potential biases in the committee system, and how political parties control the flow of information in 'hot topic' hearings."}, "https://arxiv.org/abs/2407.04701": {"title": "A convenient trick to compute cluster sizes in a Network", "link": "https://arxiv.org/abs/2407.04701", "description": "arXiv:2407.04701v1 Announce Type: cross \nAbstract: We present a convenient trick for computing the sizes of clusters within a network. The rationale relies on the mathematics of the geometric series and the fundamental matrix of a Markov Chain."}, "https://arxiv.org/abs/2407.05126": {"title": "Consistency and Discrepancy-Based Contrastive Tripartite Graph Learning for Recommendations", "link": "https://arxiv.org/abs/2407.05126", "description": "arXiv:2407.05126v1 Announce Type: cross \nAbstract: Tripartite graph-based recommender systems markedly diverge from traditional models by recommending unique combinations such as user groups and item bundles. Despite their effectiveness, these systems exacerbate the longstanding cold-start problem in traditional recommender systems, because any number of user groups or item bundles can be formed among users or items. To address this issue, we introduce a Consistency and Discrepancy-based graph contrastive learning method for tripartite graph-based Recommendation. This approach leverages two novel meta-path-based metrics consistency and discrepancy to capture nuanced, implicit associations between the recommended objects and the recommendees. These metrics, indicative of high-order similarities, can be efficiently calculated with infinite graph convolutional networks layers under a multi-objective optimization framework, using the limit theory of GCN."}, "https://arxiv.org/abs/2407.05186": {"title": "Understanding Political Communication and Political Communicators on Twitch", "link": "https://arxiv.org/abs/2407.05186", "description": "arXiv:2407.05186v1 Announce Type: cross \nAbstract: As new technologies rapidly reshape patterns of political communication, platforms like Twitch are transforming how people consume political information. This entertainment-oriented live streaming platform allows us to observe the impact of technologies such as ``live-streaming'' and ``streaming-chat'' on political communication. Despite its entertainment focus, Twitch hosts a variety of political actors, including politicians and pundits. This study explores Twitch politics by addressing three main questions: 1) Who are the political Twitch streamers? 2) What content is covered in political streams? 3) How do audiences of political streams interact with each other? To identify political streamers, I leveraged the Twitch API and supervised machine-learning techniques, identifying 574 political streamers. I used topic modeling to analyze the content of political streams, revealing seven broad categories of political topics and a unique pattern of communication involving context-specific ``emotes.'' Additionally, I created user-reference networks to examine interaction patterns, finding that a small number of users dominate the communication network. This research contributes to our understanding of how new social media technologies influence political communication, particularly among younger audiences."}, "https://arxiv.org/abs/2407.05627": {"title": "New Directions in Text Classification Research: Maximizing The Performance of Sentiment Classification from Limited Data", "link": "https://arxiv.org/abs/2407.05627", "description": "arXiv:2407.05627v1 Announce Type: cross \nAbstract: The stakeholders' needs in sentiment analysis for various issues, whether positive or negative, are speed and accuracy. One new challenge in sentiment analysis tasks is the limited training data, which often leads to suboptimal machine learning models and poor performance on test data. This paper discusses the problem of text classification based on limited training data (300 to 600 samples) into three classes: positive, negative, and neutral. A benchmark dataset is provided for training and testing data on the issue of Kaesang Pangarep's appointment as Chairman of PSI. External data for aggregation and augmentation purposes are provided, consisting of two datasets: the topic of Covid Vaccination sentiment and an open topic. The official score used is the F1-score, which balances precision and recall among the three classes, positive, negative, and neutral. A baseline score is provided as a reference for researchers for unoptimized classification methods. The optimized score is provided as a reference for the target score to be achieved by any proposed method. Both scoring (baseline and optimized) use the SVM method, which is widely reported as the state-of-the-art in conventional machine learning methods. The F1-scores achieved by the baseline and optimized methods are 40.83% and 51.28%, respectively."}, "https://arxiv.org/abs/2407.05801": {"title": "Design of a multisensory planetarium", "link": "https://arxiv.org/abs/2407.05801", "description": "arXiv:2407.05801v1 Announce Type: cross \nAbstract: We present the design and the prototype of a multisensory planetarium. The goal of this project is to offer a common perceptual and cognitive framework to all users, both sighted, deaf, and blind or visually impaired, concerning the experience of observing the night sky, but also to provide all equal access to scientific data regarding the observed objects, going beyond what can be sensed. The planetarium will consist of a Plexiglas hemisphere on which stars up to the fourth magnitude are represented by a brass bar that, when touched, activates visual, haptic, and acoustic stimuli. We mapped the magnitude of stars on acoustic and visual stimuli, while the distance of the star from us is mapped on a vibration. All the stimuli have been evaluated in pilot experiments using Plexiglas tablets representing some constellations, to assess their usability, intelligibility, and consistency with possible intuitive interpretations."}, "https://arxiv.org/abs/2407.05963": {"title": "6GSoft: Software for Edge-to-Cloud Continuum", "link": "https://arxiv.org/abs/2407.05963", "description": "arXiv:2407.05963v1 Announce Type: cross \nAbstract: In the era of 6G, developing and managing software requires cutting-edge software engineering (SE) theories and practices tailored for such complexity across a vast number of connected edge devices. Our project aims to lead the development of sustainable methods and energy-efficient orchestration models specifically for edge environments, enhancing architectural support driven by AI for contemporary edge-to-cloud continuum computing. This initiative seeks to position Finland at the forefront of the 6G landscape, focusing on sophisticated edge orchestration and robust software architectures to optimize the performance and scalability of edge networks. Collaborating with leading Finnish universities and companies, the project emphasizes deep industry-academia collaboration and international expertise to address critical challenges in edge orchestration and software architecture, aiming to drive significant advancements in software productivity and market impact."}, "https://arxiv.org/abs/2306.06683": {"title": "To be a pro-vax or not, the COVID-19 vaccine conundrum on Twitter", "link": "https://arxiv.org/abs/2306.06683", "description": "arXiv:2306.06683v2 Announce Type: replace \nAbstract: The most surprising observation reported by the study in (arXiv:2208.13523), involving stance detection of COVID-19 vaccine related tweets during the first year of pandemic, is the presence of a significant number of users (~2 million) who posted tweets with both anti-vax and pro-vax stances. This is a sizable cohort even when the stance detection noise is considered. In this paper, we tried to get deeper understanding of this 'dual-stance' group. Out of this group, 60% of users have more pro-vax tweets than anti-vax tweets and 17% have the same number of tweets in both classes. The rest have more anti-vax tweets, and they were highly active in expressing concerns about mandate and safety of a fast-tracked vaccine, while also tweeted some updates about vaccine development. The leaning pro-vax group have opposite composition: more vaccine updates and some posts about concerns. It is important to note that vaccine concerns were not always genuine and had a large dose of misinformation. 43% of the balanced group have only tweeted one tweet of each type during our study period and are the less active participants in the vaccine discourse. Our temporal study also shows that the change-of-stance behaviour became really significant once the trial results of COVID-19 vaccine were announced to the public, and it appears as the change of stance towards pro-vax is a reaction to people changing their opinion towards anti-vax. Our study finished at Mar 23, 2021 when the conundrum was still going strong. The dilemma might be a reflection of the uncertain and stressful times, but it also highlights the importance of building public trust to combat prevalent misinformation."}, "https://arxiv.org/abs/2308.04700": {"title": "BOPIM: Bayesian Optimization for influence maximization on temporal networks", "link": "https://arxiv.org/abs/2308.04700", "description": "arXiv:2308.04700v2 Announce Type: replace \nAbstract: The goal of influence maximization (IM) is to select a small set of seed nodes which maximizes the spread of influence on a network. In this work, we propose BOPIM, a Bayesian Optimization (BO) algorithm for IM on temporal networks. The IM task is well-suited for a BO solution due to its expensive and complicated objective function. We propose a simple surrogate function to model the objective function and leverage Gaussian Process regression with shrinkage priors to fit the model. A major difficulty in combinatorial BO is constructing an appropriate covariance matrix. We overcome this challenge with a kernel function based on the amount of overlap in seed set neighbors, thus tailoring the solution to our IM application. This also allows us to use the Expected Improvement acquisition function to choose the next point to evaluate. In numerical experiments on real-world networks, we prove that BOPIM outperforms competing methods and yields comparable influence spreads to a gold-standard greedy algorithm while being as much as five times faster. We also demonstrate the proposed method's ability to quantify uncertainty in optimal seed sets. To our knowledge, this is the first attempt to look at uncertainty in the seed sets for IM."}, "https://arxiv.org/abs/2309.15837": {"title": "Energy and environmental impacts of air-to-air heat pumps in a mid-latitude city", "link": "https://arxiv.org/abs/2309.15837", "description": "arXiv:2309.15837v3 Announce Type: replace \nAbstract: Heat pumps (HPs) have emerged as a key technology for reducing energy use and greenhouse gas emissions. This study evaluates the potential switch to air-to-air HPs (AAHPs) in Toulouse, France, where conventional space heating is split between electric and gas sources. In this context, we find that AAHPs reduce heating energy consumption by 57% to 76%, with electric heating energy consumption decreasing by 6% to 47%, resulting in virtually no local heating-related CO$_{2}$ emissions. We observe a slight reduction in near-surface air temperature of up to 0.5 {\\deg}C during cold spells, attributable to a reduction in sensible heat flux, which is unlikely to compromise AAHPs operational efficiency. While Toulouse's heating energy mix facilitates large energy savings, electric energy consumption may increase in cities where gas or other fossil fuel sources prevail. Furthermore, as AAHPs efficiency varies with internal and external conditions, their impact on the electrical grid is more complex than conventional heating systems. The results underscore the importance of matching heating system transitions with sustainable electricity generation to maximize environmental benefits. The study highlights the intricate balance between technological advancements in heating and their broader environmental and policy implications, offering key insights for urban energy policy and sustainability efforts."}, "https://arxiv.org/abs/2402.03100": {"title": "Inter-city infections and the role of size heterogeneity in containment strategies", "link": "https://arxiv.org/abs/2402.03100", "description": "arXiv:2402.03100v2 Announce Type: replace \nAbstract: We study the effectiveness of regional lockdown strategies to mitigate the spread of a pathogen across regional units, in the following called cities, within a country or region for a single infection wave. The heterogeneity in the epidemically relevant connectivity is defined via a random network model with cities as nodes, where the city's sizes determine their connectivity via a gravity type kernel function. Isolation of a whole city is initiated when infection numbers surpass defined thresholds. We consider two basic strategies for the lockdowns. Strategy~$(P)$ isolates cities based on a proportional threshold of infections, while stra\\-tegy~\\((U)\\) uses a uniform infection threshold for all cities. Given the heavy-tailed distribution of city sizes, strategy \\((P)\\) can potentially result in more secondary infections from larger cities than strategy \\((U)\\). As an efficiency measure we use the ratio of individuals under lockdown and the number of infected individuals. Additionally, we analytically derive formulas for the basic reproduction numbers and prevalences. Our model is fitted to mobility data from France, Japan, and Poland, and validated through simulations. The findings indicate that while the model aligns well with data from France and Poland, it deviates in Japan, highlighting the importance of geographical nuances in pathogen spread modeling. Furthermore, it suggests that for France (and Japan) both strategies perform equally well, while for Poland strategy \\((U)\\) outperforms strategy \\((P)\\)."}, "https://arxiv.org/abs/2310.00394": {"title": "Connectivity Aware and Energy Efficient Self-Organizing Distributed IoT Topology Control", "link": "https://arxiv.org/abs/2310.00394", "description": "arXiv:2310.00394v2 Announce Type: replace-cross \nAbstract: Internet of Things has pervaded every area of modern life. From a research and industry standpoint, there has been an increasing demand and desire in recent years to develop Internet of Things networks with distributed structure. Wireless communication under emergency circumstances is one of the important applications that distributed Internet of Things can have. In order for a network to be functional in this scenario, it must be developed without the aid of a pre-established or centralized structure and operated in a self-organized manner to accommodate the communication requirements of the time. Although the design and development of such networks can be highly advantageous, they frequently confront difficulties, the most significant of which is attaining and maintaining effective connectivity to have reliable communications despite the requirement to optimize energy usage. In this study, we present a model for self-organizing topology control for ad hoc-based Internet of Things networks that can address the aforementioned challenges. The model that will be presented employs the notion of the Hamiltonian function in classical mechanics and has two key objectives: regulating the network's topology and dynamics to enhance connectivity to a desirable level while requiring the least amount of energy possible. The results of the simulation indicate that the proposed model satisfactorily fulfills the goals of the problem."}, "https://arxiv.org/abs/2312.06441": {"title": "Revisiting Graph-Based Fraud Detection in Sight of Heterophily and Spectrum", "link": "https://arxiv.org/abs/2312.06441", "description": "arXiv:2312.06441v3 Announce Type: replace-cross \nAbstract: Graph-based fraud detection (GFD) can be regarded as a challenging semi-supervised node binary classification task. In recent years, Graph Neural Networks (GNN) have been widely applied to GFD, characterizing the anomalous possibility of a node by aggregating neighbor information. However, fraud graphs are inherently heterophilic, thus most of GNNs perform poorly due to their assumption of homophily. In addition, due to the existence of heterophily and class imbalance problem, the existing models do not fully utilize the precious node label information. To address the above issues, this paper proposes a semi-supervised GNN-based fraud detector SEC-GFD. This detector includes a hybrid filtering module and a local environmental constraint module, the two modules are utilized to solve heterophily and label utilization problem respectively. The first module starts from the perspective of the spectral domain, and solves the heterophily problem to a certain extent. Specifically, it divides the spectrum into various mixed-frequency bands based on the correlation between spectrum energy distribution and heterophily. Then in order to make full use of the node label information, a local environmental constraint module is adaptively designed. The comprehensive experimental results on four real-world fraud detection datasets denote that SEC-GFD outperforms other competitive graph-based fraud detectors. We release our code at https://github.com/Sunxkissed/SEC-GFD."}, "https://arxiv.org/abs/2407.06197": {"title": "On the Relation between Graph Ricci Curvature and Community Structure", "link": "https://arxiv.org/abs/2407.06197", "description": "arXiv:2407.06197v1 Announce Type: new \nAbstract: The connection between curvature and topology is a very well-studied theme in the subject of differential geometry. By suitably defining curvature on networks, the study of this theme has been extended into the domain of network analysis as well. In particular, this has led to curvature-based community detection algorithms. In this paper, we reveal the relation between community structure of a network and the curvature of its edges. In particular, we give apriori bounds on the curvature of intercommunity edges of a graph."}, "https://arxiv.org/abs/2407.06198": {"title": "Time-dependent Personalized PageRank for temporal networks: discrete and continuous scales", "link": "https://arxiv.org/abs/2407.06198", "description": "arXiv:2407.06198v1 Announce Type: new \nAbstract: In this paper we explore the PageRank of temporal networks on both discrete and continuous time scales in the presence of personalization vectors that vary over time. Also the underlying interplay between the discrete and continuous settings arising from discretization is highlighted. Additionally, localization results that set bounds to the estimated influence of the personalization vector on the ranking of a particular node are given. The theoretical results are illustrated by means of some real and synthetic examples."}, "https://arxiv.org/abs/2407.06205": {"title": "Chronological Analysis of Rigvedic Mandalas using Social Networks", "link": "https://arxiv.org/abs/2407.06205", "description": "arXiv:2407.06205v1 Announce Type: new \nAbstract: Establishing the chronology of the Vedas has interested scholars for the last two centuries. The oldest among them is Rig-Veda which has ten Mandalas, each composed separately. In this paper, we look at deciphering plausible pointers to the internal chronology of the Mandalas, by focusing on Gods and Goddesses worshiped in different Mandalas. We apply text analysis to the Mandalas using Clustering Techniques based on Cosine Similarity. Then we represent the association of deities with Mandalas using a grid-based Social Network that is amenable to chronological analysis and demonstrates the benefits of using Social Network Analysis for the problem at hand. Further, we analyze references to rivers to arrive at additional correlations. The approach used can be deployed generically to analyze other kinds of references and mentions and arrive at more substantive inferences."}, "https://arxiv.org/abs/2407.06351": {"title": "Bounded confidence modeling predicts how group work affects student math anxiety", "link": "https://arxiv.org/abs/2407.06351", "description": "arXiv:2407.06351v1 Announce Type: new \nAbstract: Math anxiety is ubiquitous. It not only affects student performance and confidence, but also can lead to avoidance of further math/STEM classes and careers. Cooperative learning (i.e., group work) is a proven strategy that can reduce math anxiety and has additional social and pedagogical benefits. However, depending on the individuals involved, some peer interactions may mitigate anxiety while others exacerbate it. Mathematical modeling is one approach to help untangle this complex dynamic. In this work we introduce a bounded confidence model to evaluate how math anxiety levels are affected by student group work. Although the model is quite simple, it captures non-obvious phenomena including how varying group sizes and frequency of switching groups can affect anxiety levels. The model is easily adaptable to incorporate additional personal and societal factors making it ripe for future research."}, "https://arxiv.org/abs/2407.06359": {"title": "Topological Determinants of Resilience in Urban Rail Networks Facing Multi-Hazard Disruptions", "link": "https://arxiv.org/abs/2407.06359", "description": "arXiv:2407.06359v1 Announce Type: new \nAbstract: This study examines the failure and recovery, two key components of resilience of nine major urban rail networks - Washington DC, Boston, Chicago, Delhi, Tokyo, Paris, Shanghai, London, and New York - against multi-hazard scenarios utilizing a quantitative approach focused on topological parameters to evaluate network resilience. Employing percolation-based network dismantling approach like Sequential Removal of Nodes and Giant Connected Component analysis, alongside random, centrality-based targeted attacks and flooding failure, findings reveal Domirank centrality's superior resilience in disruption and recovery phases. Kendall's tau coefficient's application further elucidates the relationships between network properties and resilience, underscoring larger networks' vulnerability yet faster recovery due to inherent redundancy and connectivity. Key attributes like average degree and path length consistently influence recovery effectiveness, while the clustering coefficient's positive correlation with recovery highlights the benefits of local interconnectivity. This analysis emphasizes the critical role of select nodes and the importance of balancing network design for enhanced resilience, offering insights for future urban rail system planning against multi-hazard threats."}, "https://arxiv.org/abs/2407.06558": {"title": "Sampling-Based Attack for Centrality Disruption in Complex Networks", "link": "https://arxiv.org/abs/2407.06558", "description": "arXiv:2407.06558v1 Announce Type: new \nAbstract: Many mobile networks are represented as graphs to obtain insight to their connectivity and transmission properties. Among these properties centrality resilience, that is, how well centralities, such as closeness and betweennesss, are maintained under attacks is a critical factor for proper functioning of a network. In this paper, we study the centrality resilience of complex networks by developing attack models to disrupt the rank of the top path-based centrality vertices. To develop our attack models, we extend the concept of rich clubs of influential vertices to the more general framework of scattered rich clubs. We define scattered rich clubs as dense subgraphs of high centrality vertices that are spread (scattered) across the network. Finding scattered rich clubs, although of polynomial time complexity, is extremely expensive computationally. We use snowball sampling to identify these important substructures as well as to identify which edges to target in our proposed attack models. Our results over a set of real world networks demonstrate that our proposed algorithm is effective in finding the single or scattered rich clubs efficiently and in successfully disrupting the centrality rankings of the network. To summarize, we propose sampling-based attack models for testing the resilience of networks with respect to centrality rankings. As part of this process, we introduce scattered rich clubs, a generalized form of the rich club model, efficient algorithms to detect them, and demonstrate their relation to network resilience."}, "https://arxiv.org/abs/2407.06631": {"title": "A Systematic Review of Echo Chamber Research: Comparative Analysis of Conceptualizations, Operationalizations, and Varying Outcomes", "link": "https://arxiv.org/abs/2407.06631", "description": "arXiv:2407.06631v1 Announce Type: new \nAbstract: This systematic review synthesizes current research on echo chambers and filter bubbles to highlight the reasons for the dissent in echo chamber research on the existence, antecedents, and effects of the phenomenon. The review of 112 studies reveals that the lack of consensus in echo chamber research is based on different conceptualizations and operationalizations of echo chambers. While studies that have conceptualized echo chambers with homophily and utilized data-driven computational social science (CSS) methods have confirmed the echo chamber hypothesis and polarization effects in social media, content exposure studies and surveys that have explored the full spectrum of media exposure have rejected it.\n  Most of these studies have been conducted in the United States, and the review emphasizes the need for a more comprehensive understanding of how echo chambers work in systems with more than two parties and outside the Global North. To advance our understanding of this phenomenon, future research should prioritize conducting more cross-platform studies, considering algorithmic filtering changes through continuous auditing, and examining the causal direction of the association between polarization, fragmentation, and the establishment of online echo chambers. The review also provides the advantages and disadvantages of different operationalizations and makes recommendations for studies in the European Union (EU), which will become possible with the upcoming Digital Services Act (DSA). Overall, this systematic review contributes to the ongoing scholarly discussion on the existence, antecedents, and effects of echo chambers and filter bubbles."}, "https://arxiv.org/abs/2407.06793": {"title": "Paradise-disorder transition in structural balance dynamics on Erd\\\"os-R\\'enyi graphs", "link": "https://arxiv.org/abs/2407.06793", "description": "arXiv:2407.06793v1 Announce Type: new \nAbstract: Structural balance has been posited as one of the factors influencing how friendly and hostile relations of social actors evolve over time. This study investigates the behavior of the Heider balance model in Erd\\\"os-R\\'enyi random graphs in the presence of a noisy environment, particularly the transition from an initially entirely positively polarized paradise state to a disordered phase. We examine both single-layer and bilayer network configurations and provide a mean-field solution for the average link polarization that predicts a first-order transition where the critical temperature scales with the connection probability $p$ as $p^2$ for a monolayer system and in a more complex way for a bilayer. We show that to mimic the dynamics observed in complete graphs, the intralayer Heider interaction strengths should be scaled as $p^{-2}$, while the interlayer interaction strengths should be scaled as $p^{-1}$ for random graphs. Numerical simulations have been performed, and their results confirm our analytical predictions, provided that graphs are dense enough."}, "https://arxiv.org/abs/2407.06820": {"title": "From Contact to Threat: A Social Network Perspective on Perceptions of Immigration", "link": "https://arxiv.org/abs/2407.06820", "description": "arXiv:2407.06820v1 Announce Type: new \nAbstract: Our perceptions are shaped by the social networks we are embedded in. Despite the acknowledged influence of close contacts on how we perceive the world, the role of the broader social environment remains opaque. Here, we leverage a unique combination of population-scale social network and survey data on perceptions of immigration. We find that both direct contacts and a wider social network exposure to migrants matter. Notably, for natives, network exposure shows a shift from positive to negative association with perceptions of immigration beyond a certain exposure threshold. The multi-layer nature of our data highlights this tipping point for next-door neighbors, with private social contexts exhibiting a positive relationship between exposure and immigration perceptions. Furthermore, it shows that contacts spanning multiple contexts also strengthen this relationship. The provided insights on the interplay between network composition and attitudes toward immigration highlight generic patterns shaping public opinion on pressing societal issues."}, "https://arxiv.org/abs/2407.06998": {"title": "Changepoint Detection in Highly-Attributed Dynamic Graphs", "link": "https://arxiv.org/abs/2407.06998", "description": "arXiv:2407.06998v1 Announce Type: new \nAbstract: Detecting anomalous behavior in dynamic networks remains a constant challenge. This problem is further exacerbated when the underlying topology of these networks is affected by individual highly-dimensional node attributes. We address this issue by tracking a network's modularity as a proxy of its community structure. We leverage Graph Neural Networks (GNNs) to estimate each snapshot's modularity. GNNs can account for both network structure and high-dimensional node attributes, providing a comprehensive approach for estimating network statistics. Our method is validated through simulations that demonstrate its ability to detect changes in highly-attributed networks by analyzing shifts in modularity. Moreover, we find our method is able to detect a real-world event within the \\#Iran Twitter reply network, where each node has high-dimensional textual attributes."}, "https://arxiv.org/abs/2407.06813": {"title": "Richelieu: Self-Evolving LLM-Based Agents for AI Diplomacy", "link": "https://arxiv.org/abs/2407.06813", "description": "arXiv:2407.06813v1 Announce Type: cross \nAbstract: Diplomacy is one of the most sophisticated activities in human society. The complex interactions among multiple parties/ agents involve various abilities like social reasoning, negotiation arts, and long-term strategy planning. Previous AI agents surely have proved their capability of handling multi-step games and larger action spaces on tasks involving multiple agents. However, diplomacy involves a staggering magnitude of decision spaces, especially considering the negotiation stage required. Recently, LLM agents have shown their potential for extending the boundary of previous agents on a couple of applications, however, it is still not enough to handle a very long planning period in a complex multi-agent environment. Empowered with cutting-edge LLM technology, we make the first stab to explore AI's upper bound towards a human-like agent for such a highly comprehensive multi-agent mission by combining three core and essential capabilities for stronger LLM-based societal agents: 1) strategic planner with memory and reflection; 2) goal-oriented negotiate with social reasoning; 3) augmenting memory by self-play games to self-evolving without any human in the loop."}, "https://arxiv.org/abs/2407.07026": {"title": "Resolving Sentiment Discrepancy for Multimodal Sentiment Detection via Semantics Completion and Decomposition", "link": "https://arxiv.org/abs/2407.07026", "description": "arXiv:2407.07026v1 Announce Type: cross \nAbstract: With the proliferation of social media posts in recent years, the need to detect sentiments in multimodal (image-text) content has grown rapidly. Since posts are user-generated, the image and text from the same post can express different or even contradictory sentiments, leading to potential \\textbf{sentiment discrepancy}. However, existing works mainly adopt a single-branch fusion structure that primarily captures the consistent sentiment between image and text. The ignorance or implicit modeling of discrepant sentiment results in compromised unimodal encoding and limited performances. In this paper, we propose a semantics Completion and Decomposition (CoDe) network to resolve the above issue. In the semantics completion module, we complement image and text representations with the semantics of the OCR text embedded in the image, helping bridge the sentiment gap. In the semantics decomposition module, we decompose image and text representations with exclusive projection and contrastive learning, thereby explicitly capturing the discrepant sentiment between modalities. Finally, we fuse image and text representations by cross-attention and combine them with the learned discrepant sentiment for final classification. Extensive experiments conducted on four multimodal sentiment datasets demonstrate the superiority of CoDe against SOTA methods."}, "https://arxiv.org/abs/2105.09191": {"title": "Structural dynamics of plant-pollinator mutualistic networks", "link": "https://arxiv.org/abs/2105.09191", "description": "arXiv:2105.09191v3 Announce Type: replace \nAbstract: The discourse surrounding the structural organization of mutualistic interactions mostly revolves around modularity and nestedness. The former is known to enhance the stability of communities, while the latter is related to their feasibility, albeit compromising the stability. However, it has recently been shown that the joint emergence of these structures poses challenges that can eventually lead to limitations in the dynamic properties of mutualistic communities. We hypothesize that considering compound arrangements -- modules with internal nested organization -- can offer valuable insights in this debate. We analyze the temporal structural dynamics of 20 plant-pollinator interaction networks and observe large structural variability throughout the year. Compound structures are particularly prevalent during the peak of the pollination season, often coexisting with nested and modular arrangements in varying degrees. Motivated by these empirical findings, we synthetically investigate the dynamics of the structural patterns across two control parameters -- community size and connectance levels -- mimicking the progression of the pollination season. Our analysis reveals contrasting impacts on the stability and feasibility of these mutualistic communities. We characterize the consistent relationship between network structure and stability, which follows a monotonic pattern. But, in terms of feasibility, we observe non-linear relationships. Compound structures exhibit a favorable balance between stability and feasibility, particularly in mid-sized ecological communities, suggesting they may effectively navigate the simultaneous requirements of stability and feasibility. These findings may indicate that the assembly process of mutualistic communities is driven by a delicate balance among multiple properties, rather than the dominance of a single one."}, "https://arxiv.org/abs/2306.09967": {"title": "The temporal dynamics of group interactions in higher-order social networks", "link": "https://arxiv.org/abs/2306.09967", "description": "arXiv:2306.09967v3 Announce Type: replace \nAbstract: Representing social systems as networks, starting from the interactions between individuals, sheds light on the mechanisms governing their dynamics. However, networks encode only pairwise interactions, while most social interactions occur among groups of individuals, requiring higher-order network representations. Despite the recent interest in higher-order networks, little is known about the mechanisms that govern the formation and evolution of groups, and how people move between groups. Here, we leverage empirical data on social interactions among children and university students to study their temporal dynamics at both individual and group levels, characterising how individuals navigate groups and how groups form and disaggregate. We find robust patterns across contexts and propose a dynamical model that closely reproduces empirical observations. These results represent a further step in understanding social systems, and open up research directions to study the impact of group dynamics on dynamical processes that evolve on top of them."}, "https://arxiv.org/abs/2403.01065": {"title": "Perspective: Challenges and opportunities for high-quality battery production at scale", "link": "https://arxiv.org/abs/2403.01065", "description": "arXiv:2403.01065v3 Announce Type: replace \nAbstract: As the impacts of climate change become increasingly apparent, the need for widespread electrification is now internationally recognized. As a result, global battery production is set to dramatically expand over the next decade. Unfortunately, however, batteries are both immensely difficult to produce at the gigawatt-hour scale and inordinately sensitive to minor manufacturing variation. As a result, the battery industry has already experienced a number of both highly-visible safety incidents and under-the-radar reliability issues -- a trend that will only worsen if left unaddressed. In this perspective, we highlight both the challenges and opportunities to enable battery quality at scale. We first describe the interplay between various battery failure modes and their numerous root causes. We then discuss the tensions at play to manage and improve battery quality during cell production. We hope our perspective brings greater visibility to the battery quality challenge to enable safe global electrification."}}