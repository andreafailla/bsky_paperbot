{"https://arxiv.org/abs/2405.05275": {"title": "SoMeR: Multi-View User Representation Learning for Social Media", "link": "https://arxiv.org/abs/2405.05275", "description": "arXiv:2405.05275v1 Announce Type: new \nAbstract: User representation learning aims to capture user preferences, interests, and behaviors in low-dimensional vector representations. These representations have widespread applications in recommendation systems and advertising; however, existing methods typically rely on specific features like text content, activity patterns, or platform metadata, failing to holistically model user behavior across different modalities. To address this limitation, we propose SoMeR, a Social Media user Representation learning framework that incorporates temporal activities, text content, profile information, and network interactions to learn comprehensive user portraits. SoMeR encodes user post streams as sequences of timestamped textual features, uses transformers to embed this along with profile data, and jointly trains with link prediction and contrastive learning objectives to capture user similarity. We demonstrate SoMeR's versatility through two applications: 1) Identifying inauthentic accounts involved in coordinated influence operations by detecting users posting similar content simultaneously, and 2) Measuring increased polarization in online discussions after major events by quantifying how users with different beliefs moved farther apart in the embedding space. SoMeR's ability to holistically model users enables new solutions to important problems around disinformation, societal tensions, and online behavior understanding."}, "https://arxiv.org/abs/2405.05288": {"title": "Learning Social Graph for Inactive User Recommendation", "link": "https://arxiv.org/abs/2405.05288", "description": "arXiv:2405.05288v1 Announce Type: new \nAbstract: Social relations have been widely incorporated into recommender systems to alleviate data sparsity problem. However, raw social relations don't always benefit recommendation due to their inferior quality and insufficient quantity, especially for inactive users, whose interacted items are limited. In this paper, we propose a novel social recommendation method called LSIR (\\textbf{L}earning \\textbf{S}ocial Graph for \\textbf{I}nactive User \\textbf{R}ecommendation) that learns an optimal social graph structure for social recommendation, especially for inactive users. LSIR recursively aggregates user and item embeddings to collaboratively encode item and user features. Then, graph structure learning (GSL) is employed to refine the raw user-user social graph, by removing noisy edges and adding new edges based on the enhanced embeddings. Meanwhile, mimic learning is implemented to guide active users in mimicking inactive users during model training, which improves the construction of new edges for inactive users. Extensive experiments on real-world datasets demonstrate that LSIR achieves significant improvements of up to 129.58\\% on NDCG in inactive user recommendation. Our code is available at~\\url{https://github.com/liun-online/LSIR}."}, "https://arxiv.org/abs/2405.05393": {"title": "Mutual information and the encoding of contingency tables", "link": "https://arxiv.org/abs/2405.05393", "description": "arXiv:2405.05393v1 Announce Type: new \nAbstract: Mutual information is commonly used as a measure of similarity between competing labelings of a given set of objects, for example to quantify performance in classification and community detection tasks. As argued recently, however, the mutual information as conventionally defined can return biased results because it neglects the information cost of the so-called contingency table, a crucial component of the similarity calculation. In principle the bias can be rectified by subtracting the appropriate information cost, leading to the modified measure known as the reduced mutual information, but in practice one can only ever compute an upper bound on this information cost, and the value of the reduced mutual information depends crucially on how good a bound is established. In this paper we describe an improved method for encoding contingency tables that gives a substantially better bound in typical use cases, and approaches the ideal value in the common case where the labelings are closely similar, as we demonstrate with extensive numerical results."}, "https://arxiv.org/abs/2405.05400": {"title": "Comparative analysis of graph randomization: Tools,methods, pitfalls, and best practices", "link": "https://arxiv.org/abs/2405.05400", "description": "arXiv:2405.05400v1 Announce Type: new \nAbstract: Graph randomization techniques play a crucial role in network analysis, allowing researchers to assess the statistical significance of observed network properties and distinguish meaningful patterns from random fluctuations. In this survey we provide an overview of the graph randomization methods available in the most popular software tools for network analysis. We propose a comparative analysis of popular software tools to highlight their functionalities and limitations. Through case studies involving diverse graph types, we demonstrate how different randomization methods can lead to divergent conclusions, emphasizing the importance of careful method selection based on the characteristics of the observed network and the research question at hand. This survey proposes some guidelines for researchers and practitioners seeking to understand and utilize graph randomization techniques effectively in their network analysis projects."}, "https://arxiv.org/abs/2405.05576": {"title": "LayerPlexRank: Exploring Node Centrality and Layer Influence through Algebraic Connectivity in Multiplex Networks", "link": "https://arxiv.org/abs/2405.05576", "description": "arXiv:2405.05576v1 Announce Type: new \nAbstract: As the calculation of centrality in complex networks becomes increasingly vital across technological, biological, and social systems, precise and scalable ranking methods are essential for understanding these networks. This paper introduces LayerPlexRank, an algorithm that simultaneously assesses node centrality and layer influence in multiplex networks using algebraic connectivity metrics. This method enhances the robustness of the ranking algorithm by effectively assessing structural changes across layers using random walk, considering the overall connectivity of the graph. We substantiate the utility of LayerPlexRank with theoretical analyses and empirical validations on varied real-world datasets, contrasting it with established centrality measures."}, "https://arxiv.org/abs/2405.05724": {"title": "Private Online Community Detection for Censored Block Models", "link": "https://arxiv.org/abs/2405.05724", "description": "arXiv:2405.05724v1 Announce Type: new \nAbstract: We study the private online change detection problem for dynamic communities, using a censored block model (CBM). Focusing on the notion of edge differential privacy (DP), we seek to understand the fundamental tradeoffs between the privacy budget, detection delay, and exact community recovery of community labels. We establish the theoretical lower bound on the delay in detecting changes privately and propose an algorithm capable of identifying changes in the community structure, while maintaining user privacy. Further, we provide theoretical guarantees for the effectiveness of our proposed method by showing necessary and sufficient conditions on change detection and exact recovery under edge DP. Simulation and real data examples are provided to validate the proposed method."}, "https://arxiv.org/abs/2405.05903": {"title": "The Other Side of the Coin: Recipient Norms and Their Impact on Indirect Reciprocity and Cooperation", "link": "https://arxiv.org/abs/2405.05903", "description": "arXiv:2405.05903v1 Announce Type: new \nAbstract: Human cooperation depends on indirect reciprocity. In this work, we explore the concept of indirect reciprocity using a donation game in an infinitely large population. In particular, we examine how updating the reputations of recipients influences cooperation. Our work adds a time-scale parameter for updating donor and recipient reputations. We find a trade-off between the level of cooperation and evolutionary stability influenced by social norms. `Forgiving' recipient norms enhance cooperation but increase susceptibility to defectors, whereas `unforgiving' norms reduce cooperation but defend against invasion by defectors. Expanding to include gossip groups allows us to analyze the evolutionary dynamics of the time-scale parameter, identifying `generous' norms that support cooperation, and `strict' norms that discourage such generosity, ultimately showing vulnerability to defector invasions and potential cooperation collapse."}, "https://arxiv.org/abs/2405.05433": {"title": "Robust Reward Placement under Uncertainty", "link": "https://arxiv.org/abs/2405.05433", "description": "arXiv:2405.05433v1 Announce Type: cross \nAbstract: Reward placement is a common optimization problem in network diffusion processes, where a number of rewards are to be placed in a network so as to maximize the total reward obtained as agents move randomly in it. In many settings, the precise mobility network might be one of several possible, based on parameters outside our control, such as the weather conditions affecting peoples' transportation means. Solutions to the reward placement problem must thus be robust to this uncertainty, by achieving a high utility in all possible networks. To study such scenarios, we introduce the Robust Reward Placement problem (RRP). Agents move randomly on a Markovian Mobility Model that has a predetermined set of locations but its precise connectivity is unknown and chosen adversarialy from a known set $\\Pi$ of candidates. Network optimization is achieved by selecting a set of reward states, and the goal is to maximize the minimum, among all candidates, ratio of rewards obtained over the optimal solution for each candidate. We first prove that RRP is NP-hard and inapproximable in general. We then develop $\\Psi$-Saturate, a pseudo-polynomial time algorithm that achieves an $\\epsilon$-additive approximation by exceeding the budget constraint by a factor that scales as $O(ln|\\Pi|/\\epsilon)$. In addition, we present several heuristics, most prominently one inspired from a dynamic programming algorithm for the max-min 0-1 Knapsack problem. We corroborate our theoretical findings with an experimental evaluation of the methods in both synthetic and real-world datasets."}, "https://arxiv.org/abs/2405.05487": {"title": "Design of Targeted Community-Based Resource Allocation in the Presence of Vaccine Hesitancy via a Data-Driven Compartmental Stochastic Optimization Model", "link": "https://arxiv.org/abs/2405.05487", "description": "arXiv:2405.05487v1 Announce Type: cross \nAbstract: Vaccines have proven effective in mitigating the threat of severe infections and deaths during outbreaks of infectious diseases. However, vaccine hesitancy (VH) complicates disease spread prediction and healthcare resource assessment across regions and populations. We propose a modeling framework that integrates an epidemiological compartmental model that captures the spread of an infectious disease within a multi-stage stochastic program (MSP) that determines the allocation of critical resources under uncertainty. The proposed compartmental MSP model adaptively manages the allocation of resources to account for changes in population behavior toward vaccines (i.e., variability in VH), the unique patterns of disease spread, and the availability of healthcare resources over time and space. The compartmental MSP model allowed us to analyze the price of fairness in resource allocation. Using real COVID-19 vaccination and healthcare resource data from Arkansas, U.S. (January-May 2021), our findings include: (i) delaying the initial deployment of additional ventilators by one month could lead to an average increase in the expected number of deaths by 285.41/month, highlighting the importance of prompt action; (ii) each additional ventilator in the initial stockpile and in supply leads to a decrease in the expected number of deaths by 1.09/month and 0.962/month, respectively, emphasizing the importance of maintaining a large stockpile and scalable production response; (iii) the cost of ensuring equitable resource allocation varies over time and location, peaking during the peak of a disease outbreak and in densely populated areas. This study emphasizes the importance of flexible, informed public health decision-making and preparedness, providing a model for effective resource allocation in public health emergencies."}, "https://arxiv.org/abs/2211.06352": {"title": "Spectral Triadic Decompositions of Real-World Networks", "link": "https://arxiv.org/abs/2211.06352", "description": "arXiv:2211.06352v3 Announce Type: replace \nAbstract: A fundamental problem in mathematics and network analysis is to find conditions under which a graph can be partitioned into smaller pieces. The most important tool for this partitioning is the Fiedler vector or discrete Cheeger inequality. These results relate the graph spectrum (eigenvalues of the normalized adjacency matrix) to the ability to break a graph into two pieces, with few edge deletions. An entire subfield of mathematics, called spectral graph theory, has emerged from these results. Yet these results do not say anything about the rich community structure exhibited by real-world networks, which typically have a significant fraction of edges contained in numerous densely clustered blocks. Inspired by the properties of real-world networks, we discover a new spectral condition that relates eigenvalue powers to a network decomposition into densely clustered blocks. We call this the \\emph{spectral triadic decomposition}. Our relationship exactly predicts the existence of community structure, as commonly seen in real networked data. Our proof provides an efficient algorithm to produce the spectral triadic decomposition. We observe on numerous social, coauthorship, and citation network datasets that these decompositions have significant correlation with semantically meaningful communities."}, "https://arxiv.org/abs/2301.06774": {"title": "Temporal Dynamics of Coordinated Online Behavior: Stability, Archetypes, and Influence", "link": "https://arxiv.org/abs/2301.06774", "description": "arXiv:2301.06774v2 Announce Type: replace \nAbstract: Large-scale online campaigns, malicious or otherwise, require a significant degree of coordination among participants, which sparked interest in the study of coordinated online behavior. State-of-the-art methods for detecting coordinated behavior perform static analyses, disregarding the temporal dynamics of coordination. Here, we carry out the first dynamic analysis of coordinated behavior. To reach our goal we build a multiplex temporal network and we perform dynamic community detection to identify groups of users that exhibited coordinated behaviors in time. Thanks to our novel approach we find that: (i) coordinated communities feature variable degrees of temporal instability; (ii) dynamic analyses are needed to account for such instability, and results of static analyses can be unreliable and scarcely representative of unstable communities; (iii) some users exhibit distinct archetypal behaviors that have important practical implications; (iv) content and network characteristics contribute to explaining why users leave and join coordinated communities. Our results demonstrate the advantages of dynamic analyses and open up new directions of research on the unfolding of online debates, on the strategies of coordinated communities, and on the patterns of online influence."}, "https://arxiv.org/abs/2303.03774": {"title": "Network science meets history", "link": "https://arxiv.org/abs/2303.03774", "description": "arXiv:2303.03774v3 Announce Type: replace \nAbstract: Alliances and conflicts represent important features of complex systems like international relations. Such relations create a time-evolving signed network, where each node contributes in a unique manner to the global balance of the system. Therefore, a local index mathematically quantifying such a property becomes valuable. In this work, we introduce a local balance index for signed networks. We analyze its mathematical foundations and unique structural properties, differentiating it from existing local vertex invariants. We also establish a novel methodology linking changes in a nation's local balance to historical events. By scrutinizing the time series of local balance for countries between 1816 and 2014, we detect and categorize major historic events based on balance fluctuations. This approach harmonizes quantitative and qualitative analyses, and combined with the theory of \"balance of power\" is able to build up a new mixed approach to history based on network theory."}, "https://arxiv.org/abs/2312.07077": {"title": "On the Potential of an Independent Avatar to Augment Metaverse Social Networks", "link": "https://arxiv.org/abs/2312.07077", "description": "arXiv:2312.07077v2 Announce Type: replace \nAbstract: We present a computational modelling approach which targets capturing the specifics on how to virtually augment a Metaverse user's available social time capacity via using an independent and autonomous version of her digital representation in the Metaverse. We motivate why this is a fundamental building block to model large-scale social networks in the Metaverse, and emerging properties herein. We envision a Metaverse-focused extension of the traditional avatar concept: An avatar can be as well programmed to operate independently when its user is not controlling it directly, thus turning it into an agent-based digital human representation. This way, we highlight how such an independent avatar could help its user to better navigate their social relationships and optimize their socializing time in the Metaverse by (partly) offloading some interactions to the avatar. We model the setting and identify the characteristic variables by using selected concepts from social sciences: ego networks, social presence, and social cues. Then, we formulate the problem of maximizing the user's non-avatar-mediated spare time as a linear optimization. Finally, we analyze the feasible region of the problem and we present some initial insights on the spare time that can be achieved for different parameter values of the avatar-mediated interactions."}, "https://arxiv.org/abs/2402.05739": {"title": "Critical mobility in policy making for epidemic containment", "link": "https://arxiv.org/abs/2402.05739", "description": "arXiv:2402.05739v2 Announce Type: replace \nAbstract: When considering airborne epidemic spreading in social systems, a natural connection arises between mobility and epidemic contacts. As individuals travel, possibilities to encounter new people either at the final destination or during the transportation process appear. Such contacts can lead to new contagion events. In fact, mobility has been a crucial target for early non-pharmaceutical containment measures against the recent COVID-19 pandemic, with a degree of intensity ranging from public transportation line closures to regional, city or even home confinements. Nonetheless, quantitative knowledge on the relationship between mobility-contagions and, consequently, on the efficiency of containment measures remains elusive. Here we introduce an agent-based model with a simple interaction between mobility and contacts. Despite its simplicity our model shows the emergence of a critical mobility level, inducing major outbreaks when surpassed. We explore the interplay between mobility restrictions and the infection in recent intervention policies seen across many countries, and how interventions in the form of closures triggered by incidence rates can guide the epidemic into an oscillatory regime with recurrent waves. We consider how the different interventions impact societal well-being, the economy and the population. Finally, we propose a mitigation framework based on the critical nature of mobility in an epidemic, able to suppress incidence and oscillations at will, preventing extreme incidence peaks with potential to saturate health care resources."}, "https://arxiv.org/abs/2404.12178": {"title": "Designing a sector-coupled European energy system robust to 60 years of historical weather data", "link": "https://arxiv.org/abs/2404.12178", "description": "arXiv:2404.12178v2 Announce Type: replace \nAbstract: As energy systems transform to rely on renewable energy and electrification, they encounter stronger year-to-year variability in energy supply and demand. However, most infrastructure planning is based on a single weather year, resulting in a lack of robustness. In this paper, we optimize energy infrastructure for a European energy system designed for net-zero CO$_2$ emissions in 62 different weather years. Subsequently, we fix the capacity layouts and simulate their operation in every weather year, to evaluate resource adequacy and CO$_2$ emissions abatement. We show that interannual weather variability causes variation of $\\pm$10\\% in total system cost. The most expensive capacity layout obtains the lowest net CO$_2$ emissions but not the highest resource adequacy. Instead, capacity layouts designed with years including compound weather events result in a more robust and cost-effective design. Deploying CO$_2$-emitting backup generation is a cost-effective robustness measure, which only increase CO$_2$ emissions marginally as the average CO$_2$ emissions remain less than 1\\% of 1990 levels. Our findings highlight how extreme weather years drive investments in robustness measures, making them compatible with all weather conditions within six decades of historical weather data."}, "https://arxiv.org/abs/2011.08069": {"title": "Reconciling Security and Utility in Next-Generation Epidemic Risk Mitigation Systems", "link": "https://arxiv.org/abs/2011.08069", "description": "arXiv:2011.08069v3 Announce Type: replace-cross \nAbstract: Epidemics like the recent COVID-19 require proactive contact tracing and epidemiological analysis to predict and subsequently contain infection transmissions. The proactive measures require large scale data collection, which simultaneously raise concerns regarding users' privacy. Digital contact tracing systems developed in response to COVID-19 either collected extensive data for effective analytics at the cost of users' privacy or collected minimal data for the sake of user privacy but were ineffective in predicting and mitigating the epidemic risks. We present Silmarillion--in preparation for future epidemics--a system that reconciles user's privacy with rich data collection for higher utility. In Silmarillion, user devices record Bluetooth encounters with beacons installed in strategic locations. The beacons further enrich the encounters with geo-location, location type, and environment conditions at the beacon installation site. This enriched information enables detailed scientific analysis of disease parameters as well as more accurate personalized exposure risk notification. At the same time, Silmarillion provides privacy to all participants and non-participants at the same level as that guaranteed in digital and manual contact tracing. We describe the design of Silmarillion and its communication protocols that ensure user privacy and data security. We also evaluate a prototype of Silmarillion built using low-end IoT boards, showing that the power consumption and user latencies are adequately low for a practical deployment. Finally, we briefly report on a small-scale deployment within a university building as a proof-of-concept."}, "https://arxiv.org/abs/2203.07678": {"title": "Incorporating Heterophily into Graph Neural Networks for Graph Classification", "link": "https://arxiv.org/abs/2203.07678", "description": "arXiv:2203.07678v2 Announce Type: replace-cross \nAbstract: Graph Neural Networks (GNNs) often assume strong homophily for graph classification, seldom considering heterophily, which means connected nodes tend to have different class labels and dissimilar features. In real-world scenarios, graphs may have nodes that exhibit both homophily and heterophily. Failing to generalize to this setting makes many GNNs underperform in graph classification. In this paper, we address this limitation by identifying three effective designs and develop a novel GNN architecture called IHGNN (short for Incorporating Heterophily into Graph Neural Networks). These designs include the combination of integration and separation of the ego- and neighbor-embeddings of nodes, adaptive aggregation of node embeddings from different layers, and differentiation between different node embeddings for constructing the graph-level readout function. We empirically validate IHGNN on various graph datasets and demonstrate that it outperforms the state-of-the-art GNNs for graph classification."}, "https://arxiv.org/abs/2308.13604": {"title": "Network science Ising states of matter", "link": "https://arxiv.org/abs/2308.13604", "description": "arXiv:2308.13604v3 Announce Type: replace-cross \nAbstract: Network science provides very powerful tools for extracting information from interacting data. Although recently the unsupervised detection of phases of matter using machine learning has raised significant interest, the full prediction power of network science has not yet been systematically explored in this context. Here we fill this gap by providing an in-depth statistical, combinatorial, geometrical and topological characterization of 2D Ising snapshot networks (IsingNets) extracted from Monte Carlo simulations of the $2$D Ising model at different temperatures, going across the phase transition. Our analysis reveals the complex organization properties of IsingNets in both the ferromagnetic and paramagnetic phases and demonstrates the significant deviations of the IsingNets with respect to randomized null models. In particular percolation properties of the IsingNets reflect the existence of the symmetry between configurations with opposite magnetization below the critical temperature and the very compact nature of the two emerging giant clusters revealed by our persistent homology analysis of the IsingNets. Moreover, the IsingNets display a very broad degree distribution and significant degree-degree correlations and weight-degree correlations demonstrating that they encode relevant information present in the configuration space of the $2$D Ising model. The geometrical organization of the critical IsingNets is reflected in their spectral properties deviating from the one of the null model. This work reveals the important insights that network science can bring to the characterization of phases of matter. The set of tools described hereby can be applied as well to numerical and experimental data."}, "https://arxiv.org/abs/2312.11834": {"title": "Multi-agent reinforcement learning using echo-state network and its application to pedestrian dynamics", "link": "https://arxiv.org/abs/2312.11834", "description": "arXiv:2312.11834v3 Announce Type: replace-cross \nAbstract: In recent years, simulations of pedestrians using the multi-agent reinforcement learning (MARL) have been studied. This study considered the roads on a grid-world environment, and implemented pedestrians as MARL agents using an echo-state network and the least squares policy iteration method. Under this environment, the ability of these agents to learn to move forward by avoiding other agents was investigated. Specifically, we considered two types of tasks: the choice between a narrow direct route and a broad detour, and the bidirectional pedestrian flow in a corridor. The simulations results indicated that the learning was successful when the density of the agents was not that high."}, "https://arxiv.org/abs/2401.09438": {"title": "Recurrence analysis of meteorological data from climate zones in India", "link": "https://arxiv.org/abs/2401.09438", "description": "arXiv:2401.09438v4 Announce Type: replace-cross \nAbstract: We present a study on the spatio-temporal pattern underlying the climate dynamics in various locations spread over India, including the Himalayan region, coastal region, central and northeastern parts of India. We try to capture the variations in the complexity of their dynamics derived from temperature and relative humidity data from 1948-2022. By estimating the recurrence-based measures from the reconstructed phase space dynamics using a sliding window analysis on the data sets, we study the climate variability in different spatial locations. The study brings out the variations in the complexity of the underlying dynamics as well as their heterogeneity across the locations in India. We find almost all locations indicate shifts to more irregular and stochastic dynamics for temperature data around 1972-79 and shifts back to more regular dynamics beyond 2000. These patterns correlate with reported shifts in the climate and Indian Summer Monsoon related to strong and moderate ENSO events and confirm their associated regional variability."}, "https://arxiv.org/abs/2405.06075": {"title": "The Building Blocks of Consciousness", "link": "https://arxiv.org/abs/2405.06075", "description": "arXiv:2405.06075v1 Announce Type: new \nAbstract: Consciousness is presented not as a unified and uniquely human characteristic, but rather as an emergent property of several building blocks, most of which are demonstrably present in other species. Each block has its own rationale under natural selection and could have arisen independently, and the jumps between blocks -- which culminate in consciousness -- are small enough to be evolutionarily plausible. One underappreciated block involves unconscious engram playback and discrimination, and plays a major role in brain storage optimization. This function is present in birds and nearly all mammals and is recognized by its side-effect: dreams."}, "https://arxiv.org/abs/2405.06282": {"title": "A cellular automata approach for modelling pedestrian-vehicle mixed traffic flow in urban city", "link": "https://arxiv.org/abs/2405.06282", "description": "arXiv:2405.06282v1 Announce Type: new \nAbstract: In urban streets, the intrusion of pedestrians presents significant safety challenges. Modelling mixed pedestrian-vehicle traffic is complex due to the distinct motion characteristics and spatial dimensions of pedestrians and vehicles, making unified modelling difficult, with few studies addressing these issues. This paper employs a multi-grid cellular automata model to bridge the gap between vehicle and pedestrian models. An Improved Kerner-Klenov-Wolf (IKKW) model and a pedestrian motion model that incorporates Time-To-Collision (TTC) are introduced. Both models update the spatial motions of vehicles and pedestrians uniformly. Empirical analysis indicates that the model achieves high simulation accuracy. This model effectively illustrates the impact of pedestrian intrusion within mixed traffic scenario. The fundamental diagram of heterogeneous traffic reveals substantial differences, highlighting the effects of pedestrian intrusion on traffic flow states and identifying six phase regions in mixed traffic. Additionally, this paper examines conflicts between pedestrians and vehicles under varying speed limits and sidewalk widths, demonstrating that lower speeds and broader sidewalks significantly reduce the frequency of pedestrian-vehicle conflicts. Notably, the frequency of peak conflicts at a vehicle speed limit of 60.48 km/h is more than three times higher than at 30.24 km/h. This model offers a potential approach to studying mixed traffic flows and exhibits substantial scalability."}, "https://arxiv.org/abs/2405.06285": {"title": "Pedestrian Crossing Discrepancy Within Static and Dynamic Crowds: An Experimental Study", "link": "https://arxiv.org/abs/2405.06285", "description": "arXiv:2405.06285v1 Announce Type: new \nAbstract: This paper aims to investigate the disparities in pedestrian crossing behaviors within static and dynamic crowds through experimental analysis. First, the crossing trajectories of pedestrians in various crowd environments were qualitatively observed. These trajectories have shown significant discrepancies and the phenomenon of cross-channel formation within static crowds was observed, a phenomenon similar to the evolution of human trails. To quantitatively assess these discrepancies, metrics of behavior patterns and swarm factor were introduced. Different behavioral patterns, including anticipation and reaction behaviors in pedestrian motion, were observed. Finally, through orthogonal velocity analysis, the variation trends of crossing motions within static and dynamic contexts were revealed."}, "https://arxiv.org/abs/2405.06395": {"title": "Fitness-Based Growth of Directed Networks with Hierarchy", "link": "https://arxiv.org/abs/2405.06395", "description": "arXiv:2405.06395v1 Announce Type: new \nAbstract: Growing attention has been brought to the fact that many real directed networks exhibit hierarchy and directionality as measured through techniques like Trophic Analysis and non-normality. We propose a simple growing network model where the probability of connecting to a node is defined by a preferential attachment mechanism based on degree and the difference in fitness between nodes. In particular, we show how mechanisms such as degree-based preferential attachment and node fitness interactions can lead to the emergence of the spectrum of hierarchy and directionality observed in real networks. In this work, we study various features of this model relating to network hierarchy, as measured by Trophic Analysis. This includes (I) how preferential attachment can lead to network hierarchy, (II) how scale-free degree distributions and network hierarchy can coexist, (III) the correlation between node fitness and trophic level, (IV) how the fitness parameters can predict trophic incoherence and how the trophic level difference distribution compares to the fitness difference distribution, (V) the relationship between trophic level and degree imbalance and the unique role of nodes at the ends of the fitness hierarchy and (VI) how fitness interactions and degree-based preferential attachment can interplay to generate networks of varying coherence and degree distribution. We also provide an example of the intuition this work enables in the analysis of a real historical network. This work provides insight into simple mechanisms which can give rise to hierarchy in directed networks and quantifies the usefulness and limitations of using Trophic Analysis as an analysis tool for real networks."}, "https://arxiv.org/abs/2405.06508": {"title": "Simple crowd dynamics to generate complex temporal contact networks", "link": "https://arxiv.org/abs/2405.06508", "description": "arXiv:2405.06508v1 Announce Type: new \nAbstract: Empirical contact networks or interaction networks demonstrate peculiar characteristics stemming from the fundamental social, psychological, physical mechanisms governing human interactions. Although these mechanisms are complex, we test whether we are able to reproduce some dynamical properties of these empirical networks from relatively simple models. In this study, we perform simulations for a range of 2D models of particle dynamics, namely the Random Walk, Active Brownian Particles, and Vicsek models, to generate artificial contact networks. We investigate temporal properties of these contact networks: the distributions of contact durations, inter-contact durations and number of contact per pair of particle. We demonstrate that the distribution of inter-contact durations can be recovered by the dynamics of these simple crowd particle models, and show that it is simply related to the well-know first-return process, which explains the -3/2 exponent that is found in both the numerical models and empirical contact networks."}, "https://arxiv.org/abs/2405.06476": {"title": "Is the panel fair? Evaluating panel compositions through network analysis", "link": "https://arxiv.org/abs/2405.06476", "description": "arXiv:2405.06476v1 Announce Type: cross \nAbstract: In research evaluation, the fair representation of panels is usually defined in terms of observable characteristics of scholars such as gender or affiliations. An an empirical strategy is proposed for exploring hidden connections between panellists such that, despite the respect of formal requirements, the panel could be considered alike as unfair with respect to the representation of diversity of research approaches and methodologies. The case study regards the three panels selected to evaluate research in economics, statistics and business during the Italian research assessment exercises. The first two panels were appointed directly by the governmental agency responsible for the evaluation, while the third was randomly selected. Hence the third panel can be considered as a control for evaluating about the fairness of the others. The fair representation is explored by comparing the networks of panellists based on their co-authorship relations, the networks based on journals in which they published and the networks based on their affiliated institutions (universities, research centres and newspapers). The results show that the members of the first two panels had connections much higher than the members of the control group. Hence the composition of the first two panels should be considered as unfair, as the results of the research assessments."}, "https://arxiv.org/abs/2405.06478": {"title": "Attention is all they need: Cognitive science and the (techno)political economy of attention in humans and machines", "link": "https://arxiv.org/abs/2405.06478", "description": "arXiv:2405.06478v1 Announce Type: cross \nAbstract: This paper critically analyses the \"attention economy\" within the framework of cognitive science and techno-political economics, as applied to both human and machine interactions. We explore how current business models, particularly in digital platform capitalism, harness user engagement by strategically shaping attentional patterns. These platforms utilize advanced AI and massive data analytics to enhance user engagement, creating a cycle of attention capture and data extraction. We review contemporary (neuro)cognitive theories of attention and platform engagement design techniques and criticize classical cognitivist and behaviourist theories for their inadequacies in addressing the potential harms of such engagement on user autonomy and wellbeing. 4E approaches to cognitive science, instead, emphasizing the embodied, extended, enactive, and ecological aspects of cognition, offer us an intrinsic normative standpoint and a more integrated understanding of how attentional patterns are actively constituted by adaptive digital environments. By examining the precarious nature of habit formation in digital contexts, we reveal the techno-economic underpinnings that threaten personal autonomy by disaggregating habits away from the individual, into an AI managed collection of behavioural patterns. Our current predicament suggests the necessity of a paradigm shift towards an ecology of attention. This shift aims to foster environments that respect and preserve human cognitive and social capacities, countering the exploitative tendencies of cognitive capitalism."}, "https://arxiv.org/abs/2405.06541": {"title": "ATSumm: Auxiliary information enhanced approach for abstractive disaster Tweet Summarization with sparse training data", "link": "https://arxiv.org/abs/2405.06541", "description": "arXiv:2405.06541v1 Announce Type: cross \nAbstract: The abundance of situational information on Twitter poses a challenge for users to manually discern vital and relevant information during disasters. A concise and human-interpretable overview of this information helps decision-makers in implementing efficient and quick disaster response. Existing abstractive summarization approaches can be categorized as sentence-based or key-phrase-based approaches. This paper focuses on sentence-based approach, which is typically implemented as a dual-phase procedure in literature. The initial phase, known as the extractive phase, involves identifying the most relevant tweets. The subsequent phase, referred to as the abstractive phase, entails generating a more human-interpretable summary. In this study, we adopt the methodology from prior research for the extractive phase. For the abstractive phase of summarization, most existing approaches employ deep learning-based frameworks, which can either be pre-trained or require training from scratch. However, to achieve the appropriate level of performance, it is imperative to have substantial training data for both methods, which is not readily available. This work presents an Abstractive Tweet Summarizer (ATSumm) that effectively addresses the issue of data sparsity by using auxiliary information. We introduced the Auxiliary Pointer Generator Network (AuxPGN) model, which utilizes a unique attention mechanism called Key-phrase attention. This attention mechanism incorporates auxiliary information in the form of key-phrases and their corresponding importance scores from the input tweets. We evaluate the proposed approach by comparing it with 10 state-of-the-art approaches across 13 disaster datasets. The evaluation results indicate that ATSumm achieves superior performance compared to state-of-the-art approaches, with improvement of 4-80% in ROUGE-N F1-score."}, "https://arxiv.org/abs/2405.06551": {"title": "ADSumm: Annotated Ground-truth Summary Datasets for Disaster Tweet Summarization", "link": "https://arxiv.org/abs/2405.06551", "description": "arXiv:2405.06551v1 Announce Type: cross \nAbstract: Online social media platforms, such as Twitter, provide valuable information during disaster events. Existing tweet disaster summarization approaches provide a summary of these events to aid government agencies, humanitarian organizations, etc., to ensure effective disaster response. In the literature, there are two types of approaches for disaster summarization, namely, supervised and unsupervised approaches. Although supervised approaches are typically more effective, they necessitate a sizable number of disaster event summaries for testing and training. However, there is a lack of good number of disaster summary datasets for training and evaluation. This motivates us to add more datasets to make supervised learning approaches more efficient. In this paper, we present ADSumm, which adds annotated ground-truth summaries for eight disaster events which consist of both natural and man-made disaster events belonging to seven different countries. Our experimental analysis shows that the newly added datasets improve the performance of the supervised summarization approaches by 8-28% in terms of ROUGE-N F1-score. Moreover, in newly annotated dataset, we have added a category label for each input tweet which helps to ensure good coverage from different categories in summary. Additionally, we have added two other features relevance label and key-phrase, which provide information about the quality of a tweet and explanation about the inclusion of the tweet into summary, respectively. For ground-truth summary creation, we provide the annotation procedure adapted in detail, which has not been described in existing literature. Experimental analysis shows the quality of ground-truth summary is very good with Coverage, Relevance and Diversity."}, "https://arxiv.org/abs/2306.16568": {"title": "Early warning signals for predicting cryptomarket vendor success using dark net forum networks", "link": "https://arxiv.org/abs/2306.16568", "description": "arXiv:2306.16568v3 Announce Type: replace \nAbstract: In this work we focus on identifying key players in dark net cryptomarkets that facilitate online trade of illegal goods. Law enforcement aims to disrupt criminal activity conducted through these markets by targeting key players vital to the market's existence and success. We particularly focus on detecting successful vendors responsible for the majority of illegal trade. Our methodology aims to uncover whether the task of key player identification should center around plainly measuring user and forum activity, or that it requires leveraging specific patterns of user communication. We focus on a large-scale dataset from the Evolution cryptomarket, which we model as an evolving communication network. Results indicate that user and forum activity, measured through topic engagement, is best able to identify successful vendors. Interestingly, considering users with higher betweenness centrality in the communication network further improves performance, also identifying successful vendors with moderate activity on the forum. But more importantly, analyzing the forum data over time, we find evidence that attaining a high betweenness score comes before vendor success. This suggests that the proposed network-driven approach of modelling user communication might prove useful as an early warning signal for key player identification."}, "https://arxiv.org/abs/2312.14040": {"title": "Balancing Specialization and Adaptation in a Transforming Scientific Landscape", "link": "https://arxiv.org/abs/2312.14040", "description": "arXiv:2312.14040v5 Announce Type: replace \nAbstract: How do scientists navigate between the need to capitalize on their prior knowledge through specialization, and the urge to adapt to evolving research opportunities? Drawing from diverse perspectives on adaptation, including cultural evolution, this paper proposes an unsupervised Bayesian approach motivated by Optimal Transport of the evolution of scientists' research portfolios in response to transformations in their field. The model relies on $186,162$ scientific abstracts and authorship data to evaluate the influence of intellectual, social, and institutional resources on scientists' trajectories within a cohort of $2\\,195$ high-energy physicists between 2000 and 2019. Using Inverse Optimal Transport, the reallocation of research efforts is shown to be shaped by learning costs, thus enhancing the utility of the scientific capital disseminated among scientists. Two dimensions of social capital, namely \"diversity\" and \"power\", have opposite associations with the magnitude of change in scientists' research interests: while \"diversity\" disrupts and expands research interests, \"power\" is associated with more stable research agendas. Social capital plays a more crucial role in shifts between cognitively distant research areas. More generally, this work suggests new approaches for understanding, measuring and modeling collective adaptation using Optimal Transport."}, "https://arxiv.org/abs/2401.03656": {"title": "CosIn: A Statistical-Based Algorithm for Computation of Speed-Space Time Delay in Pedestrian Motion", "link": "https://arxiv.org/abs/2401.03656", "description": "arXiv:2401.03656v3 Announce Type: replace \nAbstract: The precise assessment of speed-space time delay (TD) facilitates the differentiation between pedestrian anticipation behavior and reaction behavior. Importantly, the TD scale is instrumental in the evaluation of potential collision risks inherent in the crowd, thereby offering crucial quantitative metrics for crowd risk. This article introduces the CosIn algorithm for evaluate TD during pedestrian motion, comprising the CosIn-1 and CosIn-2 algorithms. The CosIn-1 algorithm specifically addresses the precise computation issue associated with the TD of individual pedestrians, while the CosIn-2 algorithm is employed for assessing TD at a crowd scale, concurrently addressing the imperative of real-time computation. Efficacy analyses of the CosIn-1 and CosIn-2 algorithms are conducted using the data from single-file pedestrian experiments and crowd cross experiments, respectively. The results obtained demonstrate commendable precision in the algorithmic solutions. This algorithm contributes to the precise assessment of behavior patterns and collision risk within crowd dynamics."}, "https://arxiv.org/abs/2403.01269": {"title": "Network analysis using Krylov subspace trajectories", "link": "https://arxiv.org/abs/2403.01269", "description": "arXiv:2403.01269v2 Announce Type: replace \nAbstract: We describe a set of network analysis methods based on the rows of the Krylov subspace matrix computed from a network adjacency matrix via power iteration using a non-random initial vector. We refer to these node-specific row vectors as Krylov subspace trajectories. While power iteration using a random initial starting vector is commonly applied to the network adjacency matrix to compute eigenvector centrality values, this application only uses the final vector generated after numerical convergence. Importantly, use of a random initial vector means that the intermediate results of power iteration are also random and lack a clear interpretation. To the best of our knowledge, use of intermediate power iteration results for network analysis has been limited to techniques that leverage just a single pre-convergence solution, e.g., Power Iteration Clustering. In this paper, we explore methods that apply power iteration with a non-random inital vector to the network adjacency matrix to generate Krylov subspace trajectories for each node. These non-random trajectories provide important information regarding network structure, node importance, and response to perturbations. We have created this short preprint in part to generate feedback from others in the network analysis community who might be aware of similar existing work."}, "https://arxiv.org/abs/2404.05334": {"title": "Modeling the Dynamic Process of Inventions for Reducing Knowledge Search Costs", "link": "https://arxiv.org/abs/2404.05334", "description": "arXiv:2404.05334v2 Announce Type: replace \nAbstract: A knowledge search is a key process for inventions. However, there is inadequate quantitative modeling of dynamic knowledge search processes and associated search costs. In this study, agent-based and complex network methodologies were proposed to quantitatively describe the dynamic process of knowledge search for actual inventions. Prior knowledge networks (PKNs), the search space of historical patents, were constructed, representative search rules were formulated for R&amp;D agents, and measures for knowledge search cost were designed to serve as search objectives. Simulation results in the field of photolithographic technology show that search costs differ significantly with different search rules. Familiarity and Degree rules significantly outperform BFS, DFS and Recency rules in terms of knowledge search costs, and are less affected by the size and density of PKNs. Interestingly, there is no significant correlation between the mean and variance of search costs and patent value, indicating that high-value patents are not particularly difficult to obtain. The implications for innovation theories and R&amp;D practices are drawn from the models and results."}, "https://arxiv.org/abs/2301.09289": {"title": "Fundamental Limits of Spectral Clustering in Stochastic Block Models", "link": "https://arxiv.org/abs/2301.09289", "description": "arXiv:2301.09289v3 Announce Type: replace-cross \nAbstract: Spectral clustering has been widely used for community detection in network sciences. While its empirical successes are well-documented, a clear theoretical understanding, particularly for sparse networks where degrees are much smaller than $\\log n$, remains unclear. In this paper, we address this significant gap by demonstrating that spectral clustering offers exponentially small error rates when applied to sparse networks under Stochastic Block Models. Our analysis provides sharp characterizations of its performance, backed by matching upper and lower bounds possessing an identical exponent with the same leading constant. The key to our results is a novel truncated $\\ell_2$ perturbation analysis for eigenvectors, coupled with a new analysis idea of eigenvectors truncation."}, "https://arxiv.org/abs/2312.15099": {"title": "Moderating New Waves of Online Hate with Chain-of-Thought Reasoning in Large Language Models", "link": "https://arxiv.org/abs/2312.15099", "description": "arXiv:2312.15099v2 Announce Type: replace-cross \nAbstract: Online hate is an escalating problem that negatively impacts the lives of Internet users, and is also subject to rapid changes due to evolving events, resulting in new waves of online hate that pose a critical threat. Detecting and mitigating these new waves present two key challenges: it demands reasoning-based complex decision-making to determine the presence of hateful content, and the limited availability of training samples hinders updating the detection model. To address this critical issue, we present a novel framework called HATEGUARD for effectively moderating new waves of online hate. HATEGUARD employs a reasoning-based approach that leverages the recently introduced chain-of-thought (CoT) prompting technique, harnessing the capabilities of large language models (LLMs). HATEGUARD further achieves prompt-based zero-shot detection by automatically generating and updating detection prompts with new derogatory terms and targets in new wave samples to effectively address new waves of online hate. To demonstrate the effectiveness of our approach, we compile a new dataset consisting of tweets related to three recently witnessed new waves: the 2022 Russian invasion of Ukraine, the 2021 insurrection of the US Capitol, and the COVID-19 pandemic. Our studies reveal crucial longitudinal patterns in these new waves concerning the evolution of events and the pressing need for techniques to rapidly update existing moderation tools to counteract them. Comparative evaluations against state-of-the-art tools illustrate the superiority of our framework, showcasing a substantial 22.22% to 83.33% improvement in detecting the three new waves of online hate. Our work highlights the severe threat posed by the emergence of new waves of online hate and represents a paradigm shift in addressing this threat practically."}, "https://arxiv.org/abs/2405.06698": {"title": "Optimizing Viscous Democracy", "link": "https://arxiv.org/abs/2405.06698", "description": "arXiv:2405.06698v1 Announce Type: new \nAbstract: Viscous democracy is a generalization of liquid democracy, a social choice framework in which voters may transitively delegate their votes. In viscous democracy, a \"viscosity\" factor decreases the weight of a delegation the further it travels, reducing the chance of excessive weight flowing between ideologically misaligned voters. We demonstrate that viscous democracy often significantly improves the quality of group decision-making over liquid democracy. We first show that finding optimal delegations within a viscous setting is NP-hard. However, simulations allow us to explore the practical effects of viscosity. Across social network structures, competence distributions, and delegation mechanisms we find high viscosity reduces the chance of \"super-voters\" attaining large amounts of weight and increases the number of voters that are able to affect the outcome of elections. This, in turn, improves group accuracy as a whole. As a result, we argue that viscosity should be considered a core component of liquid democracy."}, "https://arxiv.org/abs/2405.06700": {"title": "LLM-Augmented Agent-Based Modelling for Social Simulations: Challenges and Opportunities", "link": "https://arxiv.org/abs/2405.06700", "description": "arXiv:2405.06700v1 Announce Type: new \nAbstract: As large language models (LLMs) continue to make significant strides, their better integration into agent-based simulations offers a transformational potential for understanding complex social systems. However, such integration is not trivial and poses numerous challenges. Based on this observation, in this paper, we explore architectures and methods to systematically develop LLM-augmented social simulations and discuss potential research directions in this field. We conclude that integrating LLMs with agent-based simulations offers a powerful toolset for researchers and scientists, allowing for more nuanced, realistic, and comprehensive models of complex systems and human behaviours."}, "https://arxiv.org/abs/2405.06947": {"title": "A Galton Board Approximation Method for Estimating Pedestrian Walking Preferences within Crowds", "link": "https://arxiv.org/abs/2405.06947", "description": "arXiv:2405.06947v1 Announce Type: new \nAbstract: This paper proposes a Galton board approximation method to analyze the potential walking preferences of pedestrians. We employ the binomial distribution to estimate the walking preferences of pedestrians in dynamic crowds. Estimating the probability of the right-side preference $(p)$ based on observational data poses the challenge, as statistical measures such as means and variances often lead to divergent results. This paper aims to explore this issue."}, "https://arxiv.org/abs/2405.07071": {"title": "Colocation of skill related suppliers -- Revisiting coagglomeration using firm-to-firm network data", "link": "https://arxiv.org/abs/2405.07071", "description": "arXiv:2405.07071v1 Announce Type: new \nAbstract: Strong local clusters help firms compete on global markets. One explanation for this is that firms benefit from locating close to their suppliers and customers. However, the emergence of global supply chains shows that physical proximity is not necessarily a prerequisite to successfully manage customer-supplier relations anymore. This raises the question when firms need to colocate in value chains and when they can coordinate over longer distances. We hypothesize that one important aspect is the extent to which supply chain partners exchange not just goods but also know-how. To test this, we build on an expanding literature that studies the drivers of industrial coagglomeration to analyze when supply chain connections lead firms to colocation. We exploit detailed micro-data for the Hungarian economy between 2015 and 2017, linking firm registries, employer-employee matched data and firm-to-firm transaction data from value-added tax records. This allows us to observe colocation, labor flows and value chain connections at the level of firms, as well as construct aggregated coagglomeration patterns, skill relatedness and input-output connections between pairs of industries. We show that supply chains are more likely to support coagglomeration when the industries involved are also skill related. That is, input-output and labor market channels reinforce each other, but supplier connections only matter for colocation when industries have similar labor requirements, suggesting that they employ similar types of know-how. We corroborate this finding by analyzing the interactions between firms, showing that supplier relations are more geographically constrained between companies that operate in skill related industries."}, "https://arxiv.org/abs/2405.07072": {"title": "Selecting focused digital cohorts from social media using the metric backbone of biomedical knowledge graphs", "link": "https://arxiv.org/abs/2405.07072", "description": "arXiv:2405.07072v1 Announce Type: new \nAbstract: The abundance of social media data allows researchers to construct large digital cohorts to study the interplay between human behavior and medical treatment. Identifying the users most relevant to a specific health problem is, however, a challenge in that social media sites vary in the generality of their discourse. While X (formerly Twitter), Instagram, and Facebook cater to wide ranging topics, Reddit subgroups and dedicated patient advocacy forums trade in much more specific, biomedically-relevant discourse. To hone in on relevant users anywhere, we have developed a general framework and applied it to epilepsy discourse in social media as a test case. We analyzed the text from posts by users who mention epilepsy drugs in the general-purpose social media sites X and Instagram, the epilepsy-focused Reddit subgroup (r/Epilepsy), and the Epilepsy Foundation of America (EFA) forums. We curated a medical terms dictionary and used it to generate a knowledge graph (KG) for each online community. For each KG, we computed the metric backbone--the smallest subgraph that preserves all shortest paths in the network. By comparing the subset of users who contribute to the backbone to the subset who do not, we found that epilepsy-focused social media users contribute to the KG backbone in much higher proportion than do general-purpose social media users. Furthermore, using human annotation of Instagram posts, we demonstrated that users who do not contribute to the backbone are more than twice as likely to use dictionary terms in a manner inconsistent with their biomedical meaning. For biomedical research applications, our backbone-based approach thus has several benefits over simple engagement-based approaches: It can retain low-engagement users who nonetheless contribute meaningful biomedical insights. It can filter out very vocal users who contribute no relevant content."}, "https://arxiv.org/abs/2405.07096": {"title": "Multi-Relational Structural Entropy", "link": "https://arxiv.org/abs/2405.07096", "description": "arXiv:2405.07096v1 Announce Type: new \nAbstract: Structural Entropy (SE) measures the structural information contained in a graph. Minimizing or maximizing SE helps to reveal or obscure the intrinsic structural patterns underlying graphs in an interpretable manner, finding applications in various tasks driven by networked data. However, SE ignores the heterogeneity inherent in the graph relations, which is ubiquitous in modern networks. In this work, we extend SE to consider heterogeneous relations and propose the first metric for multi-relational graph structural information, namely, Multi-relational Structural Entropy (MrSE). To this end, we first cast SE through the novel lens of the stationary distribution from random surfing, which readily extends to multi-relational networks by considering the choices of both nodes and relation types simultaneously at each step. The resulting MrSE is then optimized by a new greedy algorithm to reveal the essential structures within a multi-relational network. Experimental results highlight that the proposed MrSE offers a more insightful interpretation of the structure of multi-relational graphs compared to SE. Additionally, it enhances the performance of two tasks that involve real-world multi-relational graphs, including node clustering and social event detection."}, "https://arxiv.org/abs/2405.07277": {"title": "Mining Influential Spreaders in Complex Networks by an Effective Combination of the Degree and K-Shell", "link": "https://arxiv.org/abs/2405.07277", "description": "arXiv:2405.07277v1 Announce Type: new \nAbstract: Graph mining is an important technique that used in many applications such as predicting and understanding behaviors and information dissemination within networks. One crucial aspect of graph mining is the identification and ranking of influential nodes, which has applications in various fields including marketing, social communications, and disease control. However, existing models and methods come with high computational complexity and may not accurately distinguish and identify influential nodes. This paper develops a method based on the k-shell index and degree centrality of nodes and their neighbors. Comparisons to previous works, such as Degree and Neighborhood information Centrality (DNC) and Neighborhood and Path Information Centrality (NPIC), are conducted. The evaluations, which include the correctness with Kendall's Tau, resolution with monotonicity index, correlation plots, and time complexity, demonstrate its superior results."}, "https://arxiv.org/abs/2405.07417": {"title": "Identifying Hate Speech Peddlers in Online Platforms", "link": "https://arxiv.org/abs/2405.07417", "description": "arXiv:2405.07417v1 Announce Type: new \nAbstract: This paper studies the problem of autonomous agents performing Bayesian social learning for sequential detection when the observations of the state belong to a high-dimensional space and are expensive to analyze. Specifically, when the observations are textual, the Bayesian agent can use a large language model (LLM) as a map to get a low-dimensional private observation. The agent performs Bayesian learning and takes an action that minimizes the expected cost and is visible to subsequent agents. We prove that a sequence of such Bayesian agents herd in finite time to the public belief and take the same action disregarding the private observations. We propose a stopping time formulation for quickest time herding in social learning and optimally balance privacy and herding. Structural results are shown on the threshold nature of the optimal policy to the stopping time problem. We illustrate the application of our framework when autonomous Bayesian detectors aim to sequentially identify if a user is a hate speech peddler on an online platform by parsing text observations using an LLM. We numerically validate our results on real-world hate speech datasets. We show that autonomous Bayesian agents designed to flag hate speech peddlers in online platforms herd and misclassify the users when the public prior is strong. We also numerically show the effect of a threshold policy in delaying herding."}, "https://arxiv.org/abs/2405.07574": {"title": "Is it getting harder to make a hit? Evidence from 65 years of US music chart history", "link": "https://arxiv.org/abs/2405.07574", "description": "arXiv:2405.07574v1 Announce Type: new \nAbstract: Since the creation of the Billboard Hot 100 music chart in 1958, the chart has been a window into the music consumption of Americans. Which songs succeed on the chart is decided by consumption volumes, which can be affected by consumer music taste, and other factors such as advertisement budgets, airplay time, the specifics of ranking algorithms, and more. Since its introduction, the chart has documented music consumerism through eras of globalization, economic growth, and the emergence of new technologies for music listening. In recent years, musicians and other hitmakers have voiced their worry that the music world is changing: Many claim that it is getting harder to make a hit but until now, the claims have not been backed using chart data. Here we show that the dynamics of the Billboard Hot 100 chart have changed significantly since the chart's founding in 1958, and in particular in the past 15 years. Whereas most songs spend less time on the chart now than songs did in the past, we show that top-1 songs have tripled their chart lifetime since the 1960s, the highest-ranked songs maintain their positions for far longer than previously, and the lowest-ranked songs are replaced more frequently than ever. At the same time, who occupies the chart has also changed over the years: In recent years, fewer new artists make it into the chart and more positions are occupied by established hit makers. Finally, investigating how song chart trajectories have changed over time, we show that historical song trajectories cluster into clear trajectory archetypes characteristic of the time period they were part of. The results are interesting in the context of collective attention: Whereas recent studies have documented that other cultural products such as books, news, and movies fade in popularity quicker in recent years, music hits seem to last longer now than in the past."}, "https://arxiv.org/abs/2405.07828": {"title": "Can LLMs Help Predict Elections? (Counter)Evidence from the World's Largest Democracy", "link": "https://arxiv.org/abs/2405.07828", "description": "arXiv:2405.07828v1 Announce Type: new \nAbstract: The study of how social media affects the formation of public opinion and its influence on political results has been a popular field of inquiry. However, current approaches frequently offer a limited comprehension of the complex political phenomena, yielding inconsistent outcomes. In this work, we introduce a new method: harnessing the capabilities of Large Language Models (LLMs) to examine social media data and forecast election outcomes. Our research diverges from traditional methodologies in two crucial respects. First, we utilize the sophisticated capabilities of foundational LLMs, which can comprehend the complex linguistic subtleties and contextual details present in social media data. Second, we focus on data from X (Twitter) in India to predict state assembly election outcomes. Our method entails sentiment analysis of election-related tweets through LLMs to forecast the actual election results, and we demonstrate the superiority of our LLM-based method against more traditional exit and opinion polls. Overall, our research offers valuable insights into the unique dynamics of Indian politics and the remarkable impact of social media in molding public attitudes within this context."}, "https://arxiv.org/abs/2405.07950": {"title": "Quantum-like states on complex synchronized networks", "link": "https://arxiv.org/abs/2405.07950", "description": "arXiv:2405.07950v1 Announce Type: new \nAbstract: Recent work has exposed the idea that interesting quantum-like probability laws, including interference effects, can be manifest in classical systems. Here we propose a model for quantum-like (QL) states and QL bits. We suggest a way that huge, complex systems can host robust states that can process information in a QL fashion. Axioms that such states should satisfy are proposed. Specifically, it is shown that building blocks suited for QL states are networks, possibly very complex, that we defined based on $k$-regular random graphs. These networks can dynamically encode a lot of information that is distilled into the emergent states we can use for QL like processing. Although the emergent states are classical, they have properties analogous to quantum states. Concrete examples of how QL functions are possible are given. The possibility of a `QL advantage' for computing-type operations and the potential relevance for new kinds of function in the brain are discussed and left as open questions."}, "https://arxiv.org/abs/2405.06656": {"title": "Exploring Social Media Posts for Depression Identification: A Study on Reddit Dataset", "link": "https://arxiv.org/abs/2405.06656", "description": "arXiv:2405.06656v1 Announce Type: cross \nAbstract: Depression is one of the most common mental disorders affecting an individual's personal and professional life. In this work, we investigated the possibility of utilizing social media posts to identify depression in individuals. To achieve this goal, we conducted a preliminary study where we extracted and analyzed the top Reddit posts made in 2022 from depression-related forums. The collected data were labeled as depressive and non-depressive using UMLS Metathesaurus. Further, the pre-processed data were fed to classical machine learning models, where we achieved an accuracy of 92.28\\% in predicting the depressive and non-depressive posts."}, "https://arxiv.org/abs/2405.06668": {"title": "Exposing and Explaining Fake News On-the-Fly", "link": "https://arxiv.org/abs/2405.06668", "description": "arXiv:2405.06668v1 Announce Type: cross \nAbstract: Social media platforms enable the rapid dissemination and consumption of information. However, users instantly consume such content regardless of the reliability of the shared data. Consequently, the latter crowdsourcing model is exposed to manipulation. This work contributes with an explainable and online classification method to recognize fake news in real-time. The proposed method combines both unsupervised and supervised Machine Learning approaches with online created lexica. The profiling is built using creator-, content- and context-based features using Natural Language Processing techniques. The explainable classification mechanism displays in a dashboard the features selected for classification and the prediction confidence. The performance of the proposed solution has been validated with real data sets from Twitter and the results attain 80 % accuracy and macro F-measure. This proposal is the first to jointly provide data stream processing, profiling, classification and explainability. Ultimately, the proposed early detection, isolation and explanation of fake news contribute to increase the quality and trustworthiness of social media contents."}, "https://arxiv.org/abs/2405.06684": {"title": "QuakeBERT: Accurate Classification of Social Media Texts for Rapid Earthquake Impact Assessment", "link": "https://arxiv.org/abs/2405.06684", "description": "arXiv:2405.06684v1 Announce Type: cross \nAbstract: Social media aids disaster response but suffers from noise, hindering accurate impact assessment and decision making for resilient cities, which few studies considered. To address the problem, this study proposes the first domain-specific LLM model and an integrated method for rapid earthquake impact assessment. First, a few categories are introduced to classify and filter microblogs considering their relationship to the physical and social impacts of earthquakes, and a dataset comprising 7282 earthquake-related microblogs from twenty earthquakes in different locations is developed as well. Then, with a systematic analysis of various influential factors, QuakeBERT, a domain-specific large language model (LLM), is developed and fine-tuned for accurate classification and filtering of microblogs. Meanwhile, an integrated method integrating public opinion trend analysis, sentiment analysis, and keyword-based physical impact quantification is introduced to assess both the physical and social impacts of earthquakes based on social media texts. Experiments show that data diversity and data volume dominate the performance of QuakeBERT and increase the macro average F1 score by 27%, while the best classification model QuakeBERT outperforms the CNN- or RNN-based models by improving the macro average F1 score from 60.87% to 84.33%. Finally, the proposed approach is applied to assess two earthquakes with the same magnitude and focal depth. Results show that the proposed approach can effectively enhance the impact assessment process by accurate detection of noisy microblogs, which enables effective post-disaster emergency responses to create more resilient cities."}, "https://arxiv.org/abs/2405.07217": {"title": "Improved bounds for polylogarithmic graph distances in scale-free percolation and related models", "link": "https://arxiv.org/abs/2405.07217", "description": "arXiv:2405.07217v1 Announce Type: cross \nAbstract: In this paper, we study graph distances in the geometric random graph models scale-free percolation SFP, geometric inhomogeneous random graphs GIRG, and hyperbolic random graphs HRG. Despite the wide success of the models, the parameter regime in which graph distances are polylogarithmic is poorly understood. We provide new and improved lower bounds. In a certain portion of the parameter regime, those match the known upper bounds.\n  Compared to the best previous lower bounds by Hao and Heydenreich, our result has several advantages: it gives matching bounds for a larger range of parameters, thus settling the question for a larger portion of the parameter space. It strictly improves the lower bounds by Hao and Heydenreich for all parameters settings in which those bounds were not tight. It gives tail bounds on the probability of having short paths, which imply shape theorems for the $k$-neighbourhood of a vertex whenever our lower bounds are tight, and tight bounds for the size of this $k$-neighbourhood. And last but not least, our proof is much simpler and not much longer than two pages, and we demonstrate that it generalizes well by showing that the same technique also works for first passage percolation."}, "https://arxiv.org/abs/2405.07764": {"title": "LGDE: Local Graph-based Dictionary Expansion", "link": "https://arxiv.org/abs/2405.07764", "description": "arXiv:2405.07764v1 Announce Type: cross \nAbstract: Expanding a dictionary of pre-selected keywords is crucial for tasks in information retrieval, such as database query and online data collection. Here we propose Local Graph-based Dictionary Expansion (LGDE), a method that uses tools from manifold learning and network science for the data-driven discovery of keywords starting from a seed dictionary. At the heart of LGDE lies the creation of a word similarity graph derived from word embeddings and the application of local community detection based on graph diffusion to discover semantic neighbourhoods of pre-defined seed keywords. The diffusion in the local graph manifold allows the exploration of the complex nonlinear geometry of word embeddings and can capture word similarities based on paths of semantic association. We validate our method on a corpus of hate speech-related posts from Reddit and Gab and show that LGDE enriches the list of keywords and achieves significantly better performance than threshold methods based on direct word similarities. We further demonstrate the potential of our method through a real-world use case from communication science, where LGDE is evaluated quantitatively on data collected and analysed by domain experts by expanding a conspiracy-related dictionary."}, "https://arxiv.org/abs/2405.07877": {"title": "Optimal accuracy for linear sets of equations with the graph Laplacian", "link": "https://arxiv.org/abs/2405.07877", "description": "arXiv:2405.07877v1 Announce Type: cross \nAbstract: We show that certain Graph Laplacian linear sets of equations exhibit optimal accuracy, guaranteeing that the relative error is no larger than the norm of the relative residual and that optimality occurs for carefully chosen right-hand sides. Such sets of equations arise in PageRank and Markov chain theory. We establish new relationships among the PageRank teleportation parameter, the Markov chain discount, and approximations to linear sets of equations. The set of optimally accurate systems can be separated into two groups for an undirected graph -- those that achieve optimality asymptotically with the graph size and those that do not -- determined by the angle between the right-hand side of the linear system and the vector of all ones. We provide supporting numerical experiments."}, "https://arxiv.org/abs/2306.08426": {"title": "Patterns of Patterns II", "link": "https://arxiv.org/abs/2306.08426", "description": "arXiv:2306.08426v3 Announce Type: replace \nAbstract: Our earlier paper \"Patterns of Patterns\" combined three techniques from training, futures studies, and design in a design pattern called PLACARD that helps groups of people work together effectively. We used that pattern in five hands-on workshop case studies which took place at various locations in the US and the UK. This experience report documents what we learned, including the way our thinking about PLACARD evolved, together with additional patterns our work generated. We evaluate the reproducibility of our methods and results, and consider the broader economic implications of this way of working. We discuss implications of our prototyping work for the design of future platforms, drawing connections with recent developments in cognitive science and artificial intelligence. This positions our patterns of patterns as a toolkit for the design and governance of systems that combine social dynamics with technical components."}, "https://arxiv.org/abs/2306.12136": {"title": "Node-layer duality in networked systems", "link": "https://arxiv.org/abs/2306.12136", "description": "arXiv:2306.12136v2 Announce Type: replace \nAbstract: Real-world networks typically exhibit several aspects, or layers, of interactions among their nodes. By permuting the role of the nodes and the layers, we establish a new criterion to construct the dual of a network. This approach allows to examine information from either a node-centric or layer-centric viewpoint. Through rigorous analytical methods and extensive simulations, we demonstrate that nodewise and layerwise connectivity measure different but related aspects of the same system. Leveraging node-layer duality provides complementary insights, enabling a deeper comprehension of diverse networks across social science, technology and biology. Taken together, these findings reveal previously unappreciated features of complex systems and provide a fresh tool for delving into their structure and dynamics."}, "https://arxiv.org/abs/2310.12181": {"title": "Precise influence evaluation in complex networks", "link": "https://arxiv.org/abs/2310.12181", "description": "arXiv:2310.12181v2 Announce Type: replace \nAbstract: Evaluating node influence is fundamental for identifying key nodes in complex networks. Existing methods typically rely on generic indicators to rank node influence across diverse networks, thereby ignoring the individualized features of each network itself. Actually, node influence stems not only from general features but the multi-scale individualized information encompassing specific network structure and task. Here we design an active learning architecture to predict node influence quantitively and precisely, which samples representative nodes based on graph entropy correlation matrix integrating multi-scale individualized information. This brings two intuitive advantages: (1) discovering potential high-influence but weak-connected nodes that are usually ignored in existing methods, (2) improving the influence maximization strategy by deducing influence interference. Significantly, our architecture demonstrates exceptional transfer learning capabilities across multiple types of networks, which can identify those key nodes with large disputation across different existing methods. Additionally, our approach, combined with a simple greedy algorithm, exhibits dominant performance in solving the influence maximization problem. This architecture holds great potential for applications in graph mining and prediction tasks."}, "https://arxiv.org/abs/2312.12186": {"title": "Social Learning in Community Structured Graphs", "link": "https://arxiv.org/abs/2312.12186", "description": "arXiv:2312.12186v3 Announce Type: replace \nAbstract: Traditional social learning frameworks consider environments with a homogeneous state, where each agent receives observations conditioned on that true state of nature. In this work, we relax this assumption and study the distributed hypothesis testing problem in a heterogeneous environment, where each agent can receive observations conditioned on their own personalized state of nature (or truth). We particularly focus on community structured networks, where each community admits their own true hypothesis. This scenario is common in various contexts, such as when sensors are spatially distributed, or when individuals in a social network have differing views or opinions. We show that the adaptive social learning strategy is a preferred choice for nonstationary environments, and allows each cluster to discover its own truth."}, "https://arxiv.org/abs/2401.00651": {"title": "IRWE: Inductive Random Walk for Joint Inference of Identity and Position Network Embedding", "link": "https://arxiv.org/abs/2401.00651", "description": "arXiv:2401.00651v2 Announce Type: replace \nAbstract: Network embedding, which maps graphs to distributed representations, is a unified framework for various graph inference tasks. According to the topology properties (e.g., structural roles and community memberships of nodes) to be preserved, it can be categorized into the identity and position embedding. However, existing methods can only capture one type of property. Some approaches can support the inductive inference that generalizes the embedding model to new nodes or graphs but relies on the availability of attributes. Due to the complicated correlations between topology and attributes, it is unclear for some inductive methods which type of property they can capture. In this study, we explore a unified framework for the joint inductive inference of identity and position embeddings without attributes. An inductive random walk embedding (IRWE) method is proposed, which combines multiple attention units to handle the random walk on graph topology and simultaneously derives identity and position embeddings that are jointly optimized. In particular, we demonstrate that some random walk statistics can be informative features to characterize node identities and positions while supporting the inductive embedding inference. Experiments validate the superior performance of IRWE beyond various baselines for the transductive and inductive inference of identity and position embeddings."}, "https://arxiv.org/abs/2402.03837": {"title": "Expressivity of Geometric Inhomogeneous Random Graphs -- Metric and Non-Metric", "link": "https://arxiv.org/abs/2402.03837", "description": "arXiv:2402.03837v2 Announce Type: replace \nAbstract: Recently there has been increased interest in fitting generative graph models to real-world networks. In particular, Bl\\\"asius et al. have proposed a framework for systematic evaluation of the expressivity of random graph models. We extend this framework to Geometric Inhomogeneous Random Graphs (GIRGs). This includes a family of graphs induced by non-metric distance functions which allow capturing more complex models of partial similarity between nodes as a basis of connection - as well as homogeneous and non-homogeneous feature spaces. As part of the extension, we develop schemes for estimating the multiplicative constant and the long-range parameter in the connection probability. Moreover, we devise an algorithm for sampling Minimum-Component-Distance GIRGs whose runtime is linear both in the number of vertices and in the dimension of the underlying geometric space. Our results provide evidence that GIRGs are more realistic candidates with respect to various graph features such as closeness centrality, betweenness centrality, local clustering coefficient, and graph effective diameter, while they face difficulties to replicate higher variance and more extreme values of graph statistics observed in real-world networks."}, "https://arxiv.org/abs/2402.18850": {"title": "A simple model of global cascades on random hypergraphs", "link": "https://arxiv.org/abs/2402.18850", "description": "arXiv:2402.18850v2 Announce Type: replace \nAbstract: This study introduces a comprehensive framework that situates information cascade research within the domain of higher-order interactions, utilizing a double-threshold hypergraph model. We propose that individuals (nodes) gain awareness of information through each communication channel (hyperedge) once the number of information adopters surpasses the threshold $\\phi_m$. However, actual adoption of the information only occurs when the cumulative influence across all communication channels exceeds a second threshold, $\\phi_k$. We analytically derive the cascade condition for both the case of a single seed node using percolation methods and the case of any seed size employing mean-field approximation. Our findings underscore that when considering the fractional seed size, $r_0 \\in (0,1]$, the connectivity pattern of the random hypergraph, characterized by the hyperdegree ($k$) and cardinality ($m$) distribution, exerts an asymmetric impact on the global cascade boundary. This asymmetry manifests in the observed differences in the boundaries of the global cascade within the $(\\phi_m, \\langle m \\rangle)$ and $(\\phi_k, \\langle k \\rangle)$ planes. However, as $r_0 \\to 0$, this asymmetric effect gradually diminishes. Overall, by elucidating the mechanisms driving information cascades within a broader context of higher-order interactions, our research contributes to theoretical advancements in complex systems theory."}, "https://arxiv.org/abs/2403.13945": {"title": "$N$-player game formulation of the majority-vote model of opinion dynamics", "link": "https://arxiv.org/abs/2403.13945", "description": "arXiv:2403.13945v2 Announce Type: replace \nAbstract: From a self-centered perspective, it can be assumed that people only hold opinions that can benefit them. If opinions have no intrinsic value, and acquire their value when held by the majority of individuals in a discussion group, then we have a situation that can be modeled as an $N$-player game. Here we explore the dynamics of (binary) opinion formation using a game-theoretic framework to study an $N$-player game version of Galam's local majority-vote model. The opinion dynamics is modeled by a stochastic imitation dynamics in which the individuals copy the opinion of more successful peers. In the infinite population limit, this dynamics is described by the classical replicator equation of evolutionary game theory. The equilibrium solution shows a threshold separating the initial frequencies that lead to the fixation of one opinion or the other. A comparison with Galam's deterministic model reveals contrasting results, especially in the presence of inflexible individuals, who never change their opinions. In particular, the $N$-player game predicts a polarized equilibrium consisting only of extremists. Using finite-size scaling analysis, we evaluate the critical exponents that determine the population size dependence of the opinion's fixation probability and mean fixation times near the threshold. The results underscore the usefulness of combining evolutionary game theory with opinion dynamics and the importance of statistical physics tools to summarize the results of Monte Carlo simulations."}, "https://arxiv.org/abs/2310.16181": {"title": "Hidden Citations Obscure True Impact in Science", "link": "https://arxiv.org/abs/2310.16181", "description": "arXiv:2310.16181v2 Announce Type: replace-cross \nAbstract: References, the mechanism scientists rely on to signal previous knowledge, lately have turned into widely used and misused measures of scientific impact. Yet, when a discovery becomes common knowledge, citations suffer from obliteration by incorporation. This leads to the concept of hidden citation, representing a clear textual credit to a discovery without a reference to the publication embodying it. Here, we rely on unsupervised interpretable machine learning applied to the full text of each paper to systematically identify hidden citations. We find that for influential discoveries hidden citations outnumber citation counts, emerging regardless of publishing venue and discipline. We show that the prevalence of hidden citations is not driven by citation counts, but rather by the degree of the discourse on the topic within the text of the manuscripts, indicating that the more discussed is a discovery, the less visible it is to standard bibliometric analysis. Hidden citations indicate that bibliometric measures offer a limited perspective on quantifying the true impact of a discovery, raising the need to extract knowledge from the full text of the scientific corpus."}, "https://arxiv.org/abs/2311.08605": {"title": "Exploring the Jungle of Bias: Political Bias Attribution in Language Models via Dependency Analysis", "link": "https://arxiv.org/abs/2311.08605", "description": "arXiv:2311.08605v2 Announce Type: replace-cross \nAbstract: The rapid advancement of Large Language Models (LLMs) has sparked intense debate regarding the prevalence of bias in these models and its mitigation. Yet, as exemplified by both results on debiasing methods in the literature and reports of alignment-related defects from the wider community, bias remains a poorly understood topic despite its practical relevance. To enhance the understanding of the internal causes of bias, we analyse LLM bias through the lens of causal fairness analysis, which enables us to both comprehend the origins of bias and reason about its downstream consequences and mitigation. To operationalize this framework, we propose a prompt-based method for the extraction of confounding and mediating attributes which contribute to the LLM decision process. By applying Activity Dependency Networks (ADNs), we then analyse how these attributes influence an LLM's decision process. We apply our method to LLM ratings of argument quality in political debates. We find that the observed disparate treatment can at least in part be attributed to confounding and mitigating attributes and model misalignment, and discuss the consequences of our findings for human-AI alignment and bias mitigation. Our code and data are at https://github.com/david-jenny/LLM-Political-Study."}, "https://arxiv.org/abs/2401.13248": {"title": "\"Here's Your Evidence\": False Consensus in Public Twitter Discussions of COVID-19 Science", "link": "https://arxiv.org/abs/2401.13248", "description": "arXiv:2401.13248v2 Announce Type: replace-cross \nAbstract: The COVID-19 pandemic brought about an extraordinary rate of scientific papers on the topic that were discussed among the general public, although often in biased or misinformed ways. In this paper, we present a mixed-methods analysis aimed at examining whether public discussions were commensurate with the scientific consensus on several COVID-19 issues. We estimate scientific consensus based on samples of abstracts from preprint servers and compare against the volume of public discussions on Twitter mentioning these papers. We find that anti-consensus posts and users, though overall less numerous than pro-consensus ones, are vastly over-represented on Twitter, thus producing a false consensus effect. This transpires with favorable papers being disproportionately amplified, along with an influx of new anti-consensus user sign-ups. Finally, our content analysis highlights that anti-consensus users misrepresent scientific findings or question scientists' integrity in their efforts to substantiate their claims."}, "https://arxiv.org/abs/2402.00447": {"title": "A Survey of Data-Efficient Graph Learning", "link": "https://arxiv.org/abs/2402.00447", "description": "arXiv:2402.00447v2 Announce Type: replace-cross \nAbstract: Graph-structured data, prevalent in domains ranging from social networks to biochemical analysis, serve as the foundation for diverse real-world systems. While graph neural networks demonstrate proficiency in modeling this type of data, their success is often reliant on significant amounts of labeled data, posing a challenge in practical scenarios with limited annotation resources. To tackle this problem, tremendous efforts have been devoted to enhancing graph machine learning performance under low-resource settings by exploring various approaches to minimal supervision. In this paper, we introduce a novel concept of Data-Efficient Graph Learning (DEGL) as a research frontier, and present the first survey that summarizes the current progress of DEGL. We initiate by highlighting the challenges inherent in training models with large labeled data, paving the way for our exploration into DEGL. Next, we systematically review recent advances on this topic from several key aspects, including self-supervised graph learning, semi-supervised graph learning, and few-shot graph learning. Also, we state promising directions for future research, contributing to the evolution of graph machine learning."}, "https://arxiv.org/abs/2402.15119": {"title": "A multidisciplinary framework for deconstructing bots' pluripotency in dualistic antagonism", "link": "https://arxiv.org/abs/2402.15119", "description": "arXiv:2402.15119v4 Announce Type: replace-cross \nAbstract: Anthropomorphic social bots are engineered to emulate human verbal communication and generate toxic or inflammatory content across social networking services (SNSs). Bot-disseminated misinformation could subtly yet profoundly reshape societal processes by complexly interweaving factors like repeated disinformation exposure, amplified political polarization, compromised indicators of democratic health, shifted perceptions of national identity, propagation of false social norms, and manipulation of collective memory over time. However, extrapolating bots' pluripotency across hybridized, multilingual, and heterogeneous media ecologies from isolated SNS analyses remains largely unknown, underscoring the need for a comprehensive framework to characterise bots' emergent risks to civic discourse. Here we propose an interdisciplinary framework to characterise bots' pluripotency, incorporating quantification of influence, network dynamics monitoring, and interlingual feature analysis. When applied to the geopolitical discourse around the Russo-Ukrainian conflict, results from interlanguage toxicity profiling and network analysis elucidated spatiotemporal trajectories of pro-Russian and pro-Ukrainian human and bots across hybrid SNSs. Weaponized bots predominantly inhabited X, while human primarily populated Reddit in the social media warfare. This rigorous framework promises to elucidate interlingual homogeneity and heterogeneity in bots' pluripotent behaviours, revealing synergistic human-bot mechanisms underlying regimes of information manipulation, echo chamber formation, and collective memory manifestation in algorithmically structured societies."}, "https://arxiv.org/abs/2404.15986": {"title": "Seed Selection in the Heterogeneous Moran Process", "link": "https://arxiv.org/abs/2404.15986", "description": "arXiv:2404.15986v2 Announce Type: replace-cross \nAbstract: The Moran process is a classic stochastic process that models the rise and takeover of novel traits in network-structured populations. In biological terms, a set of mutants, each with fitness $m\\in(0,\\infty)$ invade a population of residents with fitness $1$. Each agent reproduces at a rate proportional to its fitness and each offspring replaces a random network neighbor. The process ends when the mutants either fixate (take over the whole population) or go extinct. The fixation probability measures the success of the invasion. To account for environmental heterogeneity, we study a generalization of the Standard process, called the Heterogeneous Moran process. Here, the fitness of each agent is determined both by its type (resident/mutant) and the node it occupies. We study the natural optimization problem of seed selection: given a budget $k$, which $k$ agents should initiate the mutant invasion to maximize the fixation probability? We show that the problem is strongly inapproximable: it is $\\mathbf{NP}$-hard to distinguish between maximum fixation probability 0 and 1. We then focus on mutant-biased networks, where each node exhibits at least as large mutant fitness as resident fitness. We show that the problem remains $\\mathbf{NP}$-hard, but the fixation probability becomes submodular, and thus the optimization problem admits a greedy $(1-1/e)$-approximation. An experimental evaluation of the greedy algorithm along with various heuristics on real-world data sets corroborates our results."}, "https://arxiv.org/abs/2404.19634": {"title": "DF Louvain: Fast Incrementally Expanding Approach for Community Detection on Dynamic Graphs", "link": "https://arxiv.org/abs/2404.19634", "description": "arXiv:2404.19634v2 Announce Type: replace-cross \nAbstract: Community detection is the problem of recognizing natural divisions in networks. A relevant challenge in this problem is to find communities on rapidly evolving graphs. In this report we present our Parallel Dynamic Frontier (DF) Louvain algorithm, which given a batch update of edge deletions and insertions, incrementally identifies and processes an approximate set of affected vertices in the graph with minimal overhead, while using a novel approach of incrementally updating weighted-degrees of vertices and total edge weights of communities. We also present our parallel implementations of Naive-dynamic (ND) and Delta-screening (DS) Louvain. On a server with a 64-core AMD EPYC-7742 processor, our experiments show that DF Louvain obtains speedups of 179x, 7.2x, and 5.3x on real-world dynamic graphs, compared to Static, ND, and DS Louvain, respectively, and is 183x, 13.8x, and 8.7x faster, respectively, on large graphs with random batch updates. Moreover, DF Louvain improves its performance by 1.6x for every doubling of threads."}, "https://arxiv.org/abs/2405.08040": {"title": "No evidence of systematic proximity ascertainment bias in early COVID-19 cases in Wuhan Reply to Weissman (2024)", "link": "https://arxiv.org/abs/2405.08040", "description": "arXiv:2405.08040v1 Announce Type: new \nAbstract: In a short text published as Letter to the Editor of the Journal of the Royal Statistical Society Series A, Weissman (2024) argues that the finding that early COVID-19 cases without an ascertained link to Wuhan's Huanan Seafood Wholesale market resided on average closer to the market than cases epidemiologically linked to it, reveals \"major proximity ascertainment bias\". Here we show that Weissman's conclusion is based on a flawed premise, and that there is no such \"internal evidence\" of major bias. The pattern can indeed be explained by places of infection not being limited to residential neighbourhoods, and by stochasticity -- i.e., without requiring any ascertainment bias."}, "https://arxiv.org/abs/2405.08203": {"title": "Community detection in bipartite signed networks is highly dependent on parameter choice", "link": "https://arxiv.org/abs/2405.08203", "description": "arXiv:2405.08203v1 Announce Type: new \nAbstract: Decision-making processes often involve voting. Human interactions with exogenous entities such as legislations or products can be effectively modeled as two-mode (bipartite) signed networks-where people can either vote positively, negatively, or abstain from voting on the entities. Detecting communities in such networks could help us understand underlying properties: for example ideological camps or consumer preferences. While community detection is an established practice separately for bipartite and signed networks, it remains largely unexplored in the case of bipartite signed networks. In this paper, we systematically evaluate the efficacy of community detection methods on bipartite signed networks using a synthetic benchmark and real-world datasets. Our findings reveal that when no communities are present in the data, these methods often recover spurious communities. When communities are present, the algorithms exhibit promising performance, although their performance is highly susceptible to parameter choice. This indicates that researchers using community detection methods in the context of bipartite signed networks should not take the communities found at face value: it is essential to assess the robustness of parameter choices or perform domain-specific external validation."}, "https://arxiv.org/abs/2405.08331": {"title": "Are Generics and Negativity about Social Groups Common on Social Media? A Comparative Analysis of Twitter (X) Data", "link": "https://arxiv.org/abs/2405.08331", "description": "arXiv:2405.08331v1 Announce Type: new \nAbstract: Generics (unquantified generalizations) are thought to be pervasive in communication and when they are about social groups, this may offend and polarize people because generics gloss over variations between individuals. Generics about social groups might be particularly common on Twitter (X). This remains unexplored, however. Using machine learning (ML) techniques, we therefore developed an automatic classifier for social generics, applied it to more than a million tweets about people, and analyzed the tweets. We found that most tweets (78%) about people contained no generics. However, tweets with social generics received more 'likes' and retweets. Furthermore, while recent psychological research may lead to the prediction that tweets with generics about political groups are more common than tweets with generics about ethnic groups, we found the opposite. However, consistent with recent claims that political animosity is less constrained by social norms than animosity against gender and ethnic groups, negative tweets with generics about political groups were significantly more prevalent and retweeted than negative tweets about ethnic groups. Our study provides the first ML-based insights into the use and impact of social generics on Twitter."}, "https://arxiv.org/abs/2405.08398": {"title": "Exploring the spatial segmentation of housing markets from online listings", "link": "https://arxiv.org/abs/2405.08398", "description": "arXiv:2405.08398v1 Announce Type: new \nAbstract: The real estate market shows an inherent connection to space. Real estate agencies unevenly operate and specialize across space, price and type of properties, thereby segmenting the market into submarkets. We introduce here a methodology based on multipartite networks to detect the spatial segmentation emerging from data on housing online listings. Considering the spatial information of the listings, we build a bipartite network that connects agencies and spatial units. This bipartite network is projected into a network of spatial units, whose connections account for similarities in the agency ecosystem. We then apply clustering methods to this network to segment markets into spatially-coherent regions, which are found to be robust across different clustering detection algorithms, discretization of space and spatial scales, and across countries with case studies in France and Spain. This methodology addresses the long-standing issue of housing market segmentation, relevant in disciplines such as urban studies and spatial economics, and with implications for policymaking."}, "https://arxiv.org/abs/2405.08746": {"title": "Decomposing geographical and universal aspects of human mobility", "link": "https://arxiv.org/abs/2405.08746", "description": "arXiv:2405.08746v1 Announce Type: new \nAbstract: Driven by access to large volumes of detailed movement data, the study of human mobility has grown rapidly over the past decade. This body of work has argued that human mobility is scale-free, has proposed models to generate scale-free moving distance distribution, and explained how the scale-free distribution arises from aggregating displacements across scales. However, the field of human mobility has not explicitly addressed how mobility is structured by geographical constraints - such as the outlines of landmasses, lakes, rivers, the placement of buildings, roadways, and cities.\n  Using unique datasets capturing millions of movements between precise locations, this paper shows how separating the effect of geography from mobility choices reveals a universal power law spanning five orders of magnitude (from 10 m to 1,000,000 m). We incorporate geography through the pair distribution function, a fundamental quantity from condensed matter physics that encapsulates the structure of locations on which mobility occurs. This distribution captures the constraints that geography places on human mobility across different length scales.\n  Our description conclusively addresses debates between distance-based and opportunity-based perspectives on human mobility. By demonstrating how the spatial distribution of human settlements shapes human mobility, we provide a novel perspective that bridges the gap between these previously opposing ideas."}, "https://arxiv.org/abs/2405.08013": {"title": "CTRL: Continuous-Time Representation Learning on Temporal Heterogeneous Information Network", "link": "https://arxiv.org/abs/2405.08013", "description": "arXiv:2405.08013v1 Announce Type: cross \nAbstract: Inductive representation learning on temporal heterogeneous graphs is crucial for scalable deep learning on heterogeneous information networks (HINs) which are time-varying, such as citation networks. However, most existing approaches are not inductive and thus cannot handle new nodes or edges. Moreover, previous temporal graph embedding methods are often trained with the temporal link prediction task to simulate the link formation process of temporal graphs, while ignoring the evolution of high-order topological structures on temporal graphs. To fill these gaps, we propose a Continuous-Time Representation Learning (CTRL) model on temporal HINs. To preserve heterogeneous node features and temporal structures, CTRL integrates three parts in a single layer, they are 1) a \\emph{heterogeneous attention} unit that measures the semantic correlation between nodes, 2) a \\emph{edge-based Hawkes process} to capture temporal influence between heterogeneous nodes, and 3) \\emph{dynamic centrality} that indicates the dynamic importance of a node. We train the CTRL model with a future event (a subgraph) prediction task to capture the evolution of the high-order network structure. Extensive experiments have been conducted on three benchmark datasets. The results demonstrate that our model significantly boosts performance and outperforms various state-of-the-art approaches. Ablation studies are conducted to demonstrate the effectiveness of the model design."}, "https://arxiv.org/abs/2405.08278": {"title": "Facilitating Feature and Topology Lightweighting: An Ethereum Transaction Graph Compression Method for Malicious Account Detection", "link": "https://arxiv.org/abs/2405.08278", "description": "arXiv:2405.08278v1 Announce Type: cross \nAbstract: Ethereum has become one of the primary global platforms for cryptocurrency, playing an important role in promoting the diversification of the financial ecosystem. However, the relative lag in regulation has led to a proliferation of malicious activities in Ethereum, posing a serious threat to fund security. Existing regulatory methods usually detect malicious accounts through feature engineering or large-scale transaction graph mining. However, due to the immense scale of transaction data and malicious attacks, these methods suffer from inefficiency and low robustness during data processing and anomaly detection. In this regard, we propose an Ethereum Transaction Graph Compression method named TGC4Eth, which assists malicious account detection by lightweighting both features and topology of the transaction graph. At the feature level, we select transaction features based on their low importance to improve the robustness of the subsequent detection models against feature evasion attacks; at the topology level, we employ focusing and coarsening processes to compress the structure of the transaction graph, thereby improving both data processing and inference efficiency of detection models. Extensive experiments demonstrate that TGC4Eth significantly improves the computational efficiency of existing detection models while preserving the connectivity of the transaction graph. Furthermore, TGC4Eth enables existing detection models to maintain stable performance and exhibit high robustness against feature evasion attacks."}, "https://arxiv.org/abs/2405.08465": {"title": "How to Surprisingly Consider Recommendations? A Knowledge-Graph-based Approach Relying on Complex Network Metrics", "link": "https://arxiv.org/abs/2405.08465", "description": "arXiv:2405.08465v1 Announce Type: cross \nAbstract: Traditional recommendation proposals, including content-based and collaborative filtering, usually focus on similarity between items or users. Existing approaches lack ways of introducing unexpectedness into recommendations, prioritizing globally popular items over exposing users to unforeseen items. This investigation aims to design and evaluate a novel layer on top of recommender systems suited to incorporate relational information and suggest items with a user-defined degree of surprise. We propose a Knowledge Graph (KG) based recommender system by encoding user interactions on item catalogs. Our study explores whether network-level metrics on KGs can influence the degree of surprise in recommendations. We hypothesize that surprisingness correlates with certain network metrics, treating user profiles as subgraphs within a larger catalog KG. The achieved solution reranks recommendations based on their impact on structural graph metrics. Our research contributes to optimizing recommendations to reflect the metrics. We experimentally evaluate our approach on two datasets of LastFM listening histories and synthetic Netflix viewing profiles. We find that reranking items based on complex network metrics leads to a more unexpected and surprising composition of recommendation lists."}, "https://arxiv.org/abs/2405.08515": {"title": "Precarious Experiences: Citizens' Frustrations, Anxieties and Burdens of an Online Welfare Benefit System", "link": "https://arxiv.org/abs/2405.08515", "description": "arXiv:2405.08515v1 Announce Type: cross \nAbstract: There is a significant overlap between people who are supported by income-related social welfare benefits, often in precarious situations, and those who experience greater digital exclusion. We report on a study of claimants using the UK's Universal Credit online welfare benefit system designed as, and still, \"digital by default\". Through data collection involving remote interviews (n=11) and online surveys (n=66), we expose claimants' own lived experiences interacting with this system. The claimants explain how digital channels can contribute to an imbalance of power and agency, at a time when their own circumstances mean they have reduced abilities, resources and capacities, and where design choices can adversely affect people's utility to leverage help from their own wider socio-technical ecosystems. We contribute eight recommendations from these accounts to inform the future design and development of digital welfare benefit systems for this population, to reduce digital barriers and harms."}, "https://arxiv.org/abs/2405.08784": {"title": "Refinement of an Epilepsy Dictionary through Human Annotation of Health-related posts on Instagram", "link": "https://arxiv.org/abs/2405.08784", "description": "arXiv:2405.08784v1 Announce Type: cross \nAbstract: We used a dictionary built from biomedical terminology extracted from various sources such as DrugBank, MedDRA, MedlinePlus, TCMGeneDIT, to tag more than 8 million Instagram posts by users who have mentioned an epilepsy-relevant drug at least once, between 2010 and early 2016. A random sample of 1,771 posts with 2,947 term matches was evaluated by human annotators to identify false-positives. OpenAI's GPT series models were compared against human annotation. Frequent terms with a high false-positive rate were removed from the dictionary. Analysis of the estimated false-positive rates of the annotated terms revealed 8 ambiguous terms (plus synonyms) used in Instagram posts, which were removed from the original dictionary. To study the effect of removing those terms, we constructed knowledge networks using the refined and the original dictionaries and performed an eigenvector-centrality analysis on both networks. We show that the refined dictionary thus produced leads to a significantly different rank of important terms, as measured by their eigenvector-centrality of the knowledge networks. Furthermore, the most important terms obtained after refinement are of greater medical relevance. In addition, we show that OpenAI's GPT series models fare worse than human annotators in this task."}, "https://arxiv.org/abs/2305.02902": {"title": "Biased versus unbiased numerical methods for stochastic simulations", "link": "https://arxiv.org/abs/2305.02902", "description": "arXiv:2305.02902v2 Announce Type: replace \nAbstract: Approximate numerical methods are one of the most used strategies to extract information from many-interacting-agents systems. In particular, numerical approximations are of extended use to deal with epidemic, ecological and biological models, since unbiased methods like the Gillespie algorithm can become unpractical due to high CPU time usage required. However, the use of approximations has been debated and there is no clear consensus about whether unbiased methods or biased approach is the best option. In this work, we derive scaling relations for the errors in approximations based on binomial extractions. This finding allows us to build rules to compute the optimal values of both the discretization time and number of realizations needed to compute averages with the biased method with a target precision and minimum CPU-time usage. Furthermore, we also present another rule to discern whether the unbiased method or biased approach is more efficient. Ultimately, we will show that the choice of the method should depend on the desired precision for the estimation of averages."}, "https://arxiv.org/abs/2312.11529": {"title": "Efficient and Scalable Graph Generation through Iterative Local Expansion", "link": "https://arxiv.org/abs/2312.11529", "description": "arXiv:2312.11529v4 Announce Type: replace \nAbstract: In the realm of generative models for graphs, extensive research has been conducted. However, most existing methods struggle with large graphs due to the complexity of representing the entire joint distribution across all node pairs and capturing both global and local graph structures simultaneously. To overcome these issues, we introduce a method that generates a graph by progressively expanding a single node to a target graph. In each step, nodes and edges are added in a localized manner through denoising diffusion, building first the global structure, and then refining the local details. The local generation avoids modeling the entire joint distribution over all node pairs, achieving substantial computational savings with subquadratic runtime relative to node count while maintaining high expressivity through multiscale generation. Our experiments show that our model achieves state-of-the-art performance on well-established benchmark datasets while successfully scaling to graphs with at least 5000 nodes. Our method is also the first to successfully extrapolate to graphs outside of the training distribution, showcasing a much better generalization capability over existing methods."}, "https://arxiv.org/abs/2404.00793": {"title": "Learning the mechanisms of network growth", "link": "https://arxiv.org/abs/2404.00793", "description": "arXiv:2404.00793v2 Announce Type: replace \nAbstract: We propose a novel model-selection method for dynamic networks. Our approach involves training a classifier on a large body of synthetic network data. The data is generated by simulating nine state-of-the-art random graph models for dynamic networks, with parameter range chosen to ensure exponential growth of the network size in time. We design a conceptually novel type of dynamic features that count new links received by a group of vertices in a particular time interval. The proposed features are easy to compute, analytically tractable, and interpretable. Our approach achieves a near-perfect classification of synthetic networks, exceeding the state-of-the-art by a large margin. Applying our classification method to real-world citation networks gives credibility to the claims in the literature that models with preferential attachment, fitness and aging fit real-world citation networks best, although sometimes, the predicted model does not involve vertex fitness."}, "https://arxiv.org/abs/2405.01514": {"title": "Valuing maintenance strategies for fusion plants as part of a future electricity grid", "link": "https://arxiv.org/abs/2405.01514", "description": "arXiv:2405.01514v2 Announce Type: replace \nAbstract: Scheduled maintenance is likely to be lengthy and therefore consequential for the economics of fusion power plants. The maintenance strategy that maximizes the economic value of a plant depends on internal factors such as the cost and durability of the replaceable components, the frequency and duration of the maintenance blocks, and the external factors of the electricity system in which the plant operates. This paper examines the value of fusion power plants with various maintenance properties in a decarbonized United States Eastern Interconnection circa 2050. Seasonal variations in electricity supply and demand mean that certain times of year, particularly spring to early summer, are best for scheduled maintenance. Seasonality has two important consequences. First, the value of a plant can be 15% higher than what one would naively expect if value were directly proportional to its availability. Second, in some cases, replacing fractions of a component in shorter maintenance blocks spread over multiple years is better than replacing it all at once during a longer outage, even through the overall availability of the plant is lower in the former scenario."}, "https://arxiv.org/abs/2401.10057": {"title": "A method for characterizing disease emergence curves from paired pathogen detection and serology data", "link": "https://arxiv.org/abs/2401.10057", "description": "arXiv:2401.10057v2 Announce Type: replace-cross \nAbstract: Wildlife disease surveillance programs and research studies track infection and identify risk factors for wild populations, humans, and agriculture. Often, several types of samples are collected from individuals to provide more complete information about an animal's infection history. Methods that jointly analyze multiple data streams to study disease emergence and drivers of infection via epidemiological process models remain underdeveloped. Joint-analysis methods can more thoroughly analyze all available data, more precisely quantifying epidemic processes, outbreak status, and risks. We contribute a paired data modeling approach that analyzes multiple samples from individuals. We use \"characterization maps\" to link paired data to epidemiological processes through a hierarchical statistical observation model. Our approach can provide both Bayesian and frequentist estimates of epidemiological parameters and state. We motivate our approach through the need to use paired pathogen and antibody detection tests to estimate parameters and infection trajectories for the widely applicable susceptible, infectious, recovered (SIR) model. We contribute general formulas to link characterization maps to arbitrary process models and datasets and an extended SIR model that better accommodates paired data. We find via simulation that paired data can more efficiently estimate SIR parameters than unpaired data, requiring samples from 5-10 times fewer individuals. We then study SARS-CoV-2 in wild White-tailed deer (Odocoileus virginianus) from three counties in the United States. Estimates for average infectious times corroborate captive animal studies. Our methods use general statistical theory to let applications extend beyond the SIR model we consider, and to more complicated examples of paired data."}, "https://arxiv.org/abs/2405.00808": {"title": "ReeSPOT: Reeb Graph Models Semantic Patterns of Normalcy in Human Trajectories", "link": "https://arxiv.org/abs/2405.00808", "description": "arXiv:2405.00808v2 Announce Type: replace-cross \nAbstract: This paper introduces ReeSPOT, a novel Reeb graph-based method to model patterns of life in human trajectories (akin to a fingerprint). Human behavior typically follows a pattern of normalcy in day-to-day activities. This is marked by recurring activities within specific time periods. In this paper, we model this behavior using Reeb graphs where any deviation from usual day-to-day activities is encoded as nodes in the Reeb graph. The complexity of the proposed algorithm is linear with respect to the number of time points in a given trajectory. We demonstrate the usage of ReeSPOT and how it captures the critically significant spatial and temporal deviations using the nodes of the Reeb graph. Our case study presented in this paper includes realistic human movement scenarios: visiting uncommon locations, taking odd routes at infrequent times, uncommon time visits, and uncommon stay durations. We analyze the Reeb graph to interpret the topological structure of the GPS trajectories. Potential applications of ReeSPOT include urban planning, security surveillance, and behavioral research."}, "https://arxiv.org/abs/2405.09185": {"title": "Influence Maximization in Hypergraphs Using A Genetic Algorithm with New Initialization and Evaluation Methods", "link": "https://arxiv.org/abs/2405.09185", "description": "arXiv:2405.09185v1 Announce Type: new \nAbstract: Influence maximization (IM) is a crucial optimization task related to analyzing complex networks in the real world, such as social networks, disease propagation networks, and marketing networks. Publications to date about the IM problem focus mainly on graphs, which fail to capture high-order interaction relationships from the real world. Therefore, the use of hypergraphs for addressing the IM problem has been receiving increasing attention. However, identifying the most influential nodes in hypergraphs remains challenging, mainly because nodes and hyperedges are often strongly coupled and correlated. In this paper, to effectively identify the most influential nodes, we first propose a novel hypergraph-independent cascade model that integrates the influences of both node and hyperedge failures. Afterward, we introduce genetic algorithms (GA) to identify the most influential nodes that leverage hypergraph collective influences. In the GA-based method, the hypergraph collective influence is effectively used to initialize the population, thereby enhancing the quality of initial candidate solutions. The designed fitness function considers the joint influences of both nodes and hyperedges. This ensures the optimal set of nodes with the best influence on both nodes and hyperedges to be evaluated accurately. Moreover, a new mutation operator is designed by introducing factors, i.e., the collective influence and overlapping effects of nodes in hypergraphs, to breed high-quality offspring. In the experiments, several simulations on both synthetic and real hypergraphs have been conducted, and the results demonstrate that the proposed method outperforms the compared methods."}, "https://arxiv.org/abs/2405.09357": {"title": "A universal optimization framework based on cycle ranking for influence maximization in complex networks", "link": "https://arxiv.org/abs/2405.09357", "description": "arXiv:2405.09357v1 Announce Type: new \nAbstract: Influence maximization aims to identify a set of influential individuals, referred to as influencers, as information sources to maximize the spread of information within networks, constituting a vital combinatorial optimization problem with extensive practical applications and sustained interdisciplinary interest. Diverse approaches have been devised to efficiently address this issue, one of which involves selecting the influencers from a given centrality ranking. In this paper, we propose a novel optimization framework based on ranking basic cycles in networks, capable of selecting the influencers from diverse centrality measures. The experimental results demonstrate that, compared to directly selecting the top-k nodes from centrality sequences and other state-of-the-art optimization approaches, the new framework can expand the dissemination range by 1.5 to 3 times. Counterintuitively, it exhibits minimal hub property, with the average distance between influencers being only one-third of alternative approaches, regardless of the centrality metrics or network types. Our study not only paves the way for novel strategies in influence maximization but also underscores the unique potential of underappreciated cycle structures."}, "https://arxiv.org/abs/2405.09488": {"title": "Nonequilibrium phase transitions and absorbing states in a model for the dynamics of religious affiliation", "link": "https://arxiv.org/abs/2405.09488", "description": "arXiv:2405.09488v1 Announce Type: new \nAbstract: We propose a simple model to describe the dynamics of religious affiliation. For such purpose, we built a compartmental model with three distinct subpopulations, namely religious committed individuals, religious noncommitted individuals and not religious affiliated individuals. The transitions among the compartments are governed by probabilities, modeling social interactions among the groups and also spontaneous transitions among the compartments. First of all, we consider the model on a fully-connected network. Thus, we write a set of ordinary differential equations to study the evolution of the subpopulations. Our analytical and numerical results show that there is an absorbing state in the model where only one of the subpopulations survive in the long-time limit. There are also regions of parameters where some of the subpopulations coexist (two or three). We also verified the occurrence of two distinct critical points. In addition, we also present Monte Carlo simulations of the model on two-dimensional square lattices, in order to analyze the impact of the presence of a lattice structure on the critical behavior of the model. Comparison of the models' results with data for religious affiliation in Northern Ireland shows a good qualitative agreement. Finally, we considered the presence of inflexible individuals in the population, i.e., individuals that never change their states. The impact of such special agents on the critical behavior of the model is also discussed."}, "https://arxiv.org/abs/2405.08830": {"title": "Evaluating Supply Chain Resilience During Pandemic Using Agent-based Simulation", "link": "https://arxiv.org/abs/2405.08830", "description": "arXiv:2405.08830v1 Announce Type: cross \nAbstract: Recent pandemics have highlighted vulnerabilities in our global economic systems, especially supply chains. Possible future pandemic raises a dilemma for businesses owners between short-term profitability and long-term supply chain resilience planning. In this study, we propose a novel agent-based simulation model integrating extended Susceptible-Infected-Recovered (SIR) epidemiological model and supply and demand economic model to evaluate supply chain resilience strategies during pandemics. Using this model, we explore a range of supply chain resilience strategies under pandemic scenarios using in silico experiments. We find that a balanced approach to supply chain resilience performs better in both pandemic and non-pandemic times compared to extreme strategies, highlighting the importance of preparedness in the form of a better supply chain resilience. However, our analysis shows that the exact supply chain resilience strategy is hard to obtain for each firm and is relatively sensitive to the exact profile of the pandemic and economic state at the beginning of the pandemic. As such, we used a machine learning model that uses the agent-based simulation to estimate a near-optimal supply chain resilience strategy for a firm. The proposed model offers insights for policymakers and businesses to enhance supply chain resilience in the face of future pandemics, contributing to understanding the trade-offs between short-term gains and long-term sustainability in supply chain management before and during pandemics."}, "https://arxiv.org/abs/2405.09529": {"title": "Artificial Intelligence for the Internal Democracy of Political Parties", "link": "https://arxiv.org/abs/2405.09529", "description": "arXiv:2405.09529v1 Announce Type: cross \nAbstract: The article argues that AI can enhance the measurement and implementation of democratic processes within political parties, known as Intra-Party Democracy (IPD). It identifies the limitations of traditional methods for measuring IPD, which often rely on formal parameters, self-reported data, and tools like surveys. Such limitations lead to the collection of partial data, rare updates, and significant demands on resources. To address these issues, the article suggests that specific data management and Machine Learning (ML) techniques, such as natural language processing and sentiment analysis, can improve the measurement (ML about) and practice (ML for) of IPD. The article concludes by considering some of the principal risks of ML for IPD, including concerns over data privacy, the potential for manipulation, and the dangers of overreliance on technology."}, "https://arxiv.org/abs/2310.16451": {"title": "The Small-World Effect for Interferometer Networks", "link": "https://arxiv.org/abs/2310.16451", "description": "arXiv:2310.16451v2 Announce Type: replace \nAbstract: Complex network theory has focused on properties of networks with real-valued edge weights. However, in signal transfer networks, such as those representing the transfer of light across an interferometer, complex-valued edge weights are needed to represent the manipulation of the signal in both magnitude and phase. These complex-valued edge weights introduce interference into the signal transfer, but it is unknown how such interference affects network properties such as small-worldness. To address this gap, we have introduced a small-world interferometer network model with complex-valued edge weights and generalized existing network measures to define the interferometric clustering coefficient, the apparent path length, and the interferometric small-world coefficient. Using high-performance computing resources, we generated a large set of small-world interferometers over a wide range of parameters in system size, nearest-neighbor count, and edge-weight phase and computed their interferometric network measures. We found that the interferometric small-world coefficient depends significantly on the amount of phase on complex-valued edge weights: for small edge-weight phases, constructive interference led to a higher interferometric small-world coefficient; while larger edge-weight phases induced destructive interference which led to a lower interferometric small-world coefficient. Thus, for the small-world interferometer model, interferometric measures are necessary to capture the effect of interference on signal transfer. This model is an example of the type of problem that necessitates interferometric measures, and applies to any wave-based network including quantum networks."}, "https://arxiv.org/abs/2403.08493": {"title": "Rumor Forwarding Prediction Model Based on Uncertain Time Series", "link": "https://arxiv.org/abs/2403.08493", "description": "arXiv:2403.08493v2 Announce Type: replace \nAbstract: The rapid spread of rumors in social media is mainly caused by individual retweets. This paper applies uncertainty time series analysis (UTSA) to analyze a rumor retweeting behavior on Weibo. First, the rumor forwarding is modeled using uncertain time series, including order selection, parameter estimation, residual analysis, uncertainty hypothesis testing and forecast, and the validity of using uncertain time series analysis is further supported by analyzing the characteristics of the residual plot. The experimental results show that the uncertain time series can better predict the next stage of rumor forwarding. The results of the study have important practical significance for rumor management and the management of social media information dissemination."}, "https://arxiv.org/abs/2306.05597": {"title": "On the implementation of zero-determinant strategies in repeated games", "link": "https://arxiv.org/abs/2306.05597", "description": "arXiv:2306.05597v2 Announce Type: replace-cross \nAbstract: Zero-determinant strategies are a class of strategies in repeated games which unilaterally control payoffs. Zero-determinant strategies have attracted much attention in studies of social dilemma, particularly in the context of evolution of cooperation. So far, not only general properties of zero-determinant strategies have been investigated, but zero-determinant strategies have been applied to control in the fields of information and communications technology and analysis of imitation. Here, we further deepen our understanding on general mathematical properties of zero-determinant strategies. We first prove that zero-determinant strategies, if exist, can be implemented by some one-dimensional transition probability. Next, we prove that, if a two-player game has a non-trivial potential function, a zero-determinant strategy exists in its repeated version. These results assist us to implement zero-determinant strategies in broader situations."}, "https://arxiv.org/abs/2405.09640": {"title": "Personalized Content Moderation and Emergent Outcomes", "link": "https://arxiv.org/abs/2405.09640", "description": "arXiv:2405.09640v1 Announce Type: new \nAbstract: Social media platforms have implemented automated content moderation tools to preserve community norms and mitigate online hate and harassment. Recently, these platforms have started to offer Personalized Content Moderation (PCM), granting users control over moderation settings or aligning algorithms with individual user preferences. While PCM addresses the limitations of the one-size-fits-all approach and enhances user experiences, it may also impact emergent outcomes on social media platforms. Our study reveals that PCM leads to asymmetric information loss (AIL), potentially impeding the development of a shared understanding among users, crucial for healthy community dynamics. We further demonstrate that PCM tools could foster the creation of echo chambers and filter bubbles, resulting in increased community polarization. Our research is the first to identify AIL as a consequence of PCM and to highlight its potential negative impacts on online communities."}, "https://arxiv.org/abs/2405.09643": {"title": "Energy Consumption of Plant Factory with Artificial Light: Challenges and Opportunities", "link": "https://arxiv.org/abs/2405.09643", "description": "arXiv:2405.09643v1 Announce Type: new \nAbstract: Plant factory with artificial light (PFAL) is a promising technology for relieving the food crisis, especially in urban areas or arid regions endowed with abundant resources. However, lighting and HVAC (heating, ventilation, and air conditioning) systems of PFAL have led to much greater energy consumption than open-field and greenhouse farming, limiting the application of PFAL to a wider extent. Recent researches pay much more attention to the optimization of energy consumption in order to develop and promote the PFAL technology with reduced energy usage. This work comprehensively summarizes the current energy-saving methods on lighting, HVAC systems, as well as their coupling methods for a more energy-efficient PFAL. Besides, we offer our perspectives on further energy-saving strategies and exploit the renewable energy resources for PFAL to respond to the urgent need for energy-efficient production."}, "https://arxiv.org/abs/2405.09978": {"title": "Pedestrian evacuations with imitation of cooperative behavior", "link": "https://arxiv.org/abs/2405.09978", "description": "arXiv:2405.09978v1 Announce Type: new \nAbstract: We analyze the dynamics of room evacuation for mixed populations that include both competitive and cooperative individuals through numerical simulations using the social force model. Cooperative agents represent well-trained individuals who know how to behave in order to reduce risks within high-density crowds. We consider that competitive agents can imitate cooperative behavior when they are in close proximity to cooperators. We study the effects of the imitation of cooperative behavior on the duration and safety of evacuations, analyzing evacuation time and other quantities of interest for varying parameters such as the proportions of mixing, the aspect ratio of the room, and the parameters characterizing individual behaviors. Our main findings reveal that the addition of a relatively small number of cooperative agents into a crowd can reduce evacuation time and the density near the exit door, making the evacuation faster and safer despite an increase in the total number of agents. In particular, for long spaces such as corridors, a small number of added cooperative agents can significantly facilitate the evacuation process. We compare our results with those of systems without imitation and also study the general role of cooperation, providing further analysis for homogeneous populations. Our main conclusions emphasize the potential relevance of training people how to behave in high-density crowds"}, "https://arxiv.org/abs/2405.10187": {"title": "Influence Maximization in Hypergraphs using Multi-Objective Evolutionary Algorithms", "link": "https://arxiv.org/abs/2405.10187", "description": "arXiv:2405.10187v1 Announce Type: new \nAbstract: The Influence Maximization (IM) problem is a well-known NP-hard combinatorial problem over graphs whose goal is to find the set of nodes in a network that spreads influence at most. Among the various methods for solving the IM problem, evolutionary algorithms (EAs) have been shown to be particularly effective. While the literature on the topic is particularly ample, only a few attempts have been made at solving the IM problem over higher-order networks, namely extensions of standard graphs that can capture interactions that involve more than two nodes. Hypergraphs are a valuable tool for modeling complex interaction networks in various domains; however, they require rethinking of several graph-based problems, including IM. In this work, we propose a multi-objective EA for the IM problem over hypergraphs that leverages smart initialization and hypergraph-aware mutation. While the existing methods rely on greedy or heuristic methods, to our best knowledge this is the first attempt at applying EAs to this problem. Our results over nine real-world datasets and three propagation models, compared with five baseline algorithms, reveal that our method achieves in most cases state-of-the-art results in terms of hypervolume and solution diversity."}, "https://arxiv.org/abs/2405.10213": {"title": "Words as Trigger Points in Social Media Discussions", "link": "https://arxiv.org/abs/2405.10213", "description": "arXiv:2405.10213v1 Announce Type: new \nAbstract: Trigger points are a concept introduced by Mau, Lux, and Westheuser (2023) to study qualitative focus group interviews and understand polarisation in Germany. When people communicate, trigger points represent moments when individuals feel that their understanding of what is fair, normal, or appropriate in society is questioned. In the original studies, individuals react affectively to such triggers and show strong and negative emotional responses. In this paper, we introduce the first systematic study of the large-scale effect of individual words as trigger points by analysing a large amount of social media posts. We examine online deliberations on Reddit between 2020 and 2022 and collect >100 million posts from subreddits related to a set of words identified as trigger points in UK politics. We find that such trigger words affect user engagement and have noticeable consequences on animosity in online discussions. We share empirical evidence of trigger words causing animosity, and how they provide incentives for hate speech, adversarial debates, and disagreements. Our work is the first to introduce trigger points to computational studies of online communication. Our findings are relevant to researchers interested in online harms and who examine how citizens debate politics and society in light of affective polarisation."}, "https://arxiv.org/abs/2405.10233": {"title": "iDRAMA-Scored-2024: A Dataset of the Scored Social Media Platform from 2020 to 2023", "link": "https://arxiv.org/abs/2405.10233", "description": "arXiv:2405.10233v1 Announce Type: new \nAbstract: Online web communities often face bans for violating platform policies, encouraging their migration to alternative platforms. This migration, however, can result in increased toxicity and unforeseen consequences on the new platform. In recent years, researchers have collected data from many alternative platforms, indicating coordinated efforts leading to offline events, conspiracy movements, hate speech propagation, and harassment. Thus, it becomes crucial to characterize and understand these alternative platforms. To advance research in this direction, we collect and release a large-scale dataset from Scored -- an alternative Reddit platform that sheltered banned fringe communities, for example, c/TheDonald (a prominent right-wing community) and c/GreatAwakening (a conspiratorial community). Over four years, we collected approximately 57M posts from Scored, with at least 58 communities identified as migrating from Reddit and over 950 communities created since the platform's inception. Furthermore, we provide sentence embeddings of all posts in our dataset, generated through a state-of-the-art model, to further advance the field in characterizing the discussions within these communities. We aim to provide these resources to facilitate their investigations without the need for extensive data collection and processing efforts."}, "https://arxiv.org/abs/2405.09982": {"title": "Dynamical behavior and optimal control of a stochastic SAIRS epidemic model with two saturated incidences", "link": "https://arxiv.org/abs/2405.09982", "description": "arXiv:2405.09982v1 Announce Type: cross \nAbstract: Stochastic models are widely used to investigate the spread of epidemics in a complex environment. This paper extends a deterministic SAIRS epidemic model to a stochastic case with limited patient capacity and exposure. We first study the dynamical properties of the model under certain conditions, including persistence, extinction, and ergodic. Then, we introduce vaccination and isolation into the model as control variables. The optimal control strategies are obtained based on the Pontryagin minimum principle. Finally, numerical simulations are given to illustrate our theoretical results."}, "https://arxiv.org/abs/2307.04612": {"title": "Emergence of Cooperation in Two-agent Repeated Games with Reinforcement Learning", "link": "https://arxiv.org/abs/2307.04612", "description": "arXiv:2307.04612v2 Announce Type: replace \nAbstract: Cooperation is the foundation of ecosystems and the human society, and the reinforcement learning provides crucial insight into the mechanism for its emergence. However, most previous work has mostly focused on the self-organization at the population level, the fundamental dynamics at the individual level remains unclear. Here, we investigate the evolution of cooperation in a two-agent system, where each agent pursues optimal policies according to the classical Q-learning algorithm in playing the strict prisoner's dilemma. We reveal that a strong memory and long-sighted expectation yield the emergence of Coordinated Optimal Policies (COPs), where both agents act like Win-Stay, Lose-Shift (WSLS) to maintain a high level of cooperation. Otherwise, players become tolerant toward their co-player's defection and the cooperation loses stability in the end where the policy all Defection (All-D) prevails. This suggests that tolerance could be a good precursor to a crisis in cooperation. Furthermore, our analysis shows that the Coordinated Optimal Modes (COMs) for different COPs gradually lose stability as memory weakens and expectation for the future decreases, where agents fail to predict co-player's action in games and defection dominates. As a result, we give the constraint to expectations of future and memory strength for maintaining cooperation. In contrast to the previous work, the impact of exploration on cooperation is found not be consistent, but depends on composition of COMs. By clarifying these fundamental issues in this two-player system, we hope that our work could be helpful for understanding the emergence and stability of cooperation in more complex scenarios in reality."}, "https://arxiv.org/abs/2401.12732": {"title": "CDRNP: Cross-Domain Recommendation to Cold-Start Users via Neural Process", "link": "https://arxiv.org/abs/2401.12732", "description": "arXiv:2401.12732v2 Announce Type: replace-cross \nAbstract: Cross-domain recommendation (CDR) has been proven as a promising way to tackle the user cold-start problem, which aims to make recommendations for users in the target domain by transferring the user preference derived from the source domain. Traditional CDR studies follow the embedding and mapping (EMCDR) paradigm, which transfers user representations from the source to target domain by learning a user-shared mapping function, neglecting the user-specific preference. Recent CDR studies attempt to learn user-specific mapping functions in meta-learning paradigm, which regards each user's CDR as an individual task, but neglects the preference correlations among users, limiting the beneficial information for user representations. Moreover, both of the paradigms neglect the explicit user-item interactions from both domains during the mapping process. To address the above issues, this paper proposes a novel CDR framework with neural process (NP), termed as CDRNP. Particularly, it develops the meta-learning paradigm to leverage user-specific preference, and further introduces a stochastic process by NP to capture the preference correlations among the overlapping and cold-start users, thus generating more powerful mapping functions by mapping the user-specific preference and common preference correlations to a predictive probability distribution. In addition, we also introduce a preference remainer to enhance the common preference from the overlapping users, and finally devises an adaptive conditional decoder with preference modulation to make prediction for cold-start users with items in the target domain. Experimental results demonstrate that CDRNP outperforms previous SOTA methods in three real-world CDR scenarios."}, "https://arxiv.org/abs/2405.10322": {"title": "Exploring the Independent Cascade Model and Its Evolution in Social Network Information Diffusion", "link": "https://arxiv.org/abs/2405.10322", "description": "arXiv:2405.10322v1 Announce Type: new \nAbstract: This paper delves into the paramount significance of information dissemination within the dynamic realm of social networks. It underscores the pivotal role of information communication models in unraveling the intricacies of data propagation in the digital age. By shedding light on the profound influence of these models, it not only lays the groundwork for exploring various hierarchies and their manifestations but also serves as a catalyst for further research in this formidable field."}, "https://arxiv.org/abs/2405.10338": {"title": "Financial Interactions and Capital Accumulation", "link": "https://arxiv.org/abs/2405.10338", "description": "arXiv:2405.10338v1 Announce Type: new \nAbstract: In a series of precedent papers, we have presented a comprehensive methodology, termed Field Economics, for translating a standard economic model into a statistical field-formalism framework. This formalism requires a large number of heterogeneous agents, possibly of different types. It reveals the emergence of collective states among these agents or type of agents while preserving the interactions and microeconomic features of the system at the individual level. In two prior papers, we applied this formalism to analyze the dynamics of capital allocation and accumulation in a simple microeconomic framework of investors and firms.Building upon our prior work, the present paper refines the initial model by expanding its scope. Instead of considering financial firms investing solely in real sectors, we now suppose that financial agents may also invest in other financial firms. We also introduce banks in the system that act as investors with a credit multiplier. Two types of interaction are now considered within the financial sector: financial agents can lend capital to, or choose to buy shares of, other financial firms. Capital now flows between financial agents and is only partly invested in real sectors, depending on their relative returns. We translate this framework into our formalism and study the diffusion of capital and possible defaults in the system, both at the macro and micro level.At the macro level, we find that several collective states may emerge, each characterized by a distinct level of average capital and investors per sector. These collective states depend on external parameters such as level of connections between investors or firms' productivity.The multiplicity of possible collective states is the consequence of the nature of the system composed of interconnected heterogeneous agents. Several equivalent patterns of returns and portfolio allocation may emerge. The multiple collective states induce the unstable nature of financial markets, and some of them include defaults may emerge. At the micro level, we study the propagation of returns and defaults within a given collective state. Our findings highlight the significant role of banks, which can either stabilize the system through lending activities or propagate instability through loans to investors."}, "https://arxiv.org/abs/2405.10355": {"title": "Assessing the Impact of Case Correction Methods on the Fairness of COVID-19 Predictive Models", "link": "https://arxiv.org/abs/2405.10355", "description": "arXiv:2405.10355v1 Announce Type: new \nAbstract: One of the central difficulties of addressing the COVID-19 pandemic has been accurately measuring and predicting the spread of infections. In particular, official COVID-19 case counts in the United States are under counts of actual caseloads due to the absence of universal testing policies. Researchers have proposed a variety of methods for recovering true caseloads, often through the estimation of statistical models on more reliable measures, such as death and hospitalization counts, positivity rates, and demographics. However, given the disproportionate impact of COVID-19 on marginalized racial, ethnic, and socioeconomic groups, it is important to consider potential unintended effects of case correction methods on these groups. Thus, we investigate two of these correction methods for their impact on a downstream COVID-19 case prediction task. For that purpose, we tailor an auditing approach and evaluation protocol to analyze the fairness of the COVID-19 prediction task by measuring the difference in model performance between majority-White counties and majority-minority counties. We find that one of the correction methods improves fairness, decreasing differences in performance between majority-White and majority-minority counties, while the other method increases differences, introducing bias. While these results are mixed, it is evident that correction methods have the potential to exacerbate existing biases in COVID-19 case data and in downstream prediction tasks. Researchers planning to develop or use case correction methods must be careful to consider negative effects on marginalized groups."}, "https://arxiv.org/abs/2405.10417": {"title": "Cosmic rays for imaging cultural heritage objects", "link": "https://arxiv.org/abs/2405.10417", "description": "arXiv:2405.10417v1 Announce Type: new \nAbstract: In cultural heritage conservation, it is increasingly common to rely on non-destructive imaging methods based on the absorption or scattering of photons ($X$ or $\\gamma$ rays) or neutrons. However, physical and practical issues limit these techniques: their penetration depth may be insufficient for large and dense objects, they require transporting the objects of interest to dedicated laboratories, artificial radiation is hazardous and may induce activation in the material under study. Muons are elementary particles abundantly and freely produced in cosmic-ray interactions in the atmosphere. Their absorption and scattering in matter are characteristically dependent on the density and elemental composition of the material that they traverse, which offers the possibility of exploiting them for sub-surface remote imaging. This novel technique, nicknamed \"muography\", has been applied in use cases ranging from geophysics to archaeology to nuclear safety, but it has been so far under-explored for a vast category of cultural heritage objects that are relatively large (from decimeters to human size) and dense (stone, metals). The development of portable muon detectors makes muography particularly competitive in cases where the items to be analysed are not transportable, or set up in a confined environment. This document reviews the relevant literature, presents some exemplary use cases, and critically assesses the strengths and weaknesses of muography in this context."}, "https://arxiv.org/abs/2405.10450": {"title": "Quantifying national space heating flexibility potential at high spatial resolution with heating consumption data", "link": "https://arxiv.org/abs/2405.10450", "description": "arXiv:2405.10450v1 Announce Type: new \nAbstract: Decarbonizing the building stock in cold countries by replacing fossil fuel boilers with heat pumps is expected to drastically increase electricity demand. While heating flexibility could reduce the impact of additional demand from heat pumps on the power system, characterizing the national spatial distribution of heating flexibility capacity to incorporate into sophisticated power system models is challenging. This paper introduces a novel method for quantifying at large scale and high spatial resolution the energy capacity and duration of heating flexibility in existing building stock based on historical heating consumption and temperature data. This method can reflect the geographic diversity of the national building stock in sophisticated power system models. The proposed heating consumption-based method was tested in Britain using national residential gas data. The results demonstrate the potential of this approach to characterize the heterogeneous distribution of heating flexibility capacity at the national scale. Assuming a 3$^\\circ$C temperature flexibility window, a total thermal energy storage capacity of 500 GWh$_{th}$ is identified in the British housing stock. For an illustrative cold weather COP value of 2.5, this thermal energy storage capacity is equivalent to 200 GWh of electricity storage. Regarding heating flexibility duration, gas-heated homes have a median of 5.9 heat-free hours for 20th percentile regional daily winter temperatures from 2010 to 2022. However, extreme cold days nearly halve flexibility duration to a median of 3.6 heat-free hours. These high spatial resolution energy capacity and self-discharge parameters can account for geographic diversity at the national scale and provide a new data-based layer of information for sophisticated power system models to support energy transition."}, "https://arxiv.org/abs/2405.10547": {"title": "GPTs Window Shopping: An analysis of the Landscape of Custom ChatGPT Models", "link": "https://arxiv.org/abs/2405.10547", "description": "arXiv:2405.10547v1 Announce Type: new \nAbstract: OpenAI's ChatGPT initiated a wave of technical iterations in the space of Large Language Models (LLMs) by demonstrating the capability and disruptive power of LLMs. OpenAI has prompted large organizations to respond with their own advancements and models to push the LLM performance envelope. OpenAI has prompted large organizations to respond with their own advancements and models to push the LLM performance envelope. OpenAI's success in spotlighting AI can be partially attributed to decreased barriers to entry, enabling any individual with an internet-enabled device to interact with LLMs. What was previously relegated to a few researchers and developers with necessary computing resources is now available to all. A desire to customize LLMs to better accommodate individual needs prompted OpenAI's creation of the GPT Store, a central platform where users can create and share custom GPT models. Customization comes in the form of prompt-tuning, analysis of reference resources, browsing, and external API interactions, alongside a promise of revenue sharing for created custom GPTs. In this work, we peer into the window of the GPT Store and measure its impact. Our analysis constitutes a large-scale overview of the store exploring community perception, GPT details, and the GPT authors, in addition to a deep-dive into a 3rd party storefront indexing user-submitted GPTs, exploring if creators seek to monetize their creations in the absence of OpenAI's revenue sharing."}, "https://arxiv.org/abs/2405.10558": {"title": "CACL: Community-Aware Heterogeneous Graph Contrastive Learning for Social Media Bot Detection", "link": "https://arxiv.org/abs/2405.10558", "description": "arXiv:2405.10558v1 Announce Type: new \nAbstract: Social media bot detection is increasingly crucial with the rise of social media platforms. Existing methods predominantly construct social networks as graph and utilize graph neural networks (GNNs) for bot detection. However, most of these methods focus on how to improve the performance of GNNs while neglecting the community structure within social networks. Moreover, GNNs based methods still face problems such as poor model generalization due to the relatively small scale of the dataset and over-smoothness caused by information propagation mechanism. To address these problems, we propose a Community-Aware Heterogeneous Graph Contrastive Learning framework (CACL), which constructs social network as heterogeneous graph with multiple node types and edge types, and then utilizes community-aware module to dynamically mine both hard positive samples and hard negative samples for supervised graph contrastive learning with adaptive graph enhancement algorithms. Extensive experiments demonstrate that our framework addresses the previously mentioned challenges and outperforms competitive baselines on three social media bot benchmarks."}, "https://arxiv.org/abs/2405.10640": {"title": "COMET: NFT Price Prediction with Wallet Profiling", "link": "https://arxiv.org/abs/2405.10640", "description": "arXiv:2405.10640v1 Announce Type: new \nAbstract: As the non-fungible token (NFT) market flourishes, price prediction emerges as a pivotal direction for investors gaining valuable insight to maximize returns. However, existing works suffer from a lack of practical definitions and standardized evaluations, limiting their practical application. Moreover, the influence of users' multi-behaviour transactions that are publicly accessible on NFT price is still not explored and exhibits challenges. In this paper, we address these gaps by presenting a practical and hierarchical problem definition. This approach unifies both collection-level and token-level task and evaluation methods, which cater to varied practical requirements of investors. To further understand the impact of user behaviours on the variation of NFT price, we propose a general wallet profiling framework and develop a COmmunity enhanced Multi-bEhavior Transaction graph model, named COMET. COMET profiles wallets with a comprehensive view and considers the impact of diverse relations and interactions within the NFT ecosystem on NFT price variations, thereby improving prediction performance. Extensive experiments conducted in our deployed system demonstrate the superiority of COMET, underscoring its potential in the insight toolkit for NFT investors."}, "https://arxiv.org/abs/2405.10665": {"title": "Leader-Follower Identification with Vehicle-Following Calibration for Non-Lane-Based Traffic", "link": "https://arxiv.org/abs/2405.10665", "description": "arXiv:2405.10665v1 Announce Type: new \nAbstract: Most car-following models were originally developed for lane-based traffic. Over the past two decades, efforts have been made to calibrate car-following models for non-lane-based traffic. However, traffic conditions with varying vehicle dimensions, intermittent following, and multiple leaders often occur and make subjective Leader-Follower (LF) pair identification challenging. In this study, we analyze Vehicle Following (VF) behavior in traffic with a lack of lane discipline using high-resolution microscopic trajectory data collected in Chennai, India. The paper's main contributions are threefold. Firstly, three criteria are used to identify LF pairs from the driver's perspective, taking into account the intermittent following, lack of lane discipline due to consideration of lateral separation, and the presence of in-between vehicles. Second, the psycho-physical concept of the regime in the Wiedemann-99 model is leveraged to determine the traffic-dependent \"influence zone\" for LF identification. Third, a joint and consistent framework is proposed for identifying LF pairs and estimating VF parameters. The proposed methodology outperforms other heuristic-based LF identification methods from the literature in terms of quantitative and qualitative performance measures. The proposed approach can enable robust and more realistic LF identification and VF parameter calibration with practical applications such as LOS analysis, capacity, and travel time estimation."}, "https://arxiv.org/abs/2405.10798": {"title": "Understanding following patterns among high-performance athletes", "link": "https://arxiv.org/abs/2405.10798", "description": "arXiv:2405.10798v1 Announce Type: new \nAbstract: Professional sports enhance interaction among athletes through training groups, sponsored events and competitions. Among these, the Olympic Games represent the largest competition with a global impact, providing the participants with a unique opportunity for interaction. We studied the following patterns among highly successful athletes to understand the structure of their interactions. We used the list of Olympic medallists in the Tokyo 2020 Games to extract their follower-followee network in Twitter, finding 7,326 connections among 964 athletes. The network displayed frequent connections to similar peers in terms of their features including sex, country and sport. We quantified the influence of these features in the followees choice through a gravity approach capturing the number of connections between homogeneous groups. Our research remarks the importance of datasets built from public exposure of professional athletes, serving as a proxy to investigate interesting aspects of many complex socio-cultural systems at different scales."}, "https://arxiv.org/abs/2405.10818": {"title": "Modeling Supply Chain Interaction and Disruption: Insights from Real-world Data and Complex Adaptive System", "link": "https://arxiv.org/abs/2405.10818", "description": "arXiv:2405.10818v1 Announce Type: new \nAbstract: In the rapidly evolving automotive industry, Systems-on-Chips (SoCs) are playing an increasingly crucial role in enhancing vehicle intelligence, connectivity, and safety features. For enterprises whose business encompasses automotive SoCs, the sustained and stable provision and receipt of SoC relevant goods or services are essential. Considering the imperative for a resilient and adaptable supply network, enterprises are concentrating their efforts on formulating strategies to address risks stemming from supply chain disruptions caused by technological obsolescence, natural disasters, and geopolitical tensions. This study presents an open supply knowledge extraction and complement approach and build a supply chain network of automotive SoC enterprises in China, which incorporates cross-domain named entity recognition under limited information, fuzzy matching of firm entities, and supply relation inferring based on knowledge graph. Subsequently, we exhibit the degree and registered capital distribution across firms, and analyze the correlations between centrality metrics in the supply chain network. Finally, based on recovery capacity and risk transfer, two interaction disruption models (IDMs) are developed to elucidate the adaptive behaviors and effect of network disruptions under various business and attack strategies. This research not only aids in exploring the complexities of Chinese automotive SoC supply chain but also enriches our understanding of the dynamics of firm behavior in this crucial industry sector."}, "https://arxiv.org/abs/2405.09843": {"title": "Organizational Selection of Innovation", "link": "https://arxiv.org/abs/2405.09843", "description": "arXiv:2405.09843v1 Announce Type: cross \nAbstract: Budgetary constraints force organizations to pursue only a subset of possible innovation projects. Identifying which subset is most promising is an error-prone exercise, and involving multiple decision makers may be prudent. This raises the question of how to most effectively aggregate their collective nous. Our model of organizational portfolio selection provides some first answers. We show that portfolio performance can vary widely. Delegating evaluation makes sense when organizations employ the relevant experts and can assign projects to them. In most other settings, aggregating the impressions of multiple agents leads to better performance than delegation. In particular, letting agents rank projects often outperforms alternative aggregation rules -- including averaging agents' project scores as well as counting their approval votes -- especially when organizations have tight budgets and can select only a few project alternatives out of many."}, "https://arxiv.org/abs/2405.10497": {"title": "SMP Challenge: An Overview and Analysis of Social Media Prediction Challenge", "link": "https://arxiv.org/abs/2405.10497", "description": "arXiv:2405.10497v1 Announce Type: cross \nAbstract: Social Media Popularity Prediction (SMPP) is a crucial task that involves automatically predicting future popularity values of online posts, leveraging vast amounts of multimodal data available on social media platforms. Studying and investigating social media popularity becomes central to various online applications and requires novel methods of comprehensive analysis, multimodal comprehension, and accurate prediction.\n  SMP Challenge is an annual research activity that has spurred academic exploration in this area. This paper summarizes the challenging task, data, and research progress. As a critical resource for evaluating and benchmarking predictive models, we have released a large-scale SMPD benchmark encompassing approximately half a million posts authored by around 70K users. The research progress analysis provides an overall analysis of the solutions and trends in recent years. The SMP Challenge website (www.smp-challenge.com) provides the latest information and news."}, "https://arxiv.org/abs/1609.00004": {"title": "On the initial value of PageRank", "link": "https://arxiv.org/abs/1609.00004", "description": "arXiv:1609.00004v5 Announce Type: replace \nAbstract: Google employs PageRank to rank web pages, determining the order in which search results are presented to users based on their queries. PageRank is primarily utilized for directed networks, although there are instances where it is also applied to undirected networks. In this paper, we have applied PageRank to undirected networks, showing that a vertex's PageRank relies on its initial value, often referred to as an intrinsic, non-network contribution. We have analytically proved that when the initial value of vertices is either proportional to their degrees or set to zero, the PageRank values of the vertices become directly proportional to their degrees. Simulated and empirical data are employed to bolster our research findings. Additionally, we have investigated the impact of initial values on PageRank localization."}, "https://arxiv.org/abs/2304.12751": {"title": "Node Feature Augmentation Vitaminizes Network Alignment", "link": "https://arxiv.org/abs/2304.12751", "description": "arXiv:2304.12751v4 Announce Type: replace \nAbstract: Network alignment (NA) is the task of discovering node correspondences across multiple networks. Although NA methods have achieved remarkable success in a myriad of scenarios, their effectiveness is not without additional information such as prior anchor links and/or node features, which may not always be available due to privacy concerns or access restrictions. To tackle this challenge, we propose Grad-Align+, a novel NA method built upon a recent state-of-the-art NA method, the so-called Grad-Align, that gradually discovers a part of node pairs until all node pairs are found. In designing Grad-Align+, we account for how to augment node features in the sense of performing the NA task and how to design our NA method by maximally exploiting the augmented node features. To achieve this goal, Grad-Align+ consists of three key components: 1) centrality-based node feature augmentation (CNFA), 2) graph neural network (GNN)-aided embedding similarity calculation alongside the augmented node features, and 3) gradual NA with similarity calculation using aligned cross-network neighbor-pairs (ACNs). Through comprehensive experiments, we demonstrate that Grad-Align+ exhibits (a) the superiority over benchmark NA methods, (b) empirical validations as well as our theoretical findings to see the effectiveness of CNFA, (c) the influence of each component, (d) the robustness to network noises, and (e) the computational efficiency."}, "https://arxiv.org/abs/2310.10155": {"title": "Analysis and implementation of nanotargeting on LinkedIn based on publicly available non-PII", "link": "https://arxiv.org/abs/2310.10155", "description": "arXiv:2310.10155v2 Announce Type: replace \nAbstract: The literature has shown that combining a few non-Personal Identifiable Information (non-PII) is enough to make a user unique in a dataset including millions of users. This work demonstrates that a combination of a few non-PII items can be activated to nanotarget users. We demonstrate that the combination of the location and {5} rare ({13} random) skills in a LinkedIn profile is enough to become unique in a user base of {$\\sim$970M} users with a probability of 75\\%. The novelty is that these attributes are publicly accessible to anyone registered on LinkedIn and can be activated through advertising campaigns. We ran an experiment configuring ad campaigns using the location and skills of three of the paper's authors, demonstrating how all the ads using $\\geq13$ skills were delivered exclusively to the targeted user. We reported this vulnerability to LinkedIn, which initially ignored the problem, but fixed it as of November 2023.%This nanotargeting may expose LinkedIn users to privacy and security risks such as malvertising or manipulation."}, "https://arxiv.org/abs/2402.03894": {"title": "Interpersonal trust: Asymptotic analysis of a stochastic coordination game with multi-agent learning", "link": "https://arxiv.org/abs/2402.03894", "description": "arXiv:2402.03894v3 Announce Type: replace \nAbstract: We study the interpersonal trust of a population of agents, asking whether chance may decide if a population ends up in a high trust or low trust state. We model this by a discrete time, random matching stochastic coordination game. Agents are endowed with an exponential smoothing learning rule about the behaviour of their neighbours. We find that, with probability one in the long run the whole population either always cooperates or always defects. By simulation we study the impact of the distributions of the payoffs in the game and of the exponential smoothing learning (memory of the agents). We find, that as the agent memory increases or as the size of the population increases, the actual dynamics start to resemble the expectation of the process. We conclude that it is indeed possible that different populations may converge upon high or low trust between its citizens simply by chance, though the game parameters (context of the society) may be quite telling."}, "https://arxiv.org/abs/2404.01319": {"title": "Information Cascade Prediction under Public Emergencies: A Survey", "link": "https://arxiv.org/abs/2404.01319", "description": "arXiv:2404.01319v2 Announce Type: replace \nAbstract: With the advent of the era of big data, massive information, expert experience, and high-accuracy models bring great opportunities to the information cascade prediction of public emergencies. However, the involvement of specialist knowledge from various disciplines has resulted in a primarily application-specific focus (e.g., earthquakes, floods, infectious diseases) for information cascade prediction of public emergencies. The lack of a unified prediction framework poses a challenge for classifying intersectional prediction methods across different application fields. This survey paper offers a systematic classification and summary of information cascade modeling, prediction, and application. We aim to help researchers identify cutting-edge research and comprehend models and methods of information cascade prediction under public emergencies. By summarizing open issues and outlining future directions in this field, this paper has the potential to be a valuable resource for researchers conducting further studies on predicting information cascades."}, "https://arxiv.org/abs/2311.03682": {"title": "Incentive Design for Eco-driving in Urban Transportation Networks", "link": "https://arxiv.org/abs/2311.03682", "description": "arXiv:2311.03682v2 Announce Type: replace-cross \nAbstract: Eco-driving emerges as a cost-effective and efficient strategy to mitigate greenhouse gas emissions in urban transportation networks. Acknowledging the persuasive influence of incentives in shaping driver behavior, this paper presents the `eco-planner,' a digital platform devised to promote eco-driving practices in urban transportation. At the outset of their trips, users provide the platform with their trip details and travel time preferences, enabling the eco-planner to formulate personalized eco-driving recommendations and corresponding incentives, while adhering to its budgetary constraints. Upon trip completion, incentives are transferred to users who comply with the recommendations and effectively reduce their emissions. By comparing our proposed incentive mechanism with a baseline scheme that offers uniform incentives to all users, we demonstrate that our approach achieves superior emission reductions and increased user compliance with a smaller budget."}, "https://arxiv.org/abs/2404.10228": {"title": "Two-Stage Stance Labeling: User-Hashtag Heuristics with Graph Neural Networks", "link": "https://arxiv.org/abs/2404.10228", "description": "arXiv:2404.10228v2 Announce Type: replace-cross \nAbstract: The high volume and rapid evolution of content on social media present major challenges for studying the stance of social media users. In this work, we develop a two stage stance labeling method that utilizes the user-hashtag bipartite graph and the user-user interaction graph. In the first stage, a simple and efficient heuristic for stance labeling uses the user-hashtag bipartite graph to iteratively update the stance association of user and hashtag nodes via a label propagation mechanism. This set of soft labels is then integrated with the user-user interaction graph to train a graph neural network (GNN) model using semi-supervised learning. We evaluate this method on two large-scale datasets containing tweets related to climate change from June 2021 to June 2022 and gun control from January 2022 to January 2023. Our experiments demonstrate that enriching text-based embeddings of users with network information from the user interaction graph using our semi-supervised GNN method outperforms both classifiers trained on user textual embeddings and zero-shot classification using LLMs such as GPT4. We discuss the need for integrating nuanced understanding from social science with the scalability of computational methods to better understand how polarization on social media occurs for divisive issues such as climate change and gun control."}, "https://arxiv.org/abs/2405.11146": {"title": "Election Polls on Social Media: Prevalence, Biases, and Voter Fraud Beliefs", "link": "https://arxiv.org/abs/2405.11146", "description": "arXiv:2405.11146v1 Announce Type: new \nAbstract: Social media platforms allow users to create polls to gather public opinion on diverse topics. However, we know little about what such polls are used for and how reliable they are, especially in significant contexts like elections. Focusing on the 2020 presidential elections in the U.S., this study shows that outcomes of election polls on Twitter deviate from election results despite their prevalence. Leveraging demographic inference and statistical analysis, we find that Twitter polls are disproportionately authored by older males and exhibit a large bias towards candidate Donald Trump relative to representative mainstream polls. We investigate potential sources of biased outcomes from the point of view of inauthentic, automated, and counter-normative behavior. Using social media experiments and interviews with poll authors, we identify inconsistencies between public vote counts and those privately visible to poll authors, with the gap potentially attributable to purchased votes. We also find that Twitter accounts participating in election polls are more likely to be bots, and election poll outcomes tend to be more biased, before the election day than after. Finally, we identify instances of polls spreading voter fraud conspiracy theories and estimate that a couple thousand of such polls were posted in 2020. The study discusses the implications of biased election polls in the context of transparency and accountability of social media platforms."}, "https://arxiv.org/abs/2405.11166": {"title": "Learning the liveability of cities from migrants: Combinatiorial-Hodge-theory approach", "link": "https://arxiv.org/abs/2405.11166", "description": "arXiv:2405.11166v1 Announce Type: new \nAbstract: Migration is a major decision to leave one place and move to another, and involves job and life changes. The migration flow of people provides relational information across places about which is better to live by ``voting with their feet'' (Tiebout, 1956; Douglas, 1997). From the people's votes, in a ``democratic'' process, we quantify a descriptive statistic of liveable cities by a potential of migration flow in Combinatorial Hodge theory. As a case study, we measure the liveability of municipalities in Japan for specific populations such as families with small children and women of reproductive age. Using these potentials as dependent variables, we perform a regression analysis to identify the factors relevant to liveability. Additionally, using the aformentioned theoretical framework, we analytically derive the expression of the utility as a function of given flow data, which was numerically estimated in previous studies (Douglas & Wall, 1993; Douglas, 1997; Douglas & Wall, 2000; Wall, 2001; Nakajima & Tabuchi, 2011). The proposed method extracts a consistent metric of interval scale from the non-transitive, pairwise comparison between locations and provides valuable statistics for urban planning by policymakers."}, "https://arxiv.org/abs/2405.11225": {"title": "SeBot: Structural Entropy Guided Multi-View Contrastive Learning for Social Bot Detection", "link": "https://arxiv.org/abs/2405.11225", "description": "arXiv:2405.11225v1 Announce Type: new \nAbstract: Recent advancements in social bot detection have been driven by the adoption of Graph Neural Networks. The social graph, constructed from social network interactions, contains benign and bot accounts that influence each other. However, previous graph-based detection methods that follow the transductive message-passing paradigm may not fully utilize hidden graph information and are vulnerable to adversarial bot behavior. The indiscriminate message passing between nodes from different categories and communities results in excessively homogeneous node representations, ultimately reducing the effectiveness of social bot detectors. In this paper, we propose SEBot, a novel multi-view graph-based contrastive learning-enabled social bot detector. In particular, we use structural entropy as an uncertainty metric to optimize the entire graph's structure and subgraph-level granularity, revealing the implicitly existing hierarchical community structure. And we design an encoder to enable message passing beyond the homophily assumption, enhancing robustness to adversarial behaviors of social bots. Finally, we employ multi-view contrastive learning to maximize mutual information between different views and enhance the detection performance through multi-task learning. Experimental results demonstrate that our approach significantly improves the performance of social bot detection compared with SOTA methods."}, "https://arxiv.org/abs/2405.11887": {"title": "Social norm dynamics in a behavioral epidemic model on multiplex networks", "link": "https://arxiv.org/abs/2405.11887", "description": "arXiv:2405.11887v1 Announce Type: new \nAbstract: Understanding the social determinants influencing preventive measures adoption during epidemics is crucial for effective disease modeling and policy making. While traditional epidemic models focused on rational decision-making and psychological biases, recent studies highlight the role of social norms. We develop a behavioral epidemic model on a multiplex network, by integrating an Experience Weighted Attractor (EWA) learning mechanism and social norm dynamics. Incorporating social norms in our decision-making mechanism significantly reduces final infected fractions, offering an alternative to altruism for boosting vaccination coverage. Furthermore, we examine the importance of the dynamics of each one of the social norms, injunctive or descriptive, in reducing the infected fraction, finding that the former has a more significant effect in agreement with some experimental evidence. We also explore the effect of external interventions on epidemic expansion, aiding in refining public communication protocols. Enhanced models of social norm dynamics, if validated and tested, can better capture the complexities of human social behavior and mitigate various societal challenges beyond pandemics."}, "https://arxiv.org/abs/2405.11922": {"title": "Effective Clustering on Large Attributed Bipartite Graphs", "link": "https://arxiv.org/abs/2405.11922", "description": "arXiv:2405.11922v1 Announce Type: new \nAbstract: Attributed bipartite graphs (ABGs) are an expressive data model for describing the interactions between two sets of heterogeneous nodes that are associated with rich attributes, such as customer-product purchase networks and author-paper authorship graphs. Partitioning the target node set in such graphs into k disjoint clusters (referred to as k-ABGC) finds widespread use in various domains, including social network analysis, recommendation systems, information retrieval, and bioinformatics. However, the majority of existing solutions towards k-ABGC either overlook attribute information or fail to capture bipartite graph structures accurately, engendering severely compromised result quality. The severity of these issues is accentuated in real ABGs, which often encompass millions of nodes and a sheer volume of attribute data, rendering effective k-ABGC over such graphs highly challenging.\n  In this paper, we propose TPO, an effective and efficient approach to k-ABGC that achieves superb clustering performance on multiple real datasets. TPO obtains high clustering quality through two major contributions: (i) a novel formulation and transformation of the k-ABGC problem based on multi-scale attribute affinity specialized for capturing attribute affinities between nodes with the consideration of their multi-hop connections in ABGs, and (ii) a highly efficient solver that includes a suite of carefully-crafted optimizations for sidestepping explicit affinity matrix construction and facilitating faster convergence. Extensive experiments, comparing TPO against 19 baselines over 5 real ABGs, showcase the superior clustering quality of TPO measured against ground-truth labels. Moreover, compared to the state of the arts, TPO is often more than 40x faster over both small and large ABGs."}, "https://arxiv.org/abs/2405.12040": {"title": "Reputation Transfer in the Twitter Diaspora", "link": "https://arxiv.org/abs/2405.12040", "description": "arXiv:2405.12040v1 Announce Type: new \nAbstract: Social media platforms have witnessed a dynamic landscape of user migration in recent years, fueled by changes in ownership, policy, and user preferences. This paper explores the phenomenon of user migration from established platforms like X/Twitter to emerging alternatives such as Threads, Mastodon, and Truth Social. Leveraging a large dataset from X/Twitter, we investigate the extent of user departure from X/Twitter and the destinations they migrate to. Additionally, we examine whether a user's reputation on one platform correlates with their reputation on another, shedding light on the transferability of digital reputation across social media ecosystems. Overall, we find that users with a large following on X/Twitter are more likely to migrate to another platform; and that their reputation on X/Twitter is highly correlated with reputations on Threads, but not Mastodon or Truth Social."}, "https://arxiv.org/abs/2405.11121": {"title": "COVID-19's Unequal Toll: An assessment of small business impact disparities with respect to ethnorace in metropolitan areas in the US using mobility data", "link": "https://arxiv.org/abs/2405.11121", "description": "arXiv:2405.11121v1 Announce Type: cross \nAbstract: Early in the pandemic, counties and states implemented a variety of non-pharmacological interventions (NPIs) focused on mobility, such as national lockdowns or work-from-home strategies, as it became clear that restricting movement was essential to containing the epidemic. Due to these restrictions, businesses were severely affected and in particular, small, urban restaurant businesses. In addition to that, COVID-19 has also amplified many of the socioeconomic disparities and systemic racial inequities that exist in our society. The overarching objective of this study was to examine the changes in small urban restaurant visitation patterns following the COVID-19 pandemic and associated mobility restrictions, as well as to uncover potential disparities across different racial/ethnic groups in order to understand inequities in the impact and recovery. Specifically, the two key objectives were: 1) to analyze the overall changes in restaurant visitation patterns in US metropolitan areas during the pandemic compared to a pre-pandemic baseline, and 2) to investigate differences in visitation pattern changes across Census Block Groups with majority Asian, Black, Hispanic, White, and American Indian populations, identifying any disproportionate effects. Using aggregated geolocated cell phone data from SafeGraph, we document the overall changes in small urban restaurant businesses' visitation patterns with respect to racial composition at a granularity of Census Block Groups. Our results show clear indications of reduced visitation patterns after the pandemic, with slow recoveries. Via visualizations and statistical analyses, we show that reductions in visitation patterns were the highest for small urban restaurant businesses in majority Asian neighborhoods."}, "https://arxiv.org/abs/2405.11192": {"title": "BrainStorm @ iREL at SMM4H 2024: Leveraging Translation and Topical Embeddings for Annotation Detection in Tweets", "link": "https://arxiv.org/abs/2405.11192", "description": "arXiv:2405.11192v1 Announce Type: cross \nAbstract: The proliferation of LLMs in various NLP tasks has sparked debates regarding their reliability, particularly in annotation tasks where biases and hallucinations may arise. In this shared task, we address the challenge of distinguishing annotations made by LLMs from those made by human domain experts in the context of COVID-19 symptom detection from tweets in Latin American Spanish. This paper presents BrainStorm @ iREL's approach to the SMM4H 2024 Shared Task, leveraging the inherent topical information in tweets, we propose a novel approach to identify and classify annotations, aiming to enhance the trustworthiness of annotated data."}, "https://arxiv.org/abs/2405.11219": {"title": "Identifying and Aligning Medical Claims Made on Social Media with Medical Evidence", "link": "https://arxiv.org/abs/2405.11219", "description": "arXiv:2405.11219v1 Announce Type: cross \nAbstract: Evidence-based medicine is the practice of making medical decisions that adhere to the latest, and best known evidence at that time. Currently, the best evidence is often found in the form of documents, such as randomized control trials, meta-analyses and systematic reviews. This research focuses on aligning medical claims made on social media platforms with this medical evidence. By doing so, individuals without medical expertise can more effectively assess the veracity of such medical claims. We study three core tasks: identifying medical claims, extracting medical vocabulary from these claims, and retrieving evidence relevant to those identified medical claims. We propose a novel system that can generate synthetic medical claims to aid each of these core tasks. We additionally introduce a novel dataset produced by our synthetic generator that, when applied to these tasks, demonstrates not only a more flexible and holistic approach, but also an improvement in all comparable metrics. We make our dataset, the Expansive Medical Claim Corpus (EMCC), available at https://zenodo.org/records/8321460"}, "https://arxiv.org/abs/2405.11414": {"title": "High-Resolution Agent-Based Modeling of Campus Population Behaviors for Pandemic Response Planning", "link": "https://arxiv.org/abs/2405.11414", "description": "arXiv:2405.11414v1 Announce Type: cross \nAbstract: This paper reports a case study of an application of high-resolution agent-based modeling and simulation to pandemic response planning on a university campus. In the summer of 2020, we were tasked with a COVID-19 pandemic response project to create a detailed behavioral simulation model of the entire campus population at Binghamton University. We conceptualized this problem as an agent migration process on a multilayer transportation network, in which each layer represented a different transportation mode. As no direct data were available about people's behaviors on campus, we collected as much indirect information as possible to inform the agents' behavioral rules. Each agent was assumed to move along the shortest path between two locations within each transportation layer and switch layers at a parking lot or a bus stop, along with several other behavioral assumptions. Using this model, we conducted simulations of the whole campus population behaviors on a typical weekday, involving more than 25,000 agents. We measured the frequency of close social contacts at each spatial location and identified several busy locations and corridors on campus that needed substantial behavioral intervention. Moreover, systematic simulations with varying population density revealed that the effect of population density reduction was nonlinear, and that reducing the population density to 40-45% would be optimal and sufficient to suppress disease spreading on campus. These results were reported to the university administration and utilized in the pandemic response planning, which led to successful outcomes."}, "https://arxiv.org/abs/2405.11658": {"title": "A Starting Point for Dynamic Community Detection with Leiden Algorithm", "link": "https://arxiv.org/abs/2405.11658", "description": "arXiv:2405.11658v1 Announce Type: cross \nAbstract: Many real-world graphs evolve with time. Identifying communities or clusters on such graphs is an important problem. In this technical report, we extend three dynamic approaches, namely, Naive-dynamic (ND), Delta-screening (DS), and Dynamic Frontier (DF), to our multicore implementation of the Leiden algorithm, an algorithm known for its high-quality community detection. Our experiments on a server with a 64-core AMD EPYC-7742 processor demonstrate that ND, DS, and DF Leiden achieve speedups of 1.25x, 1.24x, and 1.37x on large graphs with random batch updates, compared to Static, ND, and DS Leiden, respectively. However, on real-world dynamic graphs, ND Leiden performs the best, being on average 1.14x faster than Static Leiden. We hope our early results serve as a starting point for dynamic approaches to the Leiden algorithm on evolving graphs."}, "https://arxiv.org/abs/2405.11868": {"title": "Towards Graph Contrastive Learning: A Survey and Beyond", "link": "https://arxiv.org/abs/2405.11868", "description": "arXiv:2405.11868v1 Announce Type: cross \nAbstract: In recent years, deep learning on graphs has achieved remarkable success in various domains. However, the reliance on annotated graph data remains a significant bottleneck due to its prohibitive cost and time-intensive nature. To address this challenge, self-supervised learning (SSL) on graphs has gained increasing attention and has made significant progress. SSL enables machine learning models to produce informative representations from unlabeled graph data, reducing the reliance on expensive labeled data. While SSL on graphs has witnessed widespread adoption, one critical component, Graph Contrastive Learning (GCL), has not been thoroughly investigated in the existing literature. Thus, this survey aims to fill this gap by offering a dedicated survey on GCL. We provide a comprehensive overview of the fundamental principles of GCL, including data augmentation strategies, contrastive modes, and contrastive optimization objectives. Furthermore, we explore the extensions of GCL to other aspects of data-efficient graph learning, such as weakly supervised learning, transfer learning, and related scenarios. We also discuss practical applications spanning domains such as drug discovery, genomics analysis, recommender systems, and finally outline the challenges and potential future directions in this field."}, "https://arxiv.org/abs/2405.11911": {"title": "PULL: PU-Learning-based Accurate Link Prediction", "link": "https://arxiv.org/abs/2405.11911", "description": "arXiv:2405.11911v1 Announce Type: cross \nAbstract: Given an edge-incomplete graph, how can we accurately find the missing links? The link prediction in edge-incomplete graphs aims to discover the missing relations between entities when their relationships are represented as a graph. Edge-incomplete graphs are prevalent in real-world due to practical limitations, such as not checking all users when adding friends in a social network. Addressing the problem is crucial for various tasks, including recommending friends in social networks and finding references in citation networks. However, previous approaches rely heavily on the given edge-incomplete (observed) graph, making it challenging to consider the missing (unobserved) links during training. In this paper, we propose PULL (PU-Learning-based Link predictor), an accurate link prediction method based on the positive-unlabeled (PU) learning. PULL treats the observed edges in the training graph as positive examples, and the unconnected node pairs as unlabeled ones. PULL effectively prevents the link predictor from overfitting to the observed graph by proposing latent variables for every edge, and leveraging the expected graph structure with respect to the variables. Extensive experiments on five real-world datasets show that PULL consistently outperforms the baselines for predicting links in edge-incomplete graphs."}, "https://arxiv.org/abs/2405.12023": {"title": "Estimating transmission noise on networks from stationary local order", "link": "https://arxiv.org/abs/2405.12023", "description": "arXiv:2405.12023v1 Announce Type: cross \nAbstract: In this paper we study networks of nodes characterised by binary traits that change both endogenously and through nearest-neighbour interaction. Our analytical results show that those traits can be ranked according to the noisiness of their transmission using only measures of order in the stationary state. Crucially, this ranking is independent of network topology. As an example, we explain why, in line with a long-standing hypothesis, the relative stability of the structural traits of languages can be estimated from their geospatial distribution. We conjecture that similar inferences may be possible in a more general class of Markovian systems. Consequently, in many empirical domains where longitudinal information is not easily available the propensities of traits to change could be estimated from spatial data alone."}, "https://arxiv.org/abs/2405.12180": {"title": "Estimating the Impact of Social Distance Policy in Mitigating COVID-19 Spread with Factor-Based Imputation Approach", "link": "https://arxiv.org/abs/2405.12180", "description": "arXiv:2405.12180v1 Announce Type: cross \nAbstract: We identify the effectiveness of social distancing policies in reducing the transmission of the COVID-19 spread. We build a model that measures the relative frequency and geographic distribution of the virus growth rate and provides hypothetical infection distribution in the states that enacted the social distancing policies, where we control time-varying, observed and unobserved, state-level heterogeneities. Using panel data on infection and deaths in all US states from February 20 to April 20, 2020, we find that stay-at-home orders and other types of social distancing policies significantly reduced the growth rate of infection and deaths. We show that the effects are time-varying and range from the weakest at the beginning of policy intervention to the strongest by the end of our sample period. We also found that social distancing policies were more effective in states with higher income, better education, more white people, more democratic voters, and higher CNN viewership."}, "https://arxiv.org/abs/2308.05945": {"title": "Improving Ego-Cluster for Network Effect Measurement", "link": "https://arxiv.org/abs/2308.05945", "description": "arXiv:2308.05945v2 Announce Type: replace \nAbstract: The network effect, wherein one user's activity impacts another user, is common in social network platforms. Many new features in social networks are specifically designed to create a network effect, enhancing user engagement. For instance, content creators tend to produce more when their articles and posts receive positive feedback from followers. This paper discusses a new cluster-level experimentation methodology for measuring creator-side metrics in the context of A/B experiments. The methodology is designed to address cases where the experiment randomization unit and the metric measurement unit differ. It is a crucial part of LinkedIn's overall strategy to foster a robust creator community and ecosystem. The method is developed based on widely-cited research at LinkedIn but significantly improves the efficiency and flexibility of the clustering algorithm. This improvement results in a stronger capability for measuring creator-side metrics and an increased velocity for creator-related experiments."}, "https://arxiv.org/abs/2401.08680": {"title": "Proximity Ascertainment Bias in Early Covid Case Locations", "link": "https://arxiv.org/abs/2401.08680", "description": "arXiv:2401.08680v5 Announce Type: replace \nAbstract: A comparison of the distances to the Huanan Seafood Market of early Covid cases with known links to the market versus cases without known links shows results apparently incompatible with a location model lacking proximity ascertainment bias. The sign of the difference instead agrees with a model in which such ascertainment bias is large. In the presence of such bias inferences based on the clustering of case locations become unreliable."}, "https://arxiv.org/abs/2007.05637": {"title": "Multilevel Digital Contact Tracing", "link": "https://arxiv.org/abs/2007.05637", "description": "arXiv:2007.05637v4 Announce Type: replace-cross \nAbstract: Digital contact tracing plays a crucial role in alleviating an outbreak, and designing multilevel digital contact tracing for a country is an open problem due to the analysis of large volumes of temporal contact data. We develop a multilevel digital contact tracing framework that constructs dynamic contact graphs from the proximity contact data. Prominently, we introduce the edge label of the contact graph as a binary circular contact queue, which holds the temporal social interactions during the incubation period. After that, our algorithm prepares the direct and indirect (multilevel) contact list for a given set of infected persons from the contact graph. Finally, the algorithm constructs the infection pathways for the trace list. We implement the framework and validate the contact tracing process with synthetic and real-world data sets. In addition, analysis reveals that for COVID-19 close contact parameters, the framework takes reasonable space and time to create the infection pathways. Our framework can apply to any epidemic spreading by changing the algorithm's parameters."}, "https://arxiv.org/abs/2305.14375": {"title": "MGL2Rank: Learning to Rank the Importance of Nodes in Road Networks Based on Multi-Graph Fusion", "link": "https://arxiv.org/abs/2305.14375", "description": "arXiv:2305.14375v3 Announce Type: replace-cross \nAbstract: The identification of important nodes with strong propagation capabilities in road networks is a vital topic in urban planning. Existing methods for evaluating the importance of nodes in traffic networks only consider topological information and traffic volumes, the diversity of the traffic characteristics in road networks, such as the number of lanes and average speed of road segments, is ignored, thus limiting their performance. To solve this problem, we propose a graph learning-based framework (MGL2Rank) that integrates the rich characteristics of road networks to rank the importance of nodes. This framework comprises an embedding module containing a sampling algorithm (MGWalk) and an encoder network to learn the latent representations for each road segment. MGWalk utilizes multigraph fusion to capture the topology of road networks and establish associations between road segments based on their attributes. The obtained node representation is then used to learn the importance ranking of the road segments. Finally, a synthetic dataset is constructed for ranking tasks based on the regional road network of Shenyang City, and the ranking results on this dataset demonstrate the effectiveness of our method. The data and source code for MGL2Rank are available at https://github.com/iCityLab/MGL2Rank."}, "https://arxiv.org/abs/2404.14423": {"title": "A Compositional Approach to Higher-Order Structure in Complex Systems", "link": "https://arxiv.org/abs/2404.14423", "description": "arXiv:2404.14423v2 Announce Type: replace-cross \nAbstract: Relating microscopic interactions to macroscopic observables is a central challenge in the study of complex systems. Addressing this question requires understanding both pairwise and higher-order interactions, but the latter are less well understood. Here, we show that the M\\\"obius inversion theorem provides a general mathematical formalism for deriving higher-order interactions from macroscopic observables, relative to a chosen decomposition of the system into parts. Applying this framework to a diverse range of systems, we demonstrate that many existing notions of higher-order interactions, from epistasis in genetics and many-body couplings in physics, to synergy in game theory and artificial intelligence, naturally arise from an appropriate mereological decomposition. By revealing the common mathematical structure underlying seemingly disparate phenomena, our work highlights the fundamental role of decomposition choice in the definition and estimation of higher-order interactions. We discuss how this unifying perspective can facilitate the transfer of insights between domains, guide the selection of appropriate system decompositions, and motivate the search for novel interaction types through creative decomposition strategies. More broadly, our results suggest that the M\\\"obius inversion theorem provides a powerful lens for understanding the emergence of complex behaviour from the interplay of microscopic parts, with applications across a wide range of disciplines."}, "https://arxiv.org/abs/2405.12244": {"title": "Real-Time Go-Around Prediction: A case study of JFK airport", "link": "https://arxiv.org/abs/2405.12244", "description": "arXiv:2405.12244v1 Announce Type: new \nAbstract: In this paper, we employ the long-short-term memory model (LSTM) to predict the real-time go-around probability as an arrival flight is approaching JFK airport and within 10 nm of the landing runway threshold. We further develop methods to examine the causes to go-around occurrences both from a global view and an individual flight perspective. According to our results, in-trail spacing, and simultaneous runway operation appear to be the top factors that contribute to overall go-around occurrences. We then integrate these pre-trained models and analyses with real-time data streaming, and finally develop a demo web-based user interface that integrates the different components designed previously into a real-time tool that can eventually be used by flight crews and other line personnel to identify situations in which there is a high risk of a go-around."}, "https://arxiv.org/abs/2405.12253": {"title": "The statistical and dynamic modeling of the first part of the 2013-2014 Euromaidan protests in Ukraine: The Revolution of Dignity and preceding times", "link": "https://arxiv.org/abs/2405.12253", "description": "arXiv:2405.12253v1 Announce Type: new \nAbstract: Ukraine's tug-of-war between Russia and the West has had significant and lasting consequences for the country. In 2013, Viktor Yanukovych, the Ukrainian president aligned with Russia, opted against signing an association agreement with the European Union. This agreement aimed to facilitate trade and travel between the EU and Ukraine. This decision sparked widespread protests that coalesced in Kyiv's Maidan Square, eventually becoming known as the Euromaidan protests. In this study, we analyze the protest data from 2013, sourced from Ukraine's Center for Social and Labor Research. Despite the dataset's limitations and occasional inconsistencies, we demonstrate the extraction of valuable insights and the construction of a descriptive model from such data. Our investigation reveals a pre-existing state of self-excitation within the system even before the onset of the Euromaidan protests. This self-excitation intensified during the Euromaidan protests. A statistical analysis indicates that the government's utilization of force correlates with increased future protests, exacerbating rather than quelling the protest movement. Furthermore, we introduce the implementation of Hawkes process models to comprehend the spatiotemporal dynamics of the protest activity. Our findings highlight that, while protest activities spread across the entire country, the driving force behind the dynamics of these protests was the level of activity in Kyiv. Furthermore, in contrast to prior research that emphasized geographical proximity as a key predictor of event propagation, our study illustrates that the political alignment among oblasts, which are the distinct municipalities comprising Ukraine, had a more profound impact than mere geographic distance. This underscores the significance of social and cultural factors in molding the trajectory of political movements."}, "https://arxiv.org/abs/2405.12566": {"title": "Unveiling Online Conspiracy Theorists: a Text-Based Approach and Characterization", "link": "https://arxiv.org/abs/2405.12566", "description": "arXiv:2405.12566v1 Announce Type: new \nAbstract: In today's digital landscape, the proliferation of conspiracy theories within the disinformation ecosystem of online platforms represents a growing concern. This paper delves into the complexities of this phenomenon. We conducted a comprehensive analysis of two distinct X (formerly known as Twitter) datasets: one comprising users with conspiracy theorizing patterns and another made of users lacking such tendencies and thus serving as a control group. The distinguishing factors between these two groups are explored across three dimensions: emotions, idioms, and linguistic features. Our findings reveal marked differences in the lexicon and language adopted by conspiracy theorists with respect to other users. We developed a machine learning classifier capable of identifying users who propagate conspiracy theories based on a rich set of 871 features. The results demonstrate high accuracy, with an average F1 score of 0.88. Moreover, this paper unveils the most discriminating characteristics that define conspiracy theory propagators."}, "https://arxiv.org/abs/2405.12642": {"title": "Combining Twitter and Mobile Phone Data to Observe Border-Rush: The Turkish-European Border Opening", "link": "https://arxiv.org/abs/2405.12642", "description": "arXiv:2405.12642v1 Announce Type: new \nAbstract: Following Turkey's 2020 decision to revoke border controls, many individuals journeyed towards the Greek, Bulgarian, and Turkish borders. However, the lack of verifiable statistics on irregular migration and discrepancies between media reports and actual migration patterns require further exploration. The objective of this study is to bridge this knowledge gap by harnessing novel data sources, specifically mobile phone and Twitter data, to construct estimators of cross-border mobility and to cultivate a qualitative comprehension of the unfolding events. By employing a migration diplomacy framework, we analyse emergent mobility patterns at the border. Our findings demonstrate the potential of mobile phone data for quantitative metrics and Twitter data for qualitative understanding. We underscore the ethical implications of leveraging Big Data, particularly considering the vulnerability of the population under study. This underscores the imperative for exhaustive research into the socio-political facets of human mobility, with the aim of discerning the potentialities, limitations, and risks inherent in these data sources and their integration. This scholarly endeavour contributes to a more nuanced understanding of migration dynamics and paves the way for the formulation of regulations that preclude misuse and oppressive surveillance, thereby ensuring a more accurate representation of migration realities."}, "https://arxiv.org/abs/2405.12764": {"title": "Detecting and Mitigating Bias in Algorithms Used to Disseminate Information in Social Networks", "link": "https://arxiv.org/abs/2405.12764", "description": "arXiv:2405.12764v1 Announce Type: new \nAbstract: Social connections are a conduit through which individuals communicate, information propagates, and diseases spread. Identifying individuals that are more likely to adopt ideas or technologies and spread them to others is essential in order to develop effective information campaigns, fight epidemics, and to maximize the reach of limited resources. Consequently a lot of work has focused on identifying sets of influencers. Here we show that seeding information using these influence maximization methods, only benefits connected and central individuals, consistently leaving the most vulnerable behind. Our results highlights troublesome outcomes of influence maximization algorithms: they do not disseminate information in an equitable manner threatening to create an increasingly unequal society. To overcome this issue we devise a simple, multi-objective algorithm, which maximises both influence and information equity. Our work demonstrates how to find fairer influencer sets, highlighting that in our search for maximizing information, we do not need to compromise on information equality."}, "https://arxiv.org/abs/2405.12797": {"title": "Refined Graph Encoder Embedding via Self-Training and Latent Community Recovery", "link": "https://arxiv.org/abs/2405.12797", "description": "arXiv:2405.12797v1 Announce Type: new \nAbstract: This paper introduces a refined graph encoder embedding method, enhancing the original graph encoder embedding using linear transformation, self-training, and hidden community recovery within observed communities. We provide the theoretical rationale for the refinement procedure, demonstrating how and why our proposed method can effectively identify useful hidden communities via stochastic block models, and how the refinement method leads to improved vertex embedding and better decision boundaries for subsequent vertex classification. The efficacy of our approach is validated through a collection of simulated and real-world graph data."}, "https://arxiv.org/abs/2405.12340": {"title": "Cascade-based Randomization for Inferring Causal Effects under Diffusion Interference", "link": "https://arxiv.org/abs/2405.12340", "description": "arXiv:2405.12340v1 Announce Type: cross \nAbstract: The presence of interference, where the outcome of an individual may depend on the treatment assignment and behavior of neighboring nodes, can lead to biased causal effect estimation. Current approaches to network experiment design focus on limiting interference through cluster-based randomization, in which clusters are identified using graph clustering, and cluster randomization dictates the node assignment to treatment and control. However, cluster-based randomization approaches perform poorly when interference propagates in cascades, whereby the response of individuals to treatment propagates to their multi-hop neighbors. When we have knowledge of the cascade seed nodes, we can leverage this interference structure to mitigate the resulting causal effect estimation bias. With this goal, we propose a cascade-based network experiment design that initiates treatment assignment from the cascade seed node and propagates the assignment to their multi-hop neighbors to limit interference during cascade growth and thereby reduce the overall causal effect estimation error. Our extensive experiments on real-world and synthetic datasets demonstrate that our proposed framework outperforms the existing state-of-the-art approaches in estimating causal effects in network data."}, "https://arxiv.org/abs/2405.12474": {"title": "How Universal Polynomial Bases Enhance Spectral Graph Neural Networks: Heterophily, Over-smoothing, and Over-squashing", "link": "https://arxiv.org/abs/2405.12474", "description": "arXiv:2405.12474v1 Announce Type: cross \nAbstract: Spectral Graph Neural Networks (GNNs), alternatively known as graph filters, have gained increasing prevalence for heterophily graphs. Optimal graph filters rely on Laplacian eigendecomposition for Fourier transform. In an attempt to avert prohibitive computations, numerous polynomial filters have been proposed. However, polynomials in the majority of these filters are predefined and remain fixed across different graphs, failing to accommodate the varying degrees of heterophily. Addressing this gap, we demystify the intrinsic correlation between the spectral property of desired polynomial bases and the heterophily degrees via thorough theoretical analyses. Subsequently, we develop a novel adaptive heterophily basis wherein the basis vectors mutually form angles reflecting the heterophily degree of the graph. We integrate this heterophily basis with the homophily basis to construct a universal polynomial basis UniBasis, which devises a polynomial filter based graph neural network - UniFilter. It optimizes the convolution and propagation in GNN, thus effectively limiting over-smoothing and alleviating over-squashing. Our extensive experiments, conducted on a diverse range of real-world and synthetic datasets with varying degrees of heterophily, support the superiority of UniFilter. These results not only demonstrate the universality of UniBasis but also highlight its proficiency in graph explanation."}, "https://arxiv.org/abs/2311.09262": {"title": "Disentangling the Potential Impacts of Papers into Diffusion, Conformity, and Contribution Values", "link": "https://arxiv.org/abs/2311.09262", "description": "arXiv:2311.09262v3 Announce Type: replace \nAbstract: The potential impact of an academic paper is determined by various factors, including its popularity and contribution. Existing models usually estimate original citation counts based on static graphs and fail to differentiate values from nuanced perspectives. In this study, we propose a novel graph neural network to Disentangle the Potential impacts of Papers into Diffusion, Conformity, and Contribution values (called DPPDCC). Given a target paper, DPPDCC encodes temporal and structural features within the constructed dynamic heterogeneous graph. Particularly, to capture the knowledge flow, we emphasize the importance of comparative and co-cited/citing information between papers and aggregate snapshots evolutionarily. To unravel popularity, we contrast augmented graphs to extract the essence of diffusion and predict the accumulated citation binning to model conformity. We further apply orthogonal constraints to encourage distinct modeling of each perspective and preserve the inherent value of contribution. To evaluate models' generalization for papers published at various times, we reformulate the problem by partitioning data based on specific time points to mirror real-world conditions. Extensive experimental results on three datasets demonstrate that DPPDCC significantly outperforms baselines for previously, freshly, and immediately published papers. Further analyses confirm its robust capabilities. We will make our datasets and codes publicly available."}, "https://arxiv.org/abs/2401.09310": {"title": "Asymmetric games on networks: mapping to Ising models and bounded rationality", "link": "https://arxiv.org/abs/2401.09310", "description": "arXiv:2401.09310v2 Announce Type: replace \nAbstract: We investigate the dynamics of coordination and consensus in an agent population. Considering agents endowed with bounded rationality, we study asymmetric coordination games using a mapping to random field Ising models. In doing so, we investigate the relationship between group coordination and agent rationality. Analytical calculations and numerical simulations of the proposed model lead to novel insight into opinion dynamics. For instance, we find that bounded rationality and preference intensity can determine a series of possible scenarios with different levels of opinion polarization. To conclude, we deem our investigation opens a new avenue for studying game dynamics through methods of statistical physics."}, "https://arxiv.org/abs/2403.02867": {"title": "Scalable Continuous-time Diffusion Framework for Network Inference and Influence Estimation", "link": "https://arxiv.org/abs/2403.02867", "description": "arXiv:2403.02867v2 Announce Type: replace \nAbstract: The study of continuous-time information diffusion has been an important area of research for many applications in recent years. When only the diffusion traces (cascades) are accessible, cascade-based network inference and influence estimation are two essential problems to explore. Alas, existing methods exhibit limited capability to infer and process networks with more than a few thousand nodes, suffering from scalability issues. In this paper, we view the diffusion process as a continuous-time dynamical system, based on which we establish a continuous-time diffusion model. Subsequently, we instantiate the model to a scalable and effective framework (FIM) to approximate the diffusion propagation from available cascades, thereby inferring the underlying network structure. Furthermore, we undertake an analysis of the approximation error of FIM for network inference. To achieve the desired scalability for influence estimation, we devise an advanced sampling technique and significantly boost the efficiency. We also quantify the effect of the approximation error on influence estimation theoretically. Experimental results showcase the effectiveness and superior scalability of FIM on network inference and influence estimation."}, "https://arxiv.org/abs/2405.13094": {"title": "KPG: Key Propagation Graph Generator for Rumor Detection based on Reinforcement Learning", "link": "https://arxiv.org/abs/2405.13094", "description": "arXiv:2405.13094v1 Announce Type: new \nAbstract: The proliferation of rumors on social media platforms during significant events, such as the US elections and the COVID-19 pandemic, has a profound impact on social stability and public health. Existing approaches for rumor detection primarily rely on propagation graphs to enhance model effectiveness. However, the presence of noisy and irrelevant structures during the propagation process limits the efficacy of these approaches. To tackle this issue, techniques such as weight adjustment and data augmentation have been proposed. However, these techniques heavily depend on rich original propagation structures, thus hindering performance when dealing with rumors that lack sufficient propagation information in the early propagation stages. In this paper, we propose Key Propagation Graph Generator (KPG), a novel reinforcement learning-based rumor detection framework that generates contextually coherent and informative propagation patterns for events with insufficient topology information, while also identifies indicative substructures for events with redundant and noisy propagation structures. KPG consists of two key components: the Candidate Response Generator (CRG) and the Ending Node Selector (ENS). CRG learns the latent distribution from refined propagation patterns, filtering out noise and generating new candidates for ENS. Simultaneously, ENS identifies the most influential substructures within propagation graphs and generates training data for CRG. Moreover, we introduce an end-to-end framework that utilizes rewards to guide the entire training process via a pre-trained graph neural network. Extensive experiments conducted on four datasets demonstrate the superiority of our KPG compared to the state-of-the-art approaches."}, "https://arxiv.org/abs/2405.13224": {"title": "Integrating behavioral experimental findings into dynamical models to inform social change interventions", "link": "https://arxiv.org/abs/2405.13224", "description": "arXiv:2405.13224v1 Announce Type: new \nAbstract: Addressing global challenges -- from public health to climate change -- often involves stimulating the large-scale adoption of new products or behaviors. Research traditions that focus on individual decision making suggest that achieving this objective requires better identifying the drivers of individual adoption choices. On the other hand, computational approaches rooted in complexity science focus on maximizing the propagation of a given product or behavior throughout social networks of interconnected adopters. The integration of these two perspectives -- although advocated by several research communities -- has remained elusive so far. Here we show how achieving this integration could inform seeding policies to facilitate the large-scale adoption of a given behavior or product. Drawing on complex contagion and discrete choice theories, we propose a method to estimate individual-level thresholds to adoption, and validate its predictive power in two choice experiments. By integrating the estimated thresholds into computational simulations, we show that state-of-the-art seeding methods for social influence maximization might be suboptimal if they neglect individual-level behavioral drivers, which can be corrected through the proposed experimental method."}, "https://arxiv.org/abs/2405.13480": {"title": "What is a typical signalized intersection in a city? A pipeline for intersection data imputation from OpenStreetMap", "link": "https://arxiv.org/abs/2405.13480", "description": "arXiv:2405.13480v1 Announce Type: new \nAbstract: Signalized intersections, arguably the most complicated type of traffic scenario, are essential to urban mobility systems. With recent advancements in intelligent transportation technologies, signalized intersections have great prospects for making transportation greener, safer, and faster. Several studies have been conducted focusing on intersection-level control and optimization. However, arbitrarily structured signalized intersections that are often used do not represent the ground-truth distribution, and there is no standardized way that exists to extract information about real-world signalized intersections. As the largest open-source map in the world, OpenStreetMap (OSM) has been used by many transportation researchers for a variety of studies, including intersection-level research such as adaptive traffic signal control and eco-driving. However, the quality of OSM data has been a serious concern.\n  In this paper, we propose a pipeline for effectively extracting information about signalized intersections from OSM and constructing a comprehensive dataset. We thoroughly discuss challenges related to this task and we propose our solution for each challenge. We also use Salt Lake City as an example to demonstrate the performance of our methods. The pipeline has been published as an open-source Python library so everyone can freely download and use it to facilitate their research. Hopefully, this paper can serve as a starting point that inspires more efforts to build a standardized and systematic data pipeline for various types of transportation problems."}, "https://arxiv.org/abs/2405.13530": {"title": "Through energy droughts: hydropower's ability to sustain a high output", "link": "https://arxiv.org/abs/2405.13530", "description": "arXiv:2405.13530v1 Announce Type: new \nAbstract: Previous research has raised concerns about energy droughts in renewables-based energy systems. This study explores the ability of reservoir hydropower to sustain a high output and, thereby, mitigate such energy droughts. Using detailed modelling, we estimate that Swedish hydropower can sustain 67-92% of its installed capacity for 3 weeks, with higher values possible in springtime. The variation of the sustained output, equivalent to the capacity of 3-4 Swedish nuclear reactors, under-scores the importance of understanding the potential output levels when devising strategies to counteract energy droughts. Moreover, we find that regulations imposed on the flows in river bottlenecks hinder higher sustained output levels. With the upcoming renewal of environmental permits for hydropower plants in Sweden, these findings provide valuable insights for policymakers. Furthermore, the sustained output capabilities demonstrated in this study challenge the prevalent simplified representations of hydropower in energy models, suggesting a need for more-sophisticated modelling approaches."}, "https://arxiv.org/abs/2405.13670": {"title": "GNN-based Anomaly Detection for Encoded Network Traffic", "link": "https://arxiv.org/abs/2405.13670", "description": "arXiv:2405.13670v1 Announce Type: new \nAbstract: The early research report explores the possibility of using Graph Neural Networks (GNNs) for anomaly detection in internet traffic data enriched with information. While recent studies have made significant progress in using GNNs for anomaly detection in finance, multivariate time-series, and biochemistry domains, there is limited research in the context of network flow data. In this report, we explore the idea that leverages information-enriched features extracted from network flow packet data to improve the performance of GNN in anomaly detection. The idea is to utilize feature encoding (binary, numerical, and string) to capture the relationships between the network components, allowing the GNN to learn latent relationships and better identify anomalies."}, "https://arxiv.org/abs/2405.14100": {"title": "Water Management Considerations for a Self-Sustaining Moonbase", "link": "https://arxiv.org/abs/2405.14100", "description": "arXiv:2405.14100v1 Announce Type: new \nAbstract: The most pragmatic first step in the all-but-inevitable 3rd-millennium V\\\"olkerwanderung of humanity throughout the Solar System is the establishment of a permanent human presence on the Moon. This research examines: 1. the human, agricultural, and technical water needs of a 100-person, 500 m x 100 m x 6 m self-sustaining lunar colony; 2. choosing a strategic location for the moonbase; 3. a heat drill model by which the needed lunar water ice could be sublimated; and 4. the robust water treatment and recovery infrastructure and water management personnel that would be needed for a self-sustaining moonbase."}, "https://arxiv.org/abs/2405.14168": {"title": "A generative model for community types in directed networks", "link": "https://arxiv.org/abs/2405.14168", "description": "arXiv:2405.14168v1 Announce Type: new \nAbstract: Large complex networks are often organized into groups or communities. In this paper, we introduce and investigate a generative model of network evolution that reproduces all four pairwise community types that exist in directed networks: assortative, core-periphery, disassortative, and the newly introduced source-basin type. We fix the number of nodes and the community membership of each node, allowing node connectivity to change through rewiring mechanisms that depend on the community membership of the involved nodes. We determine the dependence of the community relationship on the model parameters using a mean-field solution. It reveals that a difference in the swap probabilities of the two communities is a necessary condition to obtain a core-periphery relationship and that a difference in the average in-degree of the communities is a necessary condition for a source-basin relationship. More generally, our analysis reveals multiple possible scenarios for the transition between the different structure types, and sheds light on the mechanisms underlying the observation of the different types of communities in network data."}, "https://arxiv.org/abs/2405.14194": {"title": "Graphlets correct for the topological information missed by random walks", "link": "https://arxiv.org/abs/2405.14194", "description": "arXiv:2405.14194v1 Announce Type: new \nAbstract: Random walks are widely used for mining networks due to the computational efficiency of computing them. For instance, graph representation learning learns a d-dimensional embedding space, so that the nodes that tend to co-occur on random walks (a proxy of being in the same network neighborhood) are close in the embedding space. Specific local network topology (i.e., structure) influences the co-occurrence of nodes on random walks, so random walks of limited length capture only partial topological information, hence diminishing the performance of downstream methods. We explicitly capture all topological neighborhood information and improve performance by introducing orbit adjacencies that quantify the adjacencies of two nodes as co-occurring on a given pair of graphlet orbits, which are symmetric positions on graphlets (small, connected, non-isomorphic, induced subgraphs of a large network). Importantly, we mathematically prove that random walks on up to k nodes capture only a subset of all the possible orbit adjacencies for up to k-node graphlets. Furthermore, we enable orbit adjacency-based analysis of networks by developing an efficient GRaphlet-orbit ADjacency COunter (GRADCO), which exhaustively computes all 28 orbit adjacency matrices for up to four-node graphlets. Note that four-node graphlets suffice, because real networks are usually small-world. In large networks on around 20,000 nodes, GRADCOcomputesthe28matricesinminutes. Onsixrealnetworksfromvarious domains, we compare the performance of node-label predictors obtained by using the network embeddings based on our orbit adjacencies to those based on random walks. We find that orbit adjacencies, which include those unseen by random walks, outperform random walk-based adjacencies, demonstrating the importance of the inclusion of the topological neighborhood information that is unseen by random walks."}, "https://arxiv.org/abs/2405.14503": {"title": "Radial analysis and scaling of housing prices in French urban areas", "link": "https://arxiv.org/abs/2405.14503", "description": "arXiv:2405.14503v1 Announce Type: new \nAbstract: Urban scaling laws summarize how urban attributes evolve with city size. Recent criticism questions notably the aggregate view of this approach, which leads to neglecting the internal structure of cities. This is all the more relevant for housing prices due to their important variations across space. Based on a dataset compiling millions of real estate transactions over the period 2017-2021, we investigate the regularities of the radial (center-periphery) profiles of housing prices across cities, with respect to their size. Results are threefold. First, they corroborate prior findings in the urban scaling literature stating that largest cities agglomerate higher housing prices. Second, we find that housing price radial profiles scale in three dimensions with the power 1/5 of city population. After rescaling, great regularities between radial profiles can be observed, although some locational amenities have a significant impact on prices. Third, it appears that our rescaled profiles approach fails to explain housing price variations in the city center across cities. In fact, prices near the city center rise much faster with city size than those in the periphery. This has strong implications for low-income households seeking homeownership, because prohibitive prices in the center may contribute to pushing them out into peripheral locations."}, "https://arxiv.org/abs/2405.14543": {"title": "Initial Burst of Disruptive Efforts over Individual Scientific Careers", "link": "https://arxiv.org/abs/2405.14543", "description": "arXiv:2405.14543v1 Announce Type: new \nAbstract: Despite persistent efforts to understand the dynamics of creativity of scientists over careers in terms of productivity, impact, and prize, little is known about the dynamics of scientists' disruptive efforts that affect individual academic careers and drive scientific advance. Drawing on millions of data over six decades and across nineteen disciplines, associating the publication records of individual scientists with the disruption index, we systematically quantify the temporal pattern of disruptive ideas over individual scientific careers, providing a detailed understanding of the macro phenomenon of scientific stagnation from the individual perspective. We start by checking the relationship between disruption-based and citation-based publication profiles. Next, we observe the finite inequality in the disruptive productivity of scientists, diminishing gradually as the level of disruption increases. We then identify the initial burst phenomenon in disruption dynamics. It is further revealed that while early engagement in high disruption frictions away initial productivity, compared to initial advantage in productivity or impact, initial high disruption ensures more subsequent academic viability evidenced by a longer career span and relatively final higher productivity, but does not necessarily guarantee academic success throughout careers. Further analysis shows that increasing disruptive work is uncorrelated to overall productivity but negatively correlated with the overall impact. However, increasing disruptive work in the early career is associated with higher overall productivity, yet lower overall productivity in the later career. Our research underscores the urgent need for a policy shift that encourages a balance between the pursuit of disruptive efforts and the achievement of impactful outcomes."}, "https://arxiv.org/abs/2405.14717": {"title": "The impact of temporal hydrogen regulation on hydrogen exporters and their domestic energy transition", "link": "https://arxiv.org/abs/2405.14717", "description": "arXiv:2405.14717v1 Announce Type: new \nAbstract: As global demand for green hydrogen rises, potential hydrogen exporters move into the spotlight. However, the large-scale installation of on-grid hydrogen electrolysis for export can have profound impacts on domestic energy prices and energy-related emissions. Our investigation explores the interplay of hydrogen exports, domestic energy transition and temporal hydrogen regulation, employing a sector-coupled energy model in Morocco. We find substantial co-benets of domestic climate change mitigation and hydrogen exports, whereby exports can reduce domestic electricity prices while mitigation reduces hydrogen export prices. However, increasing hydrogen exports quickly in a system that is still dominated by fossil fuels can substantially raise domestic electricity prices, if green hydrogen production is not regulated. Surprisingly, temporal matching of hydrogen production lowers domestic electricity cost by up to 31% while the effect on exporters is minimal. This policy instrument can steer the welfare (re-)distribution between hydrogen exporting firms, hydrogen importers, and domestic electricity consumers and hereby increases acceptance among actors."}, "https://arxiv.org/abs/2310.08029": {"title": "Increasing the Earth's Albedo: The K\\\"ohler Equation at Sea", "link": "https://arxiv.org/abs/2310.08029", "description": "arXiv:2310.08029v2 Announce Type: cross \nAbstract: Increasing marine haze and clouds has been considered as a possible means of increasing the Earth's albedo. This would reduce Solar heating and global warming, counteracting the effects of the anthropogenic increase in greenhouse gases. One proposed method of doing so would inject small droplets of seawater or condensation nuclei into the marine boundary layer, creating artificial haze and cloud. The equilibrium size of such droplets is described by the K\\\"{o}hler equation that includes the vapor pressure reduction attributable to the solute according to Raoult's law and the vapor pressure increase of a small droplet as a result of surface tension according to Kelvin. Here we apply this classic result to small droplets in the marine boundary layer, where the partial pressure of water vapor is less than the equilibrium vapor pressure because it is in equilibrium with the saline ocean. We calculate the equilibrium size of a droplet containing dissolved ions and find that the radius of a droplet of seawater shrinks greatly before it achieves equilibrium."}, "https://arxiv.org/abs/2405.13005": {"title": "Understanding the Rare Inflammatory Disease Using Large Language Models and Social Media Data", "link": "https://arxiv.org/abs/2405.13005", "description": "arXiv:2405.13005v1 Announce Type: cross \nAbstract: Sarcoidosis is a rare inflammatory disease characterized by the formation of granulomas in various organs. The disease presents diagnostic and treatment challenges due to its diverse manifestations and unpredictable nature. In this study, we employed a Large Language Model (LLM) to analyze sarcoidosis-related discussions on the social media platform Reddit. Our findings underscore the efficacy of LLMs in accurately identifying sarcoidosis-related content. We discovered a wide array of symptoms reported by patients, with fatigue, swollen lymph nodes, and shortness of breath as the most prevalent. Prednisone was the most prescribed medication, while infliximab showed the highest effectiveness in improving prognoses. Notably, our analysis revealed disparities in prognosis based on age and gender, with women and younger patients experiencing good and polarized outcomes, respectively. Furthermore, unsupervised clustering identified three distinct patient subgroups (phenotypes) with unique symptom profiles, prognostic outcomes, and demographic distributions. Finally, sentiment analysis revealed a moderate negative impact on patients' mental health post-diagnosis, particularly among women and younger individuals. Our study represents the first application of LLMs to understand sarcoidosis through social media data. It contributes to understanding the disease by providing data-driven insights into its manifestations, treatments, prognoses, and impact on patients' lives. Our findings have direct implications for improving personalized treatment strategies and enhancing the quality of care for individuals living with sarcoidosis."}, "https://arxiv.org/abs/2405.13071": {"title": "A Novel Method for News Article Event-Based Embedding", "link": "https://arxiv.org/abs/2405.13071", "description": "arXiv:2405.13071v1 Announce Type: cross \nAbstract: Embedding news articles is a crucial tool for multiple fields, such as media bias detection, identifying fake news, and news recommendations. However, existing news embedding methods are not optimized for capturing the latent context of news events. In many cases, news embedding methods rely on full-textual information and neglect the importance of time-relevant embedding generation. Here, we aim to address these shortcomings by presenting a novel lightweight method that optimizes news embedding generation by focusing on the entities and themes mentioned in the articles and their historical connections to specific events. We suggest a method composed of three stages. First, we process and extract the events, entities, and themes for the given news articles. Second, we generate periodic time embeddings for themes and entities by training timely separated GloVe models on current and historical data. Lastly, we concatenate the news embeddings generated by two distinct approaches: Smooth Inverse Frequency (SIF) for article-level vectors and Siamese Neural Networks for embeddings with nuanced event-related information. To test and evaluate our method, we leveraged over 850,000 news articles and 1,000,000 events from the GDELT project. For validation purposes, we conducted a comparative analysis of different news embedding generation methods, applying them twice to a shared event detection task - first on articles published within the same day and subsequently on those published within the same month. Our experiments show that our method significantly improves the Precision-Recall (PR) AUC across all tasks and datasets. Specifically, we observed an average PR AUC improvement of 2.15% and 2.57% compared to SIF, as well as 2.57% and 2.43% compared to the semi-supervised approach for daily and monthly shared event detection tasks, respectively."}, "https://arxiv.org/abs/2405.13099": {"title": "The Role of Emotions in Informational Support Question-Response Pairs in Online Health Communities: A Multimodal Deep Learning Approach", "link": "https://arxiv.org/abs/2405.13099", "description": "arXiv:2405.13099v1 Announce Type: cross \nAbstract: This study explores the relationship between informational support seeking questions, responses, and helpfulness ratings in online health communities. We created a labeled data set of question-response pairs and developed multimodal machine learning and deep learning models to reliably predict informational support questions and responses. We employed explainable AI to reveal the emotions embedded in informational support exchanges, demonstrating the importance of emotion in providing informational support. This complex interplay between emotional and informational support has not been previously researched. The study refines social support theory and lays the groundwork for the development of user decision aids. Further implications are discussed."}, "https://arxiv.org/abs/2405.13341": {"title": "Wealth inequality and utility: Effect evaluation of redistribution and consumption morals using macro-econophysical coupled approach", "link": "https://arxiv.org/abs/2405.13341", "description": "arXiv:2405.13341v1 Announce Type: cross \nAbstract: Reducing wealth inequality and increasing utility are critical issues. This study reveals the effects of redistribution and consumption morals on wealth inequality and utility. To this end, we present a novel approach that couples the dynamic model of capital, consumption, and utility in macroeconomics with the interaction model of joint business and redistribution in econophysics. With this approach, we calculate the capital (wealth), the utility based on consumption, and the Gini index of these inequality using redistribution and consumption thresholds as moral parameters. The results show that: under-redistribution and waste exacerbate inequality; conversely, over-redistribution and stinginess reduce utility; and a balanced moderate moral leads to achieve both reduced inequality and increased utility. These findings provide renewed economic and numerical support for the moral importance known from philosophy, anthropology, and religion. The revival of redistribution and consumption morals should promote the transformation to a human mutual-aid economy, as indicated by philosopher and anthropologist, instead of the capitalist economy that has produced the current inequality. The practical challenge is to implement bottom-up social business, on a foothold of worker coops and platform cooperatives as a community against the state and the market, with moral consensus and its operation."}, "https://arxiv.org/abs/2405.13744": {"title": "A Privacy Measure Turned Upside Down? Investigating the Use of HTTP Client Hints on the Web", "link": "https://arxiv.org/abs/2405.13744", "description": "arXiv:2405.13744v1 Announce Type: cross \nAbstract: HTTP client hints are a set of standardized HTTP request headers designed to modernize and potentially replace the traditional user agent string. While the user agent string exposes a wide range of information about the client's browser and device, client hints provide a controlled and structured approach for clients to selectively disclose their capabilities and preferences to servers. Essentially, client hints aim at more effective and privacy-friendly disclosure of browser or client properties than the user agent string.\n  We present a first long-term study of the use of HTTP client hints in the wild. We found that despite being implemented in almost all web browsers, server-side usage of client hints remains generally low. However, in the context of third-party websites, which are often linked to trackers, the adoption rate is significantly higher. This is concerning because client hints allow the retrieval of more data from the client than the user agent string provides, and there are currently no mechanisms for users to detect or control this potential data leakage. Our work provides valuable insights for web users, browser vendors, and researchers by exposing potential privacy violations via client hints and providing help in developing remediation strategies as well as further research."}, "https://arxiv.org/abs/2405.14043": {"title": "Attitudes Towards Migration in a COVID-19 Context: Testing a Behavioral Immune System Hypothesis with Twitter Data", "link": "https://arxiv.org/abs/2405.14043", "description": "arXiv:2405.14043v1 Announce Type: cross \nAbstract: The COVID-19 outbreak implied many changes in the daily life of most of the world's population for a long time, prompting severe restrictions on sociality. The Behavioral Immune System (BIS) suggests that when facing pathogens, a psychological mechanism would be activated that, among other things, would generate an increase in prejudice and discrimination towards marginalized groups, including immigrants. This study aimed to test if people tend to enhance their rejection of minorities and foreign groups under the threat of contagious diseases, using the users' attitudes towards migrants in Twitter data from Chile, for pre-pandemic and pandemic contexts. Our results only partially support the BIS hypothesis, since threatened users increased their tweet production in the pandemic period, compared to empathetic users, but the latter grew in number and also increased the reach of their tweets between the two periods. We also found differences in the use of language between these types of users. Alternative explanations for these results may be context-dependent."}, "https://arxiv.org/abs/2405.14403": {"title": "Representative electricity price profiles for European day-ahead and intraday spot markets", "link": "https://arxiv.org/abs/2405.14403", "description": "arXiv:2405.14403v1 Announce Type: cross \nAbstract: We propose a method to construct representative price profiles of the day-ahead (DA) and the intraday (ID) electricity spot markets and use this method to provide examples of ready-to-use price data sets. In contrast to common scenario generation approaches, the method is deterministic and relies on a small number of degrees of freedom, with the aim to be well defined and easy to use. We thereby target an enhanced comparability of future research studies on demand-side management and energy cost optimization. We construct the price profiles based on historical time series from the spot markets of interest, e.g., European Power Exchange (EPEX) spot. To this end, we extract key price components from the data while also accounting for known dominant mechanisms in the price variation. Further, the method is able to preserve key statistical features of the historical data (e.g., mean and standard deviation) when constructing the benchmark profile. Finally, our approach ensures comparability of ID and DA price profiles by design, as their cumulative (integral) price can be made identical if needed."}, "https://arxiv.org/abs/2405.14761": {"title": "Effective & Ethical Mentorship in Physics and Astronomy through Grassroots Organizations", "link": "https://arxiv.org/abs/2405.14761", "description": "arXiv:2405.14761v1 Announce Type: cross \nAbstract: Effective and ethical mentorship practices are crucial to improving recruitment and retention especially for historically minoritized groups (HMGs). Spectrum is a diversity, inclusion, equity, and accessibility (DEIA) grassroots organization committed to empowering equitable excellence through sustainable change. By improving transparency and DEIA within the fields of physics and astronomy, we can empower the next generation of diverse scientists and increase field retention. Starting within our home department at George Mason University and moving outwards, we ensure our students leave as advocates for DEIA and AJEDI (access, justice, equity, diversity, and inclusion) through education and mentorship. Spectrum is providing professionally trained peer mentors to aid students in all facets of their academic and personal lives. Although the peer mentoring program existed since the creation of Spectrum in Spring 2020, we have recently developed and implemented a formal mentorship training for both student and faculty mentors thus increasing the quality, trustworthiness, and confidence of our mentors. Using the latest mentorship research available, this training is developed by Spectrum for George Mason University, with the ability to implement the training at any institution."}, "https://arxiv.org/abs/2108.01727": {"title": "Scalable Community Detection in Massive Networks Using Aggregated Relational Data", "link": "https://arxiv.org/abs/2108.01727", "description": "arXiv:2108.01727v3 Announce Type: replace \nAbstract: The mixed membership stochastic blockmodel (MMSB) is a popular Bayesian network model for community detection. Fitting such large Bayesian network models quickly becomes computationally infeasible when the number of nodes grows into hundreds of thousands and millions. In this paper we propose a novel mini-batch strategy based on aggregated relational data that leverages nodal information to fit MMSB to massive networks. We describe a scalable inference method that can utilize nodal information that often accompanies real-world networks. Conditioning on this extra information leads to a model that admits a parallel stochastic variational inference algorithm, utilizing stochastic gradients of bipartite graph formed from aggregated network ties between node subpopulations. We apply our method to a citation network with over two million nodes and 25 million edges, capturing explainable structure in this network. Our method recovers parameters and achieves better convergence on simulated networks generated according to the MMSB."}, "https://arxiv.org/abs/2401.08539": {"title": "Mapping low-resolution edges to high-resolution paths: the case of traffic measurements in cities", "link": "https://arxiv.org/abs/2401.08539", "description": "arXiv:2401.08539v2 Announce Type: replace \nAbstract: We consider the following problem : we have a high-resolution street network of a given city, and low-resolution measurements of traffic within this city. We want to associate to each measurement the set of streets corresponding to the observed traffic. To do so, we take benefit of specific properties of these data to match measured links to links in the street network. We propose several success criteria for the obtained matching. They show that the matching algorithm generally performs very well, and they give complementary ways to detect data discrepancies that makes any matching highly dubious."}, "https://arxiv.org/abs/2401.09647": {"title": "Large Language Models Help Reveal Unhealthy Diet and Body Concerns in Online Eating Disorders Communities", "link": "https://arxiv.org/abs/2401.09647", "description": "arXiv:2401.09647v2 Announce Type: replace \nAbstract: Eating disorders (ED), a severe mental health condition with high rates of mortality and morbidity, affect millions of people globally, especially adolescents. The proliferation of online communities that promote and normalize ED has been linked to this public health crisis. However, identifying harmful communities is challenging due to the use of coded language and other obfuscations. To address this challenge, we propose a novel framework to surface implicit attitudes of online communities by adapting large language models (LLMs) to the language of the community. We describe an alignment method and evaluate results along multiple dimensions of semantics and affect. We then use the community-aligned LLM to respond to psychometric questionnaires designed to identify ED in individuals. We demonstrate that LLMs can effectively adopt community-specific perspectives and reveal significant variations in eating disorder risks in different online communities. These findings highlight the utility of LLMs to reveal implicit attitudes and collective mindsets of communities, offering new tools for mitigating harmful content on social media."}, "https://arxiv.org/abs/2401.16504": {"title": "Effect of recommending users and opinions on the network connectivity and idea generation process", "link": "https://arxiv.org/abs/2401.16504", "description": "arXiv:2401.16504v2 Announce Type: replace \nAbstract: The growing reliance on online services underscores the crucial role of recommendation systems, especially on social media platforms seeking increased user engagement. This study investigates how recommendation systems influence the impact of personal behavioral traits on social network dynamics. It explores the interplay between homophily, users' openness to novel ideas, and recommendation-driven exposure to new opinions. Additionally, the research examines the impact of recommendation systems on the diversity of newly generated ideas, shedding light on the challenges and opportunities in designing effective systems that balance the exploration of new ideas with the risk of reinforcing biases or filtering valuable, unconventional concepts."}, "https://arxiv.org/abs/2402.19157": {"title": "Broken detailed balance and entropy production in directed networks", "link": "https://arxiv.org/abs/2402.19157", "description": "arXiv:2402.19157v3 Announce Type: replace \nAbstract: The structure of a complex network plays a crucial role in determining its dynamical properties. In this work, we show that the the degree to which a network is directed and hierarchically organised is closely associated with the degree to which its dynamics break detailed balance and produce entropy. We consider a range of dynamical processes and show how different directed network features affect their entropy production rate. We begin with an analytical treatment of a 2-node network followed by numerical simulations of synthetic networks using the preferential attachment and Erd\\\"os-Renyi algorithms. Next, we analyse a collection of 97 empirical networks to determine the effect of complex real-world topologies. Finally, we present a simple method for inferring broken detailed balance and directed network structure from multivariate time-series and apply our method to identify non-equilibrium dynamics and hierarchical organisation in both human neuroimaging and financial time-series. Overall, our results shed light on the consequences of directed network structure on non-equilibrium dynamics and highlight the importance and ubiquity of hierarchical organisation and non-equilibrium dynamics in real-world systems."}, "https://arxiv.org/abs/2404.00754": {"title": "Imitation dynamics and the replicator equation", "link": "https://arxiv.org/abs/2404.00754", "description": "arXiv:2404.00754v2 Announce Type: replace \nAbstract: Evolutionary game theory has impacted many fields of research by providing a mathematical framework for studying the evolution and maintenance of social and moral behaviors. This success is owed in large part to the demonstration that the central equation of this theory - the replicator equation - is the deterministic limit of a stochastic imitation (social learning) dynamics. Here we offer an alternative elementary proof of this result, which holds for the scenario where players compare their instantaneous (not average) payoffs to decide whether to maintain or change their strategies, and only more successful individuals can be imitated."}, "https://arxiv.org/abs/2404.04307": {"title": "PREDIS-MHI Thermal Data", "link": "https://arxiv.org/abs/2404.04307", "description": "arXiv:2404.04307v2 Announce Type: replace \nAbstract: Tertiary buildings could be an important lever to meet the goals necessitated by the energy transition. The availability of high-quality datasets from this sector will be a crucial enabler in meeting these goals by developing and testing new energy management approaches in the buildings. In this paper, we present the thermal energy datasets available and published online for the PREDIS-MHI zone of the GreEn-ER building, a tertiary building with more than a thousand sensors used for research, teaching, and administrative activities in Grenoble. PREDIS-MHI platform is a net-zero sub-section that is energetically isolated from the rest of the building. Its data has been used in a wide range of applications from indoor temperature forecasting, thermal simulation calibration, and even occupant comfort experiments"}, "https://arxiv.org/abs/2404.11465": {"title": "X-posing Free Speech: Examining the Impact of Moderation Relaxation on Online Social Networks", "link": "https://arxiv.org/abs/2404.11465", "description": "arXiv:2404.11465v2 Announce Type: replace \nAbstract: We investigate the impact of free speech and the relaxation of moderation on online social media platforms using Elon Musk's takeover of Twitter as a case study. By curating a dataset of over 10 million tweets, our study employs a novel framework combining content and network analysis. Our findings reveal a significant increase in the distribution of certain forms of hate content, particularly targeting the LGBTQ+ community and liberals. Network analysis reveals the formation of cohesive hate communities facilitated by influential bridge users, with substantial growth in interactions hinting at increased hate production and diffusion. By tracking the temporal evolution of PageRank, we identify key influencers, primarily self-identified far-right supporters disseminating hate against liberals and woke culture. Ironically, embracing free speech principles appears to have enabled hate speech against the very concept of freedom of expression and free speech itself. Our findings underscore the delicate balance platforms must strike between open expression and robust moderation to curb the proliferation of hate online."}, "https://arxiv.org/abs/2405.02856": {"title": "A tale of two emergent games: opinion dynamics in dynamical directed networks", "link": "https://arxiv.org/abs/2405.02856", "description": "arXiv:2405.02856v2 Announce Type: replace \nAbstract: Uni-directional social interactions are ubiquitous in real social networks whereas undirected interactions are intensively studied. We establish a voter model in a dynamical directed network. We analytically obtain the degree distribution of the evolving network at any given time. Furthermore, we find that the average degree is captured by an emergent game. On the other hand, we find that the fate of opinions is captured by another emergent game. Beyond expectation, the two emergent games are typically different due to the unidirectionality of the evolving networks. The Nash equilibrium analysis of the two games facilitates us to give the criterion under which the minority opinion with few disciples initially takes over the population eventually for in-group bias. Our work fosters the understanding of opinion dynamics ranging from methodology to research content."}, "https://arxiv.org/abs/2204.04510": {"title": "Translating Subgraphs to Nodes Makes Simple GNNs Strong and Efficient for Subgraph Representation Learning", "link": "https://arxiv.org/abs/2204.04510", "description": "arXiv:2204.04510v4 Announce Type: replace-cross \nAbstract: Subgraph representation learning has emerged as an important problem, but it is by default approached with specialized graph neural networks on a large global graph. These models demand extensive memory and computational resources but challenge modeling hierarchical structures of subgraphs. In this paper, we propose Subgraph-To-Node (S2N) translation, a novel formulation for learning representations of subgraphs. Specifically, given a set of subgraphs in the global graph, we construct a new graph by coarsely transforming subgraphs into nodes. Demonstrating both theoretical and empirical evidence, S2N not only significantly reduces memory and computational costs compared to state-of-the-art models but also outperforms them by capturing both local and global structures of the subgraph. By leveraging graph coarsening methods, our method outperforms baselines even in a data-scarce setting with insufficient subgraphs. Our experiments on eight benchmarks demonstrate that fined-tuned models with S2N translation can process 183 -- 711 times more subgraph samples than state-of-the-art models at a better or similar performance level."}, "https://arxiv.org/abs/2301.10960": {"title": "Visiting Distant Neighbors in Graph Convolutional Networks", "link": "https://arxiv.org/abs/2301.10960", "description": "arXiv:2301.10960v3 Announce Type: replace-cross \nAbstract: We extend the graph convolutional network method for deep learning on graph data to higher order in terms of neighboring nodes. In order to construct representations for a node in a graph, in addition to the features of the node and its immediate neighboring nodes, we also include more distant nodes in the calculations. In experimenting with a number of publicly available citation graph datasets, we show that this higher order neighbor visiting pays off by outperforming the original model especially when we have a limited number of available labeled data points for the training of the model."}, "https://arxiv.org/abs/2311.06840": {"title": "Omitted Labels in Causality: A Study of Paradoxes", "link": "https://arxiv.org/abs/2311.06840", "description": "arXiv:2311.06840v3 Announce Type: replace-cross \nAbstract: We explore what we call ``omitted label contexts,'' in which training data is limited to a subset of the possible labels. This setting is common among specialized human experts or specific focused studies. We lean on well-studied paradoxes (Simpson's and Condorcet) to illustrate the more general difficulties of causal inference in omitted label contexts. Contrary to the fundamental principles on which much of causal inference is built, we show that ``correct'' adjustments sometimes require non-exchangeable treatment and control groups. These pitfalls lead us to the study networks of conclusions drawn from different contexts and the structures the form, proving an interesting connection between these networks and social choice theory."}, "https://arxiv.org/abs/2312.09041": {"title": "Graph Neural Networks with Diverse Spectral Filtering", "link": "https://arxiv.org/abs/2312.09041", "description": "arXiv:2312.09041v3 Announce Type: replace-cross \nAbstract: Spectral Graph Neural Networks (GNNs) have achieved tremendous success in graph machine learning, with polynomial filters applied for graph convolutions, where all nodes share the identical filter weights to mine their local contexts. Despite the success, existing spectral GNNs usually fail to deal with complex networks (e.g., WWW) due to such homogeneous spectral filtering setting that ignores the regional heterogeneity as typically seen in real-world networks. To tackle this issue, we propose a novel diverse spectral filtering (DSF) framework, which automatically learns node-specific filter weights to exploit the varying local structure properly. Particularly, the diverse filter weights consist of two components -- A global one shared among all nodes, and a local one that varies along network edges to reflect node difference arising from distinct graph parts -- to balance between local and global information. As such, not only can the global graph characteristics be captured, but also the diverse local patterns can be mined with awareness of different node positions. Interestingly, we formulate a novel optimization problem to assist in learning diverse filters, which also enables us to enhance any spectral GNNs with our DSF framework. We showcase the proposed framework on three state-of-the-arts including GPR-GNN, BernNet, and JacobiConv. Extensive experiments over 10 benchmark datasets demonstrate that our framework can consistently boost model performance by up to 4.92% in node classification tasks, producing diverse filters with enhanced interpretability. Code is available at \\url{https://github.com/jingweio/DSF}."}, "https://arxiv.org/abs/2403.15855": {"title": "Initialisation and Topology Effects in Decentralised Federated Learning", "link": "https://arxiv.org/abs/2403.15855", "description": "arXiv:2403.15855v2 Announce Type: replace-cross \nAbstract: Fully decentralised federated learning enables collaborative training of individual machine learning models on distributed devices on a communication network while keeping the training data localised. This approach enhances data privacy and eliminates both the single point of failure and the necessity for central coordination. Our research highlights that the effectiveness of decentralised federated learning is significantly influenced by the network topology of connected devices. We propose a strategy for uncoordinated initialisation of the artificial neural networks, which leverages the distribution of eigenvector centralities of the nodes of the underlying communication network, leading to a radically improved training efficiency. Additionally, our study explores the scaling behaviour and choice of environmental parameters under our proposed initialisation strategy. This work paves the way for more efficient and scalable artificial neural network training in a distributed and uncoordinated environment, offering a deeper understanding of the intertwining roles of network structure and learning dynamics."}, "https://arxiv.org/abs/2405.14884": {"title": "The story around the first 4n signal", "link": "https://arxiv.org/abs/2405.14884", "description": "arXiv:2405.14884v1 Announce Type: new \nAbstract: The GANIL campaign around the first 4n signal was very peculiar. The beginning and end were both dictated by unexpected events that, unfortunately, do not fit within the streamlined format of standard scientific publications. However, they illustrate many aspects of how basic research should work, or at least does work. Therefore, I take this opportunity to share them with those not involved in the campaign, hoping that they will offer a better perspective of that research in particular and of basic research in general. As a disclaimer, this is only a personal recollection of those events."}, "https://arxiv.org/abs/2405.14902": {"title": "Global urban activity changes from COVID-19 physical distancing restrictions", "link": "https://arxiv.org/abs/2405.14902", "description": "arXiv:2405.14902v1 Announce Type: new \nAbstract: During the COVID-19 pandemic changes in human activity became widespread through official policies and organically in response to the virus's transmission, which in turn, impacted the environment and the economy. The pandemic has been described as a natural experiment that tested how social and economic disruptions impacted different components of the global Earth System. To move this beyond hypotheses, locally-resolved, globally-available measures of how, where, and when human activity changed are critically needed. Here we use satellite-derived nighttime lights to quantify and map daily changes in human activity that are atypical for each urban area globally for two years after the onset of the pandemic using machine learning anomaly detectors. Metrics characterizing changes in lights from pre-COVID baseline in human settlements and quality assurance measures are reported. This dataset, TRacking Anomalous COVID-19 induced changEs in NTL (TRACE-NTL), is the first to resolve COVID-19 disruptions for all metropolitan regions globally, daily. It is suitable to support a variety of post-pandemic studies that assess how changes in human activity impact environmental systems."}, "https://arxiv.org/abs/2405.14985": {"title": "Implicit degree bias in the link prediction task", "link": "https://arxiv.org/abs/2405.14985", "description": "arXiv:2405.14985v1 Announce Type: new \nAbstract: Link prediction -- a task of distinguishing actual hidden edges from random unconnected node pairs -- is one of the quintessential tasks in graph machine learning. Despite being widely accepted as a universal benchmark and a downstream task for representation learning, the validity of the link prediction benchmark itself has been rarely questioned. Here, we show that the common edge sampling procedure in the link prediction task has an implicit bias toward high-degree nodes and produces a highly skewed evaluation that favors methods overly dependent on node degree, to the extent that a ``null'' link prediction method based solely on node degree can yield nearly optimal performance. We propose a degree-corrected link prediction task that offers a more reasonable assessment that aligns better with the performance in the recommendation task. Finally, we demonstrate that the degree-corrected benchmark can more effectively train graph machine-learning models by reducing overfitting to node degrees and facilitating the learning of relevant structures in graphs."}, "https://arxiv.org/abs/2405.15498": {"title": "Node Accessibility Characterization of Radially-Grown Structures", "link": "https://arxiv.org/abs/2405.15498", "description": "arXiv:2405.15498v1 Announce Type: new \nAbstract: Complex systems have motivated continuing interest from the scientific community, leading to new concepts and methods. Growing systems represent a case of particular interest, as their topological, geometrical, and also dynamical properties change along time, as new elements are incorporated into the existing structure. In the present work, an approach is the case in which systems grown radially around some straight axis of reference, such as particle deposition on electrodes, or urban expansion along avenues, roads, coastline, or rivers, among several other possibilities. More specifically, we aim at characterizing the topological properties of simulated growing structures, which are represented as graphs, in terms of a measurement corresponding to the accessibility of each involved node. The incorporation of new elements (nodes and links) is performed preferentially to the angular orientation respectively to the reference axis. Several interesting results are reported, including the tendency of structures grown preferentially to the orientation normal to the axis to have smaller accessibility."}, "https://arxiv.org/abs/2405.15473": {"title": "Encoder Embedding for General Graph and Node Classification", "link": "https://arxiv.org/abs/2405.15473", "description": "arXiv:2405.15473v1 Announce Type: cross \nAbstract: Graph encoder embedding, a recent technique for graph data, offers speed and scalability in producing vertex-level representations from binary graphs. In this paper, we extend the applicability of this method to a general graph model, which includes weighted graphs, distance matrices, and kernel matrices. We prove that the encoder embedding satisfies the law of large numbers and the central limit theorem on a per-observation basis. Under certain condition, it achieves asymptotic normality on a per-class basis, enabling optimal classification through discriminant analysis. These theoretical findings are validated through a series of experiments involving weighted graphs, as well as text and image data transformed into general graph representations using appropriate distance metrics."}, "https://arxiv.org/abs/2405.15739": {"title": "Large Language Models Reflect Human Citation Patterns with a Heightened Citation Bias", "link": "https://arxiv.org/abs/2405.15739", "description": "arXiv:2405.15739v1 Announce Type: cross \nAbstract: Citation practices are crucial in shaping the structure of scientific knowledge, yet they are often influenced by contemporary norms and biases. The emergence of Large Language Models (LLMs) like GPT-4 introduces a new dynamic to these practices. Interestingly, the characteristics and potential biases of references recommended by LLMs that entirely rely on their parametric knowledge, and not on search or retrieval-augmented generation, remain unexplored. Here, we analyze these characteristics in an experiment using a dataset of 166 papers from AAAI, NeurIPS, ICML, and ICLR, published after GPT-4's knowledge cut-off date, encompassing 3,066 references in total. In our experiment, GPT-4 was tasked with suggesting scholarly references for the anonymized in-text citations within these papers. Our findings reveal a remarkable similarity between human and LLM citation patterns, but with a more pronounced high citation bias in GPT-4, which persists even after controlling for publication year, title length, number of authors, and venue. Additionally, we observe a large consistency between the characteristics of GPT-4's existing and non-existent generated references, indicating the model's internalization of citation patterns. By analyzing citation graphs, we show that the references recommended by GPT-4 are embedded in the relevant citation context, suggesting an even deeper conceptual internalization of the citation networks. While LLMs can aid in citation generation, they may also amplify existing biases and introduce new ones, potentially skewing scientific knowledge dissemination. Our results underscore the need for identifying the model's biases and for developing balanced methods to interact with LLMs in general."}, "https://arxiv.org/abs/2311.10837": {"title": "Evaluating the Relationship Between News Source Sharing and Political Beliefs", "link": "https://arxiv.org/abs/2311.10837", "description": "arXiv:2311.10837v2 Announce Type: replace \nAbstract: In an era marked by an abundance of news sources, access to information significantly influences public opinion. Notably, the bias of news sources often serves as an indicator of individuals' political leanings. This study explores this hypothesis by examining the news sharing behavior of politically active social media users, whose political ideologies were identified in a previous study. Using correspondence analysis, we estimate the Media Sharing Index (MSI), a measure that captures bias in media outlets and user preferences within a hidden space. During Argentina's 2019 election on Twitter, we observed a predictable pattern: center-right individuals predominantly shared media from center-right biased outlets. However, it is noteworthy that those with center-left inclinations displayed a more diverse media consumption, which is a significant finding. Despite a noticeable polarization based on political affiliation observed in a retweet network analysis, center-left users showed more diverse media sharing preferences, particularly concerning the MSI. Although these findings are specific to Argentina, the developed methodology can be applied in other countries to assess the correlation between users' political leanings and the media they share."}, "https://arxiv.org/abs/2302.00360": {"title": "Faster maximal clique enumeration in large real-world link streams", "link": "https://arxiv.org/abs/2302.00360", "description": "arXiv:2302.00360v3 Announce Type: replace-cross \nAbstract: Link streams offer a good model for representing interactions over time. They consist of links $(b,e,u,v)$, where $u$ and $v$ are vertices interacting during the whole time interval $[b,e]$. In this paper, we deal with the problem of enumerating maximal cliques in link streams. A clique is a pair $(C,[t_0,t_1])$, where $C$ is a set of vertices that all interact pairwise during the full interval $[t_0,t_1]$. It is maximal when neither its set of vertices nor its time interval can be increased. Some of the main works solving this problem are based on the famous Bron-Kerbosch algorithm for enumerating maximal cliques in graphs. We take this idea as a starting point to propose a new algorithm which matches the cliques of the instantaneous graphs formed by links existing at a given time $t$ to the maximal cliques of the link stream. We prove its validity and compute its complexity, which is better than the state-of-the art ones in many cases of interest. We also study the output-sensitive complexity, which is close to the output size, thereby showing that our algorithm is efficient. To confirm this, we perform experiments on link streams used in the state of the art, and on massive link streams, up to 100 million links. In all cases our algorithm is faster, mostly by a factor of at least 10 and up to a factor of $10^4$. Moreover, it scales to massive link streams for which the existing algorithms are not able to provide the solution."}, "https://arxiv.org/abs/2403.04679": {"title": "Canadian Physics Counts: An exploration of the diverse identities of physics students and professionals in Canada", "link": "https://arxiv.org/abs/2403.04679", "description": "arXiv:2403.04679v2 Announce Type: replace-cross \nAbstract: The lack of diversity in physics remains a persistent worldwide problem. Despite being a quantitative discipline which relies on measurements to construct and validate hypotheses, there remains a paucity of data on both demographics and experiences of marginalized groups. In Canada, there has never been a nationwide assessment of those studying or working in physics. Here, we present findings from Canadian Physics Counts: the first national survey of equity, diversity, and inclusion (EDI) in the Canadian physics community. Our intersectional approach allowed us to gather a wealth of information on gender identity, sexual orientation, race, disability, and more. Analyses revealed key findings, including the first data on physicists who identify as non-binary or gender diverse, as well as the first data on Black and Indigenous scholars. Black physicists (1.2%) and Indigenous physicists (.3%) were found to be the most underrepresented, while White men were overrepresented across all sectors. Among respondents with a disability, 5% reported receiving full accommodations for their required needs at their place of work or study. One in four respondents from BIPOC gender diverse backgrounds identified as being disabled, and the proportion of sexually diverse students who reported having a disability was more than three times higher than the proportion of heterosexual students with a disability. The data also revealed that students represented more demographic diversity than working professionals, highlighting the importance of acting today in order to retain the diverse physicists of tomorrow. Our analysis identifies areas for intervention and offers recommendations for building a diverse and inclusive physics community in Canada that can be a global exemplar."}, "https://arxiv.org/abs/2404.01679": {"title": "Event Detection from Social Media for Epidemic Prediction", "link": "https://arxiv.org/abs/2404.01679", "description": "arXiv:2404.01679v2 Announce Type: replace-cross \nAbstract: Social media is an easy-to-access platform providing timely updates about societal trends and events. Discussions regarding epidemic-related events such as infections, symptoms, and social interactions can be crucial for informing policymaking during epidemic outbreaks. In our work, we pioneer exploiting Event Detection (ED) for better preparedness and early warnings of any upcoming epidemic by developing a framework to extract and analyze epidemic-related events from social media posts. To this end, we curate an epidemic event ontology comprising seven disease-agnostic event types and construct a Twitter dataset SPEED with human-annotated events focused on the COVID-19 pandemic. Experimentation reveals how ED models trained on COVID-based SPEED can effectively detect epidemic events for three unseen epidemics of Monkeypox, Zika, and Dengue; while models trained on existing ED datasets fail miserably. Furthermore, we show that reporting sharp increases in the extracted events by our framework can provide warnings 4-9 weeks earlier than the WHO epidemic declaration for Monkeypox. This utility of our framework lays the foundations for better preparedness against emerging epidemics."}, "https://arxiv.org/abs/2405.04428": {"title": "BBK: a simpler, faster algorithm for enumerating maximal bicliques in large sparse bipartite graphs", "link": "https://arxiv.org/abs/2405.04428", "description": "arXiv:2405.04428v2 Announce Type: replace-cross \nAbstract: Bipartite graphs are a prevalent modeling tool for real-world networks, capturing interactions between vertices of two different types. Within this framework, bicliques emerge as crucial structures when studying dense subgraphs: they are sets of vertices such that all vertices of the first type interact with all vertices of the second type. Therefore, they allow identifying groups of closely related vertices of the network, such as individuals with similar interests or webpages with similar contents. This article introduces a new algorithm designed for the exhaustive enumeration of maximal bicliques within a bipartite graph. This algorithm, called BBK for Bipartite Bron-Kerbosch, is a new extension to the bipartite case of the Bron-Kerbosch algorithm, which enumerates the maximal cliques in standard (non-bipartite) graphs. It is faster than the state-of-the-art algorithms and allows the enumeration on massive bipartite graphs that are not manageable with existing implementations. We analyze it theoretically to establish two complexity formulas: one as a function of the input and one as a function of the output characteristics of the algorithm. We also provide an open-access implementation of BBK in C++, which we use to experiment and validate its efficiency on massive real-world datasets and show that its execution time is shorter in practice than state-of-the art algorithms. These experiments also show that the order in which the vertices are processed, as well as the choice of one of the two types of vertices on which to initiate the enumeration have an impact on the computation time."}, "https://arxiv.org/abs/2405.15838": {"title": "What You Shouldn't Know About Quantum Computers", "link": "https://arxiv.org/abs/2405.15838", "description": "arXiv:2405.15838v1 Announce Type: new \nAbstract: Whether you're a CEO strategizing the future of your company, a tech enthusiast debating your next career move, a high school teacher eager to enlighten your students, or simply tired of the relentless quantum hype, this is crafted just for you. Cutting through the complex jargon to deliver the straight facts on quantum computing, peeling away the layers of mystique to reveal the true potential and limitations of this groundbreaking technology. Prepare to have your misconceptions challenged, and your understanding deepened in this clear-eyed view of the quantum future, written to inform and inspire readers across the spectrum of curiosity and need."}, "https://arxiv.org/abs/2405.15893": {"title": "Quantifying Influencer Effects on Affective Polarization", "link": "https://arxiv.org/abs/2405.15893", "description": "arXiv:2405.15893v1 Announce Type: new \nAbstract: In an era where digital platforms increasingly mediate public discourse, grasping the complexities and nuances in affective polarization--especially as influenced by key figures on social media--has never been more vital. This study delves into the intricate web of interactions on Twitter, now rebranded as 'X', to unravel how influencer-led conversations catalyze shifts in public sentiment, laying bare the complex dynamics that underpin online polarization. Employing a novel methodological framework that includes counterfactual analysis, we analyze scenarios with and without specific influencer-led conversations. Our findings illuminate the significant role influencers play in shaping public discourse, offering insights into the mechanisms of online polarization and suggesting pathways for future research to mitigate divisiveness and explore new methods for quantifying affective polarization. This research contributes to the broader understanding of digital communication's impact on societal polarization, underscoring the importance of detailed analysis in developing strategies to foster a more cohesive digital public sphere."}, "https://arxiv.org/abs/2405.15930": {"title": "ArguSense: Argument-Centric Analysis of Online Discourse", "link": "https://arxiv.org/abs/2405.15930", "description": "arXiv:2405.15930v1 Announce Type: new \nAbstract: How can we model arguments and their dynamics in online forum discussions? The meteoric rise of online forums presents researchers across different disciplines with an unprecedented opportunity: we have access to texts containing discourse between groups of users generated in a voluntary and organic fashion. Most prior work so far has focused on classifying individual monological comments as either argumentative or not argumentative. However, few efforts quantify and describe the dialogical processes between users found in online forum discourse: the structure and content of interpersonal argumentation. Modeling dialogical discourse requires the ability to identify the presence of arguments, group them into clusters, and summarize the content and nature of clusters of arguments within a discussion thread in the forum. In this work, we develop ArguSense, a comprehensive and systematic framework for understanding arguments and debate in online forums. Our framework consists of methods for, among other things: (a) detecting argument topics in an unsupervised manner; (b) describing the structure of arguments within threads with powerful visualizations; and (c) quantifying the content and diversity of threads using argument similarity and clustering algorithms. We showcase our approach by analyzing the discussions of four communities on the Reddit platform over a span of 21 months. Specifically, we analyze the structure and content of threads related to GMOs in forums related to agriculture or farming to demonstrate the value of our framework."}, "https://arxiv.org/abs/2405.16059": {"title": "Interpretable Transformer Hawkes Processes: Unveiling Complex Interactions in Social Networks", "link": "https://arxiv.org/abs/2405.16059", "description": "arXiv:2405.16059v1 Announce Type: new \nAbstract: Social networks represent complex ecosystems where the interactions between users or groups play a pivotal role in information dissemination, opinion formation, and social interactions. Effectively harnessing event sequence data within social networks to unearth interactions among users or groups has persistently posed a challenging frontier within the realm of point processes. Current deep point process models face inherent limitations within the context of social networks, constraining both their interpretability and expressive power. These models encounter challenges in capturing interactions among users or groups and often rely on parameterized extrapolation methods when modelling intensity over non-event intervals, limiting their capacity to capture intricate intensity patterns, particularly beyond observed events. To address these challenges, this study proposes modifications to Transformer Hawkes processes (THP), leading to the development of interpretable Transformer Hawkes processes (ITHP). ITHP inherits the strengths of THP while aligning with statistical nonlinear Hawkes processes, thereby enhancing its interpretability and providing valuable insights into interactions between users or groups. Additionally, ITHP enhances the flexibility of the intensity function over non-event intervals, making it better suited to capture complex event propagation patterns in social networks. Experimental results, both on synthetic and real data, demonstrate the effectiveness of ITHP in overcoming the identified limitations. Moreover, they highlight ITHP's applicability in the context of exploring the complex impact of users or groups within social networks."}, "https://arxiv.org/abs/2405.16100": {"title": "Congestion transition on random walks on graphs", "link": "https://arxiv.org/abs/2405.16100", "description": "arXiv:2405.16100v1 Announce Type: new \nAbstract: The congestion formation on a urban road network is one of the key issue for the development of a sustainable mobility in the future smart cities. In this work we propose a reductionist approach studying the stationary states of a simple transport model using of a random process on a graph, where each node represents a location and the weight links give the transition rates to move from one node to another that represent the mobility demand. Each node has a finite transport capacity and a maximum load capacity and we assume that the average. In the approximation of the single step process we are able to analytically characterize the traffic load distribution on the single nodes, using a local Maximum Entropy Principle. Our results explain how the congested nodes emerge when the total traffic load increases in analogous way to a percolation transition where the appearance of a congested node is a independent random event, However, using numerical simulations, we show that in the more realistic case of the synchronous dynamics for the nodes, there are entropic forces that introduce correlation among the node state and favor the clustering of the empty and congested nodes. Our aim is to highlight universal properties of the congestion formation and, in particular, to understand the role traffic load fluctuations as a possible precursor of congestion in a transport network."}, "https://arxiv.org/abs/2405.16352": {"title": "Quantifying Multipolar Polarization", "link": "https://arxiv.org/abs/2405.16352", "description": "arXiv:2405.16352v1 Announce Type: new \nAbstract: Studying and understanding social networks is crucial for accurately defining ideological polarization, since they enable precise modeling of social structures. One of the limitations of many methods for quantifying polarization on networks is the assumption of a two-dimensional opinion space. This prevents accurate study of multipolar systems like multi-party political systems, where modeling more than two opinion poles is beneficial. Here, I experimentally compare methods for quantifying multipolar polarization on a network, and find that the average pairwise distance extension of generalized Euclidean distance conforms to several desired properties, showing its advantages over other methods. This allows study of multipolar polarized systems based on an empirically and intuitively good metric."}, "https://arxiv.org/abs/2405.16606": {"title": "Link Prediction on Textual Edge Graphs", "link": "https://arxiv.org/abs/2405.16606", "description": "arXiv:2405.16606v1 Announce Type: new \nAbstract: Textual-edge Graphs (TEGs), characterized by rich text annotations on edges, are increasingly significant in network science due to their ability to capture rich contextual information among entities. Existing works have proposed various edge-aware graph neural networks (GNNs) or let language models directly make predictions. However, they often fall short of fully capturing the contextualized semantics on edges and graph topology, respectively. This inadequacy is particularly evident in link prediction tasks that require a comprehensive understanding of graph topology and semantics between nodes. In this paper, we present a novel framework - Link2Doc, designed especially for link prediction on textual-edge graphs. Specifically, we propose to summarize neighborhood information between node pairs as a human-written document to preserve both semantic and topology information. A self-supervised learning model is then utilized to enhance GNN's text-understanding ability from language models. Empirical evaluations, including link prediction, edge classification, parameter analysis, runtime comparison, and ablation studies, on four real-world datasets demonstrate that Link2Doc achieves generally better performance against existing edge-aware GNNs and pre-trained language models in predicting links on TEGs."}, "https://arxiv.org/abs/2405.16772": {"title": "Balancing User Preferences by Social Networks: A Condition-Guided Social Recommendation Model for Mitigating Popularity Bias", "link": "https://arxiv.org/abs/2405.16772", "description": "arXiv:2405.16772v1 Announce Type: new \nAbstract: Social recommendation models weave social interactions into their design to provide uniquely personalized recommendation results for users. However, social networks not only amplify the popularity bias in recommendation models, resulting in more frequent recommendation of hot items and fewer long-tail items, but also include a substantial amount of redundant information that is essentially meaningless for the model's performance. Existing social recommendation models fail to address the issues of popularity bias and the redundancy of social information, as they directly characterize social influence across the entire social network without making targeted adjustments. In this paper, we propose a Condition-Guided Social Recommendation Model (named CGSoRec) to mitigate the model's popularity bias by denoising the social network and adjusting the weights of user's social preferences. More specifically, CGSoRec first includes a Condition-Guided Social Denoising Model (CSD) to remove redundant social relations in the social network for capturing users' social preferences with items more precisely. Then, CGSoRec calculates users' social preferences based on denoised social network and adjusts the weights in users' social preferences to make them can counteract the popularity bias present in the recommendation model. At last, CGSoRec includes a Condition-Guided Diffusion Recommendation Model (CGD) to introduce the adjusted social preferences as conditions to control the recommendation results for a debiased direction. Comprehensive experiments on three real-world datasets demonstrate the effectiveness of our proposed method. The code is in: https://github.com/hexin5515/CGSoRec."}, "https://arxiv.org/abs/2405.16913": {"title": "Chasing the eternal sun: Does a global super grid favor the deployment of solar power?", "link": "https://arxiv.org/abs/2405.16913", "description": "arXiv:2405.16913v1 Announce Type: new \nAbstract: The One Sun One World One Grid (OSOWOG) initiative advocates the development of a global Super grid for sharing renewable energy, especially solar energy. This study evaluates the economic benefits of such a Super grid, which connects six large regions spanning from Australia to the US, utilizing a detailed energy system optimization model and considering heterogeneous discount rates among countries. Integrating the six regions into a Super grid reduces the electricity system cost by 3.8% compared to isolating them. In contrast, grid expansion within each region reduces the electricity system cost by 12% on average. The economic benefits of the OSOWOG initiative's global Super grid expansion seem to be rather limited. Moreover, the allowance for a Super grid consistently results in decreased investments in solar power, indicating that it is not an effective strategy for enhancing the deployment of solar power, even when transmission grids covering 18 time zones are available."}, "https://arxiv.org/abs/2405.16928": {"title": "TopoLa: a novel embedding framework for understanding complex networks", "link": "https://arxiv.org/abs/2405.16928", "description": "arXiv:2405.16928v1 Announce Type: new \nAbstract: Complex networks, which are the abstractions of many real-world systems, present a persistent challenge across disciplines for people to decipher their underlying information. Recently, hyperbolic geometry of latent spaces has gained traction in network analysis, due to its ability to preserve certain local intrinsic properties of the nodes. In this study, we explore the problem from a much broader perspective: understanding the impact of nodes' global topological structures on latent space placements. Our investigations reveal a direct correlation between the topological structure of nodes and their positioning within the latent space. Building on this deep and strong connection between node distance and network topology, we propose a novel embedding framework called Topology-encoded Latent Hyperbolic Geometry (TopoLa) for analyzing complex networks. With the encoded topological information in the latent space, TopoLa is capable of enhancing both conventional and low-rank networks, using the singular value gap to clarify the mathematical principles behind this enhancement. Meanwhile, we show that the equipped TopoLa distance can also help augment pivotal deep learning models encompassing knowledge distillation and contrastive learning."}, "https://arxiv.org/abs/2405.17182": {"title": "Exploring the Performance of Continuous-Time Dynamic Link Prediction Algorithms", "link": "https://arxiv.org/abs/2405.17182", "description": "arXiv:2405.17182v1 Announce Type: new \nAbstract: Dynamic Link Prediction (DLP) addresses the prediction of future links in evolving networks. However, accurately portraying the performance of DLP algorithms poses challenges that might impede progress in the field. Importantly, common evaluation pipelines usually calculate ranking or binary classification metrics, where the scores of observed interactions (positives) are compared with those of randomly generated ones (negatives). However, a single metric is not sufficient to fully capture the differences between DLP algorithms, and is prone to overly optimistic performance evaluation. Instead, an in-depth evaluation should reflect performance variations across different nodes, edges, and time segments. In this work, we contribute tools to perform such a comprehensive evaluation. (1) We propose Birth-Death diagrams, a simple but powerful visualization technique that illustrates the effect of time-based train-test splitting on the difficulty of DLP on a given dataset. (2) We describe an exhaustive taxonomy of negative sampling methods that can be used at evaluation time. (3) We carry out an empirical study of the effect of the different negative sampling strategies. Our comparison between heuristics and state-of-the-art memory-based methods on various real-world datasets confirms a strong effect of using different negative sampling strategies on the test Area Under the Curve (AUC). Moreover, we conduct a visual exploration of the prediction, with additional insights on which different types of errors are prominent over time."}, "https://arxiv.org/abs/2405.17189": {"title": "Rebound in epidemic control: How misaligned vaccination timing amplifies infection peaks", "link": "https://arxiv.org/abs/2405.17189", "description": "arXiv:2405.17189v1 Announce Type: new \nAbstract: In this study, we explore the dynamic interplay between the timing of vaccination campaigns and the trajectory of disease spread in a population. Through comprehensive data analysis and modeling, we have uncovered a counter-intuitive phenomenon: initiating a vaccination process at an inopportune moment can paradoxically result in a more pronounced second peak of infections. This \"rebound\" phenomenon challenges the conventional understanding of vaccination impacts on epidemic dynamics. We provide a detailed examination of how improperly timed vaccination efforts can inadvertently reduce the overall immunity level in a population, considering both natural and vaccine-induced immunity. Our findings reveal that such a decrease in population-wide immunity can lead to a delayed, yet more severe, resurgence of cases. This study not only adds a critical dimension to our understanding of vaccination strategies in controlling pandemics but also underscores the necessity for strategically timed interventions to optimize public health outcomes. Furthermore, we compute which vaccination strategies are optimal for a COVID-19 tailored mathematical model, and find that there are two types of optimal strategies. The first type prioritizes vaccinating early and rapidly to reduce the number of deaths, while the second type acts later and more slowly to reduce the number of cases; both of them target primarily the elderly population. Our results hold significant implications for the formulation of vaccination policies, particularly in the context of rapidly evolving infectious diseases."}, "https://arxiv.org/abs/2405.17268": {"title": "Suppressing defection by increasing temptation: the impact of smart cooperators on a social dilemma situation", "link": "https://arxiv.org/abs/2405.17268", "description": "arXiv:2405.17268v1 Announce Type: new \nAbstract: In a social dilemma situation, where individual and collective interests are in conflict, it sounds a reasonable assumption that the presence of super or smart players, who simultaneously punish defection and reward cooperation without allowing exploitation, could solve the basic problem. The behavior of such a multi-strategy system, however, is more subtle than it is firstly anticipated. When exploring the complete parameter space, we find that the emergence of cyclic dominance among strategies is rather common, which results in several counter-intuitive phenomena. For example, the defection level can be lowered at higher temptation, or weaker punishment provides better conditions for smart players. Our study indicates that smart cooperators can unexpectedly thrive under high temptation, emphasizing the complexity of strategic interactions. This study suggests that the principles governing these interactions can be applied to other moral behaviors, such as truth-telling and honesty, providing valuable insights for future research in multi-agent systems."}, "https://arxiv.org/abs/2405.17282": {"title": "R-ODE: Ricci Curvature Tells When You Will be Informed", "link": "https://arxiv.org/abs/2405.17282", "description": "arXiv:2405.17282v1 Announce Type: new \nAbstract: Information diffusion prediction is fundamental to understand the structure and organization of the online social networks, and plays a crucial role to blocking rumor spread, influence maximization, political propaganda, etc. So far, most existing solutions primarily predict the next user who will be informed with historical cascades, but ignore an important factor in the diffusion process - the time. Such limitation motivates us to pose the problem of the time-aware personalized information diffusion prediction for the first time, telling the time when the target user will be informed. In this paper, we address this problem from a fresh geometric perspective of Ricci curvature, and propose a novel Ricci-curvature regulated Ordinary Differential Equation (R-ODE). In the diffusion process, R-ODE considers that the inter-correlated users are organized in a dynamic system in the representation space, and the cascades give the observations sampled from the continuous realm. At each infection time, the message diffuses along the largest Ricci curvature, signifying less transportation effort. In the continuous realm, the message triggers users' movement, whose trajectory in the space is parameterized by an ODE with graph neural network. Consequently, R-ODE predicts the infection time of a target user by the movement trajectory learnt from the observations. Extensive experiments evaluate the personalized time prediction ability of R-ODE, and show R-ODE outperforms the state-of-the-art baselines."}, "https://arxiv.org/abs/2405.17410": {"title": "The Peripatetic Hater: Predicting Movement Among Hate Subreddits", "link": "https://arxiv.org/abs/2405.17410", "description": "arXiv:2405.17410v1 Announce Type: new \nAbstract: Many online hate groups exist to disparage others based on race, gender identity, sex, or other characteristics. The accessibility of these communities allows users to join multiple types of hate groups (e.g., a racist community and misogynistic community), which calls into question whether these peripatetic users could be further radicalized compared to users that stay in one type of hate group. However, little is known about the dynamics of joining multiple types of hate groups, nor the effect of these groups on peripatetic users. In this paper, we develop a new method to classify hate subreddits, and the identities they disparage, which we use to better understand how users become peripatetic (join different types of hate subreddits). The hate classification technique utilizes human-validated LLMs to extract the protected identities attacked, if any, across 168 subreddits. We then cluster identity-attacking subreddits to discover three broad categories of hate: racist, anti-LGBTQ, and misogynistic. We show that becoming active in a user's first hate subreddit can cause them to become active in additional hate subreddits of a different category. We also find that users who join additional hate subreddits, especially of a different category, become more active in hate subreddits as a whole and develop a wider hate group lexicon. We are therefore motivated to train an AI model that we find usefully predicts the hate categories users will become active in based on post text read and written. The accuracy of this model may be partly driven by peripatetic users often using the language of hate subreddits they eventually join. Overall, these results highlight the unique risks associated with hate communities on a social media platform, as discussion of alternative targets of hate may lead users to target more protected identities."}, "https://arxiv.org/abs/2405.16346": {"title": "A modular and scalable web platform for computational phylogenetics", "link": "https://arxiv.org/abs/2405.16346", "description": "arXiv:2405.16346v1 Announce Type: cross \nAbstract: Phylogenetic analysis, which allow to understand the evolution of bacterial and viral epidemics, requires large quantities of data to be analysed and processed for knowledge extraction. One of the major challenges consists on the integration of the results from typing and phylogenetic inference methods with epidemiological data, namely in what concerns their integrated and simultaneous analysis and visualization. Numerous approaches to support phylogenetic analysis have been proposed, varying from standalone tools to integrative web applications that include tools and/or algorithms for executing the common analysis tasks for this kind of data. However, most of them lack the capacity to integrate epidemiological data. Others provide the ability for visualizing and analyzing such data, allowing the integration of epidemiological data but they do not scale for large data analysis and visualization. Namely, most of them run inference and/or visualization optimization tasks on the client side, which becomes often unfeasible for large amounts of data, usually implying transferring data from existing databases in order to be analysed. Moreover, the results and optimizations are not stored for reuse. We propose the PHYLOViZ Web Platform, a cloud based tool for phylogenetic analysis, that not only unifies the features of both existing versions of PHYLOViZ, but also supports structured and customized workflows for executing data processing and analyses tasks, and promotes the reproducibility of previous phylogenetic analyses. This platform supports large scale analyses by relying on a workflow system that enables the distribution of parallel computations on cloud and HPC environments. Moreover, it has a modular architecture, allowing easy integration of new methods and tools, as well as customized workflows, making it flexible and extensible."}, "https://arxiv.org/abs/2405.16616": {"title": "DPHGNN: A Dual Perspective Hypergraph Neural Networks", "link": "https://arxiv.org/abs/2405.16616", "description": "arXiv:2405.16616v1 Announce Type: cross \nAbstract: Message passing on hypergraphs has been a standard framework for learning higher-order correlations between hypernodes. Recently-proposed hypergraph neural networks (HGNNs) can be categorized into spatial and spectral methods based on their design choices. In this work, we analyze the impact of change in hypergraph topology on the suboptimal performance of HGNNs and propose DPHGNN, a novel dual-perspective HGNN that introduces equivariant operator learning to capture lower-order semantics by inducing topology-aware spatial and spectral inductive biases. DPHGNN employs a unified framework to dynamically fuse lower-order explicit feature representations from the underlying graph into the super-imposed hypergraph structure. We benchmark DPHGNN over eight benchmark hypergraph datasets for the semi-supervised hypernode classification task and obtain superior performance compared to seven state-of-the-art baselines. We also provide a theoretical framework and a synthetic hypergraph isomorphism test to express the power of spatial HGNNs and quantify the expressivity of DPHGNN beyond the Generalized Weisfeiler Leman (1-GWL) test. Finally, DPHGNN was deployed by our partner e-commerce company for the Return-to-Origin (RTO) prediction task, which shows ~7% higher macro F1-Score than the best baseline."}, "https://arxiv.org/abs/2405.16631": {"title": "Let Silence Speak: Enhancing Fake News Detection with Generated Comments from Large Language Models", "link": "https://arxiv.org/abs/2405.16631", "description": "arXiv:2405.16631v1 Announce Type: cross \nAbstract: Fake news detection plays a crucial role in protecting social media users and maintaining a healthy news ecosystem. Among existing works, comment-based fake news detection methods are empirically shown as promising because comments could reflect users' opinions, stances, and emotions and deepen models' understanding of fake news. Unfortunately, due to exposure bias and users' different willingness to comment, it is not easy to obtain diverse comments in reality, especially for early detection scenarios. Without obtaining the comments from the ``silent'' users, the perceived opinions may be incomplete, subsequently affecting news veracity judgment. In this paper, we explore the possibility of finding an alternative source of comments to guarantee the availability of diverse comments, especially those from silent users. Specifically, we propose to adopt large language models (LLMs) as a user simulator and comment generator, and design GenFEND, a generated feedback-enhanced detection framework, which generates comments by prompting LLMs with diverse user profiles and aggregating generated comments from multiple subpopulation groups. Experiments demonstrate the effectiveness of GenFEND and further analysis shows that the generated comments cover more diverse users and could even be more effective than actual comments."}, "https://arxiv.org/abs/2302.01397": {"title": "Waiting for Q: An Exploration of QAnon Users' Online Migration to Poal in the Wake of Voat's Demise", "link": "https://arxiv.org/abs/2302.01397", "description": "arXiv:2302.01397v4 Announce Type: replace \nAbstract: Online communities are groups of people who interact primarily via the Internet, often sharing common interests. Some of these groups, particularly supporters of Q who created the far-right conspiracy theory known as QAnon, are highly toxic and controversial. These communities are often banned from various mainstream online social networks due to their controversy. This study examines the deplatforming and subsequent migrations of QAnon adherents, following a two-step process. We analyze Reddit data, finding that users opt for Voat as an alternative following the Reddit bans, particularly influenced by Q's postings on 4chan. Subsequently, upon Voat's shutdown announcement, we observe users recommending Poal. Among several insights, we compare the effects of abrupt permanent bans and announced shutdowns on the migration patterns of these conspiracists. Specifically, we find that almost half of Poal's active users are Voat migrants who registered after the shutdown was announced. This contradicts the patterns observed after the Reddit bans, suggesting that advance warning can facilitate more coordinated migrations. Lastly, our research uncovers evidence of discussions and planning related to the January 6th, 2021, attack on the US Capitol, which emerged shortly after Voat's shutdown, predominantly on Poal. This underscores the continued activity of the conspiracy, albeit at a diminished scale due to various bans and a shutdown, while also exposing Poal as a platform that hosts dangerous individuals."}, "https://arxiv.org/abs/2305.15413": {"title": "Proper Interpretation of Heaps' and Zipf's Laws", "link": "https://arxiv.org/abs/2305.15413", "description": "arXiv:2305.15413v2 Announce Type: replace \nAbstract: We checked that the distribution of words in text should uniform, which gives Heaps' law as natural result, that is, the number of types of words can be expressed as a power law of the number of tokens within text. We developed a ``superposition'' model, which leads to an asymptotic power-law distribution of the number of occurrences (or frequency) of words, that is, Zipf's law. The model is well consistent with observations."}, "https://arxiv.org/abs/2401.09425": {"title": "Quantifying Attrition in Science: A Cohort-Based, Longitudinal Study of Scientists in 38 OECD Countries", "link": "https://arxiv.org/abs/2401.09425", "description": "arXiv:2401.09425v3 Announce Type: replace \nAbstract: In this paper, we explore how members of the scientific community leave academic science and how attrition (defined as ceasing to publish) differs across genders, academic disciplines, and over time. Our approach is cohort based and longitudinal: We track individual male and female scientists over time and quantify the phenomenon traditionally referred to as 'leaving science.' Using publication metadata from Scopus - a global bibliometric database of publications and citations - we follow the details of the publishing careers of scientists from 38 OECD countries who started publishing in 2000 (N = 142,776) and 2010 (N = 232,843). Our study is restricted to 16 STEMM disciplines (science, technology, engineering, mathematics, and medicine), and we track the individual scholarly output of the two cohorts until 2022. Survival analyses show that attrition becomes less gendered. In addition to the combined aggregated changes at the level of all STEMM disciplines, widely nuanced changes were found to occur at the discipline level and over time. Attrition in science means different things for men versus women depending on the discipline; moreover, it means different things for scientists from different cohorts entering the scientific workforce. Finally, global bibliometric datasets were tested in the current study, opening new opportunities to explore gender and disciplinary differences in attrition."}, "https://arxiv.org/abs/2301.01926": {"title": "Auditing citation polarization during the early COVID-19 pandemic", "link": "https://arxiv.org/abs/2301.01926", "description": "arXiv:2301.01926v2 Announce Type: replace-cross \nAbstract: The recent pandemic stimulated scientists to publish a significant amount of research that created a surge of citations of COVID-19-related publications in a short time, leading to an abrupt inflation of the journal impact factor (IF). By auditing the complete set of COVID-19-related publications in the Web of Science, we reveal here that COVID-19-related research worsened the polarization of academic journals: the IF before the pandemic was proportional to the increment of IF, which had the effect of increasing inequality while retaining the journal rankings. We also found that the most highly cited studies related to COVID-19 were published in prestigious journals at the onset of the epidemic. Through the present quantitative investigation, our findings caution against the belief that quantitative metrics, particularly IF, can indicate the significance of individual papers. Rather, such metrics reflect the social attention given to a particular study."}, "https://arxiv.org/abs/2308.11129": {"title": "Enhancing Graph Transformers with Hierarchical Distance Structural Encoding", "link": "https://arxiv.org/abs/2308.11129", "description": "arXiv:2308.11129v4 Announce Type: replace-cross \nAbstract: Graph transformers need strong inductive biases to derive meaningful attention scores. Yet, current methods often fall short in capturing longer ranges, hierarchical structures, or community structures, which are common in various graphs such as molecules, social networks, and citation networks. This paper presents a Hierarchical Distance Structural Encoding (HDSE) method to model node distances in a graph, focusing on its multi-level, hierarchical nature. We introduce a novel framework to seamlessly integrate HDSE into the attention mechanism of existing graph transformers, allowing for simultaneous application with other positional encodings. To apply graph transformers with HDSE to large-scale graphs, we further propose a high-level HDSE that effectively biases the linear transformers towards graph hierarchies. We theoretically prove the superiority of HDSE over shortest path distances in terms of expressivity and generalization. Empirically, we demonstrate that graph transformers with HDSE excel in graph classification, regression on 7 graph-level datasets, and node classification on 11 large-scale graphs, including those with up to a billion nodes."}, "https://arxiv.org/abs/2403.16049": {"title": "Improving Demand Forecasting in Open Systems with Cartogram-Enhanced Deep Learning", "link": "https://arxiv.org/abs/2403.16049", "description": "arXiv:2403.16049v2 Announce Type: replace-cross \nAbstract: Predicting temporal patterns across various domains poses significant challenges due to their nuanced and often nonlinear trajectories. To address this challenge, prediction frameworks have been continuously refined, employing data-driven statistical methods, mathematical models, and machine learning. Recently, as one of the challenging systems, shared transport systems such as public bicycles have gained prominence due to urban constraints and environmental concerns. Predicting rental and return patterns at bicycle stations remains a formidable task due to the system's openness and imbalanced usage patterns across stations. In this study, we propose a deep learning framework to predict rental and return patterns by leveraging cartogram approaches. The cartogram approach facilitates the prediction of demand for newly installed stations with no training data as well as long-period prediction, which has not been achieved before. We apply this method to public bicycle rental-and-return data in Seoul, South Korea, employing a spatial-temporal convolutional graph attention network. Our improved architecture incorporates batch attention and modified node feature updates for better prediction accuracy across different time scales. We demonstrate the effectiveness of our framework in predicting temporal patterns and its potential applications."}, "https://arxiv.org/abs/2404.14192": {"title": "Swap distance minimization beyond entropy minimization in word order variation", "link": "https://arxiv.org/abs/2404.14192", "description": "arXiv:2404.14192v3 Announce Type: replace-cross \nAbstract: Here we consider the problem of all the possible orders of a linguistic structure formed by $n$ elements, for instance, subject, direct object and verb ($n=3$) or subject, direct object, indirect object and verb ($n=4$). We investigate if the frequency of the $n!$ possible orders is constrained by two principles. First, entropy minimization, a principle that has been suggested to shape natural communication systems at distinct levels of organization. Second, swap distance minimization, namely a preference for word orders that require fewer swaps of adjacent elements to be produced from a source order. Here we present average swap distance, a novel score for research on swap distance minimization, and investigate the theoretical distribution of that score for any $n$: its minimum and maximum values and its expected value in die rolling experiments or when the word order frequencies are shuffled. We investigate whether entropy and average swap distance are significantly small in distinct linguistic structures with $n=3$ or $n=4$ in agreement with the corresponding minimization principles. We find strong evidence of entropy minimization and swap distance minimization with respect to a die rolling experiment. The evidence of these two forces with respect to a Polya urn process is strong for $n=4$ but weaker for $n=3$. We still find evidence of swap distance minimization when word order frequencies are shuffled, indicating that swap distance minimization effects are beyond pressure to minimize word order entropy."}, "https://arxiv.org/abs/2405.17511": {"title": "On the Analogy of Gauge Theory of Plasticity and Economics", "link": "https://arxiv.org/abs/2405.17511", "description": "arXiv:2405.17511v1 Announce Type: new \nAbstract: We demonstrated the analogy between Economics and Gauge Theory of Plasticity and used it to describe the relationship between money supply and inflation at the economic market. The received equations of economical dynamics in phase space are similar to the plasticity equations and economic variables - choice, competition and profit correspond to the state of the market with inflation. We described the meaning of equations and the role of its variables in the stabilization mechanism of the market with inflation. The equation of market equilibrium including the Profit turnover, time changes of competition, capital and choice was discussed in detail."}, "https://arxiv.org/abs/2405.17571": {"title": "Bluesky: Network Topology, Polarisation, and Algorithmic Curation", "link": "https://arxiv.org/abs/2405.17571", "description": "arXiv:2405.17571v1 Announce Type: new \nAbstract: Bluesky is a nascent ``Twitter-like'' and decentralized social media network with novel features and unprecedented data access. This paper provides a characterization of the network, studying the political leaning, polarization, network structure, and algorithmic curation mechanisms of five million users. The dataset spans from the website's first release in February of 2023. Users of the new social media site are predominantly left-center leaning and share little to no links associated with questionable sources. In contrast to the homogeneous political stance, we find significant issues-based divergence by studying opinions related to the Israel-Palestine conflict. Two clear homophilic clusters emerge: Pro-Palestinian voices make up the plurality of messages related to the conflict and the proportion has increased with a lessening of interest. We investigate multiple layers of the multi-scale Bluesky network based on replies, likes, reposts, and follows, highlighting differences and similarities between the layers. We differentiate between persistent and non-persistent interactions and measure metrics of network topology over time. All networks are heavy-tailed, clustered, and connected by short paths. We showcase all feeds - algorithmic content recommenders - created for and by users. A large number of custom feeds have been created but their uptake by users is limited. Multiple popular feeds aim to provide similar feeds that are neither topical nor chronological. We conclude by claiming that Bluesky - for all its novel features - is very similar in terms of its network structure to existing and larger social media sites and provides unprecedented research opportunities for social scientists, network scientists, and political scientists alike."}, "https://arxiv.org/abs/2405.17710": {"title": "Does Geo-co-location Matter? A Case Study of Public Health Conversations during COVID-19", "link": "https://arxiv.org/abs/2405.17710", "description": "arXiv:2405.17710v1 Announce Type: new \nAbstract: Social media platforms like Twitter (now X) have been pivotal in information dissemination and public engagement, especially during COVID-19. A key goal for public health experts was to encourage prosocial behavior that could impact local outcomes such as masking and social distancing. Given the importance of local news and guidance during COVID-19, the objective of our research is to analyze the effect of localized engagement, on social media conversations. This study examines the impact of geographic co-location, as a proxy for localized engagement between public health experts (PHEs) and the public, on social media. We analyze a Twitter conversation dataset from January 2020 to November 2021, comprising over 19 K tweets from nearly five hundred PHEs, along with approximately 800 K replies from 350 K participants. Our findings reveal that geo-co-location is associated with higher engagement rates, especially in conversations on topics including masking, lockdowns, and education, and in conversations with academic and medical professionals. Lexical features associated with emotion and personal experiences were more common in geo-co-located contexts. This research provides insights into how geographic co-location influences social media engagement and can inform strategies to improve public health messaging."}, "https://arxiv.org/abs/2405.18059": {"title": "Rank-Refining Seed Selection Methods for Budget Constrained Influence Maximisation in Multilayer Networks under Linear Threshold Model", "link": "https://arxiv.org/abs/2405.18059", "description": "arXiv:2405.18059v1 Announce Type: new \nAbstract: The problem of selecting an optimal seed set to maximise influence in networks has been a subject of intense research in recent years. However, despite numerous works addressing this area, it remains a topic that requires further elaboration. Most often, it is considered within the scope of classically defined graphs with a spreading model in the form of Independent Cascades. In this work, we focus on the problem of budget-constrained influence maximisation in multilayer networks using a Linear Threshold Model. Both the graph model and the spreading process we employ are less prevalent in the literature, even though their application allows for a more precise representation of the opinion dynamics in social networks. This paper aims to answer which of the sixteen evaluated seed selection methods is the most effective and how similar they are. Additionally, we focus our analysis on the impact of spreading model parameters, network characteristics, a budget, and the seed selection methods on the diffusion effectiveness in multilayer networks. Our contribution also includes extending several centrality measures and heuristics to the case of such graphs. The results indicate that all the factors mentioned above collectively contribute to the effectiveness of influence maximisation. Moreover, there is no seed selection method which always provides the best results. However, the seeds chosen with VoteRank-based methods (especially with the $v-rnk-m$ variant we propose) usually provide the most extensive diffusion."}, "https://arxiv.org/abs/2405.18085": {"title": "Network Diffusion -- Framework to Simulate Spreading Processes in Complex Networks", "link": "https://arxiv.org/abs/2405.18085", "description": "arXiv:2405.18085v1 Announce Type: new \nAbstract: With the advancement of computational network science, its research scope has significantly expanded beyond static graphs to encompass more complex structures. The introduction of streaming, temporal, multilayer, and hypernetwork approaches has brought new possibilities and imposed additional requirements. For instance, by utilising these advancements, one can model structures such as social networks in a much more refined manner, which is particularly relevant in simulations of the spreading processes. Unfortunately, the pace of advancement is often too rapid for existing computational packages to keep up with the functionality updates. This results in a significant proliferation of tools used by researchers and, consequently, a lack of a universally accepted technological stack that would standardise experimental methods (as seen, e.g. in machine learning). This article addresses that issue by presenting an extended version of the Network Diffusion library. First, a survey of the existing approaches and toolkits for simulating spreading phenomena is shown and then, an overview of the framework functionalities. Finally, we report four case studies conducted with the package to demonstrate its usefulness: the impact of sanitary measures on the spread of COVID-19, the comparison of information diffusion on two temporal network models, and the effectiveness of seed selection methods in the task of influence maximisation in multilayer networks. We conclude the paper with a critical assessment of the library and the outline of still awaiting challenges to standardise research environments in computational network science."}, "https://arxiv.org/abs/2405.17473": {"title": "Repeat-Aware Neighbor Sampling for Dynamic Graph Learning", "link": "https://arxiv.org/abs/2405.17473", "description": "arXiv:2405.17473v1 Announce Type: cross \nAbstract: Dynamic graph learning equips the edges with time attributes and allows multiple links between two nodes, which is a crucial technology for understanding evolving data scenarios like traffic prediction and recommendation systems. Existing works obtain the evolving patterns mainly depending on the most recent neighbor sequences. However, we argue that whether two nodes will have interaction with each other in the future is highly correlated with the same interaction that happened in the past. Only considering the recent neighbors overlooks the phenomenon of repeat behavior and fails to accurately capture the temporal evolution of interactions. To fill this gap, this paper presents RepeatMixer, which considers evolving patterns of first and high-order repeat behavior in the neighbor sampling strategy and temporal information learning. Firstly, we define the first-order repeat-aware nodes of the source node as the destination nodes that have interacted historically and extend this concept to high orders as nodes in the destination node's high-order neighbors. Then, we extract neighbors of the source node that interacted before the appearance of repeat-aware nodes with a slide window strategy as its neighbor sequence. Next, we leverage both the first and high-order neighbor sequences of source and destination nodes to learn temporal patterns of interactions via an MLP-based encoder. Furthermore, considering the varying temporal patterns on different orders, we introduce a time-aware aggregation mechanism that adaptively aggregates the temporal representations from different orders based on the significance of their interaction time sequences. Experimental results demonstrate the superiority of RepeatMixer over state-of-the-art models in link prediction tasks, underscoring the effectiveness of the proposed repeat-aware neighbor sampling strategy."}, "https://arxiv.org/abs/2405.17530": {"title": "Universal deterministic patterns in stochastic count data", "link": "https://arxiv.org/abs/2405.17530", "description": "arXiv:2405.17530v1 Announce Type: cross \nAbstract: We report the existence of deterministic patterns in plots showing the relationship between the mean and the Fano factor (ratio of variance and mean) of stochastic count data. These patterns are found in a wide variety of datasets, including those from genomics, paper citations, commerce, ecology, disease outbreaks, and employment statistics. We develop a theory showing that the patterns naturally emerge when data sampled from discrete probability distributions is organised in matrix form. The theory precisely predicts the patterns and shows that they are a function of only one variable - the sample size."}, "https://arxiv.org/abs/2405.17735": {"title": "State Feedback as a Strategy for Control and Analysis of COVID-19", "link": "https://arxiv.org/abs/2405.17735", "description": "arXiv:2405.17735v1 Announce Type: cross \nAbstract: This paper presents a study on a compartmental epidemic model for COVID-19, examining the stability of its equilibrium points upon the introduction of vaccination as a strategy to mitigate the spread of the disease. Initially, the SIQR (Susceptible-Infectious-Quarantine-Recovered) mathematical model and its technical aspects are introduced. Subsequently, vaccination is incorporated as a control measure within the model scope. Equilibrium points and the basic reproductive number are determined, followed by an analysis of their stability. Furthermore, controllability characteristics and Optimal Control strategies for the system are investigated, supplemented by numerical simulations."}, "https://arxiv.org/abs/2405.17768": {"title": "Revisiting the Message Passing in Heterophilous Graph Neural Networks", "link": "https://arxiv.org/abs/2405.17768", "description": "arXiv:2405.17768v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) have demonstrated strong performance in graph mining tasks due to their message-passing mechanism, which is aligned with the homophily assumption that adjacent nodes exhibit similar behaviors. However, in many real-world graphs, connected nodes may display contrasting behaviors, termed as heterophilous patterns, which has attracted increased interest in heterophilous GNNs (HTGNNs). Although the message-passing mechanism seems unsuitable for heterophilous graphs due to the propagation of class-irrelevant information, it is still widely used in many existing HTGNNs and consistently achieves notable success. This raises the question: why does message passing remain effective on heterophilous graphs? To answer this question, in this paper, we revisit the message-passing mechanisms in heterophilous graph neural networks and reformulate them into a unified heterophilious message-passing (HTMP) mechanism. Based on HTMP and empirical analysis, we reveal that the success of message passing in existing HTGNNs is attributed to implicitly enhancing the compatibility matrix among classes. Moreover, we argue that the full potential of the compatibility matrix is not completely achieved due to the existence of incomplete and noisy semantic neighborhoods in real-world heterophilous graphs. To bridge this gap, we introduce a new approach named CMGNN, which operates within the HTMP mechanism to explicitly leverage and improve the compatibility matrix. A thorough evaluation involving 10 benchmark datasets and comparative analysis against 13 well-established baselines highlights the superior performance of the HTMP mechanism and CMGNN method."}, "https://arxiv.org/abs/2405.18116": {"title": "Emergent Inequalities in a Primitive Agent-Based Good-Exchange Model", "link": "https://arxiv.org/abs/2405.18116", "description": "arXiv:2405.18116v1 Announce Type: cross \nAbstract: Rising inequalities around the globe bring into question our economic systems and the origin of such inequalities. Here we propose a toy agent-based model where each entity is simultaneously producing and consuming indivisible goods. We find that the system exhibits a non-trivial phase transition beyond which a market clearing equilibrium exists but becomes dynamically unreachable. When production capacity exceeds a threshold and adapts too slowly, some agents cannot sell all their goods. This leads to global price deflation and induces strong wealth inequalities, with the spontaneous separation of the population into a rich class and a poor class. We explore ways to alleviate poverty in this model and whether they have real life significance."}, "https://arxiv.org/abs/2405.18255": {"title": "Channel Reciprocity Based Attack Detection for Securing UWB Ranging by Autoencoder", "link": "https://arxiv.org/abs/2405.18255", "description": "arXiv:2405.18255v1 Announce Type: cross \nAbstract: A variety of ranging threats represented by Ghost Peak attack have raised concerns regarding the security performance of Ultra-Wide Band (UWB) systems with the finalization of the IEEE 802.15.4z standard. Based on channel reciprocity, this paper proposes a low complexity attack detection scheme that compares Channel Impulse Response (CIR) features of both ranging sides utilizing an autoencoder with the capability of data compression and feature extraction. Taking Ghost Peak attack as an example, this paper demonstrates the effectiveness, feasibility and generalizability of the proposed attack detection scheme through simulation and experimental validation. The proposed scheme achieves an attack detection success rate of over 99% and can be implemented in current systems at low cost."}, "https://arxiv.org/abs/2405.18414": {"title": "Don't Forget to Connect! Improving RAG with Graph-based Reranking", "link": "https://arxiv.org/abs/2405.18414", "description": "arXiv:2405.18414v1 Announce Type: cross \nAbstract: Retrieval Augmented Generation (RAG) has greatly improved the performance of Large Language Model (LLM) responses by grounding generation with context from existing documents. These systems work well when documents are clearly relevant to a question context. But what about when a document has partial information, or less obvious connections to the context? And how should we reason about connections between documents? In this work, we seek to answer these two core questions about RAG generation. We introduce G-RAG, a reranker based on graph neural networks (GNNs) between the retriever and reader in RAG. Our method combines both connections between documents and semantic information (via Abstract Meaning Representation graphs) to provide a context-informed ranker for RAG. G-RAG outperforms state-of-the-art approaches while having smaller computational footprint. Additionally, we assess the performance of PaLM 2 as a reranker and find it to significantly underperform G-RAG. This result emphasizes the importance of reranking for RAG even when using Large Language Models."}, "https://arxiv.org/abs/2405.18419": {"title": "Exploring the Evolution of Altruistic Punishment with a PDE Model of Cultural Multilevel Selection", "link": "https://arxiv.org/abs/2405.18419", "description": "arXiv:2405.18419v1 Announce Type: cross \nAbstract: Two mechanisms that have been used to study the evolution of cooperative behavior are altruistic punishment, in which cooperative individuals pay additional costs to punish defection, and multilevel selection, in which competition between groups can help to counteract individual-level incentives to cheat. Boyd, Gintis, Bowles, and Richerson have used simulation models of cultural evolution to suggest that altruistic punishment and pairwise group-level competition can work in concert to promote cooperation, even when neither mechanism can do so on its own. In this paper, we formulate a PDE model for multilevel selection motivated by the approach of Boyd and coauthors, modeling individual-level birth-death competition with a replicator equation based on individual payoffs and describing group-level competition with pairwise conflicts based on differences in the average payoffs of the competing groups. Building off of existing PDE models for multilevel selection with frequency-independent group-level competition, we use analytical and numerical techniques to understand how the forms of individual and average payoffs can impact the long-time ability to sustain altruistic punishment in group-structured populations. We find several interesting differences between the behavior of our new PDE model with pairwise group-level competition and existing multilevel PDE models, including the observation that our new model can feature a non-monotonic dependence of the long-time collective payoff on the strength of altruistic punishment. Going forward, our PDE framework can serve as a way to connect and compare disparate approaches for understanding multilevel selection across the literature in evolutionary biology and anthropology."}, "https://arxiv.org/abs/2401.06872": {"title": "Disease Transmission on Random Graphs Using Edge-Based Percolation", "link": "https://arxiv.org/abs/2401.06872", "description": "arXiv:2401.06872v2 Announce Type: replace \nAbstract: Edge-based percolation methods can be used to analyze disease transmission on complex social networks. This allows us to include complex social heterogeneity in our models while maintaining tractability. Here we review the seminal works on this field by Newman et al (2001); Newman (2002, 2003), and Miller et al (2012). We present a systematic discussion of the theoretical background behind these models, including an extensive derivation of the major results. We also connect these results relate back to the classical literature in random graph theory Molloy and Reed (1995, 1998). Finally, we also present an accompanying R package that takes epidemic and network parameters as input and generates estimates of the epidemic trajectory and final size. This manuscript and the R package was developed to help researchers easily understand and use network models to investigate the interaction between different community structures and disease transmission."}, "https://arxiv.org/abs/2401.11254": {"title": "The Great Ban: Efficacy and Unintended Consequences of a Massive Deplatforming Operation on Reddit", "link": "https://arxiv.org/abs/2401.11254", "description": "arXiv:2401.11254v5 Announce Type: replace \nAbstract: In the current landscape of online abuses and harms, effective content moderation is necessary to cultivate safe and inclusive online spaces. Yet, the effectiveness of many moderation interventions is still unclear. Here, we assess the effectiveness of The Great Ban, a massive deplatforming operation that affected nearly 2,000 communities on Reddit. By analyzing 16M comments posted by 17K users during 14 months, we provide nuanced results on the effects, both desired and otherwise, of the ban. Among our main findings is that 15.6% of the affected users left Reddit and that those who remained reduced their toxicity by 6.6% on average. The ban also caused 5% users to increase their toxicity by more than 70% of their pre-ban level. Overall, our multifaceted results provide new insights into the efficacy of deplatforming. As such, our findings can inform the development of future moderation interventions and the policing of online platforms."}, "https://arxiv.org/abs/2403.00603": {"title": "Modeling of obstacle avoidance by a dense crowd as a Mean-Field Game", "link": "https://arxiv.org/abs/2403.00603", "description": "arXiv:2403.00603v2 Announce Type: replace \nAbstract: In this paper we use a minimal model based on Mean-Field Games (a mathematical framework apt to describe situations where a large number of agents compete strategically) to simulate the scenario where a static dense human crowd is crossed by a cylindrical intruder. After a brief explanation of the mathematics behind it, we compare our model directly against the empirical data collected during a controlled experiment replicating the aforementioned situation. We then summarize the features that make the model adhere so well to the experiment and clarify the anticipation time in this framework."}, "https://arxiv.org/abs/2403.01168": {"title": "Mean-Field Games Modeling of Anticipation in Dense Crowds", "link": "https://arxiv.org/abs/2403.01168", "description": "arXiv:2403.01168v2 Announce Type: replace \nAbstract: Understanding and modeling pedestrian dynamics in dense crowds is a complex yet essential aspect of crowd management and urban planning. In this work, we investigate the dynamics of a dense crowd crossed by a cylindrical intruder using a Mean-Field Game (MFG) model. By incorporating a discount factor to account for pedestrians' limited anticipation and information processing, we examine the model's ability to simulate two distinct experimental configurations: pedestrians facing the obstacle and pedestrians giving their back to the intruder. Through a comprehensive comparison with experimental data, we demonstrate that the MFG model effectively captures essential crowd behaviors, including anticipatory motion and collision avoidance."}, "https://arxiv.org/abs/2301.10856": {"title": "Partial Mobilization: Tracking Multilingual Information Flows Amongst Russian Media Outlets and Telegram", "link": "https://arxiv.org/abs/2301.10856", "description": "arXiv:2301.10856v5 Announce Type: replace-cross \nAbstract: In response to disinformation and propaganda from Russian online media following the invasion of Ukraine, Russian media outlets such as Russia Today and Sputnik News were banned throughout Europe. To maintain viewership, many of these Russian outlets began to heavily promote their content on messaging services like Telegram. In this work, we study how 16 Russian media outlets interacted with and utilized 732 Telegram channels throughout 2022. Leveraging the foundational model MPNet, DP-means clustering, and Hawkes processes, we trace how narratives spread between news sites and Telegram channels. We show that news outlets not only propagate existing narratives through Telegram but that they source material from the messaging platform. For example, across the websites in our study, between 2.3% (ura.news) and 26.7% (ukraina.ru) of articles discussed content that originated/resulted from activity on Telegram. Finally, tracking the spread of individual topics, we measure the rate at which news outlets and Telegram channels disseminate content within the Russian media ecosystem, finding that websites like ura.news and Telegram channels such as @genshab are the most effective at disseminating their content."}, "https://arxiv.org/abs/2308.08012": {"title": "Comprehensive Analysis of Network Robustness Evaluation Based on Convolutional Neural Networks with Spatial Pyramid Pooling", "link": "https://arxiv.org/abs/2308.08012", "description": "arXiv:2308.08012v2 Announce Type: replace-cross \nAbstract: Connectivity robustness, a crucial aspect for understanding, optimizing, and repairing complex networks, has traditionally been evaluated through time-consuming and often impractical simulations. Fortunately, machine learning provides a new avenue for addressing this challenge. However, several key issues remain unresolved, including the performance in more general edge removal scenarios, capturing robustness through attack curves instead of directly training for robustness, scalability of predictive tasks, and transferability of predictive capabilities. In this paper, we address these challenges by designing a convolutional neural networks (CNN) model with spatial pyramid pooling networks (SPP-net), adapting existing evaluation metrics, redesigning the attack modes, introducing appropriate filtering rules, and incorporating the value of robustness as training data. The results demonstrate the thoroughness of the proposed CNN framework in addressing the challenges of high computational time across various network types, failure component types and failure scenarios. However, the performance of the proposed CNN model varies: for evaluation tasks that are consistent with the trained network type, the proposed CNN model consistently achieves accurate evaluations of both attack curves and robustness values across all removal scenarios. When the predicted network type differs from the trained network, the CNN model still demonstrates favorable performance in the scenario of random node failure, showcasing its scalability and performance transferability. Nevertheless, the performance falls short of expectations in other removal scenarios. This observed scenario-sensitivity in the evaluation of network features has been overlooked in previous studies and necessitates further attention and optimization. Lastly, we discuss important unresolved questions and further investigation."}, "https://arxiv.org/abs/2310.19697": {"title": "A nonlinear spectral core-periphery detection method for multiplex networks", "link": "https://arxiv.org/abs/2310.19697", "description": "arXiv:2310.19697v2 Announce Type: replace-cross \nAbstract: Core-periphery detection aims to separate the nodes of a complex network into two subsets: a core that is densely connected to the entire network and a periphery that is densely connected to the core but sparsely connected internally. The definition of core-periphery structure in multiplex networks that record different types of interactions between the same set of nodes on different layers is nontrivial since a node may belong to the core in some layers and to the periphery in others. We propose a nonlinear spectral method for multiplex networks that simultaneously optimises a node and a layer coreness vector by maximising a suitable nonconvex homogeneous objective function by a provably convergent alternating fixed point iteration. We derive a quantitative measure for the quality of a given multiplex core-periphery structure that allows the determination of the optimal core size. Numerical experiments on synthetic and real-world networks illustrate that our approach is robust against noisy layers and significantly outperforms baseline methods while improving the latter with our novel optimised layer coreness weights. As the runtime of our method depends linearly on the number of edges of the network it is scalable to large-scale multiplex networks."}, "https://arxiv.org/abs/2405.04773": {"title": "Hypergraph-enhanced Dual Semi-supervised Graph Classification", "link": "https://arxiv.org/abs/2405.04773", "description": "arXiv:2405.04773v2 Announce Type: replace-cross \nAbstract: In this paper, we study semi-supervised graph classification, which aims at accurately predicting the categories of graphs in scenarios with limited labeled graphs and abundant unlabeled graphs. Despite the promising capability of graph neural networks (GNNs), they typically require a large number of costly labeled graphs, while a wealth of unlabeled graphs fail to be effectively utilized. Moreover, GNNs are inherently limited to encoding local neighborhood information using message-passing mechanisms, thus lacking the ability to model higher-order dependencies among nodes. To tackle these challenges, we propose a Hypergraph-Enhanced DuAL framework named HEAL for semi-supervised graph classification, which captures graph semantics from the perspective of the hypergraph and the line graph, respectively. Specifically, to better explore the higher-order relationships among nodes, we design a hypergraph structure learning to adaptively learn complex node dependencies beyond pairwise relations. Meanwhile, based on the learned hypergraph, we introduce a line graph to capture the interaction between hyperedges, thereby better mining the underlying semantic structures. Finally, we develop a relational consistency learning to facilitate knowledge transfer between the two branches and provide better mutual guidance. Extensive experiments on real-world graph datasets verify the effectiveness of the proposed method against existing state-of-the-art methods."}, "https://arxiv.org/abs/2405.18555": {"title": "Multigraph reconstruction via nonlinear random walk", "link": "https://arxiv.org/abs/2405.18555", "description": "arXiv:2405.18555v1 Announce Type: new \nAbstract: Over the last few years, network science has proved to be useful in modeling a variety of complex systems, composed of a large number of interconnected units. The intricate pattern of interactions often allows the system to achieve complex tasks, such as synchronization or collective motions. In this regard, the interplay between network structure and dynamics has long been recognized as a cornerstone of network science. Among dynamical processes, random walks are undoubtedly among the most studied stochastic processes. While traditionally, the random walkers are assumed to be independent, this assumption breaks down if nodes are endowed with a finite carrying capacity, a feature shared by many real-life systems. Recently, a class of nonlinear diffusion processes accounting for the finite carrying capacities of the nodes was introduced. The stationary nodes densities were shown to be nonlinearly correlated with the nodes degrees, allowing to uncover the network structure by performing a few measurements of the stationary density at the level of a single arbitrary node and by solving an inverse problem. In this work, we extend this class of nonlinear diffusion processes to the case of multigraphs, in which links between nodes carry distinct attributes. Assuming the knowledge of the pattern of interactions associated with one type of links, we show how the degree distribution of the whole multigraph can be reconstructed. The effectiveness of the reconstruction algorithm is demonstrated through simulations on various multigraph topologies."}, "https://arxiv.org/abs/2405.18748": {"title": "Equity Implications of Net-Zero Emissions: A Multi-Model Analysis of Energy Expenditures Across Income Classes Under Economy-Wide Deep Decarbonization Policies", "link": "https://arxiv.org/abs/2405.18748", "description": "arXiv:2405.18748v1 Announce Type: new \nAbstract: With companies, states, and countries targeting net-zero emissions around midcentury, there are questions about how these targets alter household welfare and finances, including distributional effects across income groups. This paper examines the distributional dimensions of technology transitions and net-zero policies with a focus on welfare impacts across household incomes. The analysis uses a model intercomparison with a range of energy-economy models using harmonized policy scenarios reaching economy-wide, net-zero CO2 emissions across the United States in 2050. We employ a novel linking approach that connects output from detailed energy system models with survey microdata on energy expenditures across income classes to provide distributional analysis of net-zero policies. Although there are differences in model structure and input assumptions, we find broad agreement in qualitative trends in policy incidence and energy burdens across income groups. Models generally agree that direct energy expenditures for many households will likely decline over time with reference and net-zero policies. However, there is variation in the extent of changes relative to current levels, energy burdens relative to reference levels, and electricity expenditures. Policy design, primarily how climate policy revenues are used, has first-order impacts on distributional outcomes. Net-zero policy costs, in both absolute and relative terms, are unevenly distributed across households, and relative increases in energy expenditures are higher for lowest-income households. However, we also find that recycled revenues from climate policies have countervailing effects when rebated on a per-capita basis, offsetting higher energy burdens and potentially even leading to net progressive outcomes."}, "https://arxiv.org/abs/2405.18803": {"title": "Information Dynamics in Evolving Networks Based on the Birth-Death Process: Random Drift and Natural Selection Perspective", "link": "https://arxiv.org/abs/2405.18803", "description": "arXiv:2405.18803v1 Announce Type: new \nAbstract: Dynamic processes in complex networks are crucial for better understanding collective behavior in human societies, biological systems, and the internet. In this paper, we first focus on the continuous Markov-based modeling of evolving networks with the birth-death of individuals. A new individual arrives at the group by the Poisson process, while new links are established in the network through either uniform connection or preferential attachment. Moreover, an existing individual has a limited lifespan before leaving the network. We determine stationary topological properties of these networks, including their size and mean degree. To address the effect of the birth-death evolution, we further study the information dynamics in the proposed network model from the random drift and natural selection perspective, based on assumptions of total-stochastic and fitness-driven evolution, respectively. In simulations, we analyze the fixation probability of individual information and find that means of new connections affect the random drift process but do not affect the natural selection process."}, "https://arxiv.org/abs/2405.19141": {"title": "Resilience of mobility network to dynamic population response across COVID-19 interventions: evidences from Chile", "link": "https://arxiv.org/abs/2405.19141", "description": "arXiv:2405.19141v1 Announce Type: new \nAbstract: The COVID19 pandemic highlighted the importance of non-traditional data sources, such as mobile phone data, to inform effective public health interventions and monitor adherence to such measures. Previous studies showed how socioeconomic characteristics shaped population response during restrictions and how repeated interventions eroded adherence over time. Less is known about how different population strata changed their response to repeated interventions and how this impacted the resulting mobility network. We study population response during the first and second infection waves of the COVID-19 pandemic in Chile and Spain. Via spatial lag and regression models, we investigate the adherence to mobility interventions at the municipality level in Chile, highlighting the significant role of wealth, labor structure, COVID-19 incidence, and network metrics characterizing business-as-usual municipality connectivity in shaping mobility changes during the two waves. We assess network structural similarities in the two periods by defining mobility hotspots and traveling probabilities in the two countries. As a proof of concept, we simulate and compare outcomes of an epidemic diffusion occurring in the two waves. Our analysis reveals the resilience of the mobility network across waves. We test the robustness of our findings recovering similar results for Spain. Finally, epidemic modeling suggests that historical mobility data from past waves can be leveraged to inform future disease spatial invasion models in repeated interventions. This study highlights the value of historical mobile phone data for building pandemic preparedness and lessens the need for real-time data streams for risk assessment and outbreak response. Our work provides valuable insights into the complex interplay of factors driving mobility across repeated interventions, aiding in developing targeted mitigation strategies."}, "https://arxiv.org/abs/2405.19199": {"title": "A statistical analysis of drug seizures and opioid overdose deaths in Ohio from 2014 to 2018", "link": "https://arxiv.org/abs/2405.19199", "description": "arXiv:2405.19199v1 Announce Type: new \nAbstract: This paper examines the association between police drug seizures and drug overdose deaths in Ohio from 2014 to 2018. We use linear regression, ARIMA models, and categorical data analysis to quantify the effect of drug seizure composition and weight on drug overdose deaths, to quantify the lag between drug seizures and overdose deaths, and to compare the weight distributions of drug seizures conducted by different types of law enforcement (national, local, and drug task forces). We find that drug seizure composition and weight have strong predictive value for drug overdose deaths (F = 27.14, p < 0.0001, R^2 = .7799). A time series analysis demonstrates no statistically significant lag between drug seizures and overdose deaths or weight. Histograms and Kolmogorov-Smirnov tests demonstrate stark differences between seizure weight distributions of different types of law enforcement (p < 0.0001 for each pairwise comparison). We include a discussion of what our conclusions mean for law enforcement and harm reduction efforts."}, "https://arxiv.org/abs/2405.18526": {"title": "Unlocking the Potential of Renewable Energy Through Curtailment Prediction", "link": "https://arxiv.org/abs/2405.18526", "description": "arXiv:2405.18526v1 Announce Type: cross \nAbstract: A significant fraction (5-15%) of renewable energy generated goes into waste in the grids around the world today due to oversupply issues and transmission constraints. Being able to predict when and where renewable curtailment occurs would improve renewable utilization. The core of this work is to enable the machine learning community to help decarbonize electricity grids by unlocking the potential of renewable energy through curtailment prediction."}, "https://arxiv.org/abs/2405.18873": {"title": "A Return to Biased Nets: New Specifications and Approximate Bayesian Inference", "link": "https://arxiv.org/abs/2405.18873", "description": "arXiv:2405.18873v1 Announce Type: cross \nAbstract: The biased net paradigm was the first general and empirically tractable scheme for parameterizing complex patterns of dependence in networks, expressing deviations from uniform random graph structure in terms of latent ``bias events,'' whose realizations enhance reciprocity, transitivity, or other structural features. Subsequent developments have introduced local specifications of biased nets, which reduce the need for approximations required in early specifications based on tracing processes. Here, we show that while one such specification leads to inconsistencies, a closely related Markovian specification both evades these difficulties and can be extended to incorporate new types of effects. We introduce the notion of inhibitory bias events, with satiation as an example, which are useful for avoiding degeneracies that can arise from closure bias terms. Although our approach does not lead to a computable likelihood, we provide a strategy for approximate Bayesian inference using random forest prevision. We demonstrate our approach on a network of friendship ties among college students, recapitulating a relationship between the sibling bias and tie strength posited in earlier work by Fararo."}, "https://arxiv.org/abs/2405.19125": {"title": "Early Detection of Critical Urban Events using Mobile Phone Network Data", "link": "https://arxiv.org/abs/2405.19125", "description": "arXiv:2405.19125v1 Announce Type: cross \nAbstract: Network Signalling Data (NSD) have the potential to provide continuous spatio-temporal information about the presence, mobility, and usage patterns of cell phone services by individuals. Such information is invaluable for monitoring large urban areas and supporting the implementation of decision-making services. When analyzed in real time, NSD can enable the early detection of critical urban events, including fires, large accidents, stampedes, terrorist attacks, and sports and leisure gatherings, especially if these events significantly impact mobile phone network activity in the affected areas. This paper presents empirical evidence that advanced NSD can detect anomalies in mobile traffic service consumption, attributable to critical urban events, with fine spatial and temporal resolutions. We introduce two methodologies for real-time anomaly detection from multivariate time series extracted from large-scale NSD, utilizing a range of algorithms adapted from the state-of-the-art in unsupervised machine learning techniques for anomaly detection. Our research includes a comprehensive quantitative evaluation of these algorithms on a large-scale dataset of NSD service consumption for the Paris region. The evaluation uses an original dataset of documented critical or unusual urban events. This dataset has been built as a ground truth basis for assessing the algorithms performance. The obtained results demonstrate that our framework can detect unusual events almost instantaneously and locate the affected areas with high precision, largely outperforming random classifiers. This efficiency and effectiveness underline the potential of NSD-based anomaly detection in significantly enhancing emergency response strategies and urban planning."}, "https://arxiv.org/abs/2405.19242": {"title": "Modeling public opinion control by a charismatic leader", "link": "https://arxiv.org/abs/2405.19242", "description": "arXiv:2405.19242v1 Announce Type: cross \nAbstract: We study the average long-time behavior of the binary opinions of a social group with peer-to-peer interactions under the influence of an external bias and a persuadable leader, a strongly-biased agent with a dynamic opinion with the intention of spreading it across the system. We use a generalized, fully-connected Ising model, with each spin representing the binary opinion of an agent at a given time and a single, super spin representing the opinion of the leader. External fields and interaction constants model the opinion bias and peer-to-peer interactions, respectively, while the temperature $T$ models an idealized social climate, representing an authoritarian regime if $T$ is low or a liberal one if $T$ is high. We derive a mean-field solution for the average magnetization $m$, the \"social mood\", and investigate how $m$ and the super spin magnetization vary as a function of $T$. We find that, depending on the initial conditions, due to the presence of metastable states, the sign of the average magnetization depends on the temperature. Finally, we verify that this effect is also present even if we consider only nearest-neighbor interactions within the social group."}, "https://arxiv.org/abs/2207.14016": {"title": "Cascades towards noise-induced transitions on networks revealed using information flows", "link": "https://arxiv.org/abs/2207.14016", "description": "arXiv:2207.14016v4 Announce Type: replace \nAbstract: Abrupt, system-wide transitions can be endogenously generated by seemingly stable networks of interacting dynamical units, such as mode switching in neuronal networks or public opinion changes in social systems. However, it remains poorly understood how such `noise-induced transitions' emerge from the interplay of network structure and dynamics on the network. Here, we report on two key roles that nodes can play in the progression towards noise-induced tipping points. The models used are dynamical networks where the nodes are governed by the Boltzmann-Gibbs distribution, but the concept is easily generalized. First, so-called `initiator nodes' absorb and then transmit short-lived fluctuations to neighboring nodes, making them temporarily more dynamic. These neighbor nodes can then in turn transmit fluctuations to their neighbors, and so on, leading to a domino-effect where the more stable a node is (i.e., high average free energy barrier), the more neighbors are needed that have become temporarily dynamic. Interestingly, towards the tipping point we identify so-called `stabilizer nodes' whose state information becomes part of the long-term memory of the system, after which the domino-effect is reversed and settles the node in their new stable attractor. We validate these roles by targeted interventions that make tipping points more (or less) likely to begin or lead to systemic change. This opens up possibilities for understanding and controlling endogenously generated metastable behavior."}, "https://arxiv.org/abs/2311.03275": {"title": "HetCAN: A Heterogeneous Graph Cascade Attention Network with Dual-Level Awareness", "link": "https://arxiv.org/abs/2311.03275", "description": "arXiv:2311.03275v2 Announce Type: replace-cross \nAbstract: Heterogeneous graph neural networks(HGNNs) have recently shown impressive capability in modeling heterogeneous graphs that are ubiquitous in real-world applications. Most existing methods for heterogeneous graphs mainly learn node embeddings by stacking multiple convolutional or attentional layers, which can be considered as capturing the high-order information from node-level aspect. However, different types of nodes in heterogeneous graphs have diverse features, it is also necessary to capture interactions among node features, namely the high-order information from feature-level aspect. In addition, most methods first align node features by mapping them into one same low-dimensional space, while they may lose some type information of nodes in this way. To address these problems, in this paper, we propose a novel Heterogeneous graph Cascade Attention Network (HetCAN) composed of multiple cascade blocks. Each cascade block includes two components, the type-aware encoder and the dimension-aware encoder. Specifically, the type-aware encoder compensates for the loss of node type information and aims to make full use of graph heterogeneity. The dimension-aware encoder is able to learn the feature-level high-order information by capturing the interactions among node features. With the assistance of these components, HetCAN can comprehensively encode information of node features, graph heterogeneity and graph structure in node embeddings. Extensive experiments demonstrate the superiority of HetCAN over advanced competitors and also exhibit its efficiency and robustness."}, "https://arxiv.org/abs/2401.03390": {"title": "Dynamics-based Feature Augmentation of Graph Neural Networks for Variant Emergence Prediction", "link": "https://arxiv.org/abs/2401.03390", "description": "arXiv:2401.03390v2 Announce Type: replace-cross \nAbstract: During the COVID-19 pandemic, a major driver of new surges has been the emergence of new variants. When a new variant emerges in one or more countries, other nations monitor its spread in preparation for its potential arrival. The impact of the new variant and the timings of epidemic peaks in a country highly depend on when the variant arrives. The current methods for predicting the spread of new variants rely on statistical modeling, however, these methods work only when the new variant has already arrived in the region of interest and has a significant prevalence. Can we predict when a variant existing elsewhere will arrive in a given region? To address this question, we propose a variant-dynamics-informed Graph Neural Network (GNN) approach. First, we derive the dynamics of variant prevalence across pairs of regions (countries) that apply to a large class of epidemic models. The dynamics motivate the introduction of certain features in the GNN. We demonstrate that our proposed dynamics-informed GNN outperforms all the baselines, including the currently pervasive framework of Physics-Informed Neural Networks (PINNs). To advance research in this area, we introduce a benchmarking tool to assess a user-defined model's prediction performance across 87 countries and 36 variants."}, "https://arxiv.org/abs/2401.04133": {"title": "SynHING: Synthetic Heterogeneous Information Network Generation for Graph Learning and Explanation", "link": "https://arxiv.org/abs/2401.04133", "description": "arXiv:2401.04133v2 Announce Type: replace-cross \nAbstract: Graph Neural Networks (GNNs) excel in delineating graph structures in diverse domains, including community analysis and recommendation systems. As the interpretation of GNNs becomes increasingly important, the demand for robust baselines and expansive graph datasets is accentuated, particularly in the context of Heterogeneous Information Networks (HIN). Addressing this, we introduce SynHING, a novel framework for Synthetic Heterogeneous Information Network Generation aimed at enhancing graph learning and explanation. SynHING systematically identifies major motifs in a target HIN and employs a bottom-up generation process with intra-cluster and inter-cluster merge modules. This process, supplemented by post-pruning techniques, ensures the synthetic HIN closely mirrors the original graph's structural and statistical properties. Crucially, SynHING provides ground-truth motifs for evaluating GNN explainer models, setting a new standard for explainable, synthetic HIN generation and contributing to the advancement of interpretable machine learning in complex networks."}, "https://arxiv.org/abs/2402.02464": {"title": "A Graph is Worth $K$ Words: Euclideanizing Graph using Pure Transformer", "link": "https://arxiv.org/abs/2402.02464", "description": "arXiv:2402.02464v3 Announce Type: replace-cross \nAbstract: Can we model Non-Euclidean graphs as pure language or even Euclidean vectors while retaining their inherent information? The Non-Euclidean property have posed a long term challenge in graph modeling. Despite recent graph neural networks and graph transformers efforts encoding graphs as Euclidean vectors, recovering the original graph from vectors remains a challenge. In this paper, we introduce GraphsGPT, featuring an Graph2Seq encoder that transforms Non-Euclidean graphs into learnable Graph Words in the Euclidean space, along with a GraphGPT decoder that reconstructs the original graph from Graph Words to ensure information equivalence. We pretrain GraphsGPT on $100$M molecules and yield some interesting findings: (1) The pretrained Graph2Seq excels in graph representation learning, achieving state-of-the-art results on $8/9$ graph classification and regression tasks. (2) The pretrained GraphGPT serves as a strong graph generator, demonstrated by its strong ability to perform both few-shot and conditional graph generation. (3) Graph2Seq+GraphGPT enables effective graph mixup in the Euclidean space, overcoming previously known Non-Euclidean challenges. (4) The edge-centric pretraining framework GraphsGPT demonstrates its efficacy in graph domain tasks, excelling in both representation and generation. Code is available at \\href{https://github.com/A4Bio/GraphsGPT}{GitHub}."}, "https://arxiv.org/abs/2405.19369": {"title": "Sublinear Cuts are the Exception in BDF-GIRGs", "link": "https://arxiv.org/abs/2405.19369", "description": "arXiv:2405.19369v1 Announce Type: new \nAbstract: The introduction of geometry has proven instrumental in the efforts towards more realistic models for real-world networks. In Geometric Inhomogeneous Random Graphs (GIRGs), Euclidean Geometry induces clustering of the vertices, which is widely observed in networks in the wild. Euclidean Geometry in multiple dimensions however restricts proximity of vertices to those cases where vertices are close in each coordinate. We introduce a large class of GIRG extensions, called BDF-GIRGs, which capture arbitrary hierarchies of the coordinates within the distance function of the vertex feature space. These distance functions have the potential to allow more realistic modeling of the complex formation of social ties in real-world networks, where similarities between people lead to connections. Here, similarity with respect to certain features, such as familial kinship or a shared workplace, suffices for the formation of ties. It is known that - while many key properties of GIRGs, such as log-log average distance and sparsity, are independent of the distance function - the Euclidean metric induces small separators, i.e. sublinear cuts of the unique giant component in GIRGs, whereas no such sublinear separators exist under the component-wise minimum distance. Building on work of Lengler and Todorovi\\'{c}, we give a complete classification for the existence of small separators in BDF-GIRGs. We further show that BDF-GIRGs all fulfill a stochastic triangle inequality and thus also exhibit clustering."}, "https://arxiv.org/abs/2405.19375": {"title": "Improving global awareness of linkset predictions using Cross-Attentive Modulation tokens", "link": "https://arxiv.org/abs/2405.19375", "description": "arXiv:2405.19375v1 Announce Type: new \nAbstract: Most of multiple link prediction or graph generation techniques rely on the attention mechanism or on Graph Neural Networks (GNNs), which consist in leveraging node-level information exchanges in order to form proper link predictions. Such node-level interactions do not process nodes as an ordered sequence, which would imply some kind of natural ordering of the nodes: they are said to be permutation invariant mechanisms. They are well suited for graph problems, but struggle at providing a global orchestration of the predicted links, which can result in a loss of performance. Some typical issues can be the difficulty to ensure high-level properties such as global connectedness, fixed diameter or to avoid information bottleneck effects such as oversmoothing and oversquashing, which respectively consist in abundant smoothing in dense areas leading to a loss of information and a tendency to exclude isolated nodes from the message passing scheme, and often result in irrelevant, unbalanced link predictions. To tackle this problem, we hereby present Cross-Attentive Modulation (CAM) tokens, which introduce cross-attentive units used to condition node and edge-level modulations in order to enable context-aware computations that improve the global consistency of the prediction links. We will implement it on a few permutation invariant architectures, and showcase benchmarks that prove the merits of our work."}, "https://arxiv.org/abs/2405.19383": {"title": "Network Analytics for Anti-Money Laundering -- A Systematic Literature Review and Experimental Evaluation", "link": "https://arxiv.org/abs/2405.19383", "description": "arXiv:2405.19383v1 Announce Type: new \nAbstract: Money laundering presents a pervasive challenge, burdening society by financing illegal activities. To more effectively combat and detect money laundering, the use of network information is increasingly being explored, exploiting that money laundering necessarily involves interconnected parties. This has lead to a surge in literature on network analytics (NA) for anti-money laundering (AML). The literature, however, is fragmented and a comprehensive overview of existing work is missing. This results in limited understanding of the methods that may be applied and their comparative detection power. Therefore, this paper presents an extensive and systematic review of the literature. We identify and analyse 97 papers in the Web of Science and Scopus databases, resulting in a taxonomy of approaches following the fraud analytics framework of Bockel-Rickermann et al.. Moreover, this paper presents a comprehensive experimental framework to evaluate and compare the performance of prominent NA methods in a uniform setup. The framework is applied on the publicly available Elliptic data set and implements manual feature engineering, random walk-based methods, and deep learning GNNs. We conclude from the results that network analytics increases the predictive power of the AML model with graph neural networks giving the best results. An open source implementation of the experimental framework is provided to facilitate researchers and practitioners to extend upon these results and experiment on proprietary data. As such, we aim to promote a standardised approach towards the analysis and evaluation of network analytics for AML."}, "https://arxiv.org/abs/2405.19459": {"title": "Math behind everyday life: on distribution of \"black days\" and beyond", "link": "https://arxiv.org/abs/2405.19459", "description": "arXiv:2405.19459v1 Announce Type: new \nAbstract: In our daily lives, we encounter numerous independent events, each occurring with varying probabilities over time. This letter delves into the scientific background behind the inhomogeneous distribution of these events over time, often resulting in what we refer to as ``black days'', where multiple events seem to converge at once. In the first part of the work we have performed an analysis involving $D$ independent periodic and random sequences of events. Employing the Uniform Manifold Approximation and Projection (UMAP) technique, we observed a clustering of sequences of events on a 2D manifold ${\\cal M}$ at some large $D_{cr}$, which we interpret as the manifestation of ``black days'' and which occurs in a narrow interval around $D_{cr}$. We found that increasing the number of sequences within rather wide interval below $D_{cr}$ leads to a plateau in the clustering on ${\\cal M}$. In the second part of the work we examined in detail clustering patterns of independently distributed $N$ points within the corners of a $D$-dimensional cube when $1\\ll N<D$. Our findings revealed that a transition to a single-component cluster occurs at a critical dimensionality, $D_{cr}$, via a nearly third-order phase transition. Finally, we have addressed the question ``How the infinite-dimensional space could look like?'' Considering the eigenvalue problem for the hyperspherical Laplacian $\\nabla^2_D$ in the limit $D\\to\\infty$, we conjectured about the topology of a target space representing the hyperspherical layer."}, "https://arxiv.org/abs/2405.19552": {"title": "Point process analysis of geographical diffusion of news in Argentina", "link": "https://arxiv.org/abs/2405.19552", "description": "arXiv:2405.19552v1 Announce Type: new \nAbstract: The diffusion of information plays a crucial role in a society, characterizing the diffusion process is challenging because it is highly non-stationary and varies with the media type. To understand the spreading of newspaper news in Argentina, we collected data from more than 27000 articles published in six main provinces during four months. We classified the articles into 20 thematic axes and obtained a set of 120 time series that capture daily newspaper attention on different topics in different provinces. To analyze the data we use a point process approach. For each topic, $n$, and for all pairs of provinces, $i$ and $j$, we use two measures to quantify the synchronicity of the events, $Q_s(i,j)$, which quantifies the number of events that occur almost simultaneously in $i$ and $j$, and $Q_a(i,j)$, which quantifies the direction of news spreading. We also analyze the dataset using well-known measures to detect correlations and dependencies, computed from the raw time series: undirected measures (linear cross-correlation, $CC$, and nonlinear mutual information, $MI$) and directed measures (linear Granger causality, $GC$, and nonlinear Transfer entropy, $TE$). Our analysis unveils how fast the information diffusion process is, as high values of $Q_{s}$, $CC$, and $MI$ reveal pairs of provinces with very similar and almost simultaneous temporal variations of media attention. On the other hand, $GC$ and $TE$ do not perform well in this context because they often return opposite directions of information transfer. We interpret this as due to three main factors: the characteristics of the data, which is highly non-stationary, the characteristics of the information diffusion process, which is very fast and probably acts at a sub-resolution time scale, and the action of large media companies that act as global, external drivers of information dissemination."}, "https://arxiv.org/abs/2405.19565": {"title": "Unbending strategies shepherd cooperation and suppress extortion in spatial populations", "link": "https://arxiv.org/abs/2405.19565", "description": "arXiv:2405.19565v1 Announce Type: new \nAbstract: Evolutionary game dynamics on networks typically consider the competition among simple strategies such as cooperation and defection in the Prisoner's Dilemma and summarize the effect of population structure as network reciprocity. However, it remains largely unknown regarding the evolutionary dynamics involving multiple powerful strategies typically considered in repeated games, such as the zero-determinant (ZD) strategies that are able to enforce a linear payoff relationship between them and their co-players. Here, we consider the evolutionary dynamics of always cooperate (AllC), extortionate ZD (extortioners), and unbending players in lattice populations based on the commonly used death-birth updating. Out of the class of unbending strategies, we consider a particular candidate, PSO Gambler, a machine-learning-optimized memory-one strategy, which can foster reciprocal cooperation and fairness among extortionate players. We derive analytical results under weak selection and rare mutations, including pairwise fixation probabilities and long-term frequencies of strategies. In the absence of the third unbending type, extortioners can achieve a half-half split in equilibrium with unconditional cooperators for sufficiently large extortion factors. However, the presence of unbending players fundamentally changes the dynamics and tilts the system to favor unbending cooperation. Most surprisingly, extortioners cannot dominate at all regardless of how large their extortion factor is, and the long-term frequency of unbending players is maintained almost as a constant. Our analytical method is applicable to studying the evolutionary dynamics of multiple strategies in structured populations. Our work provides insights into the interplay between network reciprocity and direct reciprocity, revealing the role of unbending strategies in enforcing fairness and suppressing extortion."}, "https://arxiv.org/abs/2405.20166": {"title": "An approximation for return time distributions of random walks on sparse networks", "link": "https://arxiv.org/abs/2405.20166", "description": "arXiv:2405.20166v1 Announce Type: new \nAbstract: We propose an approximation for the first return time distribution of random walks on undirected networks. We combine a message-passing solution with a mean-field approximation, to account for the short- and long-term behaviours respectively. We test this approximation on several classes of large graphs and find excellent agreement between our approximations and the true distributions. While the statistical properties of a random walk will depend on the structure of the network, the observed agreement between our approximations and numerical calculations implies that while local structure is clearly very influential, global structure is only important in a relatively superficial way, namely through the total number of edges."}, "https://arxiv.org/abs/2405.20277": {"title": "Pre-train and Refine: Towards Higher Efficiency in K-Agnostic Community Detection without Quality Degradation", "link": "https://arxiv.org/abs/2405.20277", "description": "arXiv:2405.20277v1 Announce Type: new \nAbstract: Community detection (CD) is a classic graph inference task that partitions nodes of a graph into densely connected groups. While many CD methods have been proposed with either impressive quality or efficiency, balancing the two aspects remains a challenge. This study explores the potential of deep graph learning to achieve a better trade-off between the quality and efficiency of K-agnostic CD, where the number of communities K is unknown. We propose PRoCD (Pre-training & Refinement fOr Community Detection), a simple yet effective method that reformulates K-agnostic CD as the binary node pair classification. PRoCD follows a pre-training & refinement paradigm inspired by recent advances in pre-training techniques. We first conduct the offline pre-training of PRoCD on small synthetic graphs covering various topology properties. Based on the inductive inference across graphs, we then generalize the pre-trained model (with frozen parameters) to large real graphs and use the derived CD results as the initialization of an existing efficient CD method (e.g., InfoMap) to further refine the quality of CD results. In addition to benefiting from the transfer ability regarding quality, the online generalization and refinement can also help achieve high inference efficiency, since there is no time-consuming model optimization. Experiments on public datasets with various scales demonstrate that PRoCD can ensure higher efficiency in K-agnostic CD without significant quality degradation."}, "https://arxiv.org/abs/2405.19436": {"title": "Traffic Modeling and Forecast based on Stochastic Cell-Automata and Distributed Fiber-Optic Sensing -- A Numerical Experiment", "link": "https://arxiv.org/abs/2405.19436", "description": "arXiv:2405.19436v1 Announce Type: cross \nAbstract: This paper demonstrates accurate traffic modeling and forecast using stochastic cell-automata (CA) and distributed fiber-optic sensing (DFOS). Traffic congestion is a dominant issue in highways. To reduce congestion, real-time traffic control by short-term forecast is necessary. For achieving this, data assimilation using a stochastic CA model and DFOS is promising. Data assimilation with a CA enables us to model real-time traffic flow with simple processes even when rare or sudden events occur, which is challenging for usual machine learning-based methods. DFOS overcomes issues of conventional point sensors that have dead zones of observation. By estimating optimal model parameters that reproduce observed traffic flow in the simulation, future traffic flow is forecasted from the simulation. We propose an optimal model parameter estimation method using mean velocity as an extracted feature and the particle filter. In addition, an estimation methodology for the microscopic traffic situation is developed to set the initial condition of simulation for forecast in accordance with observation. The proposed methods are verified by simulation-based traffic flow. The simulation adopts the stochastic Nishinari-Fukui-Schadschneider model. The optimal model parameters are successfully derived from posterior probability distributions (PPDs) estimated from DFOS data. In contrast, those estimated from point sensors fail. The PPDs of model parameters also indicate that each parameter has different sensitivities to traffic flow. A traffic forecast up to 60 minutes later is carried out. Using optimal model parameters estimated from DFOS, the forecast error of mean velocity is approximately $\\pm$10 km/h (percentage error is 18%). The error attains half of it when conventional point sensors are used. We conclude that DFOS is a powerful technique for traffic modeling and short-term forecast."}, "https://arxiv.org/abs/2402.07656": {"title": "Low Cost Carriers induce specific and identifiable delay propagation patterns: an analysis of the EU and US systems", "link": "https://arxiv.org/abs/2402.07656", "description": "arXiv:2402.07656v2 Announce Type: replace \nAbstract: The impact of air transport delays and their propagation has long been studied, mainly from environmental and mobility viewpoints, using a wide range of data analysis tools and simulations. Less attention has nevertheless been devoted to how delays create meso-scale structures around each airport. In this work we tackle this issue by reconstructing functional networks of delay propagation centred at each airport, and studying their identifiability (i.e. how unique they are) using Deep Learning models. We find that such delay propagation neighbourhoods are highly unique when they correspond to airports with a high share of Low Cost Carriers operations; and demonstrate the robustness of these findings for the EU and US systems, and to different methodological choices. We further discuss some operational implications of this uniqueness."}, "https://arxiv.org/abs/2405.20457": {"title": "Online network topology shapes personal narratives and hashtag generation", "link": "https://arxiv.org/abs/2405.20457", "description": "arXiv:2405.20457v1 Announce Type: new \nAbstract: While narratives have shaped cognition and cultures for centuries, digital media and online social networks have introduced new narrative phenomena. With increased narrative agency, networked groups of individuals can directly contribute and steer narratives that center our collective discussions of politics, science, and morality. We report the results of an online network experiment on narrative and hashtag generation, in which networked groups of participants interpreted a text-based narrative of a disaster event, and were incentivized to produce matching hashtags with their network neighbors. We found that network structure not only influences the emergence of dominant beliefs through coordination with network neighbors, but also impacts participants' use of causal language in their personal narratives."}, "https://arxiv.org/abs/2405.20740": {"title": "Discrete Lanchester attrition models: the case of precautionary surrender", "link": "https://arxiv.org/abs/2405.20740", "description": "arXiv:2405.20740v1 Announce Type: new \nAbstract: Discrete Lanchester-type attrition models describe many types of antagonistic situations; the preferred interpretation is two fleets of battleships, each trying to sink the other. Such models may be characterised by a bivariate recurrence relation. Here I consider a restricted case in which a fleet that finds itself two or three units behind its opponent immediately surrenders. I present some theoretical and numerical results and suggest lines for further work."}, "https://arxiv.org/abs/2405.20918": {"title": "Flexible inference in heterogeneous and attributed multilayer networks", "link": "https://arxiv.org/abs/2405.20918", "description": "arXiv:2405.20918v1 Announce Type: new \nAbstract: Networked datasets are often enriched by different types of information about individual nodes or edges. However, most existing methods for analyzing such datasets struggle to handle the complexity of heterogeneous data, often requiring substantial model-specific analysis. In this paper, we develop a probabilistic generative model to perform inference in multilayer networks with arbitrary types of information. Our approach employs a Bayesian framework combined with the Laplace matching technique to ease interpretation of inferred parameters. Furthermore, the algorithmic implementation relies on automatic differentiation, avoiding the need for explicit derivations. This makes our model scalable and flexible to adapt to any combination of input data. We demonstrate the effectiveness of our method in detecting overlapping community structures and performing various prediction tasks on heterogeneous multilayer data, where nodes and edges have different types of attributes. Additionally, we showcase its ability to unveil a variety of patterns in a social support network among villagers in rural India by effectively utilizing all input information in a meaningful way."}, "https://arxiv.org/abs/2405.20445": {"title": "GraphAny: A Foundation Model for Node Classification on Any Graph", "link": "https://arxiv.org/abs/2405.20445", "description": "arXiv:2405.20445v1 Announce Type: cross \nAbstract: Foundation models that can perform inference on any new task without requiring specific training have revolutionized machine learning in vision and language applications. However, applications involving graph-structured data remain a tough nut for foundation models, due to challenges in the unique feature- and label spaces associated with each graph. Traditional graph ML models such as graph neural networks (GNNs) trained on graphs cannot perform inference on a new graph with feature and label spaces different from the training ones. Furthermore, existing models learn functions specific to the training graph and cannot generalize to new graphs. In this work, we tackle these two challenges with a new foundational architecture for inductive node classification named GraphAny. GraphAny models inference on a new graph as an analytical solution to a LinearGNN, thereby solving the first challenge. To solve the second challenge, we learn attention scores for each node to fuse the predictions of multiple LinearGNNs. Specifically, the attention module is carefully parameterized as a function of the entropy-normalized distance-features between multiple LinearGNNs predictions to ensure generalization to new graphs. Empirically, GraphAny trained on the Wisconsin dataset with only 120 labeled nodes can effectively generalize to 30 new graphs with an average accuracy of 67.26\\% in an inductive manner, surpassing GCN and GAT trained in the supervised regime, as well as other inductive baselines."}, "https://arxiv.org/abs/2405.20640": {"title": "Heterophilous Distribution Propagation for Graph Neural Networks", "link": "https://arxiv.org/abs/2405.20640", "description": "arXiv:2405.20640v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) have achieved remarkable success in various graph mining tasks by aggregating information from neighborhoods for representation learning. The success relies on the homophily assumption that nearby nodes exhibit similar behaviors, while it may be violated in many real-world graphs. Recently, heterophilous graph neural networks (HeterGNNs) have attracted increasing attention by modifying the neural message passing schema for heterophilous neighborhoods. However, they suffer from insufficient neighborhood partition and heterophily modeling, both of which are critical but challenging to break through. To tackle these challenges, in this paper, we propose heterophilous distribution propagation (HDP) for graph neural networks. Instead of aggregating information from all neighborhoods, HDP adaptively separates the neighbors into homophilous and heterphilous parts based on the pseudo assignments during training. The heterophilous neighborhood distribution is learned with orthogonality-oriented constraint via a trusted prototype contrastive learning paradigm. Both the homophilous and heterophilous patterns are propagated with a novel semantic-aware message passing mechanism. We conduct extensive experiments on 9 benchmark datasets with different levels of homophily. Experimental results show that our method outperforms representative baselines on heterophilous datasets."}, "https://arxiv.org/abs/2405.20702": {"title": "Effect of antibody levels on the spread of disease in multiple infections", "link": "https://arxiv.org/abs/2405.20702", "description": "arXiv:2405.20702v1 Announce Type: cross \nAbstract: There are complex interactions between antibody levels and epidemic propagation, the antibody level of an individual influences the probability of infection, and the spread of the virus influences the antibody level of each individual. There exist some viruses that, in their natural state, cause antibody levels in an infected individual to gradually decay. When these antibody levels decay to a certain point, the individual can be reinfected, such as with COVID 19. To describe their interaction, we introduce a novel mathematical model that incorporates the presence of an antibody retention rate to investigate the infection patterns of individuals who survive multiple infections. The model is composed of a system of stochastic differential equations to derive the equilibrium point and threshold of the model and presents rich experimental results of numerical simulations to further elucidate the propagation properties of the model. We find that the antibody decay rate strongly affects the propagation process, and also that different network structures have different sensitivities to the antibody decay rate, and that changes in the antibody decay rate cause stronger changes in the propagation process in Barabasi Albert networks. Furthermore, we investigate the stationary distribution of the number of infection states and the final antibody levels, and find that they both satisfy the normal distribution, but the standard deviation is small in the Barabasi Albert network. Finally, we explore the effect of individual antibody differences and decay rates on the final population antibody levels, and uncover that individual antibody differences do not affect the final mean antibody levels. The study offers valuable insights for epidemic prevention and control in practical applications."}, "https://arxiv.org/abs/2405.20724": {"title": "Learning on Large Graphs using Intersecting Communities", "link": "https://arxiv.org/abs/2405.20724", "description": "arXiv:2405.20724v1 Announce Type: cross \nAbstract: Message Passing Neural Networks (MPNNs) are a staple of graph machine learning. MPNNs iteratively update each node's representation in an input graph by aggregating messages from the node's neighbors, which necessitates a memory complexity of the order of the number of graph edges. This complexity might quickly become prohibitive for large graphs provided they are not very sparse. In this paper, we propose a novel approach to alleviate this problem by approximating the input graph as an intersecting community graph (ICG) -- a combination of intersecting cliques. The key insight is that the number of communities required to approximate a graph does not depend on the graph size. We develop a new constructive version of the Weak Graph Regularity Lemma to efficiently construct an approximating ICG for any input graph. We then devise an efficient graph learning algorithm operating directly on ICG in linear memory and time with respect to the number of nodes (rather than edges). This offers a new and fundamentally different pipeline for learning on very large non-sparse graphs, whose applicability is demonstrated empirically on node classification tasks and spatio-temporal data processing."}, "https://arxiv.org/abs/2404.01489": {"title": "Perceived Social Influence on Vaccination Decisions: A COVID-19 Case Study", "link": "https://arxiv.org/abs/2404.01489", "description": "arXiv:2404.01489v2 Announce Type: replace \nAbstract: In this study, we examine the perceived influence of others, across both strong and weak social ties, on COVID-19 vaccination decisions in the United States. We add context to social influence by measuring related concepts, such as perceived agreement of others and perceived danger of COVID-19 to others. We find that vaccinated populations perceived more influence from their social circles than unvaccinated populations. This finding holds true across various social groups, including family, close friends, and neighbors. Vaccinated participants perceived that others agreed with their decision to get vaccinated more than unvaccinated participants perceived others to agree with their decision to not get vaccinated. Despite the clear differences in perceived social influence and agreement across the groups, the majority of participants across both vaccinated and unvaccinated populations perceived no social influence from all social group in their decisions. Aligning with this result, we find through open-ended responses that both vaccinated and unvaccinated participants frequently cited fear as a motivating factor in their decision, rather than social influence: vaccinated participants feared COVID-19, while unvaccinated participants feared the vaccine itself."}, "https://arxiv.org/abs/2211.04634": {"title": "Learning Optimal Graph Filters for Clustering of Attributed Graphs", "link": "https://arxiv.org/abs/2211.04634", "description": "arXiv:2211.04634v2 Announce Type: replace-cross \nAbstract: Many real-world systems can be represented as graphs where the different entities in the system are presented by nodes and their interactions by edges. An important task in studying large datasets with graphical structure is graph clustering. While there has been a lot of work on graph clustering using the connectivity between the nodes, many real-world networks also have node attributes. Clustering attributed graphs requires joint modeling of graph structure and node attributes. Recent work has focused on combining these two complementary sources of information through graph convolutional networks and graph filtering. However, these methods are mostly limited to lowpass filtering and do not explicitly learn the filter parameters for the clustering task. In this paper, we introduce a graph signal processing based approach, where we learn the parameters of Finite Impulse Response (FIR) and Autoregressive Moving Average (ARMA) graph filters optimized for clustering. The proposed approach is formulated as a two-step iterative optimization problem, focusing on learning interpretable graph filters that are optimal for the given data and that maximize the separation between different clusters. The proposed approach is evaluated on attributed networks and compared to the state-of-the-art methods."}, "https://arxiv.org/abs/2305.09938": {"title": "Mastering Long-Tail Complexity on Graphs: Characterization, Learning, and Generalization", "link": "https://arxiv.org/abs/2305.09938", "description": "arXiv:2305.09938v4 Announce Type: replace-cross \nAbstract: In the context of long-tail classification on graphs, the vast majority of existing work primarily revolves around the development of model debiasing strategies, intending to mitigate class imbalances and enhance the overall performance. Despite the notable success, there is very limited literature that provides a theoretical tool for characterizing the behaviors of long-tail classes in graphs and gaining insight into generalization performance in real-world scenarios. To bridge this gap, we propose a generalization bound for long-tail classification on graphs by formulating the problem in the fashion of multi-task learning, i.e., each task corresponds to the prediction of one particular class. Our theoretical results show that the generalization performance of long-tail classification is dominated by the overall loss range and the task complexity. Building upon the theoretical findings, we propose a novel generic framework HierTail for long-tail classification on graphs. In particular, we start with a hierarchical task grouping module that allows us to assign related tasks into hypertasks and thus control the complexity of the task space; then, we further design a balanced contrastive learning module to adaptively balance the gradients of both head and tail classes to control the loss range across all tasks in a unified fashion. Extensive experiments demonstrate the effectiveness of HierTail in characterizing long-tail classes on real graphs, which achieves up to 12.9% improvement over the leading baseline method in accuracy."}, "https://arxiv.org/abs/2406.00344": {"title": "Efficient Historical Butterfly Counting in Large Temporal Bipartite Networks via Graph Structure-aware Index", "link": "https://arxiv.org/abs/2406.00344", "description": "arXiv:2406.00344v1 Announce Type: new \nAbstract: Bipartite graphs are ubiquitous in many domains, e.g., e-commerce platforms, social networks, and academia, by modeling interactions between distinct entity sets. Within these graphs, the butterfly motif, a complete 2*2 biclique, represents the simplest yet significant subgraph structure, crucial for analyzing complex network patterns. Counting the butterflies offers significant benefits across various applications, including community analysis and recommender systems. Additionally, the temporal dimension of bipartite graphs, where edges activate within specific time frames, introduces the concept of historical butterfly counting, i.e., counting butterflies within a given time interval. This temporal analysis sheds light on the dynamics and evolution of network interactions, offering new insights into their mechanisms. Despite its importance, no existing algorithm can efficiently solve the historical butterfly counting task. To address this, we design two novel indices whose memory footprints are dependent on #butterflies and #wedges, respectively. Combining these indices, we propose a graph structure-aware indexing approach that significantly reduces memory usage while preserving exceptional query speed. We theoretically prove that our approach is particularly advantageous on power-law graphs, a common characteristic of real-world bipartite graphs, by surpassing traditional complexity barriers for general graphs. Extensive experiments reveal that our query algorithms outperform existing methods by up to five magnitudes, effectively balancing speed with manageable memory requirements."}, "https://arxiv.org/abs/2406.01113": {"title": "Bridging the Digital Divide: Mapping Internet Connectivity Evolution, Inequalities, and Resilience in six Brazilian Cities", "link": "https://arxiv.org/abs/2406.01113", "description": "arXiv:2406.01113v1 Announce Type: new \nAbstract: We investigate the evolution of Internet speed and its implications for access to key digital services, as well as the resilience of the network during crises, focusing on six major Brazilian cities: Belo Horizonte, Bras\\'ilia, Fortaleza, Manaus, Rio de Janeiro, and S\\~ao Paulo. Leveraging a unique dataset of Internet Speedtest results provided by Ookla, we analyze Internet speed trends from 2017 to 2023. Our findings reveal significant improvements in Internet speed across all cities. However, we find that prosperous areas generally exhibit better Internet access, and that the dependence of Internet quality on wealth have increased over time. Additionally, we investigate the impact of Internet quality on access to critical online services, focusing on e-learning. Our analysis shows that nearly 13% of catchment areas around educational facilities have Internet speeds below the threshold required for e-learning, with less rich areas experiencing more significant challenges. Moreover, we investigate the network's resilience during the COVID-19 pandemic, finding a sharp decline in network quality following the declaration of national emergency. We also find that less wealthy areas experience larger drops in network quality during crises. Overall, this study underscores the importance of addressing disparities in Internet access to ensure equitable access to digital services and enhance network resilience during crises"}, "https://arxiv.org/abs/2406.01341": {"title": "Important node identification for complex networks based on improved Electre Multi-Attribute fusion", "link": "https://arxiv.org/abs/2406.01341", "description": "arXiv:2406.01341v1 Announce Type: new \nAbstract: Influence maximization problem involves selecting a subset of seed nodes within a social network to maximize information spread under a given diffusion model, so how to identify the important nodes is the problem to be considered in this paper. Due to the great differences in the reality of the network, a class of multi-attribute decision fusion methods is often used to solve this problem. Electre is mostly used to solve the problems of investment order, benefit, and risk assessment of projects in economics, which supports the decision maker to make choices by comparing the differences between a set of alternatives. In this paper, we propose a multi-attribute decision fusion method named SK-E, which construct local and global metrics for different networks, use the improved Electre to make decision fusion between local and global metrics of nodes, to get the optimal weight between local and global metrics, and then identify the important nodes. The proposed method demonstrates superior accuracy compared to other methods, as evaluated through three experiments: the SIR epidemic model, the independent cascade model, and constraint efficiency. These experiments were conducted across six different real networks selected as the experimental dataset."}, "https://arxiv.org/abs/2406.01367": {"title": "Structural prediction of super-diffusion in multiplex networks", "link": "https://arxiv.org/abs/2406.01367", "description": "arXiv:2406.01367v1 Announce Type: new \nAbstract: Diffusion dynamics in multiplex networks can model a diverse number of real-world processes. In some specific configurations of these systems, the super-diffusion phenomenon arises, in which the diffusion is faster in the multiplex network than in any of its layers. Many studies attempt to characterize this phenomenon by examining its dependency on structural properties of the network, such as overlap, average degree, network dissimilarity, and others. While certain properties show a correlation with super-diffusion in specific networks, a broader characterization is still missing. Here, we introduce a structural parameter based on the minimum node strength that effectively predicts the occurrence of super-diffusion in multiplex networks. Additionally, we propose a novel framework for deriving analytical bounds for several multiplex networks structures. Finally, we analyze and justify why certain arrangements of the inter-layer connections induce super-diffusion. These findings provide novel insights into the super-diffusion phenomenon and the interplay between network structure and dynamics."}, "https://arxiv.org/abs/2406.01517": {"title": "Beyond symmetrization: effective adjacency matrices and renormalization for (un)singed directed graphs", "link": "https://arxiv.org/abs/2406.01517", "description": "arXiv:2406.01517v1 Announce Type: new \nAbstract: To address the peculiarities of directed and/or signed graphs, new Laplacian operators have emerged. For instance, in the case of directionality, we encounter the magnetic operator, dilation (which is underexplored), operators based on random walks, and so forth. The definition of these new operators leads to the need for new studies and concepts, and consequently, the development of new computational tools. But is this really necessary? In this work, we define the concept of effective adjacency matrices that arise from the definition of deformed Laplacian operators such as magnetic, dilation, and signal. These effective matrices allow mapping generic graphs to a family of unsigned, undirected graphs, enabling the application of the well-explored toolkit of measures, machine learning methods, and renormalization groups of undirected graphs. To explore the interplay between deformed operators and effective matrices, we show how the Hodge-Helmholtz decomposition can assist us in navigating this complexity."}, "https://arxiv.org/abs/2406.00617": {"title": "Maximum $k$-Plex Search: An Alternated Reduction-and-Bound Method", "link": "https://arxiv.org/abs/2406.00617", "description": "arXiv:2406.00617v1 Announce Type: cross \nAbstract: $k$-plexes relax cliques by allowing each vertex to disconnect to at most $k$ vertices. Finding a maximum $k$-plex in a graph is a fundamental operator in graph mining and has been receiving significant attention from various domains. The state-of-the-art algorithms all adopt the branch-reduction-and-bound (BRB) framework where a key step, called reduction-and-bound (RB), is used for narrowing down the search space. A common practice of RB in existing works is SeqRB, which sequentially conducts the reduction process followed by the bounding process once at a branch. However, these algorithms suffer from the efficiency issues. In this paper, we propose a new alternated reduction-and-bound method AltRB for conducting RB. AltRB first partitions a branch into two parts and then alternatively and iteratively conducts the reduction process and the bounding process at each part of a branch. With newly-designed reduction rules and bounding methods, AltRB is superior to SeqRB in effectively narrowing down the search space in both theory and practice. Further, to boost the performance of BRB algorithms, we develop efficient and effective pre-processing methods which reduce the size of the input graph and heuristically compute a large $k$-plex as the lower bound. We conduct extensive experiments on 664 real and synthetic graphs. The experimental results show that our proposed algorithm kPEX with AltRB and novel pre-processing techniques runs up to two orders of magnitude faster and solves more instances than state-of-the-art algorithms."}, "https://arxiv.org/abs/2406.00864": {"title": "Optimal Control of General Impulsive VS-EIAR Epidemic Models with Application to Covid-19", "link": "https://arxiv.org/abs/2406.00864", "description": "arXiv:2406.00864v1 Announce Type: cross \nAbstract: In this work, we are interested in a VS-EIAR epidemiological model considering vaccinated individuals ${V_i: i=1,\\ldots,n}$, where $n\\in \\mathbb{N}^{*}$. The dynamic of the VS-EIAR model involves several ordinary differential equations that describe the changes in the vaccinated, susceptible, infected, exposed, asymptomatic, and deceased population groups. Our aim is to reduce the number of susceptible, exposed, infected, and asymptomatic individuals by administering vaccination doses to susceptible individuals and treatment to infected population. To achieve this, we utilize optimal control theory to regulate the dynamic of our considered epidemic model within a terminal optimal time $\\tau^{*}$. Pontryagin's maximum principle (PMP) will be employed to establish the existence of an optimal control time $(v^{*}(t), u^{*}(t))$. We also incorporate an impulsive VS-EIAR epidemic model, with special attention given to immigration or the travel of certain population groups. Finally, we provide a numerical simulation to demonstrate the practical implementation of the theoretical findings."}, "https://arxiv.org/abs/2406.00987": {"title": "Enhancing Fairness in Unsupervised Graph Anomaly Detection through Disentanglement", "link": "https://arxiv.org/abs/2406.00987", "description": "arXiv:2406.00987v1 Announce Type: cross \nAbstract: Graph anomaly detection (GAD) is increasingly crucial in various applications, ranging from financial fraud detection to fake news detection. However, current GAD methods largely overlook the fairness problem, which might result in discriminatory decisions skewed toward certain demographic groups defined on sensitive attributes (e.g., gender, religion, ethnicity, etc.). This greatly limits the applicability of these methods in real-world scenarios in light of societal and ethical restrictions. To address this critical gap, we make the first attempt to integrate fairness with utility in GAD decision-making. Specifically, we devise a novel DisEntangle-based FairnEss-aware aNomaly Detection framework on the attributed graph, named DEFEND. DEFEND first introduces disentanglement in GNNs to capture informative yet sensitive-irrelevant node representations, effectively reducing societal bias inherent in graph representation learning. Besides, to alleviate discriminatory bias in evaluating anomalous nodes, DEFEND adopts a reconstruction-based anomaly detection, which concentrates solely on node attributes without incorporating any graph structure. Additionally, given the inherent association between input and sensitive attributes, DEFEND constrains the correlation between the reconstruction error and the predicted sensitive attributes. Our empirical evaluations on real-world datasets reveal that DEFEND performs effectively in GAD and significantly enhances fairness compared to state-of-the-art baselines. To foster reproducibility, our code is available at https://github.com/AhaChang/DEFEND."}, "https://arxiv.org/abs/2406.01101": {"title": "Fast and Robust Flocking of Protesters on Street Networks", "link": "https://arxiv.org/abs/2406.01101", "description": "arXiv:2406.01101v1 Announce Type: cross \nAbstract: We propose a simple model of protesters scattered throughout a city who want to gather into large and mobile groups. This model relies on random walkers on a street network that follow tactics built from a set of basic rules. Our goal is to identify the most important rules for fast and robust flocking of walkers. We explore a wide set of tactics and show the central importance of a specific rule based on alignment. Other rules alone perform poorly, but our experiments show that combining alignment with them enhances flocking, and that obtained groups are then remarkably robust."}, "https://arxiv.org/abs/2010.12303": {"title": "Random hyperbolic graphs in $d+1$ dimensions", "link": "https://arxiv.org/abs/2010.12303", "description": "arXiv:2010.12303v4 Announce Type: replace \nAbstract: We consider random hyperbolic graphs in hyperbolic spaces of any dimension $d+1\\geq 2$. We present a rescaling of model parameters that casts the random hyperbolic graph model of any dimension to a unified mathematical framework, leaving the degree distribution invariant with respect to the dimension. Unlike the degree distribution, clustering does depend on the dimension, decreasing to 0 at $d \\rightarrow \\infty$. We analyze all of the other limiting regimes of the model, and we release a software package that generates random hyperbolic graphs and their limits in hyperbolic spaces of any dimension."}, "https://arxiv.org/abs/2206.01393": {"title": "Simulation of Crowd Egress with Environmental Stressors", "link": "https://arxiv.org/abs/2206.01393", "description": "arXiv:2206.01393v5 Announce Type: replace \nAbstract: This article introduces a modeling framework to characterize evacuee response to environmental stimuli during emergency egress. The model is developed in consistency with stress theory, which explains how an organism reacts to environmental stressors. We integrate the theory into the well-known social-force model, and develop a framework to simulate crowd evacuation behavior in multi-compartment buildings. Our method serves as a theoretical basis to study crowd movement at bottlenecks, and simulate their herding and way-finding behavior in normal and hazardous conditions. The pre-movement behavior is also briefly investigated by using opinion dynamics with social group model. The algorithms have been partly tested in FDS+EVAC as well as our simulation platform crowdEgress."}, "https://arxiv.org/abs/2212.11051": {"title": "Correlation distances in social networks", "link": "https://arxiv.org/abs/2212.11051", "description": "arXiv:2212.11051v2 Announce Type: replace \nAbstract: In this work we explore degree assortativity in complex networks, and extend its usual definition beyond that of nearest neighbours. We apply this definition to model networks, and describe a rewiring algorithm that induces assortativity. We compare these results to real networks. Social networks in particular tend to be assortatively mixed by degree in contrast to many other types of complex networks. However, we show here that these positive correlations diminish after one step and in most of the empirical networks analysed. Properties besides degree support this, such as the number of papers in scientific coauthorship networks, with no correlations beyond nearest neighbours. Beyond next-nearest neighbours we also observe a diasassortative tendency for nodes three steps away indicating that nodes at that distance are more likely different than similar."}, "https://arxiv.org/abs/2305.09601": {"title": "Operationalizing content moderation \"accuracy\" in the Digital Services Act", "link": "https://arxiv.org/abs/2305.09601", "description": "arXiv:2305.09601v4 Announce Type: replace \nAbstract: The Digital Services Act, recently adopted by the EU, requires social media platforms to report the \"accuracy\" of their automated content moderation systems. The colloquial term is vague, or open-textured -- the literal accuracy (number of correct predictions divided by the total) is not suitable for problems with large class imbalance, and the ground truth and dataset to measure accuracy against is unspecified. Without further specification, the regulatory requirement allows for deficient reporting. In this interdisciplinary work, we operationalize \"accuracy\" reporting by refining legal concepts and relating them to technical implementation. We start by elucidating the legislative purpose of the Act to legally justify an interpretation of \"accuracy\" as precision and recall. These metrics remain informative in class imbalanced settings, and reflect the proportional balancing of Fundamental Rights of the EU Charter. We then focus on the estimation of recall, as its naive estimation can incur extremely high annotation costs and disproportionately interfere with the platform's right to conduct business. Through a simulation study, we show that recall can be efficiently estimated using stratified sampling with trained classifiers, and provide concrete recommendations for its application. Finally, we present a case study of recall reporting for a subset of Reddit under the Act. Based on the language in the Act, we identify a number of ways recall could be reported due to underspecification. We report on one possibility using our improved estimator, and discuss the implications and areas for further legal clarification."}, "https://arxiv.org/abs/2402.10659": {"title": "Network Formation and Dynamics Among Multi-LLMs", "link": "https://arxiv.org/abs/2402.10659", "description": "arXiv:2402.10659v3 Announce Type: replace \nAbstract: Social networks shape opinions, behaviors, and information dissemination in human societies. As large language models (LLMs) increasingly integrate into social and professional environments, understanding their behavior within the context of social interactions and networks becomes essential. Our study analyzes LLMs' network formation behavior to examine whether the dynamics of multiple LLMs are similar to or different from human social dynamics. We observe that LLMs exhibit key social network principles, including preferential attachment, triadic closure, homophily, community structure, and the small-world phenomenon, when asked about their preferences in network formation. We also investigate LLMs' decision-making based on real-world networks, revealing that triadic closure and homophily have a stronger influence than preferential attachment and that LLMs perform well in network formation predictions. Overall, our study opens up new possibilities for using LLMs in network science research and helps develop socially aware LLMs by shedding light on their social interaction behaviors and exploring their impacts on social dynamics."}, "https://arxiv.org/abs/2403.08372": {"title": "Negative Impact of Online Political Incivility on Willingness to See Political Comments", "link": "https://arxiv.org/abs/2403.08372", "description": "arXiv:2403.08372v2 Announce Type: replace \nAbstract: Recently, there has been significant attention on online political incivility. While previous research suggests that uncivil political comments lead people to be less willing to see more comments on the same issue, two critical questions have received limited exploration: (1) Are people exposed to uncivil political comments less willing to see other comments from the person who posted the uncivil comment?; (2) Are people exposed to uncivil political comments less willing to see comments from people who have different thoughts than them? To address these questions, the present study conducted a preregistered online survey experiment targeting Japanese citizens, focusing on the pro- vs anti-Kishida cabinet conflict in Japan. The results show that the participants were less willing to see other comments by the person who posted the comment when the comment was uncivil than when it was civil. In addition, the anti-Kishida participants were less willing to see political opinions posted online by people who have different thoughts than them when the comment was uncivil than when it was civil, while the participants in the other subgroups did not show a similar tendency. These findings suggest that uncivil expressions in online political communication might prompt people to avoid reading opinions from those who have different thoughts than them, which might promote political echo chambers."}, "https://arxiv.org/abs/2004.03925": {"title": "Word frequency and sentiment analysis of twitter messages during Coronavirus pandemic", "link": "https://arxiv.org/abs/2004.03925", "description": "arXiv:2004.03925v2 Announce Type: replace-cross \nAbstract: The COVID-19 epidemic has had a great impact on social media conversation, especially on sites like Twitter, which has emerged as a hub for public reaction and information sharing. This paper deals by analyzing a vast dataset of Twitter messages related to this disease, starting from January 2020. Two approaches were used: a statistical analysis of word frequencies and a sentiment analysis to gauge user attitudes. Word frequencies are modeled using unigrams, bigrams, and trigrams, with power law distribution as the fitting model. The validity of the model is confirmed through metrics like Sum of Squared Errors (SSE), R-squared ($R^2$), and Root Mean Squared Error (RMSE). High $R^2$ and low SSE/RMSE values indicate a good fit for the model. Sentiment analysis is conducted to understand the general emotional tone of Twitter users messages. The results reveal that a majority of tweets exhibit neutral sentiment polarity, with only 2.57\\% expressing negative polarity."}, "https://arxiv.org/abs/2204.12095": {"title": "PyGOD: A Python Library for Graph Outlier Detection", "link": "https://arxiv.org/abs/2204.12095", "description": "arXiv:2204.12095v3 Announce Type: replace-cross \nAbstract: PyGOD is an open-source Python library for detecting outliers in graph data. As the first comprehensive library of its kind, PyGOD supports a wide array of leading graph-based methods for outlier detection under an easy-to-use, well-documented API designed for use by both researchers and practitioners. PyGOD provides modularized components of the different detectors implemented so that users can easily customize each detector for their purposes. To ease the construction of detection workflows, PyGOD offers numerous commonly used utility functions. To scale computation to large graphs, PyGOD supports functionalities for deep models such as sampling and mini-batch processing. PyGOD uses best practices in fostering code reliability and maintainability, including unit testing, continuous integration, and code coverage. To facilitate accessibility, PyGOD is released under a BSD 2-Clause license at https://pygod.org and at the Python Package Index (PyPI)."}, "https://arxiv.org/abs/2304.10578": {"title": "Quantifying the Benefit of Artificial Intelligence for Scientific Research", "link": "https://arxiv.org/abs/2304.10578", "description": "arXiv:2304.10578v2 Announce Type: replace-cross \nAbstract: The ongoing artificial intelligence (AI) revolution has the potential to change almost every line of work. As AI capabilities continue to improve in accuracy, robustness, and reach, AI may outperform and even replace human experts across many valuable tasks. Despite enormous effort devoted to understanding the impact of AI on labor and the economy and AI's recent successes in accelerating scientific discovery and progress, we lack a systematic understanding of how AI advances may benefit scientific research across disciplines and fields. Here, drawing from the literature on the future of work and the science of science, we develop a measurement framework to estimate both the direct use of AI and the potential benefit of AI in scientific research, applying natural language processing techniques to 74.6 million publications and 7.1 million patents. We find that the use of AI in research is widespread throughout the sciences, growing especially rapidly since 2015, and papers that use AI exhibit a citation premium, more likely to be highly cited both within and outside their disciplines. Moreover, our analysis reveals considerable potential for AI to benefit numerous scientific fields, yet a notable disconnect exists between AI education and its research applications, highlighting a mismatch between the supply of AI expertise and its demand in research. Lastly, we examine demographic disparities in AI's benefits across scientific disciplines and find that disciplines with a higher proportion of women or Black scientists tend to be associated with less benefit, suggesting that AI's growing impact on research may further exacerbate existing inequalities in science. As the connection between AI and scientific research deepens, our findings may become increasingly important, with implications for the equity and sustainability of the research enterprise."}, "https://arxiv.org/abs/2305.15927": {"title": "Parameter Estimation in DAGs from Incomplete Data via Optimal Transport", "link": "https://arxiv.org/abs/2305.15927", "description": "arXiv:2305.15927v4 Announce Type: replace-cross \nAbstract: Estimating the parameters of a probabilistic directed graphical model from incomplete data is a long-standing challenge. This is because, in the presence of latent variables, both the likelihood function and posterior distribution are intractable without assumptions about structural dependencies or model classes. While existing learning methods are fundamentally based on likelihood maximization, here we offer a new view of the parameter learning problem through the lens of optimal transport. This perspective licenses a general framework that operates on any directed graphs without making unrealistic assumptions on the posterior over the latent variables or resorting to variational approximations. We develop a theoretical framework and support it with extensive empirical evidence demonstrating the versatility and robustness of our approach. Across experiments, we show that not only can our method effectively recover the ground-truth parameters but it also performs comparably or better than competing baselines on downstream applications."}, "https://arxiv.org/abs/2306.00488": {"title": "Reconstructing Graph Diffusion History from a Single Snapshot", "link": "https://arxiv.org/abs/2306.00488", "description": "arXiv:2306.00488v4 Announce Type: replace-cross \nAbstract: Diffusion on graphs is ubiquitous with numerous high-impact applications. In these applications, complete diffusion histories play an essential role in terms of identifying dynamical patterns, reflecting on precaution actions, and forecasting intervention effects. Despite their importance, complete diffusion histories are rarely available and are highly challenging to reconstruct due to ill-posedness, explosive search space, and scarcity of training data. To date, few methods exist for diffusion history reconstruction. They are exclusively based on the maximum likelihood estimation (MLE) formulation and require to know true diffusion parameters. In this paper, we study an even harder problem, namely reconstructing Diffusion history from A single SnapsHot} (DASH), where we seek to reconstruct the history from only the final snapshot without knowing true diffusion parameters. We start with theoretical analyses that reveal a fundamental limitation of the MLE formulation. We prove: (a) estimation error of diffusion parameters is unavoidable due to NP-hardness of diffusion parameter estimation, and (b) the MLE formulation is sensitive to estimation error of diffusion parameters. To overcome the inherent limitation of the MLE formulation, we propose a novel barycenter formulation: finding the barycenter of the posterior distribution of histories, which is provably stable against the estimation error of diffusion parameters. We further develop an effective solver named DIffusion hiTting Times with Optimal proposal (DITTO) by reducing the problem to estimating posterior expected hitting times via the Metropolis--Hastings Markov chain Monte Carlo method (M--H MCMC) and employing an unsupervised graph neural network to learn an optimal proposal to accelerate the convergence of M--H MCMC. We conduct extensive experiments to demonstrate the efficacy of the proposed method."}, "https://arxiv.org/abs/2311.06835": {"title": "Open-Set Graph Anomaly Detection via Normal Structure Regularisation", "link": "https://arxiv.org/abs/2311.06835", "description": "arXiv:2311.06835v3 Announce Type: replace-cross \nAbstract: This paper considers an important Graph Anomaly Detection (GAD) task, namely open-set GAD, which aims to train a detection model using a small number of normal and anomaly nodes (referred to as seen anomalies) to detect both seen anomalies and unseen anomalies (i.e., anomalies that cannot be illustrated the training anomalies). The availability of those labelled training data provides crucial prior knowledge about abnormalities for GAD models, enabling substantially reduced detection errors. However, current methods tend to over-emphasise fitting the seen anomalies, leading to a weak generalisation ability to detect the unseen anomalies. Further, they were introduced to handle Euclidean data, failing to effectively capture important information on graph structure and node attributes for GAD. In this work, we propose a novel open-set GAD approach, namely Normal Structure Regularisation (NSReg) to achieve generalised detection ability to unseen anomalies, while maintaining its effectiveness on detecting seen anomalies. The key idea in NSReg is to introduce a regularisation term that enforces the learning of compact, semantically-rich representations of normal nodes based on their structural relations to other nodes. When being optimised with supervised anomaly detection losses, the regularisation term helps incorporate strong normality into the modelling, and thus, it effectively avoids the overfitting the seen anomalies solely. In doing so, it helps learn better normality decision boundary, reducing the errors of detecting unseen anomalies as normal. Extensive empirical results on seven real-world datasets show the superiority of NSReg for open-set GAD."}, "https://arxiv.org/abs/2403.02630": {"title": "FedHCDR: Federated Cross-Domain Recommendation with Hypergraph Signal Decoupling", "link": "https://arxiv.org/abs/2403.02630", "description": "arXiv:2403.02630v3 Announce Type: replace-cross \nAbstract: In recent years, Cross-Domain Recommendation (CDR) has drawn significant attention, which utilizes user data from multiple domains to enhance the recommendation performance. However, current CDR methods require sharing user data across domains, thereby violating the General Data Protection Regulation (GDPR). Consequently, numerous approaches have been proposed for Federated Cross-Domain Recommendation (FedCDR). Nevertheless, the data heterogeneity across different domains inevitably influences the overall performance of federated learning. In this study, we propose FedHCDR, a novel Federated Cross-Domain Recommendation framework with Hypergraph signal decoupling. Specifically, to address the data heterogeneity across domains, we introduce an approach called hypergraph signal decoupling (HSD) to decouple the user features into domain-exclusive and domain-shared features. The approach employs high-pass and low-pass hypergraph filters to decouple domain-exclusive and domain-shared user representations, which are trained by the local-global bi-directional transfer algorithm. In addition, a hypergraph contrastive learning (HCL) module is devised to enhance the learning of domain-shared user relationship information by perturbing the user hypergraph. Extensive experiments conducted on three real-world scenarios demonstrate that FedHCDR outperforms existing baselines significantly."}, "https://arxiv.org/abs/2403.11332": {"title": "Graph Machine Learning based Doubly Robust Estimator for Network Causal Effects", "link": "https://arxiv.org/abs/2403.11332", "description": "arXiv:2403.11332v2 Announce Type: replace-cross \nAbstract: We address the challenge of inferring causal effects in social network data. This results in challenges due to interference -- where a unit's outcome is affected by neighbors' treatments -- and network-induced confounding factors. While there is extensive literature focusing on estimating causal effects in social network setups, a majority of them make prior assumptions about the form of network-induced confounding mechanisms. Such strong assumptions are rarely likely to hold especially in high-dimensional networks. We propose a novel methodology that combines graph machine learning approaches with the double machine learning framework to enable accurate and efficient estimation of direct and peer effects using a single observational social network. We demonstrate the semiparametric efficiency of our proposed estimator under mild regularity conditions, allowing for consistent uncertainty quantification. We demonstrate that our method is accurate, robust, and scalable via an extensive simulation study. We use our method to investigate the impact of Self-Help Group participation on financial risk tolerance."}, "https://arxiv.org/abs/2404.07797": {"title": "Illicit Promotion on Twitter", "link": "https://arxiv.org/abs/2404.07797", "description": "arXiv:2404.07797v2 Announce Type: replace-cross \nAbstract: In this paper, we present an extensive study of the promotion of illicit goods and services on Twitter, a popular online social network(OSN). This study is made possible through the design and implementation of multiple novel tools for detecting and analyzing illicit promotion activities as well as their underlying campaigns. As the results, we observe that illicit promotion is prevalent on Twitter, along with noticeable existence on other three popular OSNs including Youtube, Facebook, and TikTok. Particularly, 12 million distinct posts of illicit promotion (PIPs) have been observed on the Twitter platform, which are widely distributed in 5 major natural languages and 10 categories of illicit goods and services, e.g., drugs, data leakage, gambling, and weapon sales. What are also observed are 580K Twitter accounts publishing PIPs as well as 37K distinct instant messaging (IM) accounts that are embedded in PIPs and serve as next hops of communication, which strongly indicates that the campaigns underpinning PIPs are also of a large scale. Also, an arms race between Twitter and illicit promotion operators is also observed. On one hand, Twitter is observed to conduct content moderation in a continuous manner and almost 80% PIPs will get gradually unpublished within six months since posted. However, in the meantime, miscreants adopt various evasion tactics to masquerade their PIPs, which renders more than 90% PIPs keeping hidden from the detection radar for two months or longer."}, "https://arxiv.org/abs/2405.19919": {"title": "Unraveling the Impact of Heterophilic Structures on Graph Positive-Unlabeled Learning", "link": "https://arxiv.org/abs/2405.19919", "description": "arXiv:2405.19919v2 Announce Type: replace-cross \nAbstract: While Positive-Unlabeled (PU) learning is vital in many real-world scenarios, its application to graph data still remains under-explored. We unveil that a critical challenge for PU learning on graph lies on the edge heterophily, which directly violates the irreducibility assumption for Class-Prior Estimation (class prior is essential for building PU learning algorithms) and degenerates the latent label inference on unlabeled nodes during classifier training. In response to this challenge, we introduce a new method, named Graph PU Learning with Label Propagation Loss (GPL). Specifically, GPL considers learning from PU nodes along with an intermediate heterophily reduction, which helps mitigate the negative impact of the heterophilic structure. We formulate this procedure as a bilevel optimization that reduces heterophily in the inner loop and efficiently learns a classifier in the outer loop. Extensive experiments across a variety of datasets have shown that GPL significantly outperforms baseline methods, confirming its effectiveness and superiority."}, "https://arxiv.org/abs/2406.01610": {"title": "Graph structural complexity", "link": "https://arxiv.org/abs/2406.01610", "description": "arXiv:2406.01610v1 Announce Type: new \nAbstract: Introduced the quantitative measure of the structural complexity of the graph (complex network, etc.) based on a procedure similar to the renormalization process, considering the difference between actual and averaged graph structures on different scales. The proposed concept of the graph structural complexity corresponds to qualitative comprehension of the complexity. The proposed measure can be obtained for the weighted graphs also. The structural complexities for various graph types were found - the deterministic infinite and finite size graphs, artificial graphs of different natures including percolation structures, and the time series of cardiac rhythms mapped to complex networks using the parametric visibility graph algorithm. The latter reaches a maximum near the formation of a giant component in the graph or at the percolation threshold for 2D and 3D square lattices when a giant cluster having a fractal structure has emerged. Therefore, the graph structural complexity allows us to detect and study the processes similar to a second-order phase transition in complex networks. A new node centrality index, characterizing the structural complexity of a certain node within the graph structure is introduced also, it can serve as a good auxiliary or generalization to the local clustering coefficient. Such an index provides another new ranking manner for the graph nodes. Being an easily computable measure, the graph structural complexity might help to reveal different features of complex systems and processes of the real world."}, "https://arxiv.org/abs/2406.01612": {"title": "Universal behavior of the Covid-19 tails: Inverse power-law distribution", "link": "https://arxiv.org/abs/2406.01612", "description": "arXiv:2406.01612v1 Announce Type: new \nAbstract: Power-law distribution is one of the most important laws known in nature. Such a special universal behavior is known to occur in very few physical systems. In this work, we analyzed the mortality distribution of the Covid-19 pandemic tails for different countries and continents to discuss the possible universal behavior of the pandemic. Surprisingly, we found that the mortality distribution of Covid-19 follows inverse power-law decays. These universal behaviors for the pandemic are reported in the present work for the first time. Additionally, we showed that mortality tails also decay with time obeying to the inverse power law."}, "https://arxiv.org/abs/2406.01621": {"title": "Susceptibility to Misinformation about COVID-19 Vaccines: A Signal Detection Analysis", "link": "https://arxiv.org/abs/2406.01621", "description": "arXiv:2406.01621v1 Announce Type: new \nAbstract: An analysis drawing on Signal Detection Theory suggests that people may fall for misinformation because they are unable to discern true from false information (truth insensitivity) or because they tend to accept information with a particular slant regardless of whether it is true or false (belief bias). Three preregistered experiments with participants from the United States and the United Kingdom (N = 961) revealed that (i) truth insensitivity in responses to (mis)information about COVID-19 vaccines differed as a function of prior attitudes toward COVID-19 vaccines; (ii) participants exhibited a strong belief bias favoring attitude-congruent information; (iii) truth insensitivity and belief bias jointly predicted acceptance of false information about COVID-19 vaccines, but belief bias was a much stronger predictor; (iv) cognitive elaboration increased truth sensitivity without reducing belief bias; and (v) higher levels of confidence in one's beliefs were associated with greater belief bias. The findings provide insights into why people fall for misinformation, which is essential for individual-level interventions to reduce susceptibility to misinformation."}, "https://arxiv.org/abs/2406.01639": {"title": "Apparent structural changes in contact patterns during COVID-19 were driven by survey design and long-term demographic trends", "link": "https://arxiv.org/abs/2406.01639", "description": "arXiv:2406.01639v1 Announce Type: new \nAbstract: Social contact patterns are key drivers of infectious disease transmission. During the COVID-19 pandemic, differences between pre-COVID and COVID-era contact rates were widely attributed to non-pharmaceutical interventions such as lockdowns. However, the factors that drive changes in the distribution of contacts between different subpopulations remain poorly understood. Here, we present a clustering analysis of 33 contact matrices generated from surveys conducted before and during the COVID-19 pandemic, and analyse key features distinguishing their topological structures. While we expected to identify aspects of pandemic scenarios responsible for these features, our analysis demonstrates that they can be explained by differences in study design and long-term demographic trends. Our results caution against using survey data from different studies in counterfactual analysis of epidemic mitigation strategies. Doing so risks attributing differences stemming from methodological choices or long-term changes to the short-term effects of interventions."}, "https://arxiv.org/abs/2406.01642": {"title": "The Entropy of Knowledge (EoN): Complexity, Uncertainty, and the Quest for Scientific Knowledge", "link": "https://arxiv.org/abs/2406.01642", "description": "arXiv:2406.01642v1 Announce Type: new \nAbstract: This paper explores the concept of \"entropy of knowledge\" (EoN) as a framework for understanding the challenges and complexities of scientific discovery. Drawing from principles in thermodynamics and information theory, I propose that the pursuit of knowledge is characterized by a natural tendency towards disorder, uncertainty, and false conclusions. My central argument is that this entropy of knowledge is not merely an obstacle to be overcome but a fundamental feature of the scientific process, necessary for the exploration of new ideas and the ultimate attainment of truth. The implications of this perspective for the management of scientific inquiry is considered and the same suggests a cyclical approach that balances periods of openness and disorder with phases of consolidation and consensus-building. An attempt is made to situate the EoM model within the broader context of theories of scientific progress, drawing connections to Thomas Kuhn's concept of paradigm shifts and the notion of punctuated equilibrium in the history of science."}, "https://arxiv.org/abs/2406.01911": {"title": "Influence Maximization in Hypergraphs by Stratified Sampling for Efficient Generation of Reverse Reachable Sets", "link": "https://arxiv.org/abs/2406.01911", "description": "arXiv:2406.01911v1 Announce Type: new \nAbstract: Given a hypergraph, influence maximization (IM) is to discover a seed set containing $k$ vertices that have the maximal influence. Although the existing vertex-based IM algorithms perform better than the hyperedge-based algorithms by generating random reverse researchable (RR) sets, they are inefficient because (i) they ignore important structural information associated with hyperedges and thus obtain inferior results, (ii) the frequently-used sampling methods for generating RR sets have low efficiency because of a large number of required samplings along with high sampling variances, and (iii) the vertex-based IM algorithms have large overheads in terms of running time and memory costs. To overcome these shortcomings, this paper proposes a novel approach, called \\emph{HyperIM}. The key idea behind \\emph{HyperIM} is to differentiate structural information of vertices for developing stratified sampling combined with highly-efficient strategies to generate the RR sets. With theoretical guarantees, \\emph{HyperIM} is able to accelerate the influence spread, improve the sampling efficiency, and cut down the expected running time. To further reduce the running time and memory costs, we optimize \\emph{HyperIM} by inferring the bound of the required number of RR sets in conjunction with stratified sampling. Experimental results on real-world hypergraphs show that \\emph{HyperIM} is able to reduce the number of required RR sets and running time by orders of magnitude while increasing the influence spread by up to $2.73X$ on average, compared to the state-of-the-art IM algorithms."}, "https://arxiv.org/abs/2406.02307": {"title": "Traffic Response Functions: Patterns, Propagation and Congestion", "link": "https://arxiv.org/abs/2406.02307", "description": "arXiv:2406.02307v1 Announce Type: new \nAbstract: Using empirical data gathered on motorways in Germany, we follow a new approach by further exploring response functions as a possible tool to study traffic dynamics in motorway networks. We uncover the basic characteristics of responses of flow and density to given signals and the capability of responses to capture the correlation between these fundamental observables. Furthermore, we uncover the potential use of responses to characterize traffic patterns. We are able to demonstrate the differentiation of congestion patterns and the determination of the propagation velocity of moving congestion."}, "https://arxiv.org/abs/2406.01629": {"title": "RecDiff: Diffusion Model for Social Recommendation", "link": "https://arxiv.org/abs/2406.01629", "description": "arXiv:2406.01629v1 Announce Type: cross \nAbstract: Social recommendation has emerged as a powerful approach to enhance personalized recommendations by leveraging the social connections among users, such as following and friend relations observed in online social platforms. The fundamental assumption of social recommendation is that socially-connected users exhibit homophily in their preference patterns. This means that users connected by social ties tend to have similar tastes in user-item activities, such as rating and purchasing. However, this assumption is not always valid due to the presence of irrelevant and false social ties, which can contaminate user embeddings and adversely affect recommendation accuracy. To address this challenge, we propose a novel diffusion-based social denoising framework for recommendation (RecDiff). Our approach utilizes a simple yet effective hidden-space diffusion paradigm to alleivate the noisy effect in the compressed and dense representation space. By performing multi-step noise diffusion and removal, RecDiff possesses a robust ability to identify and eliminate noise from the encoded user representations, even when the noise levels vary. The diffusion module is optimized in a downstream task-aware manner, thereby maximizing its ability to enhance the recommendation process. We conducted extensive experiments to evaluate the efficacy of our framework, and the results demonstrate its superiority in terms of recommendation accuracy, training efficiency, and denoising effectiveness. The source code for the model implementation is publicly available at: https://github.com/HKUDS/RecDiff."}, "https://arxiv.org/abs/2406.01842": {"title": "GraphWeaver: Billion-Scale Cybersecurity Incident Correlation", "link": "https://arxiv.org/abs/2406.01842", "description": "arXiv:2406.01842v1 Announce Type: cross \nAbstract: In the dynamic landscape of large enterprise cybersecurity, accurately and efficiently correlating billions of security alerts into comprehensive incidents is a substantial challenge. Traditional correlation techniques often struggle with maintenance, scaling, and adapting to emerging threats and novel sources of telemetry. We introduce GraphWeaver, an industry-scale framework that shifts the traditional incident correlation process to a data-optimized, geo-distributed graph based approach. GraphWeaver introduces a suite of innovations tailored to handle the complexities of correlating billions of shared evidence alerts across hundreds of thousands of enterprises. Key among these innovations are a geo-distributed database and PySpark analytics engine for large-scale data processing, a minimum spanning tree algorithm to optimize correlation storage, integration of security domain knowledge and threat intelligence, and a human-in-the-loop feedback system to continuously refine key correlation processes and parameters. GraphWeaver is integrated into the Microsoft Defender XDR product and deployed worldwide, handling billions of correlations with a 99% accuracy rate, as confirmed by customer feedback and extensive investigations by security experts. This integration has not only maintained high correlation accuracy but reduces traditional correlation storage requirements by 7.4x. We provide an in-depth overview of the key design and operational features of GraphWeaver, setting a precedent as the first cybersecurity company to openly discuss these critical capabilities at this level of depth."}, "https://arxiv.org/abs/2406.01865": {"title": "The influence of active agent motility on SIRS epidemiological dynamics", "link": "https://arxiv.org/abs/2406.01865", "description": "arXiv:2406.01865v1 Announce Type: cross \nAbstract: Active Brownian disks moving in two dimensions that exchange information about their internal state stochastically are chosen to model epidemic spread in a self-propelled population of agents under the susceptible-infected-recovered-susceptible (SIRS) framework. The state of infection of an agent, or disk, governs its self-propulsion speed; consequently, the activity of the agents in the system varies in time. Two different protocols (one-to-one and one-to-many) are considered for the transmission of disease from the infected to susceptible populations. The effectiveness of the two protocols are practically identical at high values of the infection transmission rate. The one-to-many protocol, however, outperforms the one-to-one protocol at lower values of the infection transmission rate. Salient features of the macroscopic SIRS model are revisited, and compared to predictions from the agent-based model. Lastly, the motility induced phase separation in a population of such agents with a fluctuating fraction of active disks is found to be well-described by theories governing phase separation in a mixture of active and passive particles with a constant fraction of passive disks."}, "https://arxiv.org/abs/2406.01866": {"title": "#EpiTwitter: Public Health Messaging During the COVID-19 Pandemic", "link": "https://arxiv.org/abs/2406.01866", "description": "arXiv:2406.01866v1 Announce Type: cross \nAbstract: Effective communication during health crises is critical, with social media serving as a key platform for public health experts (PHEs) to engage with the public. However, it also amplifies pseudo-experts promoting contrarian views. Despite its importance, the role of emotional and moral language in PHEs' communication during COVID-19 remains under explored. This study examines how PHEs and pseudo-experts communicated on Twitter during the pandemic, focusing on emotional and moral language and their engagement with political elites. Analyzing tweets from 489 PHEs and 356 pseudo-experts from January 2020 to January 2021, alongside public responses, we identified key priorities and differences in messaging strategy. PHEs prioritize masking, healthcare, education, and vaccines, using positive emotional language like optimism. In contrast, pseudo-experts discuss therapeutics and lockdowns more frequently, employing negative emotions like pessimism and disgust. Negative emotional and moral language tends to drive engagement, but positive language from PHEs fosters positivity in public responses. PHEs exhibit liberal partisanship, expressing more positivity towards liberals and negativity towards conservative elites, while pseudo-experts show conservative partisanship. These findings shed light on the polarization of COVID-19 discourse and underscore the importance of strategic use of emotional and moral language by experts to mitigate polarization and enhance public trust."}, "https://arxiv.org/abs/2406.01957": {"title": "Backward bifurcation arising from decline of immunity against emerging infectious diseases", "link": "https://arxiv.org/abs/2406.01957", "description": "arXiv:2406.01957v1 Announce Type: cross \nAbstract: Decline of immunity is a phenomenon characterized by immunocompromised host and plays a crucial role in the epidemiology of emerging infectious diseases (EIDs) such as COVID-19. In this paper, we propose an age-structured model with vaccination and reinfection of immune individuals. We prove that the disease-free equilibrium of the model undergoes backward and forward transcritical bifurcations at the critical value of the basic reproduction number for different values of parameters. We illustrate the results by numerical computations, and also find that the endemic equilibrium exhibits a saddle-node bifurcation on the extended branch of the forward transcritical bifurcation. These results allow us to understand the interplay between the decline of immunity and EIDs, and are able to provide strategies for mitigating the impact of EIDs on global health."}, "https://arxiv.org/abs/2406.01999": {"title": "Random Abstract Cell Complexes", "link": "https://arxiv.org/abs/2406.01999", "description": "arXiv:2406.01999v1 Announce Type: cross \nAbstract: We define a model for random (abstract) cell complexes (CCs), similiar to the well-known Erd\\H{o}s-R\\'enyi model for graphs and its extensions for simplicial complexes. To build a random cell complex, we first draw from an Erd\\H{o}s-R\\'enyi graph, and consecutively augment the graph with cells for each dimension with a specified probability. As the number of possible cells increases combinatorially -- e.g., 2-cells can be represented as cycles, or permutations -- we derive an approximate sampling algorithm for this model limited to two-dimensional abstract cell complexes. Since there is a large variance in the number of simple cycles on graphs drawn from the same configuration of ER, we also provide an efficient method to approximate that number, which is of independent interest. Moreover, it enables us to specify the expected number of 2-cells of each boundary length we want to sample. We provide some initial analysis into the properties of random CCs drawn from this model. We further showcase practical applications for our random CCs as null models, and in the context of (random) liftings of graphs to cell complexes. Both the sampling and cycle count estimation algorithms are available in the package `py-raccoon` on the Python Packaging Index."}, "https://arxiv.org/abs/2406.02362": {"title": "Temporal Graph Rewiring with Expander Graphs", "link": "https://arxiv.org/abs/2406.02362", "description": "arXiv:2406.02362v1 Announce Type: cross \nAbstract: Evolving relations in real-world networks are often modelled by temporal graphs. Graph rewiring techniques have been utilised on Graph Neural Networks (GNNs) to improve expressiveness and increase model performance. In this work, we propose Temporal Graph Rewiring (TGR), the first approach for graph rewiring on temporal graphs. TGR enables communication between temporally distant nodes in a continuous time dynamic graph by utilising expander graph propagation to construct a message passing highway for message passing between distant nodes. Expander graphs are suitable candidates for rewiring as they help overcome the oversquashing problem often observed in GNNs. On the public tgbl-wiki benchmark, we show that TGR improves the performance of a widely used TGN model by a significant margin. Our code repository is accessible at https://anonymous.4open.science/r/TGR-254C."}, "https://arxiv.org/abs/2208.06251": {"title": "Identifying User Profiles Via User Footprints", "link": "https://arxiv.org/abs/2208.06251", "description": "arXiv:2208.06251v2 Announce Type: replace \nAbstract: User identification has been a major field of research in privacy and security topics. Users might utilize multiple Online Social Networks (OSNs) to access a variety of text, videos, and links, and connect to their friends. Identifying user profiles corresponding to multiple virtual activities of users across social networks is significant for the development of related fields, such as network security, user behavior patterns analysis, and user recommendation systems. In addition, predicting personal attributes based on public content is a challenging topic. In this work, we perform an empirical study and proposed a scheme with considerable performance. In this work, we investigate Reddit, a famous social network for questioning and answering. By considering available personal and non-personal attributes, we discuss our main findings based on mapping the different features such as user activities to a special user profile. we collected a dataset with wide distribution consisting of 5000 samples. To map non-personal attributes to personal attributes, a classification approach based on support vector machines (SVM), Random Forests (RF), and deep belief network has been used. Experimental results demonstrate the effectiveness of the proposed methodology and achieved classification accuracy higher than 89%."}, "https://arxiv.org/abs/2303.18051": {"title": "Synergistic Graph Fusion via Encoder Embedding", "link": "https://arxiv.org/abs/2303.18051", "description": "arXiv:2303.18051v3 Announce Type: replace \nAbstract: In this paper, we introduce a method called graph fusion embedding, designed for multi-graph embedding with shared vertex sets. Under the framework of supervised learning, our method exhibits a remarkable and highly desirable synergistic effect: for sufficiently large vertex size, the accuracy of vertex classification consistently benefits from the incorporation of additional graphs. We establish the mathematical foundation for the method, including the asymptotic convergence of the embedding, a sufficient condition for asymptotic optimal classification, and the proof of the synergistic effect for vertex classification. Our comprehensive simulations and real data experiments provide compelling evidence supporting the effectiveness of our proposed method, showcasing the pronounced synergistic effect for multiple graphs from disparate sources."}, "https://arxiv.org/abs/2309.10486": {"title": "Infection patterns in simple and complex contagion processes on networks", "link": "https://arxiv.org/abs/2309.10486", "description": "arXiv:2309.10486v2 Announce Type: replace \nAbstract: Contagion processes, representing the spread of infectious diseases, information, or social behaviors, are often schematized as taking place on networks, which encode for instance the interactions between individuals. The impact of the network structure on spreading process has been widely investigated, but not the reverse question: do different processes unfolding on a given network lead to different infection patterns? How do the infection patterns depend on a model's parameters or on the nature of the contagion processes? Here we address this issue by investigating the infection patterns for a variety of models. In simple contagion processes, where contagion events involve one connection at a time, we find that the infection patterns are extremely robust across models and parameters. In complex contagion models instead, in which multiple interactions are needed for a contagion event, non-trivial dependencies on models parameters emerge, as the infection pattern depends on the interplay between pairwise and group contagions. In models involving threshold mechanisms moreover, slight parameter changes can significantly impact the spreading paths. Our results show that it is possible to study crucial features of a spread from schematized models, and inform us on the variations between spreading patterns in processes of different nature."}, "https://arxiv.org/abs/2309.16717": {"title": "A mobile observer method for the estimation of road traffic using communicating vehicles", "link": "https://arxiv.org/abs/2309.16717", "description": "arXiv:2309.16717v2 Announce Type: replace \nAbstract: Estimation of road traffic is a fundamental problem which has been addressed with a variety of methods. In the present paper, a variant of the mobile observer method is proposed. It is assumed that some vehicles composing the road traffic are communicating vehicles. These communicating vehicles broadcast periodically beacon messages. The proposed method uses only these beacon messages as input data, and needs no additional equipment such as radar or GPS device in order to estimate the road traffic. The model is tested with the bi-directional simulation framework VEINS, which combines a microscopic road traffic simulator and a communication simulator. The preliminary results show the potential of the method and confirm the validity of the approach."}, "https://arxiv.org/abs/2312.16878": {"title": "Voting power in the Council of the European Union: A comprehensive sensitivity analysis", "link": "https://arxiv.org/abs/2312.16878", "description": "arXiv:2312.16878v2 Announce Type: replace \nAbstract: The Council of the European Union (EU) is one of the main decision-making bodies of the EU. Many decisions require a qualified majority: the support of 55% of the member states (currently 15) that represent at least 65% of the total population. We investigate how the power distribution, based on the Shapley-Shubik index, and the proportion of winning coalitions change if these criteria are modified within reasonable bounds. The power of the two countries with about 4% of the total population each is found to be almost flat. The level of decisiveness decreases if the population criterion is above 68\\% or the states criterion is at least 17. The proportion of winning coalitions can be increased from 13.2% to 20.8% (30.1%) such that the maximal relative change in the Shapley-Shubik indices remains below 3.5% (5.5%). Our results are indispensable to evaluate any proposal for reforming the qualified majority voting system."}, "https://arxiv.org/abs/2401.11415": {"title": "A Fast Parallel Approach for Neighborhood-based Link Prediction by Disregarding Large Hubs", "link": "https://arxiv.org/abs/2401.11415", "description": "arXiv:2401.11415v3 Announce Type: replace \nAbstract: Link prediction can help rectify inaccuracies in various graph algorithms, stemming from unaccounted-for or overlooked links within networks. However, many existing works use a baseline approach, which incurs unnecessary computational costs due to its high time complexity. Further, many studies focus on smaller graphs, which can lead to misleading conclusions. Here, we study the prediction of links using neighborhood-based similarity measures on large graphs. In particular, we improve upon the baseline approach (IBase), and propose a heuristic approach that additionally disregards large hubs (DLH), based on the idea that high-degree nodes contribute little similarity among their neighbors. On a server equipped with dual 16-core Intel Xeon Gold 6226R processors, DLH is on average 1019x faster than IBase, especially on web graphs and social networks, while maintaining similar prediction accuracy. Notably, DLH achieves a link prediction rate of 38.1M edges/s and improves performance by 1.6x for every doubling of threads."}, "https://arxiv.org/abs/2302.00890": {"title": "Neural Common Neighbor with Completion for Link Prediction", "link": "https://arxiv.org/abs/2302.00890", "description": "arXiv:2302.00890v4 Announce Type: replace-cross \nAbstract: In this work, we propose a novel link prediction model and further boost it by studying graph incompleteness. First, we introduce MPNN-then-SF, an innovative architecture leveraging structural feature (SF) to guide MPNN's representation pooling, with its implementation, namely Neural Common Neighbor (NCN). NCN exhibits superior expressiveness and scalability compared with existing models, which can be classified into two categories: SF-then-MPNN, augmenting MPNN's input with SF, and SF-and-MPNN, decoupling SF and MPNN. Second, we investigate the impact of graph incompleteness -- the phenomenon that some links are unobserved in the input graph -- on SF, like the common neighbor. Through dataset visualization, we observe that incompleteness reduces common neighbors and induces distribution shifts, significantly affecting model performance. To address this issue, we propose to use a link prediction model to complete the common neighbor structure. Combining this method with NCN, we propose Neural Common Neighbor with Completion (NCNC). NCN and NCNC outperform recent strong baselines by large margins, and NCNC further surpasses state-of-the-art models in standard link prediction benchmarks. Our code is available at https://github.com/GraphPKU/NeuralCommonNeighbor."}, "https://arxiv.org/abs/2304.05223": {"title": "Inhomogeneous graph trend filtering via a l2,0 cardinality penalty", "link": "https://arxiv.org/abs/2304.05223", "description": "arXiv:2304.05223v3 Announce Type: replace-cross \nAbstract: We study estimation of piecewise smooth signals over a graph. We propose a $\\ell_{2,0}$-norm penalized Graph Trend Filtering (GTF) model to estimate piecewise smooth graph signals that exhibit inhomogeneous levels of smoothness across the nodes. We prove that the proposed GTF model is simultaneously a k-means clustering on the signal over the nodes and a minimum graph cut on the edges of the graph, where the clustering and the cut share the same assignment matrix. We propose two methods to solve the proposed GTF model: a spectral decomposition method and a method based on simulated annealing. In the experiment on synthetic and real-world datasets, we show that the proposed GTF model has a better performances compared with existing approaches on the tasks of denoising, support recovery and semi-supervised classification. We also show that the proposed GTF model can be solved more efficiently than existing models for the dataset with a large edge set."}, "https://arxiv.org/abs/2305.16102": {"title": "Demystifying Oversmoothing in Attention-Based Graph Neural Networks", "link": "https://arxiv.org/abs/2305.16102", "description": "arXiv:2305.16102v4 Announce Type: replace-cross \nAbstract: Oversmoothing in Graph Neural Networks (GNNs) refers to the phenomenon where increasing network depth leads to homogeneous node representations. While previous work has established that Graph Convolutional Networks (GCNs) exponentially lose expressive power, it remains controversial whether the graph attention mechanism can mitigate oversmoothing. In this work, we provide a definitive answer to this question through a rigorous mathematical analysis, by viewing attention-based GNNs as nonlinear time-varying dynamical systems and incorporating tools and techniques from the theory of products of inhomogeneous matrices and the joint spectral radius. We establish that, contrary to popular belief, the graph attention mechanism cannot prevent oversmoothing and loses expressive power exponentially. The proposed framework extends the existing results on oversmoothing for symmetric GCNs to a significantly broader class of GNN models, including random walk GCNs, Graph Attention Networks (GATs) and (graph) transformers. In particular, our analysis accounts for asymmetric, state-dependent and time-varying aggregation operators and a wide range of common nonlinear activation functions, such as ReLU, LeakyReLU, GELU and SiLU."}, "https://arxiv.org/abs/2404.14928": {"title": "Graph Machine Learning in the Era of Large Language Models (LLMs)", "link": "https://arxiv.org/abs/2404.14928", "description": "arXiv:2404.14928v2 Announce Type: replace-cross \nAbstract: Graphs play an important role in representing complex relationships in various domains like social networks, knowledge graphs, and molecular discovery. With the advent of deep learning, Graph Neural Networks (GNNs) have emerged as a cornerstone in Graph Machine Learning (Graph ML), facilitating the representation and processing of graph structures. Recently, LLMs have demonstrated unprecedented capabilities in language tasks and are widely adopted in a variety of applications such as computer vision and recommender systems. This remarkable success has also attracted interest in applying LLMs to the graph domain. Increasing efforts have been made to explore the potential of LLMs in advancing Graph ML's generalization, transferability, and few-shot learning ability. Meanwhile, graphs, especially knowledge graphs, are rich in reliable factual knowledge, which can be utilized to enhance the reasoning capabilities of LLMs and potentially alleviate their limitations such as hallucinations and the lack of explainability. Given the rapid progress of this research direction, a systematic review summarizing the latest advancements for Graph ML in the era of LLMs is necessary to provide an in-depth understanding to researchers and practitioners. Therefore, in this survey, we first review the recent developments in Graph ML. We then explore how LLMs can be utilized to enhance the quality of graph features, alleviate the reliance on labeled data, and address challenges such as graph heterogeneity and out-of-distribution (OOD) generalization. Afterward, we delve into how graphs can enhance LLMs, highlighting their abilities to enhance LLM pre-training and inference. Furthermore, we investigate various applications and discuss the potential future directions in this promising field."}, "https://arxiv.org/abs/2406.02801": {"title": "SenTopX: Benchmark for User Sentiment on Various Topics", "link": "https://arxiv.org/abs/2406.02801", "description": "arXiv:2406.02801v1 Announce Type: new \nAbstract: Toxic sentiment analysis on Twitter (X) often focuses on specific topics and events such as politics and elections. Datasets of toxic users in such research are typically gathered through lexicon-based techniques, providing only a cross-sectional view. his approach has a tight confine for studying toxic user behavior and effective platform moderation. To identify users consistently spreading toxicity, a longitudinal analysis of their tweets is essential. However, such datasets currently do not exist.\n  This study addresses this gap by collecting a longitudinal dataset from 143K Twitter users, covering the period from 2007 to 2021, amounting to a total of 293 million tweets. Using topic modeling, we extract all topics discussed by each user and categorize users into eight groups based on the predominant topic in their timelines. We then analyze the sentiments of each group using 16 toxic scores. Our research demonstrates that examining users longitudinally reveals a distinct perspective on their comprehensive personality traits and their overall impact on the platform. Our comprehensive dataset is accessible to researchers for additional analysis."}, "https://arxiv.org/abs/2406.03139": {"title": "Patterns of co-occurrent skills in UK job adverts", "link": "https://arxiv.org/abs/2406.03139", "description": "arXiv:2406.03139v1 Announce Type: new \nAbstract: A job usually involves the application of several complementary or synergistic skills to perform its required tasks. Such relationships are implicitly recognised by employers in the skills they demand when recruiting new employees. Here we construct a skills network based on their co-occurrence in a national level data set of 65 million job postings from the UK spanning 2016 to 2022. We then apply multiscale graph-based community detection to obtain data-driven skill clusters at different levels of resolution that reveal a modular structure across scales. Skill clusters display diverse levels of demand and occupy varying roles within the skills network: some have broad reach across the network (high closeness centrality) while others have higher levels of within-cluster containment, yet with high interconnection across clusters and no skill silos. The skill clusters also display varying levels of semantic similarity, highlighting the difference between co-occurrence in adverts and intrinsic thematic consistency. Clear geographic variation is evident in the demand for each skill cluster across the UK, broadly reflecting the industrial characteristics of each region, e.g., London appears as an outlier as an international hub for finance, education and business. Comparison of data from 2016 and 2022 reveals employers are demanding a broader range of skills over time, with more adverts featuring skills spanning different clusters. We also show that our data-driven clusters differ from expert-authored categorisations of skills, indicating that important relationships between skills are not captured by expert assessment alone."}, "https://arxiv.org/abs/2406.03340": {"title": "Analyzing and Estimating Support for U", "link": "https://arxiv.org/abs/2406.03340", "description": "arXiv:2406.03340v1 Announce Type: new \nAbstract: Polls posted on social media have emerged in recent years as an important tool for estimating public opinion, e.g., to gauge public support for business decisions and political candidates in national elections. Here, we examine nearly two thousand Twitter polls gauging support for U.S. presidential candidates during the 2016 and 2020 election campaigns. First, we describe the rapidly emerging prevalence of social polls. Second, we characterize social polls in terms of their heterogeneity and response options. Third, leveraging machine learning models for user attribute inference, we describe the demographics, political leanings, and other characteristics of the users who author and interact with social polls. Finally, we study the relationship between social poll results, their attributes, and the characteristics of users interacting with them. Our findings reveal that Twitter polls are biased in various ways, starting from the position of the presidential candidates among the poll options to biases in demographic attributes and poll results. The 2016 and 2020 polls were predominantly crafted by older males and manifested a pronounced bias favoring candidate Donald Trump, in contrast to traditional surveys, which favored Democratic candidates. We further identify and explore the potential reasons for such biases in social polling and discuss their potential repercussions. Finally, we show that biases in social media polls can be corrected via regression and poststratification. The errors of the resulting election estimates can be as low as 1%-2%, suggesting that social media polls can become a promising source of information about public opinion."}, "https://arxiv.org/abs/2406.03354": {"title": "Can Social Media Platforms Transcend Political Labels? An Analysis of Neutral Conservations on Truth Social", "link": "https://arxiv.org/abs/2406.03354", "description": "arXiv:2406.03354v1 Announce Type: new \nAbstract: There is a prevailing perception that content on a social media platform generally have the same political leaning. These platforms are often viewed as ideologically congruent entities, reflecting the majority opinion of their users; a prime example of this is Truth Social. While this perception may exist, it is essential to verify the platform's credibility, acknowledging that such platforms contain meaningful insights with neutral stances. To this end, we examine the dissemination of Wikipedia links on the alt-right platform, Truth Social. Wikipedia is recognized for enforcing content neutrality and serves as a unique lens to analyze the objectivity of user-generated content on Truth Social. By scrutinizing Truths with and without Wikipedia links, identifying toxicity trends & recognizing coordinated networks, we observe a lower level of engagement and a tendency for Truths shared on Truth Social to cover more neutral topics when it includes Wikipedia links (Wiki Truths). Given the significantly different engagement and nature of content shared of Wiki Truths against Non-Wiki Truths, we emphasize that we should not generalize the techno-political affiliation of a social media platform, but rather should investigate the content closely."}, "https://arxiv.org/abs/2406.03443": {"title": "Investigating the Relationship Between User Specialization and Toxicity on Reddit: A Sentiment Analysis Approach", "link": "https://arxiv.org/abs/2406.03443", "description": "arXiv:2406.03443v1 Announce Type: new \nAbstract: Online platforms host a diverse user base, which can be broadly categorized into \"specialist users\" with focused interests and \"generalist users\" who engage in a wide range of topics. This study explores the behavioral differences between these two user types on the popular platform Reddit, focusing on the level of toxicity in their posts and the associated sentiment scores across 24 emotional categories and a neutral state. By employing community embeddings to represent users in a high-dimensional space, we measure activity diversity using the GS score. We analyze a dataset of 16,291,992 posts from 4,926,237 users spanning the period from 2019 to 2021, assessing the degree of toxicity and sentiment scores for each post. Our findings indicate that specialist users exhibit higher levels of toxic behavior compared to generalist users. Furthermore, specialist users demonstrate elevated scores for annoyance, sadness, and fear, while generalist users show higher scores for curiosity, admiration, and love. These insights contribute to a better understanding of user behavior on online platforms and can inform strategies for fostering healthier online communities."}, "https://arxiv.org/abs/2406.02794": {"title": "PriME: Privacy-aware Membership profile Estimation in networks", "link": "https://arxiv.org/abs/2406.02794", "description": "arXiv:2406.02794v1 Announce Type: cross \nAbstract: This paper presents a novel approach to estimating community membership probabilities for network vertices generated by the Degree Corrected Mixed Membership Stochastic Block Model while preserving individual edge privacy. Operating within the $\\varepsilon$-edge local differential privacy framework, we introduce an optimal private algorithm based on a symmetric edge flip mechanism and spectral clustering for accurate estimation of vertex community memberships. We conduct a comprehensive analysis of the estimation risk and establish the optimality of our procedure by providing matching lower bounds to the minimax risk under privacy constraints. To validate our approach, we demonstrate its performance through numerical simulations and its practical application to real-world data. This work represents a significant step forward in balancing accurate community membership estimation with stringent privacy preservation in network data analysis."}, "https://arxiv.org/abs/2406.03245": {"title": "Reconfiguring Participatory Design to Resist AI Realism", "link": "https://arxiv.org/abs/2406.03245", "description": "arXiv:2406.03245v1 Announce Type: cross \nAbstract: The growing trend of artificial intelligence (AI) as a solution to social and technical problems reinforces AI Realism -- the belief that AI is an inevitable and natural order. In response, this paper argues that participatory design (PD), with its focus on democratic values and processes, can play a role in questioning and resisting AI Realism. I examine three concerning aspects of AI Realism: the facade of democratization that lacks true empowerment, demands for human adaptability in contrast to AI systems' inflexibility, and the obfuscation of essential human labor enabling the AI system. I propose resisting AI Realism by reconfiguring PD to continue engaging with value-centered visions, increasing its exploration of non-AI alternatives, and making the essential human labor underpinning AI systems visible. I position PD as a means to generate friction against AI Realism and open space for alternative futures centered on human needs and values."}, "https://arxiv.org/abs/2406.03390": {"title": "Author, Content or Sharers? Estimating Spread Dynamics with Bayesian Mixture Hawkes", "link": "https://arxiv.org/abs/2406.03390", "description": "arXiv:2406.03390v1 Announce Type: cross \nAbstract: The spread of content on social media is shaped by intertwining factors on three levels: the source, the content itself, and the pathways of content spread. At the lowest level, the popularity of the sharing user determines its eventual reach. However, higher-level factors such as the nature of the online item and the credibility of its source also play crucial roles in determining how widely and rapidly the online item spreads. In this work, we propose the Bayesian Mixture Hawkes (BMH) model to jointly learn the influence of source, content and spread. We formulate the BMH model as a hierarchical mixture model of separable Hawkes processes, accommodating different classes of Hawkes dynamics and the influence of feature sets on these classes. We test the BMH model on two learning tasks, cold-start popularity prediction and temporal profile generalization performance, applying to two real-world retweet cascade datasets referencing articles from controversial and traditional media publishers. The BMH model outperforms the state-of-the-art models and predictive baselines on both datasets and utilizes cascade- and item-level information better than the alternatives. Lastly, we perform a counter-factual analysis where we apply the trained publisher-level BMH models to a set of article headlines and show that effectiveness of headline writing style (neutral, clickbait, inflammatory) varies across publishers. The BMH model unveils differences in style effectiveness between controversial and reputable publishers, where we find clickbait to be notably more effective for reputable publishers as opposed to controversial ones, which links to the latter's overuse of clickbait."}, "https://arxiv.org/abs/2208.06370": {"title": "Mitigating an epidemic on a geographic network using vaccination", "link": "https://arxiv.org/abs/2208.06370", "description": "arXiv:2208.06370v3 Announce Type: replace \nAbstract: We consider a mathematical model describing the propagation of an epidemic on a geographical network. The size of the outbreak is governed by the initial growth rate of the disease given by the maximal eigenvalue of the epidemic matrix formed by the susceptibles and the graph Laplacian representing the mobility. We use matrix perturbation theory to analyze the epidemic matrix and define a vaccination strategy, assuming the vaccination reduces the susceptibles. When mobility and local disease dynamics have similar time scales, it is most efficient to vaccinate the whole network because the disease grows uniformly. However, if only a few vertices can be vaccinated then which ones do we choose? We answer this question, and show that it is most efficient to vaccinate along an eigenvector corresponding to the largest eigenvalue of the Laplacian. We illustrate these general results on a 7 vertex graph and a realistic example of the french rail network. When mobility is slower than local disease dynamics, the epidemic grows on the vertex with largest susceptibles. The epidemic growth rate is more reduced when vaccinating a larger degree vertex; it also depends on the neighboring vertices. This study and its conclusions provides guidelines for the planning of vaccination on a network at the onset of an epidemic."}, "https://arxiv.org/abs/2312.01565": {"title": "Finding mixed memberships in categorical data", "link": "https://arxiv.org/abs/2312.01565", "description": "arXiv:2312.01565v2 Announce Type: replace \nAbstract: Latent class analysis, a fundamental problem in categorical data analysis, often encounters overlapping latent classes that introduce further challenges. This paper presents a solution to this problem by focusing on finding latent mixed memberships of subjects in categorical data with polytomous responses. We employ the Grade of Membership (GoM) model, which assigns each subject a membership score in each latent class. To address this, we propose two efficient spectral algorithms for estimating these mixed memberships and other GoM parameters. Our algorithms are based on the singular value decomposition of a regularized Laplacian matrix. We establish their convergence rates under a mild condition on data sparsity. Additionally, we introduce a metric to evaluate the quality of estimated mixed memberships for real-world categorical data and determine the optimal number of latent classes based on this metric. Finally, we demonstrate the practicality of our methods through experiments on both computer-generated and real-world categorical datasets."}, "https://arxiv.org/abs/2402.13392": {"title": "An SEIR network epidemic model with manual and digital contact tracing allowing delays", "link": "https://arxiv.org/abs/2402.13392", "description": "arXiv:2402.13392v4 Announce Type: replace \nAbstract: We consider an SEIR epidemic model on a network also allowing random contacts, where recovered individuals could either recover naturally or be diagnosed. Upon diagnosis, manual contact tracing is triggered such that each infected network contact is reported, tested and isolated with some probability and after a random delay. Additionally, digital tracing (based on a tracing app) is triggered if the diagnosed individual is an app-user, and then all of its app-using infectees are immediately notified and isolated. The early phase of the epidemic with manual and/or digital tracing is approximated by different multi-type branching processes, and three respective reproduction numbers are derived. The effectiveness of both contact tracing mechanisms is numerically quantified through the reduction of the reproduction number. This shows that app-using fraction plays an essential role in the overall effectiveness of contact tracing. The relative effectiveness of manual tracing compared to digital tracing increases if: more of the transmission occurs on the network, when the tracing delay is shortened, and when the network degree distribution is heavy-tailed. For realistic values, the combined tracing case can reduce $R_0$ by $20-30\\%$, so other preventive measures are needed to reduce the reproduction number down to $1.2-1.4$ for contact tracing to make it successful in avoiding big outbreaks."}, "https://arxiv.org/abs/2404.12451": {"title": "Assessing the Risk of Proliferation via Fissile Material Breeding in ARC-class Fusion Power Plants", "link": "https://arxiv.org/abs/2404.12451", "description": "arXiv:2404.12451v2 Announce Type: replace \nAbstract: Construction of a nuclear weapon requires access to kilogram-scale quantities of fissile material, which can be bred from fertile material like U-238 and Th-232 via neutron capture. Future fusion power plants, with total neutron source rates in excess of $10^{20}$ n/s, could breed weapons-relevant quantities of fissile material on short timescales, posing a breakout proliferation risk. The ARC-class fusion reactor design is characterized by demountable high temperature superconducting magnets, a FLiBe liquid immersion blanket, and a relatively small size ($\\sim$ 4 m major radius, $\\sim$ 1 m minor radius). We use the open-source Monte Carlo neutronics code OpenMC to perform self-consistent time-dependent simulations of a representative ARC-class blanket to assess the feasibility of a fissile breeding breakout scenario. We find that a significant quantity of fissile material can be bred in less than six months of full power operation for initial fertile inventories ranging from 5 to 50 metric tons, representing a non-negligible proliferation risk. We further study the feasibility of this scenario by examining other consequences of fissile breeding such as reduced tritium breeding ratio, extra heat from fission and decay heat, isotopic purity of bred material, and self-protection time of irradiated blanket material. We also examine the impact of Li-6 enrichment on fissile breeding and find that it substantially reduces breeding rate, motivating its use as a proliferation resistance tool."}, "https://arxiv.org/abs/2305.15745": {"title": "Robust Ante-hoc Graph Explainer using Bilevel Optimization", "link": "https://arxiv.org/abs/2305.15745", "description": "arXiv:2305.15745v2 Announce Type: replace-cross \nAbstract: Explaining the decisions made by machine learning models for high-stakes applications is critical for increasing transparency and guiding improvements to these decisions. This is particularly true in the case of models for graphs, where decisions often depend on complex patterns combining rich structural and attribute data. While recent work has focused on designing so-called post-hoc explainers, the broader question of what constitutes a good explanation remains open. One intuitive property is that explanations should be sufficiently informative to reproduce the predictions given the data. In other words, a good explainer can be repurposed as a predictor. Post-hoc explainers do not achieve this goal as their explanations are highly dependent on fixed model parameters (e.g., learned GNN weights). To address this challenge, we propose RAGE (Robust Ante-hoc Graph Explainer), a novel and flexible ante-hoc explainer designed to discover explanations for graph neural networks using bilevel optimization, with a focus on the chemical domain. RAGE can effectively identify molecular substructures that contain the full information needed for prediction while enabling users to rank these explanations in terms of relevance. Our experiments on various molecular classification tasks show that RAGE explanations are better than existing post-hoc and ante-hoc approaches."}, "https://arxiv.org/abs/2309.08631": {"title": "Large Language Models Can Infer Psychological Dispositions of Social Media Users", "link": "https://arxiv.org/abs/2309.08631", "description": "arXiv:2309.08631v2 Announce Type: replace-cross \nAbstract: Large Language Models (LLMs) demonstrate increasingly human-like abilities across a wide variety of tasks. In this paper, we investigate whether LLMs like ChatGPT can accurately infer the psychological dispositions of social media users and whether their ability to do so varies across socio-demographic groups. Specifically, we test whether GPT-3.5 and GPT-4 can derive the Big Five personality traits from users' Facebook status updates in a zero-shot learning scenario. Our results show an average correlation of r = .29 (range = [.22, .33]) between LLM-inferred and self-reported trait scores - a level of accuracy that is similar to that of supervised machine learning models specifically trained to infer personality. Our findings also highlight heterogeneity in the accuracy of personality inferences across different age groups and gender categories: predictions were found to be more accurate for women and younger individuals on several traits, suggesting a potential bias stemming from the underlying training data or differences in online self-expression. The ability of LLMs to infer psychological dispositions from user-generated text has the potential to democratize access to cheap and scalable psychometric assessments for both researchers and practitioners. On the one hand, this democratization might facilitate large-scale research of high ecological validity and spark innovation in personalized services. On the other hand, it also raises ethical concerns regarding user privacy and self-determination, highlighting the need for stringent ethical frameworks and regulation."}, "https://arxiv.org/abs/2309.17417": {"title": "Networked Inequality: Preferential Attachment Bias in Graph Neural Network Link Prediction", "link": "https://arxiv.org/abs/2309.17417", "description": "arXiv:2309.17417v2 Announce Type: replace-cross \nAbstract: Graph neural network (GNN) link prediction is increasingly deployed in citation, collaboration, and online social networks to recommend academic literature, collaborators, and friends. While prior research has investigated the dyadic fairness of GNN link prediction, the within-group (e.g., queer women) fairness and \"rich get richer\" dynamics of link prediction remain underexplored. However, these aspects have significant consequences for degree and power imbalances in networks. In this paper, we shed light on how degree bias in networks affects Graph Convolutional Network (GCN) link prediction. In particular, we theoretically uncover that GCNs with a symmetric normalized graph filter have a within-group preferential attachment bias. We validate our theoretical analysis on real-world citation, collaboration, and online social networks. We further bridge GCN's preferential attachment bias with unfairness in link prediction and propose a new within-group fairness metric. This metric quantifies disparities in link prediction scores within social groups, towards combating the amplification of degree and power disparities. Finally, we propose a simple training-time strategy to alleviate within-group unfairness, and we show that it is effective on citation, social, and credit networks."}, "https://arxiv.org/abs/2404.03528": {"title": "BanglaAutoKG: Automatic Bangla Knowledge Graph Construction with Semantic Neural Graph Filtering", "link": "https://arxiv.org/abs/2404.03528", "description": "arXiv:2404.03528v3 Announce Type: replace-cross \nAbstract: Knowledge Graphs (KGs) have proven essential in information processing and reasoning applications because they link related entities and give context-rich information, supporting efficient information retrieval and knowledge discovery; presenting information flow in a very effective manner. Despite being widely used globally, Bangla is relatively underrepresented in KGs due to a lack of comprehensive datasets, encoders, NER (named entity recognition) models, POS (part-of-speech) taggers, and lemmatizers, hindering efficient information processing and reasoning applications in the language. Addressing the KG scarcity in Bengali, we propose BanglaAutoKG, a pioneering framework that is able to automatically construct Bengali KGs from any Bangla text. We utilize multilingual LLMs to understand various languages and correlate entities and relations universally. By employing a translation dictionary to identify English equivalents and extracting word features from pre-trained BERT models, we construct the foundational KG. To reduce noise and align word embeddings with our goal, we employ graph-based polynomial filters. Lastly, we implement a GNN-based semantic filter, which elevates contextual understanding and trims unnecessary edges, culminating in the formation of the definitive KG. Empirical findings and case studies demonstrate the universal effectiveness of our model, capable of autonomously constructing semantically enriched KGs from any text."}, "https://arxiv.org/abs/2406.03587": {"title": "Subsuming Complex Networks by Node Walks", "link": "https://arxiv.org/abs/2406.03587", "description": "arXiv:2406.03587v1 Announce Type: new \nAbstract: The concept of node walk in graphs and complex networks has been addressed, consisting of one or more nodes that move into adjacent nodes, henceforth incorporating the respective connections. This type of dynamics is then applied to subsume complex networks. Three types of networks (Erd\\'os- R\\'eny, Barab\\'asi-Albert, as well as a geometric model) are considered, while three node walks heuristics (uniformly random, largest degree, and smallest degree) are taken into account. Several interesting results are obtained and described, including the identification that the subsuming dynamics depend strongly on both the specific topology of the networks as well as the criteria controlling the node walks. The use of node walks as a model for studying the relationship between network topology and dynamics is motivated by this result. In addition, relatively high correlations between the initial node degree and the accumulated strength of the walking node were observed for some combinations of network types and dynamic rules, allowing some of the properties of the subsumption to be roughly predicted from the initial topology around the waking node which has been found, however, not to be enough for full determination of the subsumption dynamics. Another interesting result regards the quite distinct signatures (along the iterations) of walking node strengths obtained for the several considered combinations of network type and subsumption rules."}, "https://arxiv.org/abs/2406.03763": {"title": "The impact of nodes of information dissemination on epidemic spreading in dynamic multiplex networks", "link": "https://arxiv.org/abs/2406.03763", "description": "arXiv:2406.03763v1 Announce Type: new \nAbstract: Epidemic spreading processes on dynamic multiplex networks provide a more accurate description of natural spreading processes than those on single layered networks. To describe the influence of different individuals in the awareness layer on epidemic spreading, we propose a two-layer network-based epidemic spreading model, including some individuals who neglect the epidemic, and we explore how individuals with different properties in the awareness layer will affect the spread of epidemics. The two-layer network model is divided into an information transmission layer and a disease spreading layer. Each node in the layer represents an individual with different connections in different layers. Individuals with awareness will be infected with a lower probability compared to unaware individuals, which corresponds to the various epidemic prevention measures in real life. We adopt the micro-Markov chain approach to analytically derive the threshold for the proposed epidemic model, which demonstrates that the awareness layer affects the threshold of disease spreading. We then explore how individuals with different properties would affect the disease spreading process through extensive Monte Carlo numerical simulations. We find that individuals with high centrality in the awareness layer would significantly inhibit the transmission of infectious diseases. Additionally, we propose conjectures and explanations for the approximately linear effect of individuals with low centrality in the awareness layer on the number of infected individuals."}, "https://arxiv.org/abs/2406.03796": {"title": "Beyond a binary theorizing of prosociality", "link": "https://arxiv.org/abs/2406.03796", "description": "arXiv:2406.03796v1 Announce Type: new \nAbstract: A stylized experiment, the public goods game, has taught us the peculiar reproducible fact that humans tend to contribute more to shared resources than expected from economically rational assumptions. There have been two competing explanations for this phenomenon: either contributing to the public good is an innate human trait (the prosocial preference hypothesis) or a transitory effect while learning the game (the confused learner hypothesis). We use large-scale experimental data from a novel experimental design to distinguish between these two hypotheses. By monitoring the effects of zealots (persistently cooperating bots) and varying the participants' awareness of them, we find a considerably more complex scenario than previously reported. People indeed have a prosocial bias, but not to the degree that they always forego taking action to increase their profit. While our findings end the simplistic theorizing of prosociality in the public goods game, an observed positive, cooperative response to zealots has actionable policy implications."}, "https://arxiv.org/abs/2406.03852": {"title": "Why the Metric Backbone Preserves Community Structure", "link": "https://arxiv.org/abs/2406.03852", "description": "arXiv:2406.03852v1 Announce Type: new \nAbstract: The metric backbone of a weighted graph is the union of all-pairs shortest paths. It is obtained by removing all edges $(u,v)$ that are not the shortest path between $u$ and $v$. In networks with well-separated communities, the metric backbone tends to preserve many inter-community edges, because these edges serve as bridges connecting two communities, but tends to delete many intra-community edges because the communities are dense. This suggests that the metric backbone would dilute or destroy the community structure of the network. However, this is not borne out by prior empirical work, which instead showed that the metric backbone of real networks preserves the community structure of the original network well. In this work, we analyze the metric backbone of a broad class of weighted random graphs with communities, and we formally prove the robustness of the community structure with respect to the deletion of all the edges that are not in the metric backbone. An empirical comparison of several graph sparsification techniques confirms our theoretical finding and shows that the metric backbone is an efficient sparsifier in the presence of communities."}, "https://arxiv.org/abs/2406.03921": {"title": "Knowledge Transfer, Knowledge Gaps, and Knowledge Silos in Citation Networks", "link": "https://arxiv.org/abs/2406.03921", "description": "arXiv:2406.03921v1 Announce Type: new \nAbstract: The advancement of science relies on the exchange of ideas across disciplines and the integration of diverse knowledge domains. However, tracking knowledge flows and interdisciplinary integration in rapidly evolving, multidisciplinary fields remains a significant challenge. This work introduces a novel network analysis framework to study the dynamics of knowledge transfer directly from citation data. By applying dynamic community detection to cumulative, time-evolving citation networks, we can identify research areas as groups of papers sharing knowledge sources and outputs. Our analysis characterises the life-cycles and knowledge transfer patterns of these dynamic communities over time. We demonstrate our approach through a case study of eXplainable Artificial Intelligence (XAI) research, an emerging interdisciplinary field at the intersection of machine learning, statistics, and psychology. Key findings include: (i) knowledge transfer between these important foundational topics and the contemporary topics in XAI research is limited, and the extent of knowledge transfer varies across different contemporary research topics; (ii) certain application domains exist as isolated \"knowledge silos\"; (iii) significant \"knowledge gaps\" are identified between related XAI research areas, suggesting opportunities for cross-pollination and improved knowledge integration. By mapping interdisciplinary integration and bridging knowledge gaps, this work can inform strategies to synthesise ideas from disparate sources and drive innovation. More broadly, our proposed framework enables new insights into the evolution of knowledge ecosystems directly from citation data, with applications spanning literature review, research planning, and science policy."}, "https://arxiv.org/abs/2406.04005": {"title": "The Failed Migration of Academic Twitter", "link": "https://arxiv.org/abs/2406.04005", "description": "arXiv:2406.04005v1 Announce Type: new \nAbstract: Following change in Twitter's ownership and subsequent changes to content moderation policies, many in academia looked to move their discourse elsewhere and migration to Mastodon was pursued by some. Our study looks at the dynamics of this migration. Utilizing publicly available user account data, we track the posting activity of academics on Mastodon over a one year period. Our analyses reveal significant challenges sustaining user engagement on Mastodon due to its decentralized structure as well as competition from other platforms such as Bluesky and Threads. The movement lost momentum after an initial surge of enthusiasm as most users did not maintain their activity levels, and those who did faced lower levels of engagement compared to Twitter. Our findings highlight the challenges involved in transitioning professional communities to decentralized platforms, emphasizing the need for focusing on migrating social connections for long-term user engagement."}, "https://arxiv.org/abs/2406.04039": {"title": "Shaping History: Advanced Machine Learning Techniques for the Analysis and Dating of Cuneiform Tablets over Three Millennia", "link": "https://arxiv.org/abs/2406.04039", "description": "arXiv:2406.04039v1 Announce Type: cross \nAbstract: Cuneiform tablets, emerging in ancient Mesopotamia around the late fourth millennium BCE, represent one of humanity's earliest writing systems. Characterized by wedge-shaped marks on clay tablets, these artifacts provided insight into Mesopotamian civilization across various domains. Traditionally, the analysis and dating of these tablets rely on subjective assessment of shape and writing style, leading to uncertainties in pinpointing their exact temporal origins. Recent advances in digitization have revolutionized the study of cuneiform by enhancing accessibility and analytical capabilities. Our research uniquely focuses on the silhouette of tablets as significant indicators of their historical periods, diverging from most studies that concentrate on textual content. Utilizing an unprecedented dataset of over 94,000 images from the Cuneiform Digital Library Initiative collection, we apply deep learning methods to classify cuneiform tablets, covering over 3,000 years of history. By leveraging statistical, computational techniques, and generative modeling through Variational Auto-Encoders (VAEs), we achieve substantial advancements in the automatic classification of these ancient documents, focusing on the tablets' silhouettes as key predictors. Our classification approach begins with a Decision Tree using height-to-width ratios and culminates with a ResNet50 model, achieving a 61% macro F1-score for tablet silhouettes. Moreover, we introduce novel VAE-powered tools to enhance explainability and enable researchers to explore changes in tablet shapes across different eras and genres. This research contributes to document analysis and diplomatics by demonstrating the value of large-scale data analysis combined with statistical methods. These insights offer valuable tools for historians and epigraphists, enriching our understanding of cuneiform tablets and the cultures that produced them."}, "https://arxiv.org/abs/2406.04299": {"title": "NoisyGL: A Comprehensive Benchmark for Graph Neural Networks under Label Noise", "link": "https://arxiv.org/abs/2406.04299", "description": "arXiv:2406.04299v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) exhibit strong potential in node classification task through a message-passing mechanism. However, their performance often hinges on high-quality node labels, which are challenging to obtain in real-world scenarios due to unreliable sources or adversarial attacks. Consequently, label noise is common in real-world graph data, negatively impacting GNNs by propagating incorrect information during training. To address this issue, the study of Graph Neural Networks under Label Noise (GLN) has recently gained traction. However, due to variations in dataset selection, data splitting, and preprocessing techniques, the community currently lacks a comprehensive benchmark, which impedes deeper understanding and further development of GLN. To fill this gap, we introduce NoisyGL in this paper, the first comprehensive benchmark for graph neural networks under label noise. NoisyGL enables fair comparisons and detailed analyses of GLN methods on noisy labeled graph data across various datasets, with unified experimental settings and interface. Our benchmark has uncovered several important insights that were missed in previous research, and we believe these findings will be highly beneficial for future studies. We hope our open-source benchmark library will foster further advancements in this field. The code of the benchmark can be found in https://github.com/eaglelab-zju/NoisyGL."}, "https://arxiv.org/abs/2207.12264": {"title": "Dynamics and triggers of misinformation on vaccines", "link": "https://arxiv.org/abs/2207.12264", "description": "arXiv:2207.12264v3 Announce Type: replace \nAbstract: The Covid-19 pandemic has sparked renewed attention on the prevalence of misinformation online, whether intentional or not, underscoring the potential risks posed to individuals' quality of life associated with the dissemination of misconceptions and enduring myths on health-related subjects. In this study, we analyze 6 years (2016-2021) of Italian vaccine debate across diverse social media platforms (Facebook, Instagram, Twitter, YouTube), encompassing all major news sources - both questionable and reliable. We first use the symbolic transfer entropy analysis of news production time-series to dynamically determine which category of sources, questionable or reliable, causally drives the agenda on vaccines. Then, leveraging deep learning models capable to accurately classify vaccine-related content based on the conveyed stance and discussed topic, respectively, we evaluate the focus on various topics by news sources promoting opposing views and compare the resulting user engagement. Aside from providing valuable resources for further investigation of vaccine-related misinformation, particularly in a language (Italian) that receives less attention in scientific research compared to languages like English, our study uncovers misinformation not as a parasite of the news ecosystem that merely opposes the perspectives offered by mainstream media, but as an autonomous force capable of even overwhelming the production of vaccine-related content from the latter. While the pervasiveness of misinformation is evident in the significantly higher engagement of questionable sources compared to reliable ones, our findings underscore the importance of consistent and thorough pro-vax coverage. This is especially crucial in addressing the most sensitive topics where the risk of misinformation spreading and potentially exacerbating negative attitudes toward vaccines among the users involved is higher."}, "https://arxiv.org/abs/2307.02818": {"title": "Degree Heterogeneity in Higher-Order Networks: Inference in the Hypergraph $\\boldsymbol{\\beta}$-Model", "link": "https://arxiv.org/abs/2307.02818", "description": "arXiv:2307.02818v4 Announce Type: replace-cross \nAbstract: The $\\boldsymbol{\\beta}$-model for random graphs is commonly used for representing pairwise interactions in a network with degree heterogeneity. Going beyond pairwise interactions, Stasi et al. (2014) introduced the hypergraph $\\boldsymbol{\\beta}$-model for capturing degree heterogeneity in networks with higher-order (multi-way) interactions. In this paper we initiate the rigorous study of the hypergraph $\\boldsymbol{\\beta}$-model with multiple layers, which allows for hyperedges of different sizes across the layers. To begin with, we derive the rates of convergence of the maximum likelihood (ML) estimate and establish their minimax rate optimality. We also derive the limiting distribution of the ML estimate and construct asymptotically valid confidence intervals for the model parameters. Next, we consider the goodness-of-fit problem in the hypergraph $\\boldsymbol{\\beta}$-model. Specifically, we establish the asymptotic normality of the likelihood ratio (LR) test under the null hypothesis, derive its detection threshold, and also its limiting power at the threshold. Interestingly, the detection threshold of the LR test turns out to be minimax optimal, that is, all tests are asymptotically powerless below this threshold. The theoretical results are further validated in numerical experiments. In addition to developing the theoretical framework for estimation and inference for hypergraph $\\boldsymbol{\\beta}$-models, the above results fill a number of gaps in the graph $\\boldsymbol{\\beta}$-model literature, such as the minimax optimality of the ML estimates and the non-null properties of the LR test, which, to the best of our knowledge, have not been studied before."}, "https://arxiv.org/abs/2403.13872": {"title": "Spatial-Temporal Graph Representation Learning for Tactical Networks Future State Prediction", "link": "https://arxiv.org/abs/2403.13872", "description": "arXiv:2403.13872v2 Announce Type: replace-cross \nAbstract: Resource allocation in tactical ad-hoc networks presents unique challenges due to their dynamic and multi-hop nature. Accurate prediction of future network connectivity is essential for effective resource allocation in such environments. In this paper, we introduce the Spatial-Temporal Graph Encoder-Decoder (STGED) framework for Tactical Communication Networks that leverages both spatial and temporal features of network states to learn latent tactical behaviors effectively. STGED hierarchically utilizes graph-based attention mechanism to spatially encode a series of communication network states, leverages a recurrent neural network to temporally encode the evolution of states, and a fully-connected feed-forward network to decode the connectivity in the future state. Through extensive experiments, we demonstrate that STGED consistently outperforms baseline models by large margins across different time-steps input, achieving an accuracy of up to 99.2\\% for the future state prediction task of tactical communication networks."}, "https://arxiv.org/abs/2406.04462": {"title": "Adaptive Algorithmic Interventions for Escaping Pessimism Traps in Dynamic Sequential Decisions", "link": "https://arxiv.org/abs/2406.04462", "description": "arXiv:2406.04462v1 Announce Type: new \nAbstract: In this paper, we relate the philosophical literature on pessimism traps to information cascades, a formal model derived from the economics and mathematics literature. A pessimism trap is a social pattern in which individuals in a community, in situations of uncertainty, begin to copy the sub-optimal actions of others, despite their individual beliefs. This maps nicely onto the concept of an information cascade, which involves a sequence of agents making a decision between two alternatives, with a private signal of the superior alternative and a public history of others' actions. Key results from the economics literature show that information cascades occur with probability one in many contexts, and depending on the strength of the signal, populations can fall into the incorrect cascade very easily and quickly. Once formed, in the absence of external perturbation, a cascade cannot be broken -- therefore, we derive an intervention that can be used to nudge a population from an incorrect to a correct cascade and, importantly, maintain the cascade once the subsidy is discontinued. We study this both theoretically and empirically."}, "https://arxiv.org/abs/2406.04543": {"title": "Function and form of U", "link": "https://arxiv.org/abs/2406.04543", "description": "arXiv:2406.04543v1 Announce Type: new \nAbstract: The relationship between urban form and function is a complex challenge that can be examined from multiple perspectives. In this study, we propose a method to characterize the urban function of U.S. metropolitan areas by analyzing trip patterns extracted from the 2017 National Household Travel Survey (NHTS). To characterize urban form, we employ measures that capture road network topology. We cluster cities based on both form and function and subsequently compare these clusters. Our analysis of 52 U.S. metropolitan areas identifies 7 distinct clusters of cities that exhibit similar travel behavior, suggesting that diverse mobility patterns can be effectively grouped into a few universal classes. The observed disparity between the urban-function clustering and the urban-form clustering suggests that travel behavior in the U.S. is not strongly influenced by the physical infrastructure of the city."}, "https://arxiv.org/abs/2406.04962": {"title": "Mapping the Global Election Landscape on Social Media in 2024", "link": "https://arxiv.org/abs/2406.04962", "description": "arXiv:2406.04962v1 Announce Type: new \nAbstract: In 2024, half of the global population is expected to participate in elections, offering researchers a unique opportunity to study online information diffusion and user behavior. This study investigates the media landscape on social media by analyzing Facebook posts from national political parties and major news agencies across Europe, Mexico, and India. Our methodology identifies key topics and evaluates public interaction, reflecting broader trends in political engagement. Using Principal Component Analysis, we distil these topics to uncover patterns of correlation and differentiation. This approach reveals dominant themes that engage global audiences, providing critical insights into the interplay between public opinion and digital narratives during a major electoral cycle. Our findings highlight how different topics resonate across political spectrums, shaping political debate and offering a comprehensive view of the interaction between media content, political ideology, and audience engagement."}, "https://arxiv.org/abs/2406.05021": {"title": "From cryptomarkets to the surface web: Scouting eBay for counterfeits", "link": "https://arxiv.org/abs/2406.05021", "description": "arXiv:2406.05021v1 Announce Type: new \nAbstract: Detecting counterfeits on online marketplaces is challenging, and current methods struggle with the volume of sales on platforms like eBay, while cryptomarkets openly sell counterfeits. Leveraging information from 453 cryptomarket counterfeits, we automated a search for corresponding products on eBay, utilizing image and text similarity metrics. We collected data twice over 4-months to analyze changes with an average of 159 eBay products per cryptomarket item, totaling 134k products. We found identical products, which would warrant further investigation as to whether they are counterfeits. Results indicate increasing difficulty finding similar products over time, moderated by product type and origin. Future improved versions of the current system could be used to examine possible connections between cryptomarket and surface web listings more closely and could hold practical value in supporting the detection of counterfeits on the surface web."}, "https://arxiv.org/abs/2406.05026": {"title": "Higher-order modeling of face-to-face interactions", "link": "https://arxiv.org/abs/2406.05026", "description": "arXiv:2406.05026v1 Announce Type: new \nAbstract: The most fundamental social interactions among humans occur face to face. Their features have been extensively studied in recent years, owing to the availability of high-resolution data on individuals' proximity. Mathematical models based on mobile agents have been crucial to understand the spatio-temporal organization of face-to-face interactions. However, these models focus on dyadic relationships only, failing to characterize interactions in larger groups of individuals. Here, we propose a model in which agents interact with each other by forming groups of different sizes. Each group has a degree of social attractiveness, based on which neighboring agents decide whether to join. Our framework reproduces different properties of groups in face-to-face interactions, including their distribution, the correlation in their number, and their persistence in time, which cannot be replicated by dyadic models. Furthermore, it captures homophilic patterns at the level of higher-order interactions, going beyond standard pairwise approaches. Our work sheds light on the higher-order mechanisms at the heart of human face-to-face interactions, paving the way for further investigation of how group dynamics at a microscopic scale affects social phenomena at a macroscopic scale."}, "https://arxiv.org/abs/2406.04423": {"title": "Determining the Number of Communities in Sparse and Imbalanced Settings", "link": "https://arxiv.org/abs/2406.04423", "description": "arXiv:2406.04423v1 Announce Type: cross \nAbstract: Community structures represent a crucial aspect of network analysis, and various methods have been developed to identify these communities. However, a common hurdle lies in determining the number of communities K, a parameter that often requires estimation in practice. Existing approaches for estimating K face two notable challenges: the weak community signal present in sparse networks and the imbalance in community sizes or edge densities that result in unequal per-community expected degree. We propose a spectral method based on a novel network operator whose spectral properties effectively overcome both challenges. This operator is a refined version of the non-backtracking operator, adapted from a \"centered\" adjacency matrix. Its leading eigenvalues are more concentrated than those of the adjacency matrix for sparse networks, while they also demonstrate enhanced signal under imbalance scenarios, a benefit attributed to the centering step. This is justified, either theoretically or numerically, under the null model K = 1, in both dense and ultra-sparse settings. A goodness-of-fit test based on the leading eigenvalue can be applied to determine the number of communities K."}, "https://arxiv.org/abs/2406.04548": {"title": "GNNAnatomy: Systematic Generation and Evaluation of Multi-Level Explanations for Graph Neural Networks", "link": "https://arxiv.org/abs/2406.04548", "description": "arXiv:2406.04548v1 Announce Type: cross \nAbstract: Graph Neural Networks (GNNs) have proven highly effective in various machine learning (ML) tasks involving graphs, such as node/graph classification and link prediction. However, explaining the decisions made by GNNs poses challenges because of the aggregated relational information based on graph structure, leading to complex data transformations. Existing methods for explaining GNNs often face limitations in systematically exploring diverse substructures and evaluating results in the absence of ground truths. To address this gap, we introduce GNNAnatomy, a model- and dataset-agnostic visual analytics system designed to facilitate the generation and evaluation of multi-level explanations for GNNs. In GNNAnatomy, we employ graphlets to elucidate GNN behavior in graph-level classification tasks. By analyzing the associations between GNN classifications and graphlet frequencies, we formulate hypothesized factual and counterfactual explanations. To validate a hypothesized graphlet explanation, we introduce two metrics: (1) the correlation between its frequency and the classification confidence, and (2) the change in classification confidence after removing this substructure from the original graph. To demonstrate the effectiveness of GNNAnatomy, we conduct case studies on both real-world and synthetic graph datasets from various domains. Additionally, we qualitatively compare GNNAnatomy with a state-of-the-art GNN explainer, demonstrating the utility and versatility of our design."}, "https://arxiv.org/abs/2406.04612": {"title": "Revisiting Attention Weights as Interpretations of Message-Passing Neural Networks", "link": "https://arxiv.org/abs/2406.04612", "description": "arXiv:2406.04612v1 Announce Type: cross \nAbstract: The self-attention mechanism has been adopted in several widely-used message-passing neural networks (MPNNs) (e.g., GATs), which adaptively controls the amount of information that flows along the edges of the underlying graph. This usage of attention has made such models a baseline for studies on explainable AI (XAI) since interpretations via attention have been popularized in various domains (e.g., natural language processing and computer vision). However, existing studies often use naive calculations to derive attribution scores from attention, and do not take the precise and careful calculation of edge attribution into consideration. In our study, we aim to fill the gap between the widespread usage of attention-enabled MPNNs and their potential in largely under-explored explainability, a topic that has been actively investigated in other areas. To this end, as the first attempt, we formalize the problem of edge attribution from attention weights in GNNs. Then, we propose GATT, an edge attribution calculation method built upon the computation tree. Through comprehensive experiments, we demonstrate the effectiveness of our proposed method when evaluating attributions from GATs. Conversely, we empirically validate that simply averaging attention weights over graph attention layers is insufficient to interpret the GAT model's behavior. Code is publicly available at https://github.com/jordan7186/GAtt/tree/main."}, "https://arxiv.org/abs/2406.04701": {"title": "Transition to synchronization in adaptive Sakaguchi-Kuramoto model with higher-order interactions", "link": "https://arxiv.org/abs/2406.04701", "description": "arXiv:2406.04701v1 Announce Type: cross \nAbstract: We investigate the phenomenon of transition to synchronization in Sakaguchi-Kuramoto model in the presence of higher-order interactions and global order parameter adaptation. The investigation is done by performing extensive numerical simulations and low dimensional modeling of the system. Numerical simulations of the full system show both continuous (second order) as well as discontinuous transitions. The discontinuous transitions can either be associated with explosive (first order) or with tiered synchronization states depending on the choice of parameters. To develop an in depth understanding of the transition scenario in the parameter space we derive a reduced order model (ROM) using the Ott-Antonsen ansatz, the results of which closely matches with that of the numerical simulations of the full system. The simplicity and analytical accessibility of the ROM helps to conveniently unfold the transition scenario in the system having complex dependence on the parameters. Simultaneous analysis of the full system and the ROM clearly identifies the regions of the parameter space exhibiting different types of transitions. It is observed that the second order continuous transition is connected with a supercritical pitchfork bifurcation (PB) of the ROM. On the other hand, the discontinuous teired transition is associated with multiple saddle-node (SN) bifurcations along with a supercritical PB and the first order explosive transition involves a subcritical PB alongside a SN bifurcation."}, "https://arxiv.org/abs/2406.04916": {"title": "Combinatorial Complex Score-based Diffusion Modelling through Stochastic Differential Equations", "link": "https://arxiv.org/abs/2406.04916", "description": "arXiv:2406.04916v1 Announce Type: cross \nAbstract: Graph structures offer a versatile framework for representing diverse patterns in nature and complex systems, applicable across domains like molecular chemistry, social networks, and transportation systems. While diffusion models have excelled in generating various objects, generating graphs remains challenging. This thesis explores the potential of score-based generative models in generating such objects through a modelization as combinatorial complexes, which are powerful topological structures that encompass higher-order relationships.\n  In this thesis, we propose a unified framework by employing stochastic differential equations. We not only generalize the generation of complex objects such as graphs and hypergraphs, but we also unify existing generative modelling approaches such as Score Matching with Langevin dynamics and Denoising Diffusion Probabilistic Models. This innovation overcomes limitations in existing frameworks that focus solely on graph generation, opening up new possibilities in generative AI.\n  The experiment results showed that our framework could generate these complex objects, and could also compete against state-of-the-art approaches for mere graph and molecule generation tasks."}, "https://arxiv.org/abs/2305.16488": {"title": "Assessing inequities in electrification via heat pumps across the U", "link": "https://arxiv.org/abs/2305.16488", "description": "arXiv:2305.16488v3 Announce Type: replace \nAbstract: Heat pumps are an energy-efficient and increasingly cost-effective solution for reducing greenhouse gas emissions in the building sector. However, other clean energy technologies such as rooftop solar are less likely to be adopted in underserved communities, and thus policies incentivizing their adoption may funnel tax dollars to well-resourced communities. Unlike previously-studied technologies, the effects of heat pumps on household energy bills may be positive or negative depending on local climate, fuel availability and costs, and other factors. Here we propose a framework for assessing heat pump inequities across the U.S. We find that households in communities of color and with higher percentages of renters are less likely to use heat pumps across the board. Moreover, communities of color are least likely to use heat pumps in regions where they are most likely to reduce energy bills. Public policies must address these inequities to advance beneficial electrification and energy justice."}, "https://arxiv.org/abs/2404.17082": {"title": "Evolutionary game dynamics with environmental feedback in a network with two communities", "link": "https://arxiv.org/abs/2404.17082", "description": "arXiv:2404.17082v2 Announce Type: replace \nAbstract: Recent developments of eco-evolutionary models have shown that evolving feedbacks between behavioral strategies and the environment of game interactions, leading to changes in the underlying payoff matrix, can impact the underlying population dynamics in various manners. We propose and analyze an eco-evolutionary game dynamics model on a network with two communities such that players interact with other players in the same community and those in the opposite community at different rates. In our model, we consider two-person matrix games with pairwise interactions occurring on individual edges and assume that the environmental state depends on edges rather than on nodes or being globally shared in the population. We analytically determine the equilibria and their stability under a symmetric population structure assumption, and we also numerically study the replicator dynamics of the general model. The model shows rich dynamical behavior, such as multiple transcritical bifurcations, multistability, and anti-synchronous oscillations. Our work offers insights into understanding how the presence of community structure impacts the eco-evolutionary dynamics within and between niches."}, "https://arxiv.org/abs/2403.07294": {"title": "Graph Data Condensation via Self-expressive Graph Structure Reconstruction", "link": "https://arxiv.org/abs/2403.07294", "description": "arXiv:2403.07294v2 Announce Type: replace-cross \nAbstract: With the increasing demands of training graph neural networks (GNNs) on large-scale graphs, graph data condensation has emerged as a critical technique to relieve the storage and time costs during the training phase. It aims to condense the original large-scale graph to a much smaller synthetic graph while preserving the essential information necessary for efficiently training a downstream GNN. However, existing methods concentrate either on optimizing node features exclusively or endeavor to independently learn node features and the graph structure generator. They could not explicitly leverage the information of the original graph structure and failed to construct an interpretable graph structure for the synthetic dataset. To address these issues, we introduce a novel framework named \\textbf{G}raph Data \\textbf{C}ondensation via \\textbf{S}elf-expressive Graph Structure \\textbf{R}econstruction (\\textbf{GCSR}). Our method stands out by (1) explicitly incorporating the original graph structure into the condensing process and (2) capturing the nuanced interdependencies between the condensed nodes by reconstructing an interpretable self-expressive graph structure. Extensive experiments and comprehensive analysis validate the efficacy of the proposed method across diverse GNN models and datasets. Our code is available at \\url{https://github.com/zclzcl0223/GCSR}."}, "https://arxiv.org/abs/2404.13468": {"title": "A Grassroots Architecture to Supplant Global Digital Platforms by a Global Digital Democracy", "link": "https://arxiv.org/abs/2404.13468", "description": "arXiv:2404.13468v4 Announce Type: replace-cross \nAbstract: We present an architectural alternative to global digital platforms termed grassroots, designed to serve the social, economic, civic, and political needs of local digital communities, as well as their federation. Grassroots platforms may offer local communities an alternative to global digital platforms while operating solely on the smartphones of their members, forsaking any global resources other than the network itself. Such communities may form digital economies without initial capital or external credit, exercise sovereign democratic governance, and federate, ultimately resulting in the grassroots formation of a global digital democracy."}}